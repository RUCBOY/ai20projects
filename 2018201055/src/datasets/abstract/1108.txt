Characterizing urban hydrographs during rain storms, hurricanes, and river floods is important to decrease loss of lives and assist emergency responders with mapping disruptions to operation of major cities. High water marks, stream gages, and rapidly deployed instrumentation are the current state-of-practice for hydrological data during a flood event. The objective of this study was to develop technology that can provide accurate and timely flood hydrographs while harnessing the Big Data generated from videos and images. In particular, levels are predicted from images by using reference objects as a scale. The novelty of this work involved leveraging object-based image analysis (OBIA), which used image segmentation training algorithms to differentiate areas of images or videos. In particular, the deep learning-based semantic segmentation technique was trained using images from an MIT database along with images compiled from traffic cameras and the experiments and a case study. The fully convolutional network was used for image segmentation and subsequent object labeling. This algorithm was applied to a laboratory and two field experiments before demonstration at Buffalo Bayou in Houston, TX during Hurricane Harvey. The laboratory and field experiments indicated that the image segmentation technique was reproducible and accurate from a controlled environment to rain storms and localized flooding in small streams on the LSU campus. Moreover, the segmentation algorithm successfully estimated flood levels in Buffalo Bayou in downtown Houston, Texas during Hurricane Harvey. This signifies that if time-lapse imagery is available, this algorithm- and program-estimated water elevations can provide insight to the hydrograph and spatial inundation during flooding from rainstorms or hurricanes.
