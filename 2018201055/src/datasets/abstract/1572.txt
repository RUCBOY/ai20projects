Differential privacy is commonly used in the computer science literature as a mathematical definition of privacy for the purpose of quantifying and bounding privacy loss. It induces a preference order over the set of privacy-jeopardizing mechanisms which, in turn, adhere to some properties of this order. We show that a set of five such properties uniquely captures the ordinal implications of prioritizing the alternatives in agreement with differential privacy. The model can also be applied to evaluate the appropriateness of differential privacy in different settings.
