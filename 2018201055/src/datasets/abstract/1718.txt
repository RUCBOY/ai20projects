Crowd counting is a fundamental computer vision task that draws increasing attention in recent years, due to its wide applications in commercial activities and public securities. Despite much process has been achieved by applying the resurgent neural networks in this task, critical challenges still lie in tremendous variation of crowd scales, together with other issues like background clutters and occlusions, making the crowd appearances hard to model. To address these challenges, we propose a scale-communicative aggregation network (SCANet) for crowd counting. Our model is characterized by three aspects: (i) It contains different streams of convolutional neural networks (CNNs), where each stream consumes an individual scaled version of the input image and communicates complementarily to produce a high-resolution density map. (ii) Each CNN stream obtains robust feature presentation via our proposed multi-scale feature encoders (MSFEs) with dilated convolutional layers, and skip connections are adopted to exploit multi-stage feature aggregation. (iii) A multi-scale structural similarity metric along with Euclidean distance is introduced for optimizing the quality of generated density maps. Extensive experiments and comparisons on several crowd counting benchmarks demonstrate the effectiveness of our proposed method.
