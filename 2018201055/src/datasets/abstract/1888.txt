Early diagnosis of breast cancer, when it is small and has not spread, can make the disease easier to treat which increases the patient's chances of survival. The recent proposed methods for the early diagnosis of breast cancer, and while showing great success in achieving this goal, rely on one of the indicators in the mammogram to diagnose the patient's condition. Whether it is identifying differences in shapes and patterns of the findings (i.e. masses, calcifications,â€¦etc.) or assessing the breast density as a risk indicator, these Computer-aided Diagnosis (CAD) systems by using single-label classification, fail to exploit the intrinsic useful correlation information among data from correlated domains.
Rather than learning to identify the disease based on one of the indicators, we propose the joint learning of the tasks using multi-label image classification. Furthermore, we introduce a new fine-tuning strategy for using transfer learning, that takes advantage of the end-to-end image representation learning when adapting the pre-trained Convolutional Neural Network (CNN) to the new task. We also propose a customized label decision scheme, adapted to this problem, which estimates the optimal confidence for each visual concept. We demonstrate the effectiveness of our approach on four benchmark datasets, CBIS-DDSM, BCDR, INBreast and MIAS, obtaining better results compared to other commonly used baselines.
