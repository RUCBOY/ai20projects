Feature analysis plays a crucial role in various applications in both computer vision and computer graphics. The semantic gap between 2D images and 3D graphical models is the major obstacle to improve the universality of existing valuable technologies. To bridge the gap, we propose an effective and robust representation of 3D models, named multi-scale Graphical Image (GI), which is constructed by introducing the statistics mapping from 3D models to 2D images with both local and global information. Therefore, the excellent innovations and techniques in 2D visual retrieval can be adapted to 3D geometric retrieval. In the multi-scale GI space, the joint Bayesian formulation is exploited to analyze the structure of the space and learn a new metric. It benefits several attractive properties, including high discriminative, isometric invariant and robust to noise and topological changes, etc. In order to prove the validity, we apply the proposed method to 3D shape retrieval, and test our method on two well-known benchmark datasets. The results show that our method substantially outperforms the state-of-the-art non-rigid 3D shape retrieval methods.
