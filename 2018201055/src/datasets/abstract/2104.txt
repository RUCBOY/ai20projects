The paper aims to control an electric wheel chair with a Brain-Computer Interface (BCI) headset. This wheel chair would be helpful for disabled people who cannot move their hands and legs or basically suffering from cerebromedullospinal disconnection. The main objective is to map different facial expression to the movement of the wheelchair.
The headset used for this purpose comprises of an EEG cap which has a total of 16 electrodes connected out of which 14 electrodes are used for acquiring data and the rest 2 are used as ground and reference. To operate the wheelchair the subject has to place the cap on his/her head and different facial expressions (clench, smile, blink, etc.) are performed. The movement of muscles around the face due to facial expressions can be observed from the EEG signals being recorded. Each expression is linked to movement of the wheelchair. Signal is preprocessed to remove the artifacts and then features are extracted using Fast Fourier Transform. In this paper, for classification we have used state-of-the-art machine learning technique which is a slight variation of Extreme Learning Machine called as Online Sequential Extreme Learning Machine abbreviated as OS-ELM.
An overall accuracy of 97.62% was obtained using 10-fold cross validation.
The proposed framework attains better classification accuracy compared to various other classifiers.
