Emotion plays a vital role in human daily life, and EEG signals are widely used in emotion recognition. Due to individual variability, training a generic emotion recognition model across different subjects is difficult. The conventional method involves the collection of a large amount of calibration data to build subject-specific models. Recently, developing an effective brain-computer interface with a short calibration time has become a challenge. To solve this problem, we propose a domain adaptation SPD matrix network (daSPDnet) that can successfully capture an intrinsic emotional representation shared between different subjects. Our method jointly exploits feature adaptation with distribution confusion and sample adaptation with centroid alignment. We compute the SPD matrix based on the covariance as a feature and make a novel attempt to combine prototype learning with the Riemannian metric. Extensive experiments are conducted on the DREAMER and DEAP datasets, and the results show the superiority of our proposed method.
