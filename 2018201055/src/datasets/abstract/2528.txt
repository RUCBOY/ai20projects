Commercially available artificial intelligence (AI) algorithms outside of health care have been shown to be susceptible to ethnic, gender, and social bias, which has important implications in the development of AI algorithms in health care and the radiologic sciences. To prevent the introduction bias in health care AI, the physician community should work with developers and regulators to develop pathways to ensure that algorithms marketed for widespread clinical practice are safe, effective, and free of unintended bias. The ACR Data Science Institute has developed structured AI use cases with data elements that allow the development of standardized data sets for AI testing and training across multiple institutions to promote the availability of diverse data for algorithm development. Additionally, the ACR Data Science Institute validation and monitoring services, ACR Certify-AI and ACR Assess-AI, incorporate standards to mitigate algorithm bias and promote health equity. In addition to promoting diversity, the ACR should promote and advocate for payment models for AI that afford access to AI tools for all of our patients regardless of socioeconomic status or the inherent resources of their health systems.
