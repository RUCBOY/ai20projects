Recently, deep learning has been applied to many image restoration tasks. In this work, we focus on studying an efficient deep learning architecture to restore damaged character photographs (DCPs) which are spoiled by natural or human factors including creases, spots, cracks, light, etc. A large amount of work has focused on image restoration such as super-resolution, image inpainting, image deblurring, and image denoising. However, few studies focus on restoring DCPs based on deep learning since DCPs are varied and complex, along with the difficulty of getting paired training dataset. In this work, we propose a new generative adversarial network (GAN) architecture to restore DCPs. Specifically, a residual U-Net (ResU-Net) GAN (RUGAN) is firstly constructed to generate fake DCPs by employing real DCPs, clear character photographs (CCPs), and dirty masks. Then, a ResU-Net conditional GAN (RUCGAN) is built to restore DCPs by exploiting paired CCPs and fake DCPs. To further improve the quality of restored character photographs, a weighted multi-features loss function is adopted in RUCGAN. Finally, numerical results show that our approach can restore spots, creases, cracks, and other spoiled manners in DCPs.
