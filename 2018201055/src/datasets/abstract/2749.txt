Dynamic computer pipelines use feedback loops for iterative computation, due to which, data items, while traversing them often collide with one another. These pipelines, therefore, employ specialized mechanisms to detect and avoid such collisions in real-time. Mostly, this is done by deciding when, and when not, to allow newer data items to enter the pipeline. We will show that such decisions may lead to different throughput, and guaranteeing optimal performance is an optimization problem. We begin by building a mathematical model of dynamic pipelines, and make use of genetic algorithm to yield near-optimal throughput. The proposed optimization technique accounts for the hardware overhead, incurred due to the extensions in the pipeline organization, as suggested by itself. Our confidence in the results stems from simulation of 10,000 dynamic pipeline organizations, and for verification of results, we present hardware implementation of one of those. The proposed framework will specifically be useful in embedded systems for digital signal processing applications.
