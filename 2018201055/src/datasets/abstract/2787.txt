This paper tackles the task of person search, which is a new challenging computer version task in real-world scenarios. The challenge of this task is mainly from: i) Due to viewpoints, occlusions, etc., the visual appearance of a particular person varies greatly, making re-identification difficult; ii) the bounding box where pedestrians are not available, the model needs to search for the person in the entire gallery image. The task of person search is consisted of pedestrian detection and person re-identification (re-id). Instead of completing the two tasks separately, we put the two pieces together to address these issues. We design a more suitable end-to-end framework for person search, which both improve re-id and detection at the same time. Through the change of the anchor with structural prior, the pedestrian detection can be refined faster and better. By introducing self-attention, the framework enhances the fusion of global information. An Online Instance Aggregation Matching (OIAM) loss function is proposed to train the network, and it effectively solves the problem of many categories but few samples of the same category. Extensive experiments are conducted on the PRW and CUHK-SYSU datasets, and our proposed method can outperform other person search methods in both mAP and top-1 evaluation protocols.
