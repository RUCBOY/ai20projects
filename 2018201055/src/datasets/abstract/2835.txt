Low-light is a challenging environment for image processing and computer vision tasks, either in contrast enhancement for better visibility and quality, or application oriented tasks such as detection. We found that the current trend of low-light enhancement research is heavily on quality improvement. In this work, we aim to shift the focus towards a more functional direction, that is enhancement that prioritizes feature retrieval. For this reason, we first propose to model low-light enhancement as a set of localized functions using Gaussian Process (GP) that is trained at runtime using data from a simple Convolutional Neural Network (CNN) to provide the necessary feature information as reference. The CNN is in turn trained using large amount of synthetic data, based upon the luminance distribution of real world low-light images to learn the relationship between features and pixels. Secondly, we also proposed two new evaluation metrics to better assess enhancement algorithms to support high level computer vision tasks, namely, local features matching and intensity histogram similarity. In our experiments, our proposed low-light enhancement framework outperforms the state-of-the-arts with significant improvement in Recall, F1, and F2-score of SIFT features matching, and achieve comparable results for l1-norm distance of histograms as well as the PSNR. Moreover, our analysis of the performance showed that the PSNR quality metric is not only unable to assess the practicality of the results, but also inappropriately gives high assessment to low visual quality images.
