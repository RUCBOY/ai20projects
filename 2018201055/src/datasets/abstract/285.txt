We propose a distributed and decentralized Generative Adversarial Networks (GANs) framework without the exchange of the training data. Each node contains local dataset, a discriminator and a generator, from which only the generator gradients are shared with other nodes. In this paper, we introduce a novel, distributed technique in which workers communicate directly with each other, having no central nodes. Our experimental results on the benchmark datasets demonstrate almost the same performance and accuracy compared with existing centralized GAN frameworks. The proposed framework addresses the lack of decentralized learning for GANs.
