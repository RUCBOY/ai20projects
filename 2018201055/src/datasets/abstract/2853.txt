In recent years, person re-identification is becoming an important technique, which can be applied in computer vision, pedestrian tracking and intelligent monitoring. Due to the large variations of visual appearance caused by view angle, pose changing, light changing, background clutter and occlusion, person re-identification is very challenging. In practice, there exist large differences among different types of features and among different cameras. To improve the favorable representation of different features, we propose a multi-view based coupled dictionary pair learning framework, which can learn dictionary pairs for multiple categories of features, e.g., the color features, texture features and hybrid features etc. Specifically, with the learned color feature dictionary pair, we can obtain the color feature representation coefficients of each person from different cameras. The texture feature dictionary pair seeks to learn the texture feature representation coefficients of each person from both cameras. The hybrid feature dictionary pair aims to learn the hybrid feature coefficients for each person. The learned coupled dictionary pairs can demonstrate the intrinsic relationship of different cameras and different types of features. When the resolution of image is too low, the texture information will be lost to some extent. There is few high-resolution person dataset so far, we contribute a newly collected dataset, named High-Resolution Pedestrian re-Identification Dataset (HRPID) on the campus of Wuhan University. The size of person images is normalized to 230 Ã— 560 pixels, which is bigger than existing person re-identification datasets. Experimental results on a new dataset and two public pedestrian datasets demonstrate that our proposed approach can perform better than the other competing methods.
