Salient Object Detection (SOD), which aims to find the most important region of interest and segment the relevant objects/items in that region, is an important yet challenging task in computer vision and image processing. This vision problem is inspired by the fact that human perceives the main scene elements with high priorities. Thus, accurate detection of salient objects in complex scenes is critical for human-computer interaction. In this paper, we present a novel reflective feature learning framework, which results in high detection accuracy while maintaining a compact model design. The proposed framework utilizes a hyper-densely reflective feature fusion network (named HyperFusion-Net) to automatically predict the most important area and segment the associated objects in an end-to-end manner. Specifically, inspired by the human perception system and image reflection separation, we first decompose the input images into reflective image pairs by content-preserving transforms. Then, the complementary information of reflective image pairs is jointly extracted by an Interweaved Convolutional Neural Network (ICNN) and hierarchically combined with a hyper-dense fusion mechanism. Based on the fused multi-scale features, our method finally achieves a promising way of predicting salient objects, in which we cast the SOD as a pixel-wise classification problem. Extensive experiments on seven public datasets demonstrate that the proposed method consistently outperforms other state-of-the-art methods with a large margin.
