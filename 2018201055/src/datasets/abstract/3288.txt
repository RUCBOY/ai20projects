In this paper, we pursue privacy analysis of nonlinear dynamical systems from two different aspects. As a quantitative criterion for privacy of “mechanisms” in the form of data-generating processes, the concept of differential privacy was proposed in computer science and has been applied to linear dynamical systems. In this paper, we further extend this concept to nonlinear dynamical systems and show that the incrementally input-to-output stable system is always differentially private. In fact, differential privacy evaluates the privacy level of the scenario involving the least private information. Therefore, based on differential privacy, it is difficult to study exactly what kind of information is protected. To address this problem, we proceed with qualitative analysis of privacy in terms of input observability for nonlinear systems. In particular, we provide a necessary and sufficient condition for input observability, revealing an impossibility result on protecting private information.
