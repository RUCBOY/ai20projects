Cognitive sciences and computer vision have proposed diverse models to acquire, transform and interpret visual information, mainly aimed to achieve realistic, yet efficient approaches to those capacities. One of the key aspects of visual processing is the identification of objects in the scene, that entails the perceptual association of visual features with semantic information extracted from memory. In this study, we present a model for visual recognition that resembles the way the humanâ€™s brain interacts to achieve this process. The model describes the processes in V1 and V2 to extract features of lines, angles, and contours; as well as a template matching process in ITC, that uses early low spatial frequency visual information to bias the available comparisons. Operations of prefrontal areas DLPFC and VLPFC to maintain the representation and OFC to give a response are also described. Our proposal is intended to be the basis to treat visual information in a broader cognitive architecture. We find that matching of ITC templates provide a general and biologically inspired representation for objects. We also show how the use of low spatial frequency visual information can lead to a faster identification process when previous data exists. This is achieved by selecting a small number of ITC templates to handle the incoming bottom-up input.
