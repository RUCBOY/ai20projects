Historically, the assessment of nonverbal behaviors such as facial expressions and gestures have relied heavily on observations made with the naked eye. Previous studies have shown that the manual analysis of micro-expressions can be both arduous and time consuming, and often suffers from a low level of reliability. However, new technology may bring forth new opportunities to refine this type of investigation. This research applied three feature extraction algorithms from the field of computer science to assist in measuring subtle dynamic movements in the human face. The Constraint Local Model (CLM) algorithm was employed to detect the faces and track the feature points; coordinates changing position across the frame indicated local facial activity. Based on these features points, facial regions of interest (ROIs) were identified for further analysis by Local Binary Pattern (LBP) and Optical Flow (OF). The LBP algorithm was used to extract texture information from the ROIs and measure correlations among frames; OF was used to analyze facial actions based on the main direction and distance of movement. The results of the three methods were then compared with manual coding. The proposed methods, especially OF, proved to be both robust and reliable.
