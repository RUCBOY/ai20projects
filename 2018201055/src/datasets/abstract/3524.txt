Recent research has shown that conditional adversarial network (cGAN) can be adopted to perform image-to-image translation task effectively. Saliency detection is another challenging computer vision task to model human vision attention mechanism. By reformulating the saliency detection task, in this work, we propose to conduct saliency detection by exploiting conditional adversarial network under the cGAN framework, in which saliency map prediction is transformed as a saliency segmentation task by using pair-wised image-to-ground-truth saliency. To further investigate the potential of cGAN for saliency detection, we train the cGAN model to capture saliency-to-context information by translating saliency mask to real image. Experimental results confirm that the trained generator can achieve comparable state-of-the-art performance on saliency segmentation, and can generate reasonable results for saliency-to-image translation.
