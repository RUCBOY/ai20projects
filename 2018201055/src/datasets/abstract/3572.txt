Blur detection is an important and challenging task in computer vision. An essential problem in blur detection is how to choose effective features to distinguish blurred and non-blurred image regions. Unlike previous methods relying on various handcrafted features, we propose to learn discriminative blur features via deep convolutional neural networks (CNNs). We design a simple yet effective 6-layer CNN model, with 5 layers for feature extraction and 1 for binary classification, which can faithfully produce patch-level blur likelihood. We empirically show that, by going to deeper layers, our model is able to generate more effective features with refined discriminative power. We apply this network at three coarse-to-fine scales and optimally fuse multiscale blur likelihood maps to generate better blur detection. Extensive experiments on challenging benchmark dataset validate that our model can significantly improve the performance of blur detection. We also show that the accuracy of saliency detection can always be improved by treating regional blur likelihood as saliency prior.
