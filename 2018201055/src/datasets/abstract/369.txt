Accurate acquisition of end-systolic (ES) and end-diastolic (ED) frames from ultrasound videos of fetal echocardiograms is a key procedure in the automated biometric measurement and diagnosis in obstetric examination. Compared with adults, the fetal detection task remains an additional challenge due to the variation of cardiac anatomy with fetal position and sound-beam angle, variations in cardiac views of different gestational weeks, and faster heart rates. These challenges have led to multi-resource fetal echocardiogram data, which means that adult detection methods may not be applicable. We formulate this problem as a classification problem and present a deep-learning hybrid framework that uses class score to localize the ES and ED frames. To the best of our knowledge, this is the first framework that utilizes a hybrid classification framework for the detection task. The proposed architecture integrates the extracting region-of-interest (ROI) component based on target detection, retaining a temporal dependency module and classification module based on a domain-transferred deep convolutional neural network (CNN). We conduct YOLOv3 as a ROI module (RD) to extract attention regions for improving classification performance and determining the four-chamber view. Meanwhile, the temporal dependence is not lost by the merged neighbor frame difference into image channels. Different CNN architectures are explored herein, i.e., Xeception, ResNet, InceptionV3, MobileNet, NasNetmobile, and different channel fusion strategies, i.e., SF, DF, and MDF. The optimal deep-learning model consists of a MobileNet, MDF, and RD trained by adding a transition class strategy. On average, 94.84% accuracy of classification results was achieved, and the average detection errors of ES and ED frames are 1.25 and 0.80 frame, respectively.
