Ephemeral computing is a term that describes computing systems whose nodes or their connectivity have an ephemeral, heterogeneous and possibly also unpredictable nature. These properties will affect the functioning of distributed versions of computer algorithms. Such algorithms, which are usually straightforward extensions of sequential algorithms, will have to be redesigned and, in many cases, rethought from the ground up, to be able to use all ephemerally available resources. Porting algorithms to an inherently ephemeral, unreliable and massively heterogeneous computing substrate is thus one of the main challenges in the ephemeral computing field. Algorithms adapted so that they can be consciously running on this kind of environments require specific properties in terms of flexibility, plasticity and robustness. Bioinspired algorithms are particularly well suited to this endeavor, thanks to their decentralized functioning, intrinsic parallelism, resilience, adaptiveness, and amenability for being endowed with algorithmic components dealing with both the massive complexity of the computational substrate and that of the problem being tackled. Arranging these components and functionalities in a collection of algorithmic strata results in deep architectures, whereby different layers of optimization are organized into loosely-coupled hierarchies that not only are able to use ephemeral computing environments, but also profit from them by making adaptivity and diversity maintenance features of the algorithm. Moreover, the synergies that arise when these massively heterogeneous computing resources are made available to deep versions of bioinspired algorithms may enable hard real-world problems and applications to be successfully faced in the Big Data context (including but not limited to social data analysis) as well as problems in the areas of computational creativity or computer gaming.
