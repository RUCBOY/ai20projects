Matrix completion is widely used in many practical applications such as computer vision and data mining. In this paper, we consider the following two issues arising in real scenarios. First, the collected datasets are damaged by sparse noise and column outliers simultaneously; second, the datasets are not static in nature due to the existing of out-of-sample. Both of them have been ignored by most existing methods.
In contrast with the traditional matrix completion algorithms which aim at recovering the entire matrix directly, we in this paper aim to first learn a low dimensional subspace by recovering a subset of collected samples, and then utilize it to estimate the missing values of residual data. There are two important advantages about this transformation. First, weakening the deviation caused by column outliers. Second, providing a direction for efficiently solving the out-of-sample problem. Particularly, to further improve the robustness of proposed method to sparse noise, we present a novel robust matrix completion model and a robust vector completion model, and both of them are based on non-convex ℓp-norm (0 < p < 1).
In experiments, the proposed method and other state-of-the-art algorithms will be used to cope with two problems: matrix completion and vector completion. Numerical results on real datasets and artificial datasets demonstrate that our method can provide a significant performance advantage over alternative methods.
