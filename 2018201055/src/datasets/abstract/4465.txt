Several fields in biology tend to view the concept of information from one or the other of two extreme positions. Exclusionists base their stance of total rejection on gene-centrism and gene-determinism, typified by the recently-established endo-Darwinist school of life sciences. At the other end of the spectrum, there is total acceptance, as in the newly developed information-centred paradigms that populate biosemiotics. We propose in this paper to split the informational concepts into two irreducible (but linked) poles: the syntactic (concerned with the quantification of the information structure or complexity in a system), and the semantic (concerned with the organization rules and causality weights of interactions in a system). We claim that the past and present uses of the concept could then be classified as various degrees of oscillation between the two poles. The concept of language presents itself as a good tool with which to bridge the syntactic and the semantic poles, combining as it does the form-related and the meaning-related aspects of information, while methodologically supporting formal grammatical models in life sciences. We aim to show, at the same time, that neither of these poles alone can suffice to efficiently and holistically describe, model, and predict natural phenomena.
