This paper describes an efficient generation of large-scale dataset of human depth images with body part labels. The size of image datasets has recently been increasingly important as it is shown to be strongly related to the performance of learning-based classifiers. In human pose recognition, many datasets for ordinary poses like standing, walking, and doing gestures have already been developed and effectively utilized. However, those for unusual ones like lying fainted and crouching do not exist. Pose recognition for such cases may have a large potential applicability to various assistive scenarios. Moreover, locating each body part could also be important for an accurate care and diagnosis or anomaly detection. We therefore develop a method of generating body part-annotated depth images in various body shapes and poses, which are handled by a flexible human body model and a motion capture system, respectively. We constructed a dataset of 10,076 images with eight body types for various sitting poses. The effectiveness of generated dataset is verified by part labeling tasks with a fully convolutional network (FCN) for synthetic and real test data.
