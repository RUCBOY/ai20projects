The degradation of visibility due to foggy weather conditions is a common trigger for road accidents and, as a result, there has been a growing interest to develop intelligent fog detection and visibility range estimation systems. In this contribution, we provide a brief overview of the state-of-the-art contributions in relation to estimating visibility distance under foggy weather conditions. We then present a neural network approach for estimating visibility distances using a camera that can be fixed to a roadside unit (RSU) or mounted onboard a moving vehicle. We evaluate the proposed solution using a diverse set of images under various fog density scenarios. Our approach shows very promising results that outperform the classical method of estimating the maximum distance at which a selected target can be seen. The originality of the approach stems from the usage of a single camera and a neural network learning phase based on a hybrid global feature descriptor. The proposed method can be applied to support next-generation cooperative hazard & incident warning systems based on I2V, I2I and V2V communications.
