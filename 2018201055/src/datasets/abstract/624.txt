The current work proposes a method for age estimation of face videos. To attenuate the effect of pose, our method is based on facial uv texture maps reconstructed from original frames of videos. A Wasserstein-based GAN is used to restore the full uv texture presentation. Age is then predicted from the completed uv mappings such that the proposed AgeGAN method simultaneously learns to capture the facial uv texture map and age characteristics. To train our method, we have created the UvAge dataset, the largest video dataset of face videos with age annotation (together with identity, gender, and ethnicity labels). The dataset contains videos in-the-wild from celebrities that are recorded in a variety of imaging settings. In total, we collected 6898 video segments (788,640 frames) from 516 celebrities in 57 events. Extensive experiments demonstrate that our proposed method outperforms other advanced age estimation methods.
