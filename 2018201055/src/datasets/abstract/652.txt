Overextension—the phenomenon that children extend known words to describe referents outside their vocabulary—is a hallmark of lexical innovation in early childhood. Overextension is a subject of extensive inquiry in linguistics and developmental psychology, but there exists no coherent formal account of this phenomenon. We develop a general computational framework that captures important properties of overextension reported separately in the previous literature. We operationalize overextension as probabilistic inference over a conceptual space that draws on a fusion of knowledge from lexical semantics, deep neural networks, and psychological experiments to support both production and comprehension. We show how this minimally parameterized framework explains overextension in young children over a comprehensive set of noun-referent pairs previously reported in child speech, and it also predicts the behavioral asymmetry in children's overextensional production and comprehension reported in lab settings. Our work offers a computational theory for the origins of word meaning extension and supports a single-system view of language production and comprehension.
