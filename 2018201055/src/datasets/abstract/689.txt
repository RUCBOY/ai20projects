In this paper, we develop a machine learning method with the Least Squares Support Vector Regression (LS-SVR) for the numerical solution of Fredholm integral equations. Two different approaches are proposed for training the network by using the shifted Legendre kernel, the collocation and Galerkin LS-SVR approaches. As with the standard LS-SVR for known dataset regression, the formulation of the method gives rise to an optimization problem. An equivalent system of algebraic equations is then derived and in linear cases discussed in terms of the sparsity of the matrices and computational efficiency. Finally, the method is carried out on some numerical examples, including nonlinear and multidimensional cases to show the accuracy and efficiency of the method.
