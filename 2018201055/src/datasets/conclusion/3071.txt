In this paper, we propose DocChat, a response retrieval method for human-computer conversation systems. Unlike existing retrieval-based methods using utterance-response pairs as candidates, our method finds responses based on unstructured documents. The core of our method is a learning to rank model, which ranks candidate responses with a set of well-designed matching features at different levels. We evaluate our method on both answer sentence selection and response sentence selection, and find our method achieving promising results. A side-by-side evaluation with Xiaoice shows that DocChat is a good complement for human-computer conversation systems. We also release our answer sentence selection dataset to research communities to enable researchers to use it for more natural language proceeding tasks. We leave better triggering components and multiple rounds of conversation handling to be addressed in our future work.
