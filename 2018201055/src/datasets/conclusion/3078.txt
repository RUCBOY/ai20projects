6.1. LimitationsAlthough this study has produced new insights into writing test equivalence between paper-based and computer-based conditions, it has several limitations.First, the nature of a test equivalence study imposes difficulty in recruiting a large number of participants, as each needs to complete a test under two conditions. Nevertheless, we believe a sampled population of about 150 in this study is satisfactory for the findings to be generalisable to the wider test population. A further complication is that although the two versions of the task prompt used in this study may exhibit equivalence with one population, this may not necessarily hold true for another. In research designs such as the one used in this study, achieving complete equivalence of task may not be possible unless participants take both versions of the test in both conditions. As we considered inappropriate for participants to do the same version in both modes, we took the view that establishing acceptable boundaries of equivalence (e.g. counter-balancing the versions and conditions) within which we could have confidence was a suitable modus operandi.
6.2. Summary of findingsThese limitations not withstanding, the most important conclusion from the study is that according to the 5-facet MFRM analysis, there were no significant differences in the scores awarded by two independent raters for candidates’ performances on the tests taken under two conditions, one paper-and-pencil and the other computer. The difference between the fair means of the overall test scores in two modes was 0.03 for the whole group. Based on the 4-facet MFRM analyses, the differences in three analytic scores criteria (i.e. Task Achievement, Coherence and Cohesion, and Grammatical Range and Accuracy) were not significant, but the difference reported in Lexical Resources was significant.With respect to the test takers’ writing processes under the two conditions, results of the Writing Process Questionnaire indicate a similar pattern in the use of processes elicited by the PB and CB test. Most differences were 0.15 or below out of a 4-point scale. Secondly, the means of all items in each of six cognitive phases between the two modes were compared and tested by Wilcoxon Signed Ranks Test. All differences were non-significant. This indicates that the cognitive processes were employed in a similar fashion under the two delivery conditions.This finding is confirmed by the interview data, where all test takers stated they composed the PB and CB tests in a comparable way. Nevertheless, a few differences in how test takers planned, generated texts and monitored and revised their texts emerged from the interviews. In terms of aspects of the revisions, some participants tended to focus more at the word level in the PB mode and more at the levels of clauses and sentences to improve coherence and argument in the CB mode. Based on evidence from the questionnaire and interview, the data generated on test takers' cognitive processes activated in completing the CB AWT2 in this study are of great value to the test provider. They will help in the elaboration of the cognitive parameters in the test specification.The Computer Familiarity Questionnaire shows that participants in this study are familiar with computer usage, and their overall reactions towards working with a computer are positive. Most participants prefer to take the test under CB conditions. The results of Multiple Regression analysis indicate that three out of 15 of the computer familiarity variables (i.e. CFQ1c – access to computers at public library, CFQ4b – frequency of using computers for word processing, and CFQ13 - forgetting time) have a small but significant impact on their performance in the computer mode. This implies that test takers who do not have a suitable familiarity profile might perform slightly worse than those who do in computer mode.
6.3. Final thoughtsA difference of 0.25 in observed mean and 0.03 in fair mean between the test scores in the PB and CB modes were reported in this study. While no significant statistical difference was found in scores between the two modes, future research might investigate whether the test-takers themselves or test users would see the differences as ‘non-significant’. Where there is a difference of one band, or even of half a band, it may turn out to be the difference between being accepted onto a programme or not, which might therefore have a 'significant' impact on a candidate's future. While the statistical test of significance is important and previous research has used this or similar measures, it is recommended that test developers need to bear in mind the human perception and consequences of even small differences such as a half band on IELTS between different modes and take steps accordingly, perhaps to the extent of issuing a “health warning” with results.
