In this paper we have presented a new method for CG images detection using a deep convolutional neural network model based on ResNet-50 and transfer learning concepts. After a simple pre-processing, each image in our dataset is fed into our deep CNN model and, as result, we obtain a 2048 dimension feature vector, here called bottleneck features. Exploring different approaches looking for achieving the most effective problem solution, we evaluate different approaches, since train ResNet-50 architecture from scratch (just changing the 1000fc softmax from original architecture to a 2fc softmax in top layer), using our dataset, for CG detection process, until full transfer learning, where ImageNet weights for ResNet-50 are totally frozen in a way to produce bottleneck features, which are used to train different machine learning classifiers to detect if an image is, or not, produced by computer graphics methods.
Conducting different rounds of experiments, we evaluate the efficiency and effectiveness of using a deep CNN architecture proposed for an object recognition task in a CG detection problem, where we are looking for distinguishing between a CG and a PG image, involving different kinds of objects and context. Results showed that proposed approach performs as good as the top state-of-the-art methods in the same dataset, achieving more than 0.97 accuracy rate. These results highlight three main advantages of the proposed method: (i) no requirement for hand-craft feature extraction, (ii) robustness against image processing operations and, (iii) extremely lower execution time when compared against state-of-the-art method with similar accuracy.
In special, in Round #6 of experiments (Section 4.10) we showed for DSTok dataset, using t-SNE dimensionality reduction, the expression power of bottleneck features generated by ResNet-50 transfer layers, which increases the classes separability when compared against raw input features. The same behavior is kept in DSTokExt with more and different kinds of images.
Furthermore, it is important to realize that, as showed in Section 4.9, even with a extended dataset, the learning curve from the SVM classifier it is still not stable, which suggest that training score is not still around the maximum. Since deep learning models needs an astonishing number of images to achieve a satisfactory accuracy, we conclude that if we keep increasing the number of images, it can lead to an accuracy even better.
A limitation of this method is its difficulty in dealing with CG images with a high degree of realism. We conducted an experiment with two datasets involving images very similar and with high degree of realism, one proposed by Holmes et al. [1] and a second one proposed by Carvalho et al. [49]. This left a door open for the improvement of this technique or development of a new one that could cope with this difficult scenario.
As research directions, our proposal is to explore different architectures for bottleneck features extraction and to perform fusion of these architectures in a way to construct an ensemble of deep architectures.
