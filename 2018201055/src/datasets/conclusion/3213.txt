In this paper, employees’ preferences for technical security measures that companies can take to protect information are studied within the empirical frameworks of discrete choice theory and discrete choice experiments. More specifically, an experiment is conducted, in which employees evaluate combinations of technical security measures in terms of security and usability perceptions and make choices among security packages. Regression models were estimated from the observed perception ratings, the parameters of which express to what extent security measures affect perceived security and perceived usability. In addition, a so-called MNL model (being the workhorse model for discrete choice analysis) was estimated from the observed choices, which revealed the relative impact of security and usability perceptions on choice. Our results provide insight into the trade-off made by users of information technology, between security and user-friendliness aspects of technical security measures.
Based on the results of the estimated models, answers are formulated to four research questions, which can be summarized as follows. First, perceived usability and perceived security indeed correlate negatively as is suggested in the literature, although we find that the association is relatively weak (−0.14). Second, as expected, more restrictive security measures are perceived as more secure and as less usable. Third, perceived security and usability affect choice to the same extent; that is, both dimensions of technical security measures are considered equally important by users of information technology. As expected, higher security and usability perception scores increase the preference for security packages; however, and in line with intuition, the marginal increase diminishes with higher initial levels of security and usability perceptions. Fourth, perceived security fully mediates the effect of security related aspects of technical security measures, while perceived usability does not fully mediate the effects of user-friendliness related aspects of security measures. The results give rise to the possibility that other dimensions exists that mediate the effects of TSMs, such as for example familiarity. However, this possibility needs further research.
Our findings that (a) employees clearly recognize that more restrictive measures improve security, and (b) security is considered by them to be equally important as usability, may encourage CISOs of companies to adopt a more cooperative process in their security design process, in which perceptions and preferences of employees are taken into account. Investigating employee preferences, like in our study, may lead to the design and implementation of packages of security controls that are better tailored towards employee's needs, reducing circumvention activities that could be exploited in cyberattacks. We provided an illustration of how the models estimated in this study can be applied for this purpose. However, this will not be simply a matter of selecting the right controls; it will also involve properly managing commitment and awareness.
Interesting avenues for further research within the discrete choice framework include the following. First, the number of technical security measures included in our study was rather limited (for good reasons). Hence, it would be of interest to include more of those measures, such as for example, multifactor authentication, and examine whether the strength of the correlation between perceived security and usability as found in this study is robust. Second, in our study perceptions are measured first, and then choices are observed. The question is whether explicitly asking about usability and security first makes respondents more conscious of these aspects (i.e., increases their salience), so the issue is to what extent the presentation order affected the results. It would be of interest to study to what extent our results are robust under a different order of both measurement tasks. Third, the possibility of other dimensions in addition to security and usability, e.g. familiarity, could be further investigated. Fourth, the results presented in this paper were based on a convenience sample, and should therefore be treated with care. Hence, further research should include more representative samples. Fifth, heterogeneity in perceptions and preference could be examined. The discrete choice paradigm offers a range of methods to study heterogeneity (Greene & Hensher, 2003), of which the following three are probably most promising in the context of response to information security measures. First, traditional segmentation could be applied, which implies examining to what extent people with different sociodemographic characteristics differ in their perception of and preferences for TSMs. Second, it can be assumed that preference weights do not have crisp values but follow a certain distribution across employees, which can be examined by estimating more advanced choice models, such as mixed logit models. Third, latent classes may be assumed, which are groups in the population that are internally homogeneous in their preferences and which can be identified based on their observed choices. In these models, membership functions can be estimated that allow predicting the probability of belonging to a latent class based on observed individual characteristics.
Apart from extensions to the present study, it is hoped that this paper stimulates other choice modelling applications in this field, both extending the work on employee preferences as well as focusing on the choices of other actors in the cybersecurity playing field. In terms of employees, this may not only involve studying preferences for security controls, but also choices in terms of compliance or non-compliance with security policies. Choices for non-compliance may happen spontaneously, for example when official security is found too cumbersome, or in response to deceptive acts of attackers, such as in phishing (Finn and Jakobsson 2007) or social engineering (Bullée et al. 2015) attacks. How attributes of policies and situations contribute to preferences for (non-)compliance may help in improving organizational aspects of security. One possible application to other actors lies in analysing the choices security officers make when selecting controls to be implemented in their organization. Which attributes contribute to the utility of a possible control, and how does this affect the decision? Another possibility is to study choices of cyber-attackers, in terms of which targets to attack using which means, assuming that there are subjects willing to participate, either known offenders or white-hat (ethical) hackers. Better understanding of attacker choices may inform better representations of attacker behaviour in security models and risk analyses. In these ways, discrete choice theory and discrete choice experiments may become useful tools in the portfolio of techniques for improving security in cyberspace by considering the human factor.
As a final note, there is a debate around how much control should actually be given to employees regarding security choices. Much of the existing practices assume centralized control of security solutions (cf. Parkin, Kassab & Van Moorsel 2008), but one could imagine frameworks in which employees can decide how much security the data or applications they work with require. This so-called “laissez-faire security” (Johnson et al. 2009) requires investigation not just of the preferences of employees with respect to technical security measures, but also regarding their preferred level of control over such measures.
