This study sought to fill the gap between the need for labelled data for training supervised monitoring algorithms and the raw, unclassified data that have accumulated in process historical databases. We demonstrated how unsupervised learning techniques drawn from the computer science literature can identify fault states and extract knowledge from chemical process databases. A selection of dimensionality reduction and data clustering techniques identified different operating and fault states in data from real and simulated chemical processes. On the Tennessee Eastman Process simulation, data clustering and DR functioned in tandem to isolate data from the different faults in the process, information which could be used to train a supervised classification technique for fault detection. On an industrial scale separation tower, data clustering identified a large, dense normal region corresponding to normal process operations and distinguished it from data from a fault that had occurred during the months of operations considered. Further analysis reveals that at the grade studied each start-up of the column formed a new cluster in the dimensionally reduced space, as visualized by a PCA projection of the clusters found by DBSCAN.
More ongoing work will study how unsupervised learning can improve process data analytics. While the data clustering techniques in this study performed satisfactorily on the data from the industrial separation tower, further work will study multistate processes where the steady state may move more often based on the rate of production or other frequent changes to the process steady state. Additionally, further tools are needed to leverage process knowledge in explaining the meaning and significance of clusters, such as identifying which sensors measurements contribute most to the separation between two given clusters. Finally, a weakness of this research is that supervised clustering metrics were used to evaluate the different clustering strategies which require labelled process data. The methods used to evaluate the quality of the clusters found are nearly as important as the cluster algorithms themselves. Several different clustering algorithms may find good clusters in the data, but identifying the right parameter values for a given technique and data set can be a challenging task. Unsupervised clustering metrics can provide crucial insight into identifying good parameter settings.
