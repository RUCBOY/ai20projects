There are many emerging approaches to “computational scientific methods,” using machine learning or other techniques to recover equations from data (Sozou et al., 2017). The model we showcase here has certain desirable properties. It is extremely simple to deploy. It requires only a handful of adjustments to raw data, and the process of finding coefficients B does not require high-performance computing resources. With these in hand, a high-dimensional space of features, obtained from raw data X, can be explored. Few assumptions about the underlying form of the governing equations are needed. And this is implemented in just a few lines of code. Our demonstrations also illustrate the value in manipulating and exploring dynamic models as subjects of study in and of themselves. By creating new datasets under varying conditions, we are able to validate and expand these new analysis techniques. Such a strategy is an important part of expanding the toolkit of dynamic systems methods (cf. discussion in this issue: Spivey, 2018).
We did demonstrate that the approach can suffer under noise. It also requires distinct application in discrete dynamic systems, illustrated in the logistic map and the Lorenz system. In the former model, we take the first-order derivative to be the next values of the system variables. In the latter, we use numeric differentiation. These modeling choices are not necessarily clearly motivated, and still have to be set by the researcher. In addition, the thresholding of the coefficients may be better implemented by standard regularization techniques, such as LASSO (Tibshirani, 1996).
We proposed three possible extensions of this specific approach. By more elegantly integrating stochasticity in a continuous-field approach, we could obtain a more compelling recovery of the source system, including systems that are not sparse, but rather radically interactive. Second, we showcased how something like SINDy could serve as a basis for new descriptive measures of a system being studied in the lab. In the cognitive context, for example, SINDy’s output may help describe the relative complexity of behavior in different contexts. Finally, we demonstrated that SINDy can be used to explore multiple systems, and map out potential interactive relationships that lie between them. Here models get considerably more complex, and the value of using SINDy as a source of new aggregate measures may be again useful.
These illustrations and concerns raised lead to a set of important pointers for application of SINDy to a real research context. To a great extent, these are open to future investigation. Application of these techniques to raw, noisy datasets is an important next step. When doing so, the researcher should bear in mind the following three concerns, as practical recommendations that are preliminary in nature.
1.Time series length. SINDy can work with surprisingly short time series (in our models 20–30 samples, across just 100 trials), but the more densely sampled the dynamics, the better the observed fit. The general lesson here is that if the observed time series thoroughly explores the underlying system’s phase space—including stable/unstable equilibria, periodic orbits, and attractors—then SINDy will have a much better chance of reconstructing the right equations of motion. For example, in the logistic map case, if we only sampled from control parameters that had a point attractor, the fit is based on less variance than if we sampled from values of the parameter in chaotic regimes.2.System drift. If the system’s underlying dynamics are changing, if the researcher suspects drift, a single application of SINDy is unlikely to be interpretable. In this case, the researcher can explore a sliding-window approach. Such an option is offered in the sindyr package that the authors created. A single time series can be segmented using a sliding window. The researcher can explore the extent to which drift is taking place, and may derive new dependent variables that align with an experimental task or stimuli.3.Unknown and complex models. We had to include parameters a (for the logistic map) and k (for the choice model), but an experimenter may not know the underlying control variables. In these cases, an experimenter may be able to propose a set of parameters (similar to priors, in the Bayesian sense), and adjust a SINDy model to capture behavioral dynamics. Researchers using trial conditions could propose specific fixed control variables to input into SINDy. Finally, in both unknown and complex systems, the threshold selection will not be obvious, and should be done by exploration. With each added polynomial order, the threshold may need to be scaled down to avoid iterative removal of viable terms. This is because, as the dimensionality of the feature space increases, coefficient magnitudes tend to be lower and more evenly distributed. This may be due to the iterative thresholding by least squares; a LASSO approach or the vector-field extensions we have described would be an important next step in general.
There is much left to do, of course. For example, a systematic comparison of these methods is still needed. It would be of value simply to compare the predictions of these methods with basic machine learning tools. A simple autoregressive model may compete with fits from recovered equations, suggesting that while equations provide a certain epistemological inspiration (such as expressing nonlinearities), their practical role could be humbler. This is especially true in the application of these methods to raw behavioral data from the lab or beyond it. The interactions among brain, behavior, and environment are robust (Chemero, 2011, Favela and Chemero, 2015). As noted above, human behaviors may undergo sudden drift in the equations that best fit data, through perturbation from environmental sources or even from dynamic adaptation to a task. For example, Dixon, Kelty-Stephen, and others (Dixon and Bangert, 2004, Dixon et al., 2010, Stephen et al., 2009) have studied how the cognitive system may show a pronounced “representational reorganization” during problem solving. In some of these studies, reorganization is detected through dynamics of body movement (such as movements of the hand). This work suggests that these data science approaches may need gentler summary measures, rather than pure formulaic outcomes.
In this paper, we focused on introducing this data science approach under very limiting assumptions about known systems. A crucial next step in all these domains is to move into raw data, perhaps even data for which the governing equations are not at all clear. This could have profound theoretical relevance for cognitive systems research (Favela, 2014). Finding lower-order descriptions that can encapsulate the high-dimensional complexity of human behavior is a long sought goal of our field. Using emerging data science tools may offer new ideas regarding what lower-order descriptions can do in a wide variety of contexts in which these data are collected.
