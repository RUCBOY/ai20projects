Based on the principles of genomics, a novel video analysis paradigm, ‘vide-omics’, has been proposed. Evaluation of its first implementation has provided some evidence of not only its validity, but also its potential. Indeed, using genomics analogies, a background/foreground segmentation pipeline for freely moving cameras has been designed with variability at their core so that performance is constrained by neither camera motions, specific foreground object behaviours nor scene structures. Experimental results showed state-of-the-art performance and robustness when dealing with a challenging video including a variety of camera motions and scene, while remaining competitive in scenes which can be modelled by a specific camera motion model.
One should recognise that initial implementation has limitations which should be overcome to build a system suitable for most real-world applications. First, since scanlines are processed independently from their neighbours, current segmentation does not benefit from vertical spatial coherence. This could be addressed through either an additional post-processing stage which would ensure vertical spatial coherence, combining scanline alignments with ‘scancolumn’ alignments or a 2D version of the Needleman–Wunsch algorithm which would take into account a pixel’s vertical neighbourhood during optimisation of scanline alignment. Second, as discussed, current implementation requires processing times which are far from being real-time. Since usage of heurestics-based alignments has proved particularly efficient in optimising genomics algorithms without altering significantly performance, there is every confidence that such approach would address the high computational complexity of the proposed pipeline.
