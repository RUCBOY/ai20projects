This research work presents a task-based observational study in a clinical setting, which was conducted for the objective of verification and validation of augmenting speech therapy sessions with Emo-in-Speech system. This system design provides an intuitive interface for exploring rich datasets of brain visualizations, activity, and quantitative measures and its goal is to assist the professionals in better analysis of the data. Emo-in-Speech system provides an observation and assessment tool that records and monitors the brain activity and provides longitudinal information of the people who stutter in clinical contexts to augment speech assessment.
In this paper, we reported on an EEG experimental study to identify the feasibility and the potential benefits of applying EEG-based emotion detection in speech-language therapy contexts of use. We presented the protocol implementation and synchronization with audio, video and electrophysiological signals recorded with Enobio. Then, the electrophysiological offline data-analysis and results presentation is described.
In our work, we found that (i) emotional detection and classification using EEG-based BCI system is sufficient to differentiate between affective states of individuals in treatment contexts, and (ii) BCI headsets are perceived by clinicians as unobtrusive devices that can be considered during therapy sessions in speech-language pathology, and (iii) deep neural network (DNN) can effectively mirror emotional affective states of subjects.
