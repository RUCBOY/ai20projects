In this paper, we propose a decomposition and re-fusion approach to mitigate the memory occupancy of the intermediate data generated by default CP-decomposition. By re-fusing the convolutions across tensors, our approach reduces the size of the intermediate data by 84.6% and 77.4% for AlexNet and VGG-19 respectively. In the meanwhile, we optimize the cache locality of the convolution operations after re-fusion, which in turn improves the performance of AlexNet and VGG-19 by 1.77× and 1.4× respectively. Moreover, we provide formal analysis on the memory occupancy and computation complexity of our approach in order to demonstrate the advantage of our approach compared to the default CP-decomposition. With our approach, we receive the benefit of reduced computation complexity from CP-decomposition, in the meanwhile mitigate the memory occupancy of the intermediate data from convolution re-fusion.
For the future work, we would like to evaluate more CNN models such as GoogleNet [41] and ResNet [1] with our approach. In addition, we are also interested to apply our approach on accelerators such as GPU. Since the PCIe bandwidth between CPU and GPU is quite limited for CNN applications, it is expected that our approach is effective to alleviate this performance bottleneck. Furthermore, as previous work [5] concludes that the accuracy of the CNN models after CP-decomposition can be improved significantly with model fine tune. We would like to explore this opportunity to experiment with more radical decomposition and re-fusion methods, which achieves better performance in both computation complexity and memory occupancy with acceptable accuracy.
