These research results have important implications for continuation of the research and also for implementation. Regarding research, further studies might focus on new multimodality learning support tools for sighted students or students with special needs (such as dyslexia, text reading difficulties), and their ability to collect and understand information through the integration of various sensory modalities (visual and auditory versus visual only). Future research should compare the relative benefits of learning CC1 for sighted participants or people with special needs through sonified feedback (via L2C models), sonified and visual feedback (via L2C models), and visual feedback (via the NetLogo system). Figueiras and Arcavi (2014), who examined learning tools that are used in visually impaired classrooms, suggested using these tactile and auditory modalities tools to support the mathematics learning process for sighted students as well. The underlying idea is to create one more path to transfer knowledge; sighted students whose visual modality is weak can improve their learning ability using other modalities, such as sonified interactions.
The results of this research and that of Samon and Levy (2011) point to the need for further studies that compare scientific learning ability by students, both blind and sighted who are studying through the same L2C models. The L2C models include visual and sonified feedback; students who are blind can make use of the sonified feedback and sighted students can employ the visual feedback or both sonified and visual feedback.
Following these research results, other studies should focus on the effect of time exposure while learning through a sonified system. This learning process is cognitively demanding, requiring the identification of each stream followed by the integration of all information into one combined representation. In our research the participants were able to integrate five auditory streams simultaneously. We assume that a longer time exposure would improve their auditory skills and learning ability and would allow them to identify and integrate more than five sonified streams.
For implementation, sonified feedback such as L2C agent-based models can be implemented in K–12 or higher education, or as an assistive tool allowing access to visual information by multimodality learning support tools for sighted students, people who are blind, and other children with special needs (Figueiras & Arcavi, 2014). Douglas (2001) supported the use of assistive technologies by students who are blind to allow them equal opportunity to be integrated in public schools. The accessible standard learning materials, with or without L2C sonified NetLogo models developed for this research, could play a central role in STEM education for students who are blind and for their independent integration in general education schools, placing them on an equal basis with students with sight. The research results highlight the potential of integrating students who are blind with sighted students in STEM curriculum study. The L2C models include visual and sonified feedbacks, which allow students who are blind and sighted to work together with the same model at the same time.
This approach should include providing accessible standard learning materials for students who are blind in STEM and other curricular areas. Design and development of a NetLogo L2C library based on sonified feedback from these developed sonified models will enable inclusion in other STEM curricula. It will allow teachers to use adaptive learning materials without the need to expend valuable time and effort, which are already spread thin (Toenders et al., 2017b). Teacher training will be needed to effectively implement the NetLogo L2C sonified model in an integrated classroom, and, in the future, trained teachers should be able to design additional new sonified models independently.
Sonified audio graphs can also be integrated in other areas, as an assistive tool allowing access to a static graph. For example, access to digital newspaper, articles, and other learning materials, which integrate a static graph (e.g., in mathematics education, statistics, or economics).
The L2C agent-based model has some challenges or limitations. First, the L2C models are based on the NetLogo library, whose models focus mostly on STEM education, although this library is continuing to grow. Secondly, each agent-based model represents only one scientific phenomenon, for example the CC1 included three L2C models: experimenting with particles, pressure, changing pressure (Fig. 2a and b), diffusion (Fig. 2c), and atmospheric pressure and gravitational force (Fig. 2d). Third, there is a need to develop a simple editor, which will allow the teacher to create new L2C models for students who are blind in a short time. The forth limitation involves the dependency of the learning materials on the phenomena they depict, requiring a dynamic phenomenon such as the sound. It will be much more difficult to use sonified simulation to study static artifacts such as in art. Static artifact (e.g., a painting) has extensive visual information that is integrated in one “view” (shapes, colors, space, depth, etc.). Of concern, also is the number of auditory streams that the user can receive simultaneously and still be able to construct a cognitive concept of a whole representation. Stifelman (1994) has demonstrated that gradual exposure aids in building stream segregation, thus enabling participants to increase the number of perceived channels beyond three. In this research the participants were able to identify and construct a cognitive concept of four and five sounds and varied sound streams (events and audio graphs).
Despite these limitations, the research results show promise for improving achievement in science for students who are blind, and follow-up research and implementation should prove beneficial.
