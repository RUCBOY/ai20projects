Cyber attacks are becoming increasingly complex with obfuscation of network traffic and system level interactions in recent APTs, and polymorphic malware changing the measurable behaviour of the executable. We aimed to use machine data to classify malware using data that is presently more difficult to obfuscate – system level behaviour such as CPU, RAM, process data and network bytes/packet count. We built machine classifiers using state of the art methods from the extant literature as a baseline, with data that is continuous and represents behaviour on the system without depending on precise system level operations.
We then implemented a two-map SOFM with the aim of enabling 'fuzzy boundaries' to be captured around system behaviour and the hypothesis that this method would improve classification accuracy over the state of the art methods. The ’fuzzy boundaries’ enable us to map new samples onto existing maps and determine that the behaviour may be different but similar enough to previously observed behaviour to label it as malicious - that is, to better generalize between samples over time. Essentially what we have developed are representations of behavioural ‘DNA’ in a malicious or trusted context that provide a model to which potentially malicious executables can be compared for similarity - introducing a new way of thinking about malicious behaviour modeling. We found a 3.45% increase in classification performance using an unseen testing dataset.
We also investigated the impact on classifier performance when using the unseen test dataset versus a k-fold cross validation method, which is frequently used in malware classification research. The rationale for this was to determine whether system behaviour that was not exposed to the classification model during the training phase would evade classification during testing. K-fold cross validation of course leaves a sample out during training, but having a separate dataset of samples allowed us to test beyond the holdout approach. It is effectively a simulation of polymorphic malware or hand-crafted malware behaviour, where the interaction with the system on which it is run leaves a different footprint to previous samples. We found that there was a significant drop in performance when the model was exposed to an unseen dataset with an equal balance between classes.
Finally we combined the SOFM with an ensemble classifier based around a Logistic Regression model and used the Best Matching Unit output from the SOFM – which represents “fuzzy neighbourhoods” of system behaviour – as features, in place of the continuous machine activity data used in the previous experiments. We saw an increase of classifier performance of between 7.24% and 24.68% over the state of the art when using this novel approach to malware classification. The findings suggest that the neural-type model for learning, combined with an ability to provide flexible classification boundaries using the SOFM shows promise as a method for the detection of APTs and polymorphic malware where the activity carried out during the attack may vary between samples.
Future work will include increasing samples size and granularity of data to determine if other models can perform better with increased behavioural context through more fine-grained data. We will also look to try and model phases of system behaviour with an aim to detect such attacks at an early stage rather than waiting for full execution of the malicious payload.
