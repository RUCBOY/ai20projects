LPA and K-shell decomposition algorithm are two efficient algorithm with simple concept. In this study, we combine the advantages of the two algorithm and implement the parallelization of the procedure of our algorithm. Propagation probability and similarity are integrated into the iteration of label propagation and selection. All the procedures run in parallel, and multiple label with probability are allowed to be assigned to a node. Hence the algorithm can discover overlapping communities. The experiments on large-scale networks shows the stability and extension of our proposed method. In this section, we conclude some key points of our algorithm. Different neighbors may have different influence on a node, so it is reasonable to assign weight for every node. In the preprocessing stage, we use traditional K-shell decomposition combined with neighborhood index and position index to obtain the final weight of nodes, we can easily get the neighborhood index using degree of each node, and the position index can be calculated by the iterative information during K-Shell decomposition. Since the time cost of K-shell is nearly linear, so the weight of nodes will be soon obtained. Then calculate the propagation probability and similarity between each pair of nodes, it is convenient to figure out through formulation 3,4 and 5, so the time cost of preprocessing stage is fast. In the parallel computation stage, we use GraphX framework to implement our algorithm, GraphX exposes a set of fundamental operators as well as an optimized variant of the Pregel API and supply convenient tools to support iterative computation, the intermediate results are stored in the memory instead of disks. In the stage of label selection, suppose that node A want to update its labels, A receives labels from its neighbors, then calculates the most similar node among its neighbors, finally, updates its labels by formulation 6. We also set the threshold parameter to control the speed of convergence. That is why our algorithm so efficient.
Several issues remain for further research. First, the calculation of similarity between nodes can be enhanced to get more stable results. Second, the algorithm can be improved to be practical by considering the dynamic network. Third, with the rapid emergence of new parallel computation frameworks aside from Hadoop and Spark, efficient parallel operators may be utilized to improve the performance of the algorithm.
