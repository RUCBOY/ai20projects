This paper focuses on a new insight into structure-driven optimization from the perspective of manifold constraint. With a simple neighbor-preserving embedding method, a MADMM scheme is developed to solve our problem. Finally, based on a new and general theory, we transfer the data manifold constraints to the optimized variables, leading to the manifold constrain transfer (MCT) method. In MCT, we introduce a general framework to transfer the structure of the data as the constraint of the variable, in other words MCT addresses the new problem: “how to transfer the data structure into the optimization process”. The proposed approach is successfully applied on correlation filter learning and SRC. On real applications including object tracking, face, digit, action and general object recognition, MCT achieved a consistent increase on performance compared to the state of the arts. The future work can focus on more applications, object detection and low rank data recovery, where manifold constraint can be considered for performance improvement. Considering that the manifold assumption and linear model may not hold for every problem in the literature, there are possibilities to study an even stronger generalization of our approach. For instance, a Taylor expansion method could be a possible way to relax the non-linear constraint problems to be linear ones. In a different way, we can also try to give a theoretical result when the data has a more complex distribution in terms of manifold structure.
