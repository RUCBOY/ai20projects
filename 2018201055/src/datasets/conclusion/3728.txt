6.1. ConclusionsAs explained in Sections 3 and 4, information for estimating breast cancer stage and risk can be obtained using different imaging modalities. Methods focused on in this review include histological appearance of the breast nuclei and epithelium detected in biopsy specimens, radiological appearance of abnormality and parenchymal patterns in densities revealed by mammograms. These imaging modalities that manifest across multiple different length scales (micro and macro imaging scales) offer a wide range of information and clinicians combine these heterogeneous sources of data for better disease diagnosis and treatment planning. However, as described in Section 2, many cases with suspicious abnormal findings in mammography who went for further biopsy, eventually were found to have unnecessary biopsies. Motivated by the biological association between mammography and histology (covered in Section 5) and considering the capabilities of deep learning based models in learning from raw data suggests a methodology to potentially reduce biopsies. It is assumed that the appearance of mammographic abnormalities can be linked to specific histological information and can predict how the micro-biological changes are reflected in macro-images.
6.2. Mammography–Histology–Phenotype–Linking–ModelFinding radiological-histopathological correlation/association has been investigated from a biological point of view as described in Section 5. Most of these epidemiological studies are based on empirical observations and statistical risk analysis. However, to the best of our knowledge, a computer based model of such correlation/association is not yet developed. In this paper, we have tried to cover this research question and propose a general framework for fully automatic linking of mammographic and histologic phenotypes.Fig. 8, shows the development of automatic CAD systems for the mammography and histology data analysis (covered in Sections 3 and 4, respectively), which are expected to use modern machine learning techniques (e.g. deep learning, Convolutional Neural Networks, autoencoders, etc.) to determine a set of mammographic (FM) and histological (FH) phenotypes/features/abstracts, which are discriminative in various image processing tasks such as detection, segmentation and classification. It should be noted that the modelling will be an optimisation process and for the training data the labels are used to estimate the model parameters and generate appropriate features.Download : Download high-res image (718KB)Download : Download full-size imageFig. 8. Separate CAD models for (a) mammography (ModelM) and (b) breast histology (ModelH).Once the mammographic and histological models are estimated, they can be used to generate patient matched mammographic and histological feature/phenotype weighting and their relationship can be estimated by developing a model linking the two based on machine learning techniques (see Fig. 9). The automatic extraction of morphological/appearance features from mammographic and histological images and building a map between these based on a large dataset form essential parts in developing such a model. One possible solution for developing such a “Mammography–Histology–Phenotype–Linking–Model” or in short “MLM<−>H” is shown in Fig. 10. In this approach, a mammographic model (ModelM) can be trained, which is based on minimising the difference between NHS/BIRADS labels provided by expert radiologists and those predicted/estimated by the model. Subsequently, salient deep and high level features are generated (FM) and a pool of deep learning based features is created for each individual image. Similarly, a histological model (ModelH), which is based on minimising the difference between NHSBSP histopathology reports and those predicted/estimated by the model can be trained. Using the Nottingham Grading System (NGS), this model is able to predict scores of 1–3 for three cellular components important in breast histology diagnosis (i.e. nuclei, tubules and mitoses). At the same time, this model is capable of creating a pool of high level and deep learning based features for each component. Permutation of the 3 scores for each histological component with 2 possible outcomes (benign and malignant) will result in 54 possible occurrences (33 × 2). Therefore, 54 clusters can be formed, although it should be noted that some might only be sparsely populated. To develop the MLM<−>H model, the starting point is to generate a set of matched mammographic and histologic features/abstracts created by ModelM and ModelH, respectively. To achieve this, the created mammographic features are associated with their respective NGS cluster and a pool of representative mammographic features for a specific cluster is formed. Meanwhile, each cluster in the permuted set contains a pool of previously generated histologic features. A mapping between the two feature spaces will be provided considering that mammographic and histologic data are provided for individual cases. Eventually, machine learning techniques are exploited to retrieve different morphological appearances for each cluster, resulting in the final MLM<−>H model.Download : Download high-res image (414KB)Download : Download full-size imageFig. 9. General framework for developing the Mammography–Histology–Phenotype–Linking–Model. (a) ModelM: mammographic machine learning based model creating mammographic features (FM); (b) ModelH: histological machine learning based model creating histological features (FH); (c) the MLM<−>H model for providing associations between mammographic and histologic features.Download : Download high-res image (440KB)Download : Download full-size imageFig. 10. Proposed methodology of developing the Mammography–Histology–Phenotype–Linking–Model using deep learning based approaches. ModelM: mammographic deep learning based model, ModelH: histological deep learning based model, FM: mammographic high level deep learning based features, FH: histological high level deep learning based features, MLM<−>H: relationships between the mammographic and histologic phenotypes. This can be achieved by: (1) creating different clusters based on permutation of 3 histological score occurrences; (2) associating created pools of deep learning based features to the proper cluster based on the available annotations and making discriminative clusters; (3) matching representative pools of mammographic and histologic features; (4) by using high level histologic abstracts and performing deconvolution/decoding of ModelH, morphological approximations can be estimated.An alternative approach to develop the MLM<−>H model (see Fig. 11) avoids the need for clustering and basically uses the matched FM and FH features, as respectively input and output to build a simple autoencoder model which maps the two domains through a reduced set of features. The downside of such a model is the lack of clinical reference of the reduced feature set, whilst the advantage is the simplicity of the resulting MLM<−>H model.Download : Download high-res image (61KB)Download : Download full-size imageFig. 11. Proposed methodology of developing the Mammography–Histology–Phenotype–Linking–Model using deep learning based approaches. ModelM: mammographic deep learning based model, ModelH: histological deep learning based model, FM: mammographic high level deep learning based features, FH: histological high level deep learning based features, MLM<−>H: relationships between the mammographic and histologic phenotypes. This can be achieved by using matched FM and FH features as input and output of a neural network (e.g. an autoencoder)The final stage of development is to use unseen mammographic cases to predict the histological classification based on the Nottingham Grading Scheme. An overall predictive model is shown in Fig. 12. An unseen mammographic case can be processed in a number of ways, which all require initial processing towards a mammographic phenotype/feature (FM) representation. The mammographic classification stage (CM) leads to mammographic NHS/BIRADS classification. Using appropriate similarity measures in the MLM<−>H model, predicted feature sets are associated to the closest cluster which results in NHSBSP Histopathology Reporting Form classification (or the NN model) and the set of matched abstract features (FH), which with ModelH leads to the estimation of histological appearance/ phenotypes.Download : Download high-res image (293KB)Download : Download full-size imageFig. 12. Using the Mammography–Histology–Phenotype–Linking–Model (MLM<−>H) for unseen cases. ModelM: Mammographic machine learning based model, ModelH: histological machine learning based model, FM: mammographic phenotypes, FH: histological phenotypes, CM: mammographic classification, MLM<−>H: relationships between mammographic and histologic phenotypes.
6.3. Possible challengesDespite the promising results obtained by deep learning approaches, there are remaining challenges for the development of the MLM<−>H model, which include:
1.Data availability: The first and most basic challenge is the availability of a large number of training samples specifically for this application since the mammograms and histological images should be matched for individual women. The number of samples should be large enough for deep network training purposes. However, existing datasets can be used in the pre-training stage to compensate for the lack of annotated mammography/histopathology data. Appropriate data might be available on existing PACS (Picture Archiving and Communication Systems). As explained in Section 1.1, women are sent for mammography imaging prior to biopsy. Therefore, for the existing histological data, the respective mammograms and the corresponding diagnostic reports exist in digital structured archives, but ethical and research governance agreement and approval will be necessary.2.Combinational ground truth: Appropriate ground truth for the validation part of each individual, mammography and histology image processing, task should be defined systematically. For example the annotations required for breast tissue segmentation in mammograms (characterisation) is different from the annotation required for cancer and non-cancer classification of the tissues. The annotation required for the mitotic count (characterisation) in histopathology is very different from the annotation required for cancer and non-cancer classification of the regions (classification). For associating abnormal phenotypes in a mammogram to characteristics of the tumour in histology, some specific annotations (location and type of abnormality along with locations of nuclei, mitosis count and tubules morphology) are of interest.3.Subjectivity of annotations: If possible, annotations should be provided by different radiologists and histopathologists to accommodate subjective variations. This inter/intra expert variation then needs to be taken into account (Irshad et al., 2014).4.Robustness to data acquisition methods: The issue of robustness to various clinical/technical conditions should be addressed so that gradually more datasets can be added. These variations include: different scanners used for image acquisition; different lighting conditions; various size and views in both mammography and histology; different staining appearance characteristics and magnification factors in histology. The developed method should be robust with respect to such variabilities and appropriate normalisation techniques could facilitate this.5.Interpretability of model layer information: Unlike hand-crafted features that provide transparent information, which are more intuitive and interpretable to clinicians and researchers, deep learning driven features rely on filter responses solicited from a large amount of training data which suffer from a lack of direct human interpretability. Therefore, approaches to blend domain inspired features with deep learning based features can be taken into consideration in order to take advantage of domain knowledge while enabling the classifier to discover additional features.6.Association making algorithms: New algorithms for combining mammographic and histologic measurements should be designed, which is a more detailed version of the high level descriptions provided in Section 6.2. By finding and visualising a logical association between outcome features introduced by deep networks and the salient diagnostic features incorporated in conventional machine learning based CAD systems, a subset of clinically salient features can be determined. Such association making algorithms, as the novel part of mammographic-histologic linking map introduced in this paper, is an open challenge for future research. One alternative approach to tackle this challenge is by combining image data with text reports as addressed by Shin et al. (2015) while expanding this to the field of radiology and histology in order to mine the semantic interactions between radiology and histology images and the corresponding reports.7.Clinical feedback: More evidence and feedback regarding the results of clinical applications using the developed models will need to be provided by clinicians. Close cooperation between radiologists, pathologists and computer scientists will be necessary for the optimum management of data, analysing the performance of developed methods in a clinical setting with feedback from the radiologists and histopathologists throughout the research process.
6.4. Clinical relevanceThe described linking map is expected to reduce the need for further biopsy when the mammographic abnormality is deemed benign as it is reported from a biological point of view (Tot and Tabár, 2011). This association map could contribute to clinical decision making, diagnosis and treatment management. This may also improve the capabilities of computer aided prognosis systems to find patients susceptible to specific breast cancer types at an early stage and as such decrease time before diagnosis, expense and stress. This exploratory research work could be further extended to finding the link between mammography phenotypes, histological signatures and protein/gene expression and so be useful for predicting recurrence of and survival after breast cancer. Other imaging modalities for breast imaging, such as MRI and Ultrasound could be exploited in the development of a linking map. This could also cover various ethnic populations and links to breast cancer pathways. It could identify sub-cellular patterns of involved proteins and their locations for cancerous and non-cancerous tissues by avoiding the need for invasive biopsy sampling. Identification of the factors responsible for high-risk histological changes can potentially lead to modelling of disease appearance, better prediction of disease aggressiveness and finally patient outcome.
