In this paper, we have presented an iterative, improved CNN framework to handle unbalanced training datasets. It provides a universal and powerful scheme to further enhance the performance of the sate-of-the-art deep neural networks. Meanwhile, many of the involved technical elements, including hyper-graph based CNN feature subspace construction, inner-class heterogeneity, and inter-class homogeneity definition, multi-level features/distributions involved hierarchical Bayesian model, and Bayesian prior guided iterative generation of virtual training samples, collectively contribute to many other pattern recognition related applications in computer vision and other related fields. Moreover, different types of experiments have demonstrated our frameworkâ€™s advantages in terms of accuracy, robustness, convergence, efficiency, and versatility.
However, at present our framework still has some limitations. According to our experiments, both GoogLenet and deep residual networks, trained over the willfully-tailored subset of the well-balanced Imagenet dataset, perform worse than those trained over complete Imagenet dataset. It indicates that, the synthetic images generated by our DVN may have some semantic conflicts with the real-captured images. Therefore, in the near future, we will also endeavor our upcoming efforts to exploit and encode more semantically meaningful priors in our framework.
