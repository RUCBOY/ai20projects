We argued that actions may serve as information-dense states and provide rich context information for the learning agent. Such a density is quantified and measured by entropy of information in actions. Furthermore, some discrete, fine-grained, and handcrafted labels typically used by Markov models such as phoneme stages helped by k-mean clustering, which are popular in speech recognition and object recognition research, are not always necessary. We introduced the free-of-labeling property of DN-2 to support our viewpoint. To deal with the silence problem, we proposed a model of cochlear processing which includes volume information. Our experimental results have shown an improvement of the performance. In the simulated cochlea, hair cells are refined so that temporally denser frames are fed to the DN for learning. Our experimental results indicate, to some degree, that taking actions as contexts is useful for context generation. With more information-dense contexts, the processing performance of the sequential data is better. Hidden neurons’ distributions in different stages are visualized to help us analyze DN’s learning procedure. We plan to implement this approach to word level and sentence level in the future.
