The current work describes a method of understanding 3D indoor scenes from a single image. Through extracting and classifying the projected rectangles, the method not only estimates room layout of scene, but also can reconstruct excellent details of scene. In the mathematical inference, the camera focal length f was considered an unknown constant. However, the method requires no concrete value of focal length. Therefore, the method can run without the knowledge of cameraâ€™s intrinsic parameters, nor of the relation between the camera and world. Also, for an input image that contains a lot of occlusions and clutter, the method can cope with clutter without prior training. Comparing against the room box ground truth labels, methods performed well in measuring the percentage of pixels that were classified correctly. Furthermore, estimating correct details is an important indicator of scene understanding, and our method can reconstruct excellent details without prior training. Due to simple geometric inferences, our method runs in real-time, making it practical and efficient for a navigating robot. In addition it is robust against changes in illumination, color, and features of realistic scenes, such as different levels of clutter with incomplete surfaces and coverage. Without other external device, it has the advantages of lower investment and energy efficiency. The current approach supports processing for video frames. The experimental results indicated that our method is capable of reconstructing various structures of indoor environments and that the accuracy and speed of this method can meet the requirements of indoor robot navigation.
