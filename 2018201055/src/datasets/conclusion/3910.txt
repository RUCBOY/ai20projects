In this project, our team of social scientists and computer science engineering researchers proposed a novel framework for analyzing, identifying, and predicting the flow of misinformation on digital platforms. Using an evolution tree modeling method, we examined how misinformation was initiated, transmitted, and managed and how it evolved in the hybrid online news system. Specifically, we identified antecedent tweets about fake news stories as well as the authors of those root tweets. We also observed that tweets about real and fake news showed different evolution patterns.
Moving forward, to combat fake news, academics and industries need richer insights into the presence and spread of misinformation on social media venues. In this vein, the current findings help broaden our understanding of the origin and spreading pattern of fake news stories, which is essential to enhance the quality of information flow in digital space. Given that prior research has raised doubts about the role of fact-checking efforts and crowdsourcing corrections (Flynn et al., 2017), it is important to understand socio-technical factors embedded in a networked system and to design interventions and algorithms that disrupt the flow of information from non-credible sources. For example, by detecting information promoted by non-credible sources or related bot accounts, computer scientists can create algorithms that decrease the visibility of such information. This approach would be particularly effective if a handful of sources are linked to the origin of most fake information. Finally, along with this line of algorithmic approach, educational efforts, including literacy interventions about information and digital media, can help inform the digital public about the issues at hand and minimize the misperceptions surrounding them (Mele et al., 2017).
