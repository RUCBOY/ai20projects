This paper provides a novel approach for estimating the missing values of input data matrix. We translate the traditional matrix completion problem as a subspace learning system, and provide a simple formulation proof for its reasonability. To learn the optimal subspace from a matrix contaminated by sparse noise and column outliers simultaneously, we propose a robust matrix completion model and introduce a potential outliers removing strategy. The former can improve the robustness of algorithm to sparse noise, and provide a preliminary estimation for potential outliers. The final subspace learning procedure is conducted on the residual inliers.
Moreover, we present a robust vector completion method, which can be naturally used to estimate the missing values of out-of-sample. More importantly, our method provides a direction for generalizing the existing batch methods to cope with this issue.
It should be noted that we in this paper consider only the situation that the subspace of streaming data is constant or changes slowly. Nevertheless, it may be inapplicable in some practical applications. For instance, the background of a parking lot generally changes over time due to the existing of illumination variation and moving objects. Actually, we can follow the online methods such as ISVD [36] and GRASTA [22] to track the changes of subspace. The relevant investigation will be presented in our future work.
