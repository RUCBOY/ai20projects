In this study, we defined CQHNNs as an analogy of twin-multistate QHNNs. Fig.Â 7 presents a flowchart of the construction of CQHNNs. The current version of CQHNNs underperformed QHNNs in our computer simulations. We discussed the reason for low noise tolerance in CQHNNs from the viewpoint of rotational invariance and self loops. We analyzed the rotational invariance of CQHNNs, and concluded that 2K rotated patterns exist corresponding to each training pattern, as in QHNNs. In addition, we provided the mixture patterns of CQHNNs. We employed the projection rule in our computer simulations, since it is a one-shot learning with large storage capacity. However, the self loops could not be removed. We will need to solve the problem of self loops to improve the noise tolerance of CQHNNs. In future, we plan to study other learning algorithms, in an effort to remove the self loops [25], [26].Download : Download high-res image (392KB)Download : Download full-size imageFig. 7. Flow chart of construction of CQHNNs.
