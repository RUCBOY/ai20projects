In this paper, we have reviewed the latest developments of deep neural networks. Some widely-used deep learning architectures are investigated and selected applications to computer vision, pattern recognition and speech recognition are highlighted. More specifically, four classes of deep learning architectures, namely the restricted Boltzmann machine, the deep belief networks, the autoencoder, and the convolutional neural network, are discussed in detail. Since it is rarely possible to obtain labeled data in applications involving big data analysis, the supervised learning algorithms can hardly provide satisfactory performance in such cases. Based on these deep learning approaches, we can now use unsupervised learning algorithms to process the unlabeled data. Moreover, the trade-off between accuracy and computational complexity can be adjusted with flexibility in most deep learning algorithms. With the rapid development of hardware resources and computation technologies, we are confident that deep neural networks will receive wider attention and find broader applications in the future.
Based on the literature review, some related topics for future research are listed as follows.
•Design of deep models to learn from fewer training data: With the development of big data analysis, deep learning have been used for scenarios where massive amounts of unsupervised data are involved. As an efficient tool for big data analysis, the deep learning technique have achieved great success with huge amounts of unlabeled training data. However, when only a limited amount of training data is available, more powerful models are required to achieve an enhanced learning ability. It is therefore of great significance to consider how to design deep models to learn from fewer training data, especially for speech and visual recognition systems.•Uses of optimization algorithms to adjust the network parameters: The method to adjust the parameters in machine learning algorithms is an emerging topic in computer science. In DNNs, a large number of parameters need to be adjusted. Moreover, with an increasing number of hidden nodes, the algorithm is more likely get trapped in the local optimum. Optimization techniques, such as the PSO [172], are therefore required to avoid this problem. The proposed training algorithm should be able to extract the features automatically and reduce the loss of information so as to mitigate both the curse of dimensionality and the local optimum.•Applications of unsupervised, semi-supervised and reinforcement-learning approaches to DNNs for complex systems: As mentioned previously, deep learning techniques have not brought satisfactory results in NLP. With the development of deep unsupervised learning and deep reinforcement learning, we have more alternatives to train the DNNs for complex systems. The Alpha Go, which combines CNNs and reinforcement learning, has already achieved a great success. Compared with the supervised learning approaches, the unsupervised, semi-supervised and reinforcement-learning approaches, capable of overcoming the computational limitations, deserve further investigation.•Implementation of deep learning algorithms on mobile devices: It should be noted that deep learning approaches, especially CNNs, usually require great computational burden. Recently, the idea of deep learning chips has emerged and attracted great research attention. A chip for neural networks implementation has already been presented by MIT researchers. This chip is 10 times as efficient as a mobile GPU, which means that we can run AI algorithms in mobile devices with lower power consumption. Additionally, Stanford has started the project aiming at optimizing the CPU for deep learning. This area can bring numerous benefits for both industries and academia.•Analysis of the stability of deep neural networks: Dynamic neural networks have been widely used to solve optimization problems and applied to many engineering applications. Nowadays, the stability analysis of deep neural networks has become a hot research topic because of the numerous benefits for industries. It should be pointed out that, so far, there have been a multitude of research results on the stability analysis, stabilization and synchronization problems for various types of systems and networks in the literature, see [174], [163], [168], [64], [67], [68], [143], [102] for some recent publications. By utilizing these exploited techniques, we can further deal with the corresponding issues including stability analysis, synchronization and state estimation for deep neural networks.•Applications of deep neural networks in nonlinear networked control systems (NCSs): Neural networks have been extensively used in control engineering and signal processing to approximate the nonlinear systems. On the other hand, up to now, the NCSs have been widely investigated and considerable results have been reported in the literature, see [106], [107], [108], [109], [21], [170], [169], [69], [65], [142], [103], [104], among which the networked control systems under consideration are either linear or nonlinear with relative simple forms. Thus, it is natural to apply the deep neural networks to approximate the nonlinear NCSs with complicated dynamics to obtain better control/filtering performances.
