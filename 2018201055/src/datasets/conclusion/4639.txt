ZNN achieves high performances by efficiently utilizing the available CPUs. We expect an increase in the number of cores per chip (or Xeon Phi™ card) in the future, making ZNN even more practical. In fact, we have already used ZNN to achieve state of the art results in boundary detection  [18] and computation of dendritic arbor densities  [29].
Having a large amount of RAM available to the CPU, ZNN can efficiently train very large ConvNets with large kernels. ZNN allows for easy extensions and can efficiently train a ConvNet with an arbitrary topology, allowing for new research. This is a unique feature of ZNN, enabled by ZNN’s task parallelization model. Current GPU implementations employ SIMD parallelism to perform computation on one whole layer at a time, thus limiting the network structure. Mainly, the computation is parallelized such that a single thread computes the value of a single voxel of an output image. Libraries like cuDNN provide optimized primitives for fully connected convolutional layers by reducing all the required convolutions in the layer to a matrix multiplication, which is then parallelized on the GPU.
Extending the functionality requires the user to provide a parallelized implementation of the new layer type, which typically requires great knowledge of GPU programming. Researchers often have to wait for a long time for efficient implementation by GPU programming experts. Contrary to that, ZNN’s task parallelism allows for easy extensions by simply providing serial functions for the forward and backward passes, as well as the gradient computation, if required. ZNN’s repository contains some sample extensions providing functionality of dropout   [28] and multi-scale   [20], [27] networks.
