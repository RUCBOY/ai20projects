The main theme of the present paper is parallelization of an implicit DG scheme on a set of networked computers. In order to distribute the computation onto the nodes in the computer network we divide the computational domain into a set of pairwise overlapping subdomains, according to the Schwarz method [15]. The problem is then solved on each subdomain by a different node. The nodes exchange data from the corresponding overlaps after each time step. This enables that the solution may propagate between subdomains. We propose that one iteration of the Schwarz method is sufficient if the width of the overlap is chosen larger enough so that the particles of the fluid cannot cross the overlap in one time step. We also employed parallelization on each of the nodes by means of parallelizing the matrix-vector products in the GMRES algorithm. In addition to parallelization, the paper deals with stabilization of the DG method. We adopt a recently developed stabilization technique published in [25], [30]. Moreover, we propose a modification of the stabilization approach which reduces computational demands and complexity of the implementation.
Ideally, the computational time should be n × k shorter when we use n nodes and k threads at each node in comparison with the same computation with only one node and one thread. This means that the speedup would be n × k which corresponds to 100% of efficiency. In reality this is never the case due to the transfer of data among nodes and threads and also because of the redundant computation, which is, in the case of our algorithm, caused by the overlaps. In general, the overhead tends to decrease with the size of the problem. In other words, the more element the computational mesh has and the higher the degree of approximation, the more efficient the parallelization tend to be, see Table 2, Table 3, Table 4, Table 5, Table 6 in Appendix. This is mainly caused by the fact that the data transfer, which occurs between time steps, is less frequent. This is evident in the test problem 1, where the maximal speedup (for 9 nodes and 24 threads) is 45.9, 65.8 and 79.5 for the 2nd, 3rd and 4th order of accuracy, respectively. The test problem 2 demonstrates the efficiency of parallelization when seeking the time-dependent solution for inviscid fluid flow problems. The benchmarks for the first two test problems were performed on the nine-node cluster each with 12 cores, which corresponds to the total of 108 cores. Therefore we can compare benchmarks in the test problem 1 and 2 with the same 2nd order of accuracy. As expected, speedup is higher in case of the test problem 1, since its computational mesh has more elements (82 299 elements with maximal speedup of 45.9) in comparison with the test problem 2 (41 666 elements with maximal speedup of 28.6). Note that the efficiency for 24 threads in the test problem 1 and 2 and for 8 threads for test problem 3 is expected to be relatively low, as in these cases the number of threads is two times larger than the number of physical cores (hyper-threading technology is exploited here).
Let us look at the efficiency of the parallelization on n nodes each using only one thread in comparison with a single node with n threads. Table 1 contains such result extracted from Table 2, Table 3, Table 4, Table 5, Table 6 in Appendix. Here, the parallelization at the level of a computer network shows slightly higher efficiency than the parallelization at the level of a single computer.Table 1. Comparison of efficiency of the parallelization at the level of computer network and at the level of a single computer.# of nodes# of threadsη [%]problem 118742nd order81808850problem 118613rd order81838864problem 118824th order81908873problem 218752nd order81668836problem 312942nd order21942286
One of the crucial requirement for the parallelization was to be able to use it for various types of computers with various operating systems installed. This is relatively easy with the Java Remote Method Invocation (Java RMI) technology, since it is included in Java, which is a platform independent programming language. The size of the subdomains may also be adjusted to the performance of the particular nodes. In order to test the performance on a heterogeneous computer network, we designed the test problem 3, results of which are available in Table 6 in Appendix.
In this work we conducted performance test only for smaller test problems. The efficiency for smaller problems drops rapidly when we approach to 10 nodes. In case of large scale problem we expect improvement of efficiency. Our future work will include benchmarking the developed parallelization approach on complex 2D and ultimately 3D problems for larger number of nodes.
