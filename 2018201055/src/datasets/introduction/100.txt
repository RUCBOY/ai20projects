Visual object classification is a fundamental task for a wide range of applications. Traditional algorithms mostly conduct classification tasks in two steps: extraction of hand-crafted features, and classification using a particular classifier [2]. Those manually designed features only work well in specific applications, with relatively small data, and may fail once transferred to a new application, or a much large dataset. In recent years, Convolutional Neural Networks (CNNs) have become the dominant computer vision approach in image classification. Compared with the two-step traditional classification pipeline, CNN completes the task using an end-to-end method. The way of self-feature generation improves the robustness of CNN, producing the state-of-the-art results in many applications [3], [4], [5].
To yield higher level feature maps, the number of convolutional layers of the state-of-the-art CNN has increased generation by generation [3], [6]. More recently, Residual Network (ResNet) [7] and Densely Connected Convolutional Networks (DenseNet) [8] have expanded this number to more than 100 layers. However, the channels in the inputs of a layer may be redundant. In [9], Veit et al. have found that the deep residual network performs as a combination of several shallow networks. The heat map of DenseNet (shown in Fig. 1) demonstrates the same effect: not all channels in the concatenated input feature maps are essential for the classification tasks. Only a few channels are weighted with a relatively high value and the rest are depressed. The redundant information from these low significance inputs will not only impede the prediction accuracy, but also cause a waste of computational resource.Download : Download high-res image (213KB)Download : Download full-size imageFig. 1. The average absolute filter weights of convolutional layers in DenseNet40 (G=12), trained on the CIFAR-10 dataset. The color patch (s, t) denotes the average L1 normalized (by number of input depth) weights in the layer “t” which takes input from the layer “s” in the same block. The last column of each block denotes the transition layer for the first two blocks and the fully connected layer for the last block, respectively. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)
In this paper, we aim to develop a robust approach to achieve a good trade-off between the efficiency and accuracy by selecting key channels from the inputs. The whole structure is self-generated without manual interference. Generating the model from scratch without constraints [10], [11], [12] would involve a huge amount of computational cost, and the generated model could easily suffer from overfitting. Thus, we constrain the framework of the model, which is learnt using state-of-the-art CNN models, as the “prior knowledge” of the model. Finding the best one by enumerating all the combinations is impractical, because the number of permutations increases exponentially with the number of layers. Rather than a full search of all the combinations, a more effective solution is to optimize the structure using neural architecture search (NAS), which may be based on an evolutionary algorithm (EA) [10], [13], reinforcement learning (RL) [12], [14], gradient descent [15], or other methods [16]. For the existing approaches, there exist the following drawbacks:
i.High computational complexity and cost: For neural evolution methods [10], [13], [17], denote the number of populations as I and the number of the generation as NG, the whole training procedure will be required to train I × NG individuals. In order to achieve a higher performance, the values of both I and NG should be sufficiently large. In [10], experiments were conducted on about 250 high-end computers. A similar limitation also exists in the reinforcement learning and gradient descent based method. The “discover” process also consumes a huge amount of computational resources. In [11], which adopts reinforcement learning, about 10 Graphic Processing Units (GPUs) are deployed.ii.More hyperparameters are required to control the searching process;iii.The learnt architectures are not robust, i.e. architectures obtained by EA perform well on the datasets they are trained on, but perform poorly on the new datasets.
To tackle these challenges, in this paper, an improved pipeline is proposed for training, in which the Genetic algorithm (GA) is employed to optimize the self-generated model. As we focus mainly on reducing the computational cost, we apply a binary encoding method to represent the structure of the model in a binary string, where “1” and “0” indicates whether the feature is allowed to pass into a layer or not. Three GA operations, selection, crossover and mutation, are employed to evolve the structure. After conducting the selection on each generation, poorly-performing structures are discarded. We measure the performance of the model by evaluating the accuracy on a validation/test dataset.
To improve the training efficiency, a variable-inheritance-fine-tune training method is proposed. Following the experimental settings in [10], instead of training each “individual” from scratch, we apply “variable inheritance” to reduce computational cost on each “individual”. This means that a reused kernel will be reinitialized using the values obtained from training on the previous generation rather than randomly generated from a Gaussian distribution. We utilize the structure of the DenseNet as our baseline framework. Compared with the baseline, our model can reduce the number of parameters by up to 30% whilst maintaining the same accuracy. Although the GA procedure is mainly conducted on the CIFAR-10 dataset[18], the model produced also performs well on other datasets and is easily transferred onto large-scale datasets. The experiments can be conducted on a single GTX1080Ti GPU hence the model is very portable and affordable.
Contributions. the main contributions of this paper can be summarized as follows:
i.Based on the DenseNet, an effective GA training pipeline is proposed to select the key input channels of the convolution layers automatically;ii.Under limited computational resources, mechanisms are proposed to optimize the GA process by applying ’weight inheritance’ to reduce the total computational cost without degrading the training or testing accuracy of the models;iii.The self-generated model structure can reduce the number of parameters by up to 30% while achieving a similar accuracy as the baseline with a significantly reduced computation time;iv.Experiments show that our self-generated model structure performs well not only on the trained dataset, but also on untrained datasets. Even when the structure is generated using a small-size dataset, it was found to work well on large-scale image datasets.
The remaining parts of this paper are organized as follows. Section 2 gives a brief introduction to the related work. The design of the GA training pipeline and the experimental results are detailed in Section 3 and Section 4, respectively. Finally, some concluding remarks are given in Section 5.
