1.1. BackgroundThe past decade has seen unprecedented growth in industries and services that depend on computational capabilities provided by computer scientists and other STEM professionals trained in the use of computational and data-intensive tools, techniques, and theory (Stanton et al., 2017). However, this growth has not benefited all who are capable or aspire to do this computationally-intensive work. Large segments of the United States (U.S.) population, including women and people from historically marginalized groups such as African-Americans and Hispanic/Latinx, are not adequately represented in computationally-intensive STEM professions and in the higher education degree programs that train them (Google and Gallup, 2016; Levitan, 2018).Middle grades (ages 11–13) have been identified as a critical age for engaging students, especially females and students from historically marginalized groups, in computational thinking (CT) and computer science (CS; Denner et al., 2012; Grover et al., 2016). Research has explored how we can increase student retention (Basawapatna et al., 2010) and improve learning for CT and CS (Rachmatullah et al., 2020; Wilkerson-Jerde et al., 2015) using approaches ranging from game-based learning to robotics and music (e.g., Sharek & Wiebe, 2014; Edwards, 2011).Exposure to computational activities in school can increase students’ interest and ability in computational thinking and computer science, which in turn can shape their motivation to engage in computing activities in the future and perhaps even to consider careers in computer science. Researchers and curriculum developers have sought to design curricula and learning experiences that positively impact students’ computer science (CS) attitudes, especially during these crucial, formative middle-grade years (Lewis, 2010). Thus, attitudinal assessment is an essential component of curriculum development as it helps to verify the effectiveness of new curriculum interventions (Porter, 2006).To date, there are some published validation studies on the development of CS-attitudes scales (e.g., Korkmaz et al., 2017; Tsai et al., 2019). However, much of this work is not guided by foundational psychological theory nor does it utilize robust psychometric validation methods. The published instruments focused more on measuring attitudes towards the CS constructs, such as algorithm, conditional, and control (e.g., Tsai et al., 2019). We argue that these specific constructs, as well as the vernacular associated with them, are too complex for middle school students to respond to in a meaningful manner. In addition, a construct-level approach misses the goal of capturing a holistic affective response to CS rather than to specific topical areas within the field. Finally, construct level assessment works at a granularity that greatly lengthens the instrument, creating the risk of subject fatigue and non-compliance that far outweighs any additional information that might be gained (Groves et al., 2009; Tourangeau et al., 2000).In response, we followed previous studies on STEM attitudes, such as the studies conducted by Else-Quest et al. (2013), Summers and Abd-El-Khalick (2018), and Shin et al. (2018), where they define attitudes as psychological constructs that consist of, but not limited to, self-efficacy and outcome expectancy. In this current study, we focused on these two constructs suggested by Osborne et al. (2003) as considered core components of education-related attitudes. They also add that these constructs are easily recognized by students in self-report questionnaires. Building off of these initial works, we report on the development and validation process of an English language instrument for measuring attitudinal states related to CS educational experiences for middle-grade students (MG-CS Attitudes) that utilizes a theoretically guided validation process.
1.2. Theoretical framingThe goal in developing this instrument is to give researchers and evaluators a short, self-report instrument that would provide insight as to the impact of educational interventions intended to improve students’ interest in engaging in CS-related educational activities. Our study attempted to address this need by utilizing a well-accepted psychological theory – expectancy-value theory (Eccles and Wigfield, 2002; Wigfield and Eccles, 2000). A modern social psychology model, expectancy-value theory, takes the fundamental notions of self-determination theory (Deci and Ryan, 1985) and places them within a goal-directed environment, such as academic and career pathways. Expectancy-value theory also leverages Bandura’s (1986) conceptualization of self-efficacy, the belief in one’s ability to complete tasks or influence events that have an impact on one’s life. Self-efficacy has two broad facets: general self-efficacy to face challenges and tasks and self-efficacy specific to a particular task domain (Chen et al., 2001). Drawing on the latter, expectancy-value theory helps frame self-efficacy and outcome expectancy in terms of prospects of success in a particular academic domain and the value of this academic subject area in relation to future goals. Expectancy-value theory expands on outcome expectancy in academic work by positing that achievement-related performance and future academic or career choices are most directly influenced by the individual’s expectations of academic success and the subjective assessment of the inherent value of these academic tasks (Eccles and Wigfield, 2002; Guo et al., 2015). Expectations for success and the value a student associates with this are assumed to directly influence performance, persistence, and choice in (academic-related) tasks.Collectively, self-efficacy and outcome expectations shape the goals students set for themselves, based on both the expected outcome and the value they place on that outcome. These goals can be motivated by both the positive desire for a particular outcome and the desire to avoid negative outcomes (Eccles, 1994). Early in the development of these social psychology theories, researchers explored the influence of demographic—including age, gender, and race/ethnicity—and individual differences on the development of self-efficacy, outcome expectations, and career interest (Fouad and Smith, 1996). For example, closer to career entry, these goals may be aligned with actual career choices, while earlier in a student’s academic life, they may be manifested in broader, more abstracted career interests. Thus, it is important to recognize the dynamic, reciprocal nature of self-efficacy, expectancy outcomes and academic-career goals that emerge from these psychological states and evolve over time.
1.3. Related workPrior research on the relationship between students’ non-cognitive aspects of learning in other STEM areas such as science and mathematics has shown a strong relationship between learning experiences, attitudinal variables such as self-efficacy and outcome expectancy, and future intentions with regards to career pathways (e.g., Beal and Crockett, 2010; DeWitt et al., 2014; Sadler et al., 2012). Emerging research in K-12 CS education has similarly revealed important relationships between gender (Guzdial et al., 2012), membership in underrepresented groups (McKlin et al., 2019), and future career paths (Orton et al., 2016).Separate literature synthesis efforts by both Fraillon et al. (2019) and Román-González et al. (2019) reaffirmed the need to continue working on developing instruments designed to measure the cognitive dimensions of computer science and computational thinking (CT) understanding, and the associated non-cognitive factors such as self-efficacy and outcome expectancy that influence these cognitive outcomes. One of the earlier instruments related to these non-cognitive factors include the CS Attitude Survey (Wiebe, Williams, Yang, & Miller, 2003), though McKlin et al. (2019) and others have noted this instrument’s basis in somewhat outdated psychological models and the lack of construct validation work to link it to more modern attitudinal and motivational models. More current works on the development and validation of the CS-attitudes instrument were conducted with students from non-English speaking population, which can create issues of measurement error when translated to English. (e.g., Korkmaz et al., 2017). Korkmaz et al.’s (2017) Computational Thinking Scales (CTS) is a 29-item instrument that has individuals self-report on their agreement with statements related to five different dimensions of computational thinking, such as algorithmic thinking and creativity. The instrument was validated with undergraduate students without clear theoretical guidance from non-cognitive constructs such as self-efficacy or outcome expectancy, though many items could be construed as measuring these factors. A similar effort by Kukul et al. (2017) was undertaken with the Computer Programming Self-efficacy Scale (CPSES). This 31-item instrument was based on self-efficacy theory and validated with 12–14 year old Turkish students. As with Korkmaz’s instrument, they developed items around a computational thinking framework, with the items targeting self-efficacy related to fine-grained CT concepts (e.g., “I know how to use the programming variables”). These two recent instruments both take an approach to structure item sets around CT/CS constructs and attain reliability through the development of multiple items related to each facet of these CT practices or concepts. The broad nature of the CT/CS frameworks used in their development results in multiple factors and fairly long instruments. Long instruments are often the result of attempting to cover all facets of a construct but can create their own reliability and validity problems resulting from logistical time pressures or respondent fatigue (Maloney et al., 2011).The most recent work on a CS-related self-efficacy scale is the Computer Programming Self-Efficacy Scale (CPSES) developed by Tsai et al. (2019). CPSES consists of fifteen Likert-scale items that measure students’ self-efficacy in five programming domains: logical thinking, algorithm, control, debugging, and cooperation. Thus, this instrument takes the same general approach as Korkmaz et al. (2017) and Kukul et al. (2017) did in developing multiple items across different CT/CS practices. Even though the Tsai et al. (2019) claim that their instrument is capable of measuring students’ perceptions of their computational thinking skills, the instrument lacks a clear exposition of the psychological theory that underpins its development. Moreover, the wording of some of the Tsai et al.‘s CPSES items shown in publication (e.g., I can make use of divisions to enhance programming efficiency, and I can figure out program procedures without a sample.) raises questions as to whether validation was undertaken in the same language as that of the publication. As Messick (1995) notes, theoretical framing and wording precision are essential in the instrument development process, because it is central to ensuring the content validity of an instrument. Thus, translations of instruments need to be revalidated. Finally, while they state the instrument is for use with middle school students and older, the validation sample was college-aged students.
1.4. Current workBased on this literature review, there is a clear need for a validated, short self-report instrument that captures key attitudinal dimensions that might be affected by CT/CS interventions. Literature also points to middle grades as a logical starting point for development of such an instrument. A fine-grained understanding of these CT/CS practices and concepts, and instead target students’ attitudes towards computer science and programming more generally. Guided by prior research work on non-cognitive STEM factors in this grade range, developing item sets would be done around the psychological constructs of self-efficacy and outcome expectancy, both of which have a strong theoretical and empirical basis and have been utilized extensively in the study of student engagement and persistence in STEM-oriented academics and career pathways. Rather than attempt to measure fine-grained distinctions in a students’ attitudinal orientation towards specific CS concepts (e.g., loops, variables), this new instrument would capture broader orientation towards CT/CS based on these two constructs, thus resulting in a relatively compact instrument. Our argument would be that students in this age range are unlikely to have formed distinct responses regarding specific CS concepts and that even if they did, it would be of little utility in guiding intervention design.The current work combines two robust psychometric approaches, Classical Test Theory (CTT) and Item-Response Theory (IRT) Rasch which have been well documented and utilized in the psychometric research literature base. These two approaches, in turn, will be guided by well-established construct validity frameworks (AERA, APA & NCME, 2014; Messick, 1995) to guide the process. There are a limited number of studies in CS education research that utilize these validation methods (e.g., Werner et al., 2012; Zendler, 2019), particularly in the case of attitudinal instruments. We believe that our current work, utilizing foundational psychological theory and robust validation methods will result in an improved instrument for measuring CS-related attitudes for middle grade students. The following sections will report on the development of such an instrument.
