Space travel, up until recently, was constrained by chemical propulsion, large spacecraft, and therefore, relatively slow speeds. Since the main objective has been exploration of our solar system, these methods were sufficient. In contrast, the recent Starlight program (Kulkarni et al., 2017) has introduced methods for deep space travel that utilize small discs, which travel at approximately one-fourth of the speed of light via directed energy.
Alongside the prospect of fast deep space travel comes many new challenges. The normal model for space travel includes spacecraft capable of housing instruments, propulsion and navigational equipment, telescopes, energy banks, and much more. Since the Starlight program will be utilizing small wafersats that are approximately the size of a coffee can lid, all of these features need to be reworked or discarded.
Besides physical constraints, this new model of space travel introduces feasibility constraints as well. The star of interest is beyond four light-years away, meaning that transmission of data and response command transmissions are a combined eight years or more. Thus, the wafersats need to be able to make decisions without human intervention, and for that, artificial intelligence (AI) is paramount.
The major hurdles that we will discuss are those concerning computer vision via planetary detection, data and storage blockages via novelty detection and ranking, and energy management via combining simulator features with subtraction-algorithm-fed computer vision. For all of these issues, taking advantage of a universe simulator will introduce solutions that were otherwise ineffective or impossible to find.
1.1. Previous workThe effectiveness of machine learning, specifically deep learning via TensorFlow and cuDNN, has been indisputably demonstrated in the last decade (Abadi, Agarwal, Barham, et al., Chetlur, Woolley, Vandermersch, et al., Canziani, Paszke, Culurciello). The fight over the best model and the most accurate results, especially between the most popular models like ResNets, DenseNets (Huang et al., 2018), Inception (Szegedy et al., 2015), Masks (He et al., 2018), and models that combine some of these together (Szegedy et al., 2016), is one that has produced a plethora of potent options to choose from. Models that are more accurate than human beings at doing extremely difficult tasks are still being discovered (Rajpurkar et al., 2017).The areas of deep learning and astronomy have come together in recent years (Ruffio, Mawet, Czekala, et al., 2018, Morad, Nallapu, Kalita, et al., Schaefer, Geiger, Kuntzer, Kneib, 2018, Pearson, Palafox, Griffith), mostly in the form of light curves (Shallue, Vanderburg, 2017, Zucker, Giryes, 2018, Carrasco-Davis, Cabrera-Vives, Frster, et al.). The results and general concepts promote a healthy symbiosis between deep learning and the problems that arise in astronomy. Yet, the processes are carried out from Earth, not space, and do not address real images, two big issues that create a gap in comparability.Outside of astronomy, simulators have been used to train data in specific instances where the benefits outweigh the drawbacks. Smyth et al. (2018) outlines some major drawbacks, namely that the process takes a lot of time and knowledge, as well as a note that simulator-based training may not generalize well to real images. Alongside those concerns, McDuff et al. (2018) begins with a common issue in machine learning models, which is that training data sets are often biased. This bias arises when there are minorities in the training set, which in turn produces poor results when the model is asked to evaluate a similar entity in the population. These issues are handled throughout this paper and are shown to not be an issue with the specific problem at hand.Simulators also introduce a lot of benefits. One large one, also seen in Connor and Leeuwen (2018), is that “the small catalogue of real events is probably not yet a representative sample of the underlying. population, nor is it big enough to build a meaningful training set for machine learning, deep or otherwise.” An important theme throughout this paper, and an extremely useful aspect of simulators, is that they provide an untold amount of training data, assuming that one can create realistic simulations.
1.2. Unsupervised learning for planetary detectionThe intuition behind object detection, in particular planetary detection, might point toward an unsupervised learning technique. After all, one might reasonably think that detecting a nearby planet after months of traveling through deep space would be easy. We test this idea using an unsupervised technique called a Grow When Required (GWR) Network (Marsland et al., 2002).1.2.1. GWR setupUsing the worldwide telescope, we generated a 9000 frame series of solar system images. It begins with Neptune, then it explores Mercury, the Sun, and finally Mars. The majority of images contain only background stars.The images were down-scaled to a 320x180 resolution in order to improve computational speed. For learning, they were decomposed into red, green, and blue channels and vectors were constructed of length 320×180×3=172,800.Our challenge is to label each image as novel or regular. That is, we wish to generate a classification n s.t. for each input x, n(x) ∈ {0, 1}, where a 0 indicates regularity and a 1 indicates novelty. Since the video is composed of 9000 images, large objects like planets or the Sun will be in view for a few hundred or thousand consecutive frames. During these large bins when a planet or the Sun is clearly in view, the algorithm should hopefully yield a large number of 1’s and should yield very few 1’s when the image is mostly distant stars.1.2.2. GWR algorithmDefine A as the set of nodes in our network and C as the set of edges between these nodes. We denote our inputs as ξ and the weight vector for any node n as wn. Each node n has a habituation hn which represents how familiar that node is to the system.1.Initialize two nodes that represent two random samples from the dataset. We set their habituations each to 1. The set of edges between nodes begins empty.2.Iterate through the dataset. For each data sample ξ:(a)For each node i in the network, calculate its distance from ξ, which is ∥ξ−wi∥.(b)Find the node s with the smallest distance and the node t with the second-smallest distance.(c)Add an edge between s and t if it does not already exist.(d)Calculate the activity a=exp(−∑j(ξ[j]−ws[j])2/C), where C = 29,203,200 was chosen to prevent an integer overflow. There are 172,800 fields in each data vector, and since the average of the quantities in each vector is close to 13, and 132=169, we divide by 172,800×169=29,203,200.(e)If a < aT and s’s habituation hs < hT (where aT is some insertion threshold and hT is some habituation threshold), then add a new node r. If a new node is added, data point is considered novel. Set wr=ws+ξ2. Insert edges between s and r and r and t and remove the edge between s and t.(f)Otherwise, update the weight and habituation of s as follows: Δws=ϵb×(ξ−ws) and Δhs=τb×1.05×(1−hs)−τb, where ϵb and τb are parameters. Next, update the weight and habituation of s’s neighbors i as follows: Δwi=ϵn×(ξ−wi) and Δhi=τn×1.05×(1−hi)−τn, where ϵn and τn are other parameters.(g)Remove any nodes without any neighbors.Our chosen values are: aT=0.7,hT=0.1,τb=0.3,τn=0.1,ϵb=0.1, and ϵn=0.01.1.2.3. ResultsFig. 1 is a scatter plot that was generated to visualize the novelty detected from the data. The x-axis is the id of each picture, and the y-axis is the number of novel images that were detected in each bin of 100 images. Fig. 2 is a continuous representation of the same concept.Download : Download high-res image (107KB)Download : Download full-size imageFig. 1. A scatter plot of the detected novelty of the data.Download : Download high-res image (108KB)Download : Download full-size imageFig. 2. A binned scatter plot of the novelty of the data. Image ranges that are salient to the human eye are labeled on the plot.Moving along the Image ID axis, we see that novelty was detected in clumps around 0–500, 900, 4000–4500, 6000–6500, 7000–7500, 7700–8000, and 8200–8500. We observed that novelty was detected first on Neptune, then again on some particularly bright stars. No novelty is detected during the long period of only stars. Next we see increased novelty detection when Mercury is plainly in view, and then when the sun appears, and finally when we zoom into Mars.We notice that Neptune’s collection of novelty is roughly one quarter the size of the other three celestial objects that come into view. We also notice a huge spike around image 8300. This is very interesting because there are no large celestial objects in view at this time.1.2.4. GWR discussionA deep space exploration mission would come with many challenging objectives. A small but connected subset of those would involve detecting objects, deciding whether they are important, extracting key features that we would want to study or observe, and prioritizing their information retrieval.GWR wouldn’t be able to decide importance, extract features, or prioritize information retrieval, yet if it could detect novel objects in deep space, this would be useful. We can see from Figs. 1 and 2 that the detection is inconsistent and unreliable. Neptune is almost completely missed and the three smaller peaks at the Sun, as seen in Fig. 2, are larger than Neptune. The largest peak of all happens while Mars is minuscule and essentially not in view.Although GWR had high novelty detection peaks while passing by Mercury and the Sun, it failed to correctly activate at Mars or Neptune. These observations, paired with its inability to do anything further with the data, introduce a need for a more advanced model that can achieve all of the above objectives.
1.3. Object detection vs. novelty detectionThroughout this paper, our main goals will constantly be alluding to object detection and novelty detection. In a general computer science setting, object detection is used to identify something in an image that has already been trained via some algorithm. For example, we may feed thousands of images of human beings into a YOLO algorithm (Redmon et al., 2016), and then once it is trained, we can walk the streets of New York and see if our algorithm can identify human beings. In this setting, identifying a human being is a success, and not identifying a car or stop sign as a human being would also be a success. Yet, identifying anything non-human as a human being would be a failure. The accuracy of a model, which is mathematically computed per identification, can be used as a measure of how sure the algorithm is that the object being identified is the correct type. In this paper, we will delve into why this is difficult for our specific scenario, and we will test whether this can benefit severely from the use of simulators.On the other hand, novelty detection is used to attempt to identify something that has never been seen before. One powerful example is self-driving cars being able to see traffic signs that are unique to a certain country, and therefore have never been seen or used during the training process (Kim et al., 2017). In this example, the self-driving car algorithm has never seen this specific sign before, and so identifying it without any training data is very difficult. In our paper, unseen planetary features are analogous to the unseen traffic sign in the example, and we delve into methods of solving this via simulators.
