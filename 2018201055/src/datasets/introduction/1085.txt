One relatively recent problem that has peeked research interest lately is that of pedestrian attribute recognition. The goal is to identify visual attributes from images, such as age group, gender, clothing style, footwear etc. The problem has a number of applications, mainly in the areas of person identification or visual surveillance, or in the domains for business intelligence by means of video analytics etc. Using the recognized visual attributes, one can search for the suspects in a criminal database. It is a challenging problem because of a number of factors. As there are a large number of variations in these visual attributes, it is one of the main factors that makes this problem difficult to solve. As an example, due to varying lighting conditions, same type of clothing can appear completely different or vice versa. Additionally, weather conditions play an important role in how an attribute will appear to the camera, for example, depending on the conditions, it will be very difficult to distinguish between dark blue and black colors. Furthermore, a number of visual attributes can be completely or partially occluded due to the camera orientation, such as a backpack that can be hidden from the view, or a scarf or the hat that may not appear in the image due to the viewing direction or self occlusions. These issues highlight the fact that a very high intra-class variation exists for the same attributes depending on the number of conditions that exist at the time of image or video acquisition. As this work focuses on the image and video data, the distance of the pedestrian from the camera poses another challenge. As a common practice, the surveillance cameras are typically installed at quite a distance, therefore the acquired image is not able to capture the pedestrian with a good detail. Depending on the image resolution and the distance, the size of the object can be very small, and the poor image quality results in very few pixels assigned to each attribute, e.g. shoes, hats or a backpack can only be a small number of pixels in an already low resolution image. Due to self occlusions, body parts are not always fully visible, and lack in important visual data because of a very low image quality. Some of the sample images from the PEdesTrian Attribute (PETA) and A Richly Annotated Pedestrian (RAP) datasets are shown in Fig. 1. It can be seen that the images are of a very low quality due to a number of reasons: attributes are not visible to due to severe occlusions, the image quality is quite low, some of the images show a significant blur due to acquisition problems.Download : Download high-res image (813KB)Download : Download full-size imageFigure 1. (a) Some of the samples from the PEdesTrian Attribute (PETA) dataset. It is one of the largest dataset that covers more than 60 attributes in 19,000 images of different resolution. A total of 8,705 persons are included in this dataset that are captured from real-world surveillance camera systems. The dataset is very challenging, due to scene settings and the acquisition setup. It can be seen that the images are of a very low quality due to a number of reasons: attributes are not visible to due to severe occlusions, the image quality is quite low, some of the images show a significant blur due to acquisition problems. (b) Some of the samples from the A Richly Annotated Pedestrian (RAP) dataset. This dataset is acquired from more than one viewpoints and covers around 72 attributes over 41 thousand images. The dataset has a large number of variation in viewpoints, pedestrian appearance, and severe occlusions.
Most of the current works that try to solve the visual attribute recognition problem propose a two step solution comprising of feature extraction followed by the attribute classification. Derived features, such as SIFT [1], HoG [2] or Haar-like feature [3], have been predominantly employed for the feature representation in the earlier works. These derived features, which are employed in most of the computer vision solutions over the past two decades, not only need a very high domain knowledge but also require fine tuning for an accurate representation. After the feature representation step, most of the solutions employed Support Vector Machines (SVM) for the features classification [4].
SVM are increasingly replaced by the convolutional neural networks (CNNs) in the last five years. CNNs have been demonstrated to outperform many of the previous approaches for both tasks of attribute learning or image classification. Specifically, we also employ a CNN, but instead of using the regular 2D convolution layers, we adopt the depthwise separable convolution (DSC) layer as proposed in the Xception [5] framework. DSC layers have been used in various applications due to its efficient learning capabilities and reduced parameter set [6], [7], [8]. As shown Fig. 2, each input channel (3 in our case) is treated independently from other channels. The split channels are convolved with a 3×3 spatial filter. The output channels are concatenated and then convolved with a 1×1×n filter, where n matches the depth of our channels. This process reduces the number of parameters for our network considerably. Fewer computations are performed, and results in speeder and smaller models. Specially, when the data available is not sufficiently large, DSC layers have been shown to learn a better data representation and learns better performing models [5].Download : Download high-res image (44KB)Download : Download full-size imageFigure 2. Depthwise Separable Convolution. (Source: [5]).
Based on our previous work [9], the main contributions of the proposed method are:
•To the best of our knowledge, this is the first work to introduce depthwise separable convolution neural networks for the problem of pedestrian attribute recognition.•The proposed multi-layered network is trained efficiently with a smaller number of parameters.•We make novel use of the color spaces for training our network.•The proposed method is demonstrated to have better recognition results than the state of the art on two of the most challenging public datasets.
