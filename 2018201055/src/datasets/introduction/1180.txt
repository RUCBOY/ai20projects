Data mining is the process of revealing hidden, previously unknown, potentially useful information from a large amount of data in a data warehouse. Data mining is becoming a new and increasingly popular research area. Using a database to store data, a machine learning method to analyze data, and mining the knowledge behind a large amount of data, the combination of the two has led to the emergence of data mining. Data mining is an indispensable part of knowledge discovery in databases. In fact, data mining is a cross-disciplinary subject involving databases, statistics, artificial intelligence and machine learning [1], [2].
In recent years, with the introduction of data mining technology, new ideas have been provided for extracting useful information from these massive data. In [3], the author used data mining techniques combined with logistic regression, decision tree graphs, neural network models, and partial least squares models to determine the impact of word exposure frequency on online news based on the usability heuristic concept. In [4], the authors analyzed the acupoint selection rules of diabetic peripheral neuropathy (DPN) based on data mining technology. The results showed that the acupuncture DPN was mainly based on the enhancement method, which promoted the circulation of blood and blood; the acupoint selection was mainly based on Yangming meridian and back-shu points. Data mining technology is a very common computer technology that has been widely used in many fields due to its superior performance. In [5], the author studied the data management technology based data management method for wireless sensor network. The author also proposed a cluster-based replication record deletion algorithm, and finally verified the accuracy of the data cleaning method. The results showed that the research method in this paper is correct and effective. In [6], in order to find out the main factors affecting the wearing comfort, and how they affect the wearing comfort of the clothing. The wearing comfort of the trousers was mainly affected by four factors: waist and hip factors, knee tibia factors, c factors and thigh calf factors. Their contributions accounted for 39.17%, 16.4%, 13.96% and 6.95%, respectively. In [7], the authors described the performance of the diesel engine using the relationship between the diesel engine load data and the fuel consumption rate at different speeds. Data mining is the process of extracting important and useful information from large amounts of data [8], [9]. In [10], the author applied data mining to medicine. In the analysis of a single cancer, it was found that patients treated with angiotensin receptor blockers (ARB) had a significantly reduced risk of breast cancer, while the pancreas cancer and prostate cancer are at increased risk. In [11], the author studied the formal framework of a data mining query language for mobility data and its related implementations, illustrating its analytical capabilities in revealing the complexity of urban mobility in large urban areas. In [12], the authors proposed a data mining-based intelligent differential protection scheme for microgrids. The proposed intelligent differential relay scheme can provide effective protection measures for the safe operation of the microgrid with high reliability. In [13], the authors used data mining techniques to examine different formats of review data to predict student performance. The research results show that the method proposed by the author improves the predictive performance of final student performance. In [14], the authors proposed an enhanced cascading fault model combining data mining techniques. The article proves the effectiveness and effectiveness of the proposed enhanced cascading fault model. In [15], the author used a real-time digital simulator to develop a WAMS network physical test bench, and introduced the test bench application, simulated network capability scenarios, data set development process, and selected results.
Over the years, people have been working on the versatility and scalability of computer test systems to improve the utilization and execution efficiency of mechanical engineering automated test equipment. In [16], the author applied computer testing techniques to image recognition. In order to find an isolation scheme that can automatically find the cause of the diagnosis of damage and economically related insects, the author developed a fruit fly image recognition system called AFIS1.0. The system used Gabor surface features in automatic recognition, and the overall classification success rate obtained by independent multi-part image automatic recognition test reaches 87% of the species level. In [17], the author applied computer test technology to error measurement, and proposed a method to test the influence of computer generated hologram (CGH) manufacturing error in cylindrical interferometry system. In [18], the authors proposed a computer-aided test method based on inverse Hartmann test for high-precision testing of reflective surfaces. The author also proposed an iterative ray tracing calibration method based on computer-assisted reverse optimization, which was used for high-precision testing of reflective surfaces. In [19], the authors proposed a simulation test system for a non-contact D-point transformer for voltage measurement. The analog test system consists of a D-point transformer, a signal processing circuit and a grounded PC port. Finally, a test platform was built to simulate the performance of the entire single-phase transformer test system [20]. In [21], the authors designed a computer-based breath sound analysis system to identify normal lung sounds in children and validated the effectiveness of a computer-based breath sound analysis system. This computer-based breath sound analysis system performed 58 lung sound recognitions, correctly identified 52 times, and misidentified 6 times. The accuracy is 89.7%. In [22], the authors developed a computer adaptive test (CAT) input technique to measure the entire potential anxiety continuity. The CAT simulation showed efficient and highly accurate measurement results. In [23], the authors evaluated the parameters of the severity of traffic accidents, including speed change (delta-v) and energy equivalent speed (EES). In [24], the author proposed an effective test generation procedure using a method called “diagnosis using parallel models”. In [25], the author further analyzed high-quality and appropriate-quality research in terms of content and specific teaching practices. The article discusses computer aided instruction (CAI) suggestions for future research and its implications for practice. In [26], the author systematically developed the visual literacy assessment test (VLAT), and conducted a necessity assessment on the test items in VLAT (average content effective ratio = 0.66).
Through the analysis of literature review at home and abroad, it can be seen that although many research teams at home and abroad have carried out more research and Analysis on computer technology for mechanical engineering, most of them are limited to the internal principles of mechanical engineering, but not to the technical level [27]. As a result, there is not enough powerful computer technology to carry out in-depth analysis of mechanical engineering. As an advanced computer technology, data mining technology is gradually concerned by people because of its unique algorithm settings and high recognition accuracy [28], but there is still no team that can effectively combine the principles of mechanical engineering and data mining technology. The purpose of this paper is to combine data mining technology and mechanical engineering principle effectively, which can improve the accuracy of algorithm recognition, optimize algorithm model and reduce experimental error.
The first part of the article is an introduction, introducing the overall structure of the article and the content of each part, and a review of the relevant literature on data mining technology and computer testing systems; the second part is the algorithm model established by the article; the third part is the experiment mainly data sources and experimental settings; the fourth part is the processing and analysis of experimental results; the fifth part is the conclusion.
