In 2018, 4779 fatal occupational injuries occurred in the private industry across the United States, of which, 1008 occurred in construction sites [1]. Over 70% of construction injuries can be attributed to workers' unsafe behavior; however, this is not deliberate and is mainly caused by an inability to adequately recognize hazards [2]. Hazard recognition (HR) is a high-level cognitive process by which workers detect sensory cues from the environment, selectively attend and match them with potential hazards, resulting in an appropriate response after confirmation [3]. Improving HR is important, as it is the first step towards injury prevention and facilitates effective safety management [4].
Presently, the construction industry heavily relies on manual safety inspection; however, this approach has several inherent drawbacks, such as subjective evaluation and limited cognitive capability. Although various interventions and auxiliary techniques (e.g., questionnaires [5], videos [6], and checklists [7]) have improved HR performance, they provide no qualitative change [8]. This is consistent with the fact that 40%–60% of construction hazards remain unrecognized [[9], [10], [11]]. Therefore, new technologies—such as wearables for human-machine interaction [12] and computer vision for automated image analysis [13]—have emerged to provide alternative strategies for promoting construction safety either by assisting or replacing workers.
Brain-computer interface (BCI)—the best-known application of neuroengineering—provides a direct communicational pathway between the human brain and external facilities. It is widely used for real-time mental-state monitoring during cognitive tasks [14]. Therefore, we hypothesized that a BCI may be applied to evaluate HR performance in construction; however, there is no direct evidence whether HR tasks can be differentiated with a classification accuracy, exceeding the chance level. Most BCI studies focus on selecting optimal mental task combinations [15] and performance parameters (e.g., signal features, classifiers, recording sites, and time window length [16]) to ensure that the cognitive content can be decoded automatically and reliably; otherwise, practical BCI applications may be blocked by unnecessarily protracted machine learning, data overfitting, and extravagant development costs. Another area of interest is the correlation between artificial intelligence and brain research; identifying salient activated areas of the brain can offer insight into individuals' intrinsic cognitive processes during HR and encourage future research to focus on these critical areas for a deeper understanding of their functional mechanism.
We attempted to evaluate the potential feasibility of applying a BCI to HR to improve hazard inspection. We first investigated whether HR tasks can be differentiated; moreover, we investigated whether particular pairs of hazards and corresponding recording sites are more advantageous for an increase of the binary classification performance of near-infrared spectroscopy (NIRS)-based BCI. Then, we considered the potential roles of critical areas of the prefrontal cortex that contain optimal channel combinations for the corresponding hazards to determine how the human brain differentiates hazardous situations. A NIRS-based experiment was designed to compare the classification accuracies of various combinations of HR tasks. The hemodynamic responses of 48 participants (i.e., changes in oxygenated, deoxygenated, and total hemoglobin concentrations [oxy-Hb, deoxy-Hb, and total-Hb, respectively]) were collected while performing eight HR tasks in a simulated construction environment. Linear discriminant analysis (LDA) with 10 × 10-fold cross-validations were employed to estimate the classification accuracy of all possible hazard pairs (C82 = 28) for each channel combination (C52 = 10) that was selected according to the Fisher criterion. Finally, we developed a feasible neurophysical mechanism for HR based on cognitive neuroscience.
