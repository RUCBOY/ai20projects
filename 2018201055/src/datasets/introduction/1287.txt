With the rapid development of information and communication technologies (ICTs), modern humans’ information transmission and communication models are gradually changing with time. Multiple convenient communication media that allow information transmission through computer-mediated communication (CMC) media not being restricted to traditional face-to-face are rapidly rising as well. CMC is tentatively defined as any human symbolic text-based interaction conducted or facilitated through digitally-based technologies, such as the Internet, cellular phone text, instant messaging (IM), email, and so on (Spitzberg, 2006). CMC competence refers to whether a person can appropriately and effectively communicate with others through digitally-based technologies as the intermediary communication media (Windahl & McQuail, 1993), and is affected by a person’s communication motivation, communication knowledge, communication skills, and contextual parameters (Spitzberg, 1997, 2006). A person who is more motivated to generate, use, and distribute information, who is more knowledgeable about the technologies and the topics involved, who is more skilled at actually using intermediary communication media in the process of communicating, and who has more facile contextual incentives and fewer contextual delimitations, is more likely to play a significant role in the diffusion of information via the intermediary communication media (Spitzberg, 1997, 2006). Thus, the mastery of CMC competence is considered extremely important for group discussions in online collaborative learning. Nevertheless, some learners could not effectively deliver opinions to communicate with their peers through intermediary communication media due to low CMC competence, thus resulting in learning burnout and frustration and further affecting the collaborative learning effectiveness. Accordingly, CMC competence is a key success factor in collaborative learning (Chun, 1994; Hertz-Lazarowitz & Bar-Natan, 2002; Smith, 2003). Chua and Chua’s study (2017) confirmed that the remarkable correlation exists between learners’ CMC motivation, CMC knowledge, CMC skills in a network community interaction. It therefore could be reasonably expected that learners with more CMC knowledge and skills would appear more motivated to interact with others via the CMC tools.
To evaluate whether a learner is good at communication with others through digitally-based technologies as the intermediary communication media or not, Spitzberg (1997) summarized several relevant research on computer-mediated communication to develop a CMC competence scale as the evaluation tool from the aspect of interpersonal communication as well as continuously revised such a scale so that it is more reliability. Additionally, Bubas, Radosevic, and Hutinski (2003) reviewed CMC competence related research to conclude that most elements in the CMC competence model were based on modifying the CMC scale V.1 and V.2 published by Spitzberg in 1997 and 2002 to improve the reliability and validity of Spitzberg’s CMC competence scale as the more reliable CMC competence scale for actual self-test. For this reason, the scale could be used for teachers to understand students’ mastery of CMC competence in an online communication environment with peers. The CMC competence scale is very useful for schools and organizations to diagnose learners who require early intervention to improve their CMC competence (Spitzberg, 2006). Nevertheless, the CMC competence evaluation through questionnaires could merely be done before and after the learning activity or preceded during the learning process with a limited number of times. Namely, it could not achieve the objective of real-time evaluation. Besides, the questionnaire survey was the afterward memory that the evaluation result might not completely conform to learners’ situations at the time (Araujo, Wonneberger, Neijens, & Vreese, 2017). For this reason, the development of a novel evaluation method to replace traditional questionnaire for effectively and promptly evaluating learners’ CMC competence could assist teachers in instantaneously grasping students’ CMC competence in an online collaborative learning process for adjusting their teaching strategies as well as help students precede learning reflection or adjust learning strategies to achieve the high-quality collaborative learning objective. It is considered as a worth-exploring research issue.
In the digital learning environment, various information technologies can be used to record a learner’s micro-behavioral data when a learner performs a learning activity on a digital learning platform. A learner’s micro-behavioral data is generally recorded through a log file. Such a recording method could purposively, accurately, and authentically record learners’ learning behaviors, such as learners’ log-in time, material browsing time, material content browsed, discussion behaviors, without interfering in the learning activity (Paulson, Paulson, & Meyer, 1991). Hwang, Spikol, and Li (2018) proposed the potential research issues of learning analytics and mining educational big data based on the logs recorded in learning management systems, the interactive contents recorded in online discussion forums, or the learning process captured on video, to provide constructive feedback to learners, instructors or educational policymakers. Hwang, Chu, and Yin (2017) indicated that several frequent methods adopted for learning analytics and mining educational big data include decision tree, clustering, association rules, time-sequence analysis, and visualization techniques. The idea of mining learning micro-behaviors for promoting students’ learning outcomes is gradually being paid attention to by the e-learning field along with the development of educational big data (Cantabella, Martínez-España, Ayuso, Yáñez, & Muñoz, 2019; Romero & Ventura, 2010). According to the big data development handbook proposed by United Nations Global Pulse (Global Pulse, 2012), learning micro-behavior records should consider five basic principles. 1. Digitally generated, i.e. micro-behavior records being digitally generated, rather than manually input. 2. Passively produced, i.e. micro-behavior records appearing during learners’ operation. 3. Automatically collected, micro-behavior being automatically collected and stored by the system. 4. Geographically or temporally trackable: details of location data and time being collected in micro-behavior records to support informal learning situations (e.g. mobile learning, learning at odd moments). 5. Continuously analyzed: being able to instantaneously analyze the collected learning micro-behavior records.
To overcome the restriction of SCORM (Sharable Content Object Reference Model) merely being able to track specific course oriented learning behavior records, the Advanced Distributed Learning (ADL) Initiative that conducts research and development on distributed learning and coordinates related efforts broadly across public and private organizations proposed xAPI (Experience Application Programming Interface, also called Experience API or Tin Can API) as the new standard for recording learning behaviors (Tin Can API, 2017). xAPI describes learning behavior with the idea of activity stream and records learning processes through the statement with the components of actor, verb, and object to accurately record learning micro-behaviors from learners. The idea of the Learning Record Store (LRS) was proposed with xAPI standards to store learning micro-behaviors for forming learning micro-behaviors big data (Tin Can API, 2017). The offered learning micro-behavior framework of xAPI provides technology bases and standards for the practice of monitoring, acquisition, storage, and sharing of learning micro-behaviors under education big data (Gu, Zheng, & Jian, 2014). With big data analysis, more useful feedback which can assist in teachers’ teaching and learners’ learning was mined from micro-behavioral data. For example, Chen and Wang (2020) utilized xAPI technologies with LRS to record students’ learning micro-behaviors in a web-based inquiry learning environment and used sequential pattern mining and lag sequential analysis to explore the inquiry-based learning behaviors of learners with different learning effectiveness and scientific inquiry abilities. Manso-Vázquez, Caeiro-Rodríguez, and Llamas-Nistal’s study (2018) focused on developing the standardization of self-regulated learning (SRL) traces to enable data collection from multiple sources and data analysis to ease the monitoring process for teachers and learners based on xAPI technologies. Moreover, Nouira, Cheniti-Belcadhi, and Braham (2018) argued the suitability of the xAPI standard in tracking the assessment data and tried to present an ontological model which can support effectively the assessment analytics based on enhancing the weaknesses of the xAPI data model so that the proposed model can support inference mechanisms related to the learner level of assessment performance. Besides, analyzing learner’s micro-behavioral data based on the formative evaluation method can provide real-time feedback for learning suggestions and reflection during a learning process. For example, Chen, Chen, and Horng (2019) employed the C4.5 decision tree to develop a collaborative reading annotation system with formative assessment and feedback mechanisms (CRAS-FAFM) based on four considered social network indicators, which could forecast the learners with low reading comprehension and suggest them to interact with the learners who are predicted with high reading comprehension performance and infrequently interact in the digital reading activity to enhance their reading comprehension through interactive discussion. Also, Hwang et al. (2018) indicated that providing personalized supports by analyzing students’ learning logs and making predictions is a potential research issue. In this kind of application, Chen, Wang, Chen, and Wu (2016) adopted a C4.5 decision tree, which is a widely used data mining technique, to develop a personalized reading anxiety prediction model (PRAPM) that can provide forecasting feedback to an individual learner based on her/his reading annotation behaviors in a collaborative digital reading annotation system (CDRAS) to reduce effectively the reading anxiety of the learner while reading English articles online.
Due to the high potential of applying xAPI to collect learners’ micro-behavioral data for making predictions based on educational data mining technology, this study thus develops a CMC competence forecasting model (CMCCFM) based on learning micro-behaviors features collected by Google Analytics like xAPI technologies to replace traditional paper-based CMC competence scale to instantaneously evaluate learners’ CMC competence without interfering in the learning activity. This is because Google Analytics is not only one of the most widely used analytics tools available but it is also easy to be implemented. It has been a mature and free commercial product that can also record learners’ micro-behavioral data like xAPI for educational data mining and visually display learning analytics just by adding a snippet of code to an e-learning system (Google, 2017; Luo, Rocco, & Schaad, 2005). Moreover, the CMC competence scale V.5 developed by Spitzberg (2006) was used as the evaluation tool of a learner’s CMC competence and the evaluation results were regarded as the target prediction values of the CMCCFM constructed by the five considered machine learning schemes based on the gathered learners’ micro-behavioral data. The objectives of this study contain (1) developing a “learning micro-behavior monitoring module” in a WCPBL system, (2) exploring proper learning micro-behavior features for the establishment of learners’ CMCCFM, (3) evaluating and comparing the effects of learners’ CMCCFM established with different machine learning algorithms on prediction accuracy, prediction stability, and model establishment speed, and (4) exploring the effects of teaching situations and learners’ background on the prediction accuracy of the developed CMCCFM.
