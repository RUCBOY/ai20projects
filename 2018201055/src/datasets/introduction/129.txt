Three-dimensional (3D) visualization has been widely used in many professional fields, such as medicine (Preim and Bartz, 2007), architecture and industrial manufacturing (Bouchlaghem et al., 2005). In medicine, 3D visualizations of the human skeleton, organs and other anatomic structures are implemented based on radiological imaging, such as computed tomography (CT) and magnetic resonance imaging (MRI) scans (Sutton, 1993). 3D visualization technique offers numerous benefits. For example, volumetric medical images can enable medical students to better understand the spatial anatomy of body organs (Silén et al., 2008), improve the accuracy of medical diagnoses (Satava and Robb, 1997) and help surgeons plan and simulate surgical procedures (Gross, 1998).
Highlighting relevant points on volumetric medical images of CT and MRI scans is an important 3D manipulation task performed by medical practitioners in computer-aided medical diagnosis and planning. Medical practitioners manipulate the models (i.e., rotate, pan and zoom) and mark critical points for later inspection, measurement and analysis of skeletal relationships (Kula and Ghoneima, 2018), treatment planning (Harrell, 2007) and as a tool for discussing and developing treatment consensus (Reinschluessel et al., 2019). For example, during cephalometric tracing, medical practitioners select and mark a point on the skeleton model or surrounding soft tissue as a point of reference for operations related to positioning, measurement and orientation. The task difficulty depends on the marking locations and the structure complexity of the virtual models (Medellín-Castillo et al., 2016). The accuracy of the markers directly influences the results of the medical analyses, and thus, the overall quality of the medical services (Lindner et al., 2016).
Despite the recent advances in 3D visualization technology, the tools used to present and interact with these volumetric images have not changed in the field of medicine. A conventional 2D display is still the main visual channel to present volumetric data from CT and MRI scans, which provides the user with a fixed screen-based viewing perspective. Further, it is still a common practice to use a mouse with the rotate-pan-zoom technique to indirectly manipulate 3D models (Jankowski and Hachet, 2013). However, previous studies (Hinckley et al., 1997; Bowman et al., 2004) have argued that using the mouse-based interface for 3D manipulation is difficult. Some researchers have investigated the mouse-based rotation techniques to understand their issues for 3D manipulation (Bade et al., 2005). Other researchers have conducted comparative studies to examine the usability of other user interfaces such as the tangible interface (Besançon et al., 2017) and the touchscreen-based interface (Yu et al., 2010). However, these interaction methods either did not exceed the performance of the mouse (Yu et al., 2010) or had a limited application area (Besançon et al., 2017).
Following the technical advances in virtual reality (VR), VR equipment (e.g., Oculus Rift (Oculus, 2020) and HTC Vive (VIVE, 2020)) has been developed. A combination of a VR headset and a handheld VR controller can provide the user with an intuitive and immersive interaction environment. In this VR interface, 3D models are presented to the user through the head-mounted display and the models can be manipulated by the user using the VR controller with six degrees of freedom (Oculus, 2020; VIVE, 2020). Compared with the traditional 2D interface, VR devices offer a flexible 3D view based on the position and orientation of the user's head and allow using 3D hand gestures to manipulate the objects. In addition, the VR controller can provide vibrotactile feedback to the user's hand and enable tactile interaction. Vibrotactile feedback as an augmentative sensory channel has many medical applications, such as, robot-assisted teleoperation (Peddamatham et al., 2008), minimally invasive surgery (Schoonmaker and Cao, 2006) and rehabilitation medicine (Shing et al., 2003). Because of the flexible viewing perspective and the natural hand-based input, the VR interface has been proposed to use in the field of medicine. For example, it has been employed to interact with skeleton and organ models for anatomy learning (Fahmi et al., 2019) and treatment planning (Reinschluessel et al., 2019). Multiple companies have employed it to develop software for medical diagnosis services (e.g., Surgical Theater, 2020; Adesante, 2020). However, the potentially beneficial vibrotactile feedback generated from the VR controller was not used in their interactive VR systems.
Further, force-feedback devices, such as the Geomagic Touch (3D systems, 2020) and the Novint Falcon (Novint, 2020), have been proposed as another beneficial interaction device for medical services (Ribeiro et al., 2016). These devices can support bidirectional kinesthetic exploration. The mechanical arm of the devices not only allows hand-based motions with six degrees of freedom for object manipulation but also transfers the generated kinesthetic feedback to the hand, to simulate the feeling of touch (Massie and Salisbury, 1994). Force-feedback devices have been used with a 2D display for, for example, anatomy education (Kinnison et al., 2009), surgery training (Steinberg et al., 2007; Webster et al., 2004) and medical analysis (Medellín-Castillo et al., 2016). The only study that has combined the force-feedback device with the VR headset, to the best of our knowledge, is the work by Saad et al. (2018). They have technically investigated the feasibility to connect these devices.
We combined a VR headset with a VR controller and a force-feedback device to create haptic VR interfaces which provide the user with a flexible viewing perspective, a natural hand-based input and haptic feedback simultaneously. These VR interfaces can enable intuitive and realistic 3D interaction, thus promising for the tasks involving 3D manipulation (Bowman et al., 2004) such as medical diagnosis and planning tasks. However, the usability of the haptic VR interfaces for these medical tasks, covering effectiveness, efficiency and satisfaction (Issa and Isaias, 2015), has not been explored. Furthermore, these two VR interfaces are based on similar interaction models but employ different interaction devices with different types of haptic feedback. Their difference in usability remains unclear in the context of medical diagnosis and planning. A comparison of two VR interfaces can help better understand the suitability of their interaction methods for 3D manipulation and reveal the effects of different types of haptic feedback for these high-standard medical tasks. More importantly, 2D interaction method using a mouse and a 2D display is still a powerful user interface and dominant in the field of medicine. A comparative study with the 2D interaction technique is necessary to explore the potential of the haptic VR interfaces to improve current medical diagnosis and planning work.
In the present study, we examined the two haptic VR interfaces, the kinesthetic VR interface using a force-feedback device and the vibrotactile VR interface using a VR controller, in an experiment involving medical marking on 3D models. To examine their practical usability, we compared two VR interfaces with the traditional 2D interface that uses a mouse and a 2D display as the baseline. In the experiment, because the structural complexity of the models and the marking locations can influence users’ performance in the medical marking task, we employed three human anatomic structures as the experimental models with two different difficulty levels for the marking positions. To evaluate the three user interfaces, we collected both objective and subjective data. The objective data included task completion time and marking accuracy, and the subjective data included rating data for the perceived mental effort, hand fatigue, naturalness, immersiveness and user preference. The aim of the study was to answer the following questions in the context of medical marking:
•What are the differences between the kinesthetic VR interface and the vibrotactile VR interface, in terms of task completion time, marking accuracy and user experience? How do the marking locations affect users' performance with the two VR interfaces?•What are the differences between the two VR interfaces and the traditional 2D interface? How do the marking locations affect users' performance with the traditional 2D interface?
This study makes the following contributions: We proposed two haptic VR interfaces to interact with volumetric medical images for computer-aided medical diagnosis and planning. The vibrotactile VR interface and the kinesthetic VR interface were evaluated based on a medical diagnosis and planning task on virtual models of the human skeleton and organ. The results revealed the strengths and weaknesses of two VR interfaces associated with current popular VR equipment and haptic device, which simultaneously provided empirical understanding for developing efficient and user-friendly interactive VR systems. In addition, through comparing with the 2D interaction technique, the better performances of two VR interfaces, in terms of marking accuracy (the kinesthetic VR interface) and task completion time (the vibrotactile VR interface), demonstrated their potential to replace the traditional 2D interface for these medical tasks.
The paper is organized as follows. Relevant previous studies are introduced, and then the prototype system and the experiment are described. The results are presented in detail, followed by the discussion of the main findings and the conclusion.
