Alzheimer's Disease (AD) is a progressive brain disorder and the most common of dementia in the late life. AD leads to the death of nerve cell and tissue loss throughout the brain, thus reducing the brain volume in size dramatically through time and affecting most of its function [1]. The estimated number of affected people will double for next two decades, so that one out of 85 persons will have the AD by 2050 [3]. Because the cost of caring the AD patients is expected to rise dramatically, the necessity of having a computer aided diagnosis (CAD) system for early and accurate AD diagnosis becomes critical [4]. Moreover, Mild Cognitive Impairment (MCI) is an intermediate stage between Normal Cognition (NC) and clinical dementia. Exiting study [6] has shown that MCI subjects progress to clinical AD with an annual rate of approximately 10–15%. Research on identifying MCI individuals who will progress to clinical dementia has received increasing attention in recent years [7].
Among many modalities of medical images, Magnetic Resonance Imaging (MRI), Computed Tomography (CT), and Positron Emission Tomography (PET) scans contain information about the effects of AD on the structure and function aspects. Compared with MRI, CT and PET, MRI is the most standardized and widely available imaging modality in clinical practice [8], and MRI examinations can provide an opportunity to track different clinical phases of AD. However, analyzing such MRI images consumes more time for doctors and researches because each image contains millions of voxels and tremendous information.
There are many functional connectivity modeling methods proposed for AD diagnosis, including the correlation-based methods [9], graphical models [10] partial-correlation-based methods [11], and sparse representation-based methods [12]. Furthermore, several types of features [12], [13], [21], [23], [26] were extracted from MRI image for AD prediction, such as gray matter density maps, cortical thickness as well as volume and shape measures. Another popular method [7] achieves the classification through segmenting the whole brain into multiple anatomical or discriminative regions and then extracting regional features. Some recent methods [14] introduced that the features extracted from neuroimaging data are not isolated and exhibit high correlations. Considering the relationships among these features, tree guided sparse coding methods [16] and re-sampling schemes using Elastic net [17] have been proposed for AD diagnosis. Although the low-level features can be hand crafted with great success for certain applications, most of the hand-crafted features cannot be adapted to new condition because designing effective features for new situations usually requires new domain knowledge. Learning features from data of interest is considered as a plausible method of remedying the limitations of hand-crafted features.
Deep learning systems are more effective in many research areas, such as image object detection [2], image segmentation [5], image saliency detection [9], image classification [15] and remote sensing image processing [19]. These systems have the ability to extract high-level features from raw sensory data after using statistical learning over a large amount of data to obtain an effective representation of input data space. Among those systems, the convolutional neural network (CNN) is a popular form since it achieved breakthrough performance in AD diagnosis. Hosseiniasl et al. [18] presented the deep 3D-CNN for learning generic and transferable features across different domains, and it can detect the characteristic AD biomarkers in one (source) domain and perform task specific classification in another (target) domain. Choi and Jin [20] developed a deep CNN-based method for prediction of cognitive decline and selection of subjects who would eventually convert to AD. Sarraf et al. [22] outlined the deep learning-based pipelines which was employed to distinguish Alzheimer's MRI and fMRI from normal healthy control data for a given age group. Hosseini-Asl et al. [23] proposed a method to predict the AD with a deep 3D convolutional neural network, which is pre-trained to capture anatomical shape variations in structural brain MRI scans. Liu et al. [24] constructed a cascaded CNNs structure to learn the multi-level and multimodal features of MRI and PET brain images for AD diagnosis. Farooq et al. [25] proposed a CNN-based pipeline for the diagnosis of Alzheimer's disease and its stages using MRI images.
Although CNN-based methods could learn highly discriminative feature in medical images, there often arises the issue that labeled data is often not enough to learn the filter banks in CNNs, especially in medical applications. CNNs are unable to train in parameter setting and learn highly discrimination visual features when insufficient labeled datasets for training are available. This is the reason that few studies have been investigated in applying CNN to medical analysis due to the rare availability of labeled medical image data. Recently, an investigation [27] showed that the unsupervised CNN learns the filter banks by a traditional unsupervised machine learning algorithm can extract the features successfully in image classification tasks. This investigation employed the unsupervised CNN structure to learn the features and followed by a support vector machine (SVM) classifier to achieve the final classification result. However, the SVM is a supervised machine learning method which still requires labeled data to train and test the classifier. Therefore, how to develop a fully unsupervised method for achieving the medical image classification is still an open problem.
The fully unsupervised deep learning framework for medical image classification, in our opinion, mainly contains two parts. The first part is how to learn the features from input data by some unsupervised machine learning methods. And the second part is how to utilize the unsupervised classification methods to achieve the final classification results. In this paper, we focus on the problem of insufficient labeled data available in medicine, and propose a fully unsupervised deep learning technology for AD diagnosis. The proposed method includes the following two parts. Firstly, we employ an unsupervised CNN named PCANet for achieving the feature learning on MRI images. PCANet can learn the filters in CNNs by a traditional unsupervised machine learning algorithm and extract the features through the first convolution stage, the second convolution stage and the output stage. The main superiority of PCANet is that it doesn't involve the stochastic gradient descent (SGD) method that requires a large number of labeled data, and critically depends on expertise in parameter tuning and various ad hoc tricks. Secondly, we address the unsupervised classification method that is based on k-means to achieve the final prediction for AD diagnosis. Moreover, two different views of MRI image are introduced as input data in the proposed method, which includes one view of MRI image and three orthogonal panels (TOP) data from the three orthogonal views.
The remainder of this paper is organized as follows. Section 2 provides a brief introduction on PCANet and k-means. The proposed method for AD prediction are presented in details in Section 3. Section 4 describes the experiments and comparative analysis. A discussion is provided in Section 4. Section 5 concludes this paper.
