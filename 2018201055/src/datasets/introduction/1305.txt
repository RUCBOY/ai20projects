Construction sites are places with a high hazard rate in the construction industry. It was reported that the accidents occurred on construction sites accounted for 10.1% [1] and 11.5% [2] of all occupational injuries in the United States and Hong Kong, respectively. A major reason for the high rate of on-site hazards is the dynamic characteristic of construction-related entities such as the movement of construction workers and heavy equipment, as well as the interaction among them. Construction equipment, such as excavators and cranes, plays an important role in various construction activities such as earth moving and material transporting. Nevertheless, due to the complex operation and heavy self-weight, construction equipment tends to cause a large number of safety issues, e.g. collisions with construction workers and other types of equipment when transporting materials or interacting with other on-site objects, during which the location and pose of the equipment are varying most of the time. As such, it is vital to track the real-time location, pose, and movement of the construction equipment for monitoring their operating status and avoiding potential hazards or casualties. Computational optimization and artificial intelligence technologies (such as multi-agent systems) were utilized to enhance the performance of design, engineering, and construction [3,4]. Visual technologies, such as surveillance cameras, were also utilized to monitor the construction site through capturing videos in real time. Inspectors are required to watch the monitoring videos all the time and identify the potential hazards according to their experience. Such manual observation and identification of on-site hazards are subjective to the physical status and expertise of inspectors. In addition, the reaction of the inspectors may not be prompt and accurate enough to prevent the occurrence of hazards. Hence, automation of the monitoring process by interpreting the captured video through computer vision techniques is expected to improve the efficiency of on-site monitoring.
Previous researches have attempted to locate and identify construction equipment from surveillance videos using computer vision techniques [[5], [6], [7]]. However, heavy construction equipment (e.g. excavators and cranes) seldom changes its location frequently during constructional activities, while different equipment components (e.g. arms and booms of excavators) are manipulated and the equipment poses keep varying, which can threat the safety of surrounding construction-related entities including workers and other construction equipment. To avoid the safety issues caused by construction equipment, it is crucial to monitor the poses of construction equipment and ensure the safe operation of them, based on which early warnings can be provided when construction equipment and workers are exposed to potential hazards.
As claimed by previous studies, either depth sensors or stereo vision are required to obtain three-dimensional (3D) pose information of human [8] or equipment [9]. It is known that pre-installing depth sensors on construction equipment is labor-intensive and time consuming. On the other hand, it is quite difficult for companies to purchase and install new sensors on construction equipment, since the onsite construction equipment is very likely to be changed according to the actual engineering requirements in different stages of the construction project. Apart from attaching separable depth sensors, using depth sensors equipped with an RGB-D camera or a laser scanner can also obtain the depth information of construction equipment [10], which however is very expensive and hard to achieve high accuracy. In addition, detection distance of current affordable commercial RGB-D cameras, such as Kinect, is limited to a few meters, which is only suitable for the indoor tasks, and the detection accuracy is not satisfactory enough. As for stereo vision based methods, two or more RGB cameras with overlapping views, can rebuild precise 3D objects by stereo matching methods [11], which can be used for 3D pose estimation. With a large number of RGB cameras installed on construction sites for surveillance purposes, obtaining stereo vision with multiple RGB cameras seems feasible for estimating equipment poses. However, the foremost challenging step of estimating 3D equipment poses is processing the data from each RGB camera individually for extracting the 2D pose of the equipment, which means that 2D pose estimation is the base for 3D equipment pose estimation. Such challenge is mainly caused by the abundant variations arising from different appearances and poses of construction equipment in various working scenarios. There are studies leveraging data from RGB cameras to estimate the partial poses of a piece of equipment, i.e. the poses of boom and arm [9,12,13], which is not sufficient for interpreting the whole dynamic working region of construction equipment. Such limitation of previous studies constraints the applicability of their methods in identifying the safe interaction zones and providing hazard alarms on construction sites. Therefore, the full body pose of the whole construction equipment is important because it can help to understand the dynamic working state of the whole equipment body based on the movement of all the key components of a piece of construction equipment. Estimating full body poses instead of partial poses provides more comprehensive information of the on-site interaction, even from the front view and the back view, which is more convincing and may reduce the influence of occlusion problems.
In addition, previous studies of equipment pose estimation rely on conventional image processing and computer vision methods, such as background subtraction which estimates equipment poses by subtracting the current video frame with the background (i.e. the original view of the construction site without any equipment). Such a method tightly depends on the prior information of the construction site to process new surveillance videos while the prior information may become invalid when processing the latest surveillance videos since the resources on construction sites are changing continuously. In the recent few years, deep learning models have achieved promising performance for estimating human poses after being trained with benchmark datasets, which contain large numbers of human pose images annotated by keypoints (e.g. MS COCO [14] and MPII [15]). For example, Stacked Hourglass Network (HG) and Cascaded Pyramid Network (CPN) are two typical deep learning networks with wide applications and good performances for single human pose estimation. In the construction industry, deep learning techniques are also attracting attentions for various tasks, such as the automated inspection of civil infrastructure [16,17], as well as the construction site monitoring, e.g. identifying and locating construction workers [18] and equipment [7], for which the prior knowledge of the monitored jobsite is not required. So far, there are few studies focusing on full body pose estimation of construction equipment based on deep learning techniques.
With the objective to address the limitations of approaches based on manual monitoring, pre-installed sensors, and conventional computer vision techniques, this paper proposed an methodology framework for automated full body poses estimation of different types of construction equipment in surveillance videos using computer vision and deep learning techniques, which includes (1) dataset preparation, (2) deep learning model training, and (3) model evaluation on testing images. Specifically, the dataset for equipment pose estimation is collected from images and videos captured on real construction sites, after which the keypoints consisting of the full body poses of the equipment are defined and annotated on the collected images. Then, three deep learning networks, including the Stacked Hourglass Network (HG), Cascaded Pyramid Network (CPN) and the ensemble model of HG and CPN (HG-CPN) are constructed and trained with our annotated equipment pose dataset. After training the models, the performances of the three deep learning networks are evaluated and compared through experiments in order to investigate the capability of the proposed method. The experiment results demonstrated that the proposed methodology framework is capable of automatically estimating the full body poses of construction equipment with a high accuracy and a fast speed, which lays the foundation of 3D full body pose estimation using stereo vision and overcomes the limitation of applying partial pose estimation in determining the safety zone around the whole body of a piece of construction equipment. Besides construction safety, this research also has great values in the estimation of construction productivity through interpreting periodic working states of different types of construction equipment based on surveillance videos.
The rest of the paper is organized as follows. Related works are reviewed in Section 2 and the proposed approach is described in Section 3 in detail. Section 4 presents the experiments conducted using three different deep learning networks and the performance comparison of the three applied networks. Finally, the conclusion is given in Section 5 to summarize the paper content, discuss the limitations, and the future work.
