Target recognition within ISAR image is a critical and difficult problem in computer vision tasks (Demirci et al., 2020, Xue and Tong, 2019a, Xue and Tong, 2020, Liu et al., 2020a). Particularly, the modal diversity problem in real-world environment, that is there are numerous different angles of view, sizes, postures, and different degrees of deformation and low resolution for the same ISAR target, brings great difficulty to target recognition within ISAR image.
For the modal diversity problem, there are generally three solutions. One is to use sufficient modal templates to construct training data sets, which usually requires affine transformation (Pflugfelder and Scharr, 2020) or deformable diversity similarity (Talmi et al., 2017), component deformation model (Morozov et al., 2020) and other existing data samples can be extended to achieve robust feature representation from these data, but usually at the cost of expensive training and complex model parameters. The second method is to build invariant features and algorithms in a feature domain, such as scale invariant feature transformation (SIFT) (Nuari et al., 2019), the extremum point is found in the special scale, and its position, scale and rotation invariants are extracted, and the rotation, scale scaling and brightness changes are invariant, and the angle change and noise are stable to a certain extent. The information is rich, and can be quickly and accurately matched in massive feature data. However, the above methods need to assume that the geometric transformation is fixed and known, and that the invariant features and algorithms designed manually are difficult to deal with the complicated transformation. The third solution is the learning-based methods, such as deep convolutional neural network (DCNN), are used to handle the geometric transformation via learning transformation modes. But CNN is difficult to deal with large and unknown transformations because of the fixed geometry in CNN. Therefore, these methods can only deal with some fixed, known or small modal diversity cases, and there are some shortcomings such as consuming a lot of resources and insufficient samples, it is difficult to achieve good performance of real-world ISAR target recognition by the traditional methods.
Therefore, in this paper, deep adaptive learning (DAL) is proposed to achieve an excellent real-world ISAR target recognition system. Particularly, deep adaptive multimodal mechanism (DAMM) is proposed to solve the modal diversity problem. In this model, different critical components are jointly learned: feature sampling, feature extraction, deformation handling and classification. It not only can handle the real-world complex target recognition problem quickly and efficiently, but also be used well on computationally limited platforms. With the deep model, these components interact with each other during learning, which allows each component to maximize its power when cooperating with others. Such interaction helps to learn more discriminative representations.
