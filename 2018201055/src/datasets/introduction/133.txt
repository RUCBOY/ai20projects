Detailed physics-based simulation of electrochemical devices such as fuel cells and batteries involves a complex system of coupled, nonlinear partial differential equations (PDEs) and constitutive relations [1], [2], [3] embodying conservation laws. Geometries consisting of distinct layers with different microstructures and spatial scales (open space, porous layers, pure solids, membranes and separators) further complicate the models. The sheer complexity of these models, as well as the incorporation of approximating sub-models for partially understood processes, leads to a large number of important and tunable parameters. Model-based performance evaluation and design can therefore be extremely time consuming, typically involving the estimation of several parameters followed by exploration over a multi-dimensional design space. For applications that demand real-time executions of a code, or executions in the 100−10,000’s, complex models and codes will be rendered unusable. This issue arises in design optimization [4], [5], control [6], [7], [8], parameter estimation [9], [10], sensitivity analysis and uncertainty quantification [4], [11], [12], [13], [14], [15], [16], [17].
Simplified models can instead be employed but for design or control purposes they may lead to sub-optimal results or poor decisions. They are usually based on spatial averaging, equivalent circuits analogies or polynomial approximations [18], [19], [20], [21], [22], [23]. In recent years, there has been a growing interest in the use of so-called surrogate models for replacing complex computer and battery codes. The goal of a surrogate model is to provide accurate and rapid approximations of one or more quantities of interest from a full model, specifically for tasks that require numerous or instantaneous runs. Different approaches can be adopted, including multi-fidelity models, reduced order models (ROMs) or machine-learning methods [24]. The first of these approaches uses two or more solvers of differing resolution or complexity (fidelity), and exploits the lower fidelity model outputs to accelerate learning of the highest fidelity outputs [25].
ROMs rely on projecting numerical formulations onto low-dimensional subspaces, e.g., using  a Karhunen–Loéve basis [26], [27], [28], [29]. The most common approaches for surrogate modeling, however, are based on machine learning, by virtue of their flexibility and ability to handle nonlinearities. For electrochemical devices, examples include polynomial linear regression [30], [31], Kalman filtering [7] and neural networks (ANN) [12], [32], [33], [34], [35], [36], [37], [38]. These models are designed to estimate a single or small number of outputs. For example, Wang et al. [5] approximate the pressure difference between the air inlet and outlet and the maximum temperature difference among Li-ion battery cells for optimization of a thermal management system. Pourrahmani et al. [12] estimate the Nusselt number and friction factor for thermal management of a PEMFC using a standard ANN to replace a full CFD code.
In this paper, we instead address the following important challenges facing the application or development of machine-learning approaches for complex fuel cell and battery models:

1.Prediction of high-dimensional outputs, such as charge–discharge (temporal) data and 2-d/3-d spatial or spatio-temporal profiles of reactant concentrations, potentials, flow velocity, etc.2.Multi-task learning, such as learning temporal profiles, spatial profiles and scalar quantities simultaneously. It is clearly desirable to obtain as much information as possible from a model rather than focusing on a few scalar summaries.3.Noisy data. Frequently, computer model solutions are corrupted by numerical errors. In such cases, it may be possible to gain valuable and accurate predictions without having to resort to the expensive task of re-running all cases, which may not even be possible.
The problems associated with challenge (1) are the computational expense of learning a large number of outputs (e.g., 106). Very few approaches have been developed for such cases. An ANN will be extremely difficult and expensive to train with such a high number of variables. More importantly, it requires a large training data set from the high-fidelity computer model, which in many scenarios will be beyond the computational budget available, and will be prone to overfitting. Wang et al. [39] used a basic feedforward ANN and SVR for predicting spatial profiles in 2-d slices at 70 spatial locations, treating the spatial index as an input in the first case and independently learning the value of the output at each spatial location in the second. The first will require an exponentially increasing number of training points as the number of locations increases, while the second completely ignores spatial correlations and is only practicable for a relative small number of outputs, even with parallelization.
GP models have the advantage of requiring fewer training points than ANNs and of providing a measure of uncertainty in the predicted values. Uncertainty estimates are critical for many engineering applications in which decisions are taken based on a quantifiable measure of reliability in the prediction. The lower training point number is particularly advantageous when even low-fidelity data is costly to obtain, as is often the case. The linear model of coregionalisation (LMC) [40] is a general framework for multivariate GP models. For very high dimensional problems, the main issue with the LMC is that the number of hyperparameters is proportional to the square of the output space dimension [41], [42], [43]. This limitation can be circumvented by employing linear or nonlinear dimension reduction [44], [45], [46]. A GP model using linear dimension reduction was successfully employed by Shah [47] for predicting 3-d and 2-d spatial profiles from a PEMFC model at up to 5×105 grid points.
A naive solution to challenge (2) is to learn separate models for each task, and to make predictions using the independent models. This approach does not take advantage of all the information contained in the data and may therefore provide unsatisfactory results, a consideration that has given rise to the subset of machine learning termed multi-task learning. Multi-task learning seeks to exploit the correlations amongst different tasks of the same numerical or computational experiment by learning the tasks simultaneously rather than individually [48]. When the tasks, or at least a subset of them, are related, joint learning has been shown to improve predictive power over independent learning [49].
To make progress on challenges (1)–(3) simultaneously we develop a new framework for multi-output, multi-task learning by combining a multivariate GP model with a separate LMC to account for the covariances between the tasks. The multivariate GP model uses dimension reduction [44], [47], which allows for very high-dimensional output spaces. The LMC is then applied to a vector of coefficients in a low-dimensional subspace, with each coefficient corresponding to a particular task. The framework is designed such that the LMC problem is kept to a small size (equal to the number of tasks), which results in highly-efficient training.
We test the framework on two different 3-d hydrogen fuel cell simulation codes. The results are compared to the independent application of different multivariate GP models [41], [42], [44] to each task, and also to single multivariate GP models with combined (concatenated) tasks. The results reveal that our framework is more accurate and also more computationally efficient (fewer training samples and basis vectors). The framework also provides predictive covariances between outputs at different spatial locations of different tasks. This is particularly valuable information in the context of challenge (3), including cases where there is missing information [50]. Finally, we consider a case with noisy data and show that our framework is able to provide accurate predictions even with a relatively high noise level. In the knowledge that many readers will be unfamiliar with the underlying concepts, in the next section we provide an introductory explanation of the application of machine learning to the present task. Further details of the methods employed are provided in Appendix A Univariate Gaussian process models, Appendix B Linear models of coregionalisation for the benefit of the reader. We then describe the data generation followed by the multi-output, multi-task framework. The simulation results are presented in Section 5.
