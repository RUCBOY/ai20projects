With a brain-computer interface (BCI) system, users can directly connect with their surrounding environment via brain activity. The new pathway is independent of users’ peripheral nerves and muscles [1]. The BCIs can help some patients (such as amyotrophic lateral sclerosis (ALS)) communicate with the outside world. The control of wearable robot has been a successful application example [2]. As a novel way of communication and entertainment equipment, the BCIs can be also introduced into the daily life of healthy people [3]. Considering some factors such as measuring environment, instrument cost and experimenter safety, the control signals of BCIs are mainly derived from electroencephalography (EEG) signals [4]. The EEG signals are time series with frequency characteristics, and they are produced by the thinking activities of the human brain. The BCIs based on EEG have been gradually developed into a variety of applications. Besides the wearable robot [2], the BCIs can be used to control an embedded web server application in the home environment [3]. Quadcopters and virtual helicopters are successfully controlled by the BCIs based on motor imagery [5].
There are mainly several brain activities to induce and evoke EEG signals for the BCIs [5], e.g. motor imagery, steady state visually evoked potentials (SSVEP) and P300 evoked potentials etc. Motor imagery is an active experimental paradigm, and it allows users to control the equipment as they imagine. When the users perform motor imagery, the EEG signals from the sensorimotor cortex of ipsilateral brain will be enhance. The phenomenon is called event-related synchronization (ERS). At the same time, the EEG signals from the sensorimotor cortex of contralateral brain will be reduced, which is called event-related desynchronization (ERD) [6,7]. With these phenomena, motor imagery has four recognizable operations (right hand, left hand, tongue and foot) [8]. Compared with motor imagery, SSVEP and P300 evoked potentials have higher classification results and information transmission rates [9]. However, SSVEP and P300 evoked potentials are passive experimental paradigms. To produce SSVEP and P300 evoked potentials, additional equipment is needed, so they are very inconvenient to use. In particular, uses are prone to visual fatigue after long-term use. Considering the above reasons, one of the data sets studied in this paper is from motor imagery.
To further improve the practicality and stability of BCIs, some new experimental paradigms have been proposed, such as speech imagery. Based on electrocorticography (ECoG), a new neural decoder is used to control the BCIs by speech imagery [10]. Furthermore, as the EEG-based BCI, vowel speech imagery is designed with reading /a/ and /u/ silently [11]. Various categories of speech imagery are constantly proposed, such as vowels, short words and long words. The difference between sound and word makes the classification more accurate [12]. In our previous research, the speech imagery according to Chinese characters is proposed. The classification results between speech imagery and idle state are satisfactory [13]. We also find that the results of mental tasks can be improved with simultaneously performing speech imagery [14]. The stability of BCIs can be effectively improved by this method, so it is selected as another data set for analysis in this paper.
Before EEG signals can be used to control the BCIs, they should be further processed. The process is mainly divided into two steps: feature extraction and feature classification. Similar to the experimental paradigm of motor imagery, the EEG signals can be actively changed when subjects perform mental tasks with speech imagery. Therefore, their signal processing methods can draw lessons from motor imagery. The main difference between the two data sets is the activation of different cerebral cortex. Therefore, the two data sets have different spatial features. To fully test the performance of our proposed methods, we select the two data sets to verify together. As time series, the EEG signals are also distributed with useful features in both spatial and frequency domains. It is helpful to analyze the EEG signals by jointly extracting their temporal, spatial and frequency features. After this, the classification accuracy can be improved [15]. Common spatial pattern (CSP) is a state-of-the-art spatial feature extraction algorithm. Based on CSP, temporal-spatial-frequency feature extraction is developed step by step [16,17]. The frequency characteristics are obtained by wavelet transform, and then they are combined with the spatial features of CSP to improve the classification accuracy [2]. Compared to the single features, the spatial features combined with phase synchronization information also make the classification accuracy higher [18]. After optimizing the filter range by a unified Fisher’s ratio, the features extracted by CSP are more efficiently. The classification results are also significantly improved [19]. As an extension of the frequency domain, another famous improved approach of CSP is filter bank common spatial pattern algorithm (FBCSP) [20]. With a bank of band-pass filters, the optimal spatial-frequency features are effectively constructed by FBCSP. The effect of feature extraction of CSP can be further improved by optimizing the frequency-temporal-spatial features at the same time [15]. After selecting the time period and frequency band related to the task, the spatial features are extracted by CSP [17]. The classification effect of the above method is significantly better than the method of only extracting the spatial features or extracting the spatial and frequency features. After feature extraction, feature classification is the final critical step. With unique advantages to classify the features with less data and high dimension, support vector machine (SVM) is often selected to classify the features of EEG [21].
The above traditional methods separate the feature extraction from the feature classification. The matching between two processing steps may not always achieve the best result. Besides, the matching processes are time-consuming and they highly dependent on researchers’ experience. Recently, deep neural networks (DNN) have achieved better results than traditional methods in the fields of image classification, video analysis, natural language processing and EEG signals processing [22]. From the research of artificial neural network, the structure of DNN has multiple hidden layers. Without any priori feature extraction and selection, DNN can directly obtain the results from end-to-end learning. Several architectures of DNN have been proposed, including convolutional neural network (CNN), recurrent neural network (RNN), deep Boltzmann machine (DBM) and deep belief network (DBN) etc [[23], [24], [25]]. These architectures usually require a large amount of training data to fit their huge number of hyperparameters. However, limited by the experiments, the amount of EEG data is often relatively small. When P300 evoked potentials are identified by CNN, Batch Normalization is used in the input and convolutional layers to alleviate overfitting [23]. Depthwise and separable convolutions are constructed as EEGNet, and the spatial and frequency features can be extracted from the limited training data [26]. The temporal features of the signals can be extracted by RNN. As an improved version of RNN, long short term memory (LSTM) is more widely used. After the decomposition of discrete wavelet transform, the EEG signals are extracted by a deep BLSTM-LSTM network [27].
The above DNN models only have one type of network. In order to improve the recognition effect of the network, different types of networks are combined together. One of the combinations is CNN and LSTM. Bashivan et al. propose recurrent-convolutional neural networks (RCNNs) with CNN and LSTM [28]. To extract the spectral and spatial features, EEG signals are transformed into 2-D topologypreserving multi-spectral images at first. The robust representations are learned by RCNNs from the sequence of images. Their experimental results illustrate the effectiveness of the method. However, the process of converting to an image takes a certain amount of time, and it is not conducive to the establishment of an online BCI. Xie et al. propose a CNN-LSTM model to decode the finger trajectory from ECoG [29]. For CNN, spatial and temporal filtering is applied by a spatial convolution layer and a temporal convolution layer, respectively. The temporal dynamics of the signals can be captured by LSTM. Compared with the conventional regression methods, their method gives a prediction with higher correlation coeffcient. But the signal their model deals with is ECoG, whose signal-to-noise ratio is much higher than that of EEG. To identify intracortical data, Schwemmer et al. propose a deep neural network decoding framework [30]. The signals are first transformed into 2-D images by wavelet transform. A LSTM layer and a convolutional layer are used to extract the characteristics of images in turn. The results show that deep neural network decoders can be used in the BCI technology. Their method also includes an image conversion process, and the complexity of the model has increased. Zhang et al. propose cascade and parallel CNN-LSTM models [31]. According to the channel distribution, EEG signals are converted to 2-D EEG data meshes. The spatial and temporal features are extracted by CNN and LSTM, respectively. Their method outperforms state-of-the-art models. However, they ignore the frequency features of EEG.
EEG signals can be extracted with three different features, and they come from three domains: time, frequency and space. These three features are more often extracted by conventional methods, but they are rarely extracted by conventional DNN at the same time. The classification accuracy of EEG can be improved by fully extracting the three features. Moreover, different extraction order may lead to different classification results. The existing CNN-LSTM models have too many parameters. When the amount of data is small, these models are easy to overfit. With too many parameters, these models also need more time to train. This limits these models’ use for the online BCI. Therefore, a novel DNN architecture should be built to efficiently extract the temporal-spatial-frequency features of the signal. The above content is the motivation of this paper.
There are three advantages of our idea. Firstly, in order to further improve the classification accuracy of EEG signals, novel DNN architectures are proposed to jointly extract the temporal-spatial-frequency features. The frequency and spatial features of EEG signals can be extracted by CNN, and the temporal features are extracted by LSTM. Secondly, to compare the classification effects of different extraction orders, two series and parallel structures with CNN and LSTM are proposed, respectively. It is found that series structures are superior to parallel structures, and the reason is also analyzed. Finally, our best model has fewer parameters. Compared with conventional CNN, the number of parameters of compact CNN is relatively small. It has the advantages of higher classification accuracy and faster training speed. In future studies, it will be beneficial to apply this model to the online BCIs. The above contents are also the contribution of this paper.
The following section introduces the method of acquisition for the EEG signals of two types of data sets, and the architectures of our proposed deep learning models. Section 3 gives the results of analysis and classification. The further analysis about experimental results is discussed in Section 4. Section 5 concludes the paper.
