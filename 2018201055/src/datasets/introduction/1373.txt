The current educational reform focuses on developing and measuring students' abilities to engage in complex reasoning and thinking processes (e.g., scientific inquiry and problem solving) (Dasgupta, Magana, & Vieira, 2019; Eichmann, Goldhammer, Greiff, Pucite, & Naumann, 2019; Lederman et al., 2014) so the assessment tools nowadays should enable teachers to evaluate these abilities of their students (Pellegrino, Chudowsky, & Glaser, 2001). In the process of assessing students' complex abilities, teachers not only need to observe and record their students' behaviors when they perform the inquiry or problem-solving tasks, but also need to evaluate their abilities on the basis of their performance of these tasks. However, even though teachers can score students' performances, it is still challenging for them to record students’ every single action and manage their longitudinal data (Brown, Hinze, & Pellegrino, 2008).
Thanks to the improvements in information and communication technology in education, technology-based assessments (TBAs) make measuring and evaluating students' performances easier and more reliable (Brown et al., 2008). For example, TBAs can help teachers collect students' responses or record their observable performances (e.g., students' interactions with science simulations) and decrease the time required to gather and input test data (Brown et al., 2008; Kuo & Wu, 2013; Pellegrino et al., 2001). Additionally, teachers can diagnose students’ learning problems by retrieving the process data and comparing the process to the target performance (Brown et al., 2008). All of these potentials of TBAs make the measurement of complex abilities or skills possible and reliable. Furthermore, an increasing number of TBAs have been adopted by large-scale and international evaluation programs in recent years (Quellmalz, Timms, Silberglitt, & Buckley, 2012), such as the Programme for International Student Assessment. TBAs have been increasingly and widely utilized as important assessment tools for both researchers and teachers.
To promote and understand the usage of TBAs in classroom settings, previous research has explored factors related to the implementation of TBAs. For example, Zakrzewski and Bull (1998) indicated that, while teachers perceived the benefits of the rapid feedback and comprehensive statistical analysis provided by TBAs, they needed professional development and technical personnel to support their use of TBAs. Similarly, Hsu (2016) reported the need to support personnel and time for teachers to integrate technology into classrooms. In addition, Chien, Wu, and Hsu (2014) argued for the interplay between teachers' beliefs and their usage of TBAs, and found that teachers who frequently used TBAs held more positive beliefs about their perceived usefulness. Furthermore, the statistical analyses done by Chien, Wu, and Wu (2018) confirmed that teachers' willingness to use TBAs was determined by their beliefs about the perceived usefulness, ease of use, and compatibility of TBAs. While some studies have focused on factors related to teachers, others have dealt with students' acceptance of technology. For instance, Cheon, Lee, Crooks, and Song (2012) found that students' attitudes and control beliefs affected their intention to adopt learning with mobile technology. Nikou and Economides (2017) showed that, in addition to the perceived usefulness and ease of use of TBAs, the user interface and feedback provided by TBAs influenced students’ acceptance of using TBAs in the classroom.
Although the aforementioned studies revealed or suggested factors related to the implementation of TBAs, they focused on either teachers' or students' factors. None of them conducted a multilevel analysis to explore factors and relationships at different levels (e.g., school, teacher, and student levels). Secondly, while three of the aforementioned studies employed modeling procedures to examine relationships among factors (Cheon et al., 2012; Chien et al., 2018; Nikou & Economides, 2017), the outcome variables of these models were teachers' use of TBAs and students' acceptance of using TBAs. None of them addressed students' performances on TBAs. An investigation of students' learning performances is important for both research and practice because teachers' implementation of innovations is to eventually promote students' performances, which is a crucial indicator of teaching quality. Thirdly, in addition to teachers' and students' factors, other factors such as infrastructure and supporting personnel are contextual and closely related to school organization and settings. This suggests a nested structure of the data because neither students nor teachers could be randomly assigned to schools, but are clustered within schools. The nested nature of the data should be taken into consideration when researchers carry out quantitative investigations of teachers’ use of technological innovations in schools.
Therefore, this study aimed at filling the research gaps by conducting a multilevel study, and examined both student and teacher predictors of students’ performances on a TBA. In the next section, the teacher and student predictors are introduced and the relevant literature is discussed. The literature review provides a foundation for the proposed multilevel model, research questions, and hypotheses of this study.
