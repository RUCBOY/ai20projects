Owing to the fast data expansion nowadays, processing terabytes or petabytes of data has become a reality for data-intensive computing [1]. Especially, study [2] has pointed out that the latency and energy of loading and storing data between main memory and storage devices have become larger than that of processing data. As a result, the efficiencies of both data processing and the underlying storage devices have become major concerns. Among various data-intensive computing applications, external sorting is considered as a primary data processing technique. External sorting is used extensively in the data-intensive computing, such as the Hadoop framework or database management systems (DBMS) for query resolution and index creation [3], [4], [5]. From the perspective of storage devices, to accommodate the sheer amount of data, shingled magnetic recording (SMR) [6] drive is regarded as an attractive option since SMR drives can further enhance the storage density of existing magnetic recording disk drives via overlapping adjacent tracks at low cost. However, the overlapped track layout induces the sequential-write constraint because writing to one track could overwrite valid data on overlapped tracks. Therefore, I/O requests of external sorting may lead to serious write amplification and performance degradation if the data layout is not carefully configured. To resolve the inefficiency of external sorting on SMR drives, this study proposes a SMR-based External Merge Sort (SMR-EMS) strategy to boost the performance of external sorting on SMR drives via the concept of storage-centric computing [2], [7], [8] with the consideration of SMR characteristics. The technical difficulty of this study lies in how to mitigate write amplification issue of performing external sorting on SMR drives via considering the SMR characteristics and storage-centric computing concept for enabling efficient SMR-based external sorting.
To store big data at low cost, SMR is considered as a promising next-generation storage technology since SMR can enhance the storage density of existing magnetic recording disk drives without significant technology changes. SMR enhances the storage capacity via leveraging the size difference between disk read and write heads to overlap tracks on top of previous tracks, thus achieving higher areal density. However, the overlapped track layout imposes the sequential-write constraint on data write traffic to SMR drives. Therefore, random write requests to a group of overlapped tracks are not allowed. To absorb random writes on SMR drives, a small portion of the disk storage space is usually utilized as the on-disk cache area [9], [10], [11] to accommodate write requests via logging and an address translation table1 , which is also known as the shingled translation layer (STL). When the on-disk cache area is full, those cached data are flushed to the remaining portion of the storage space, which is known as persistent storage area. Nevertheless, due to the use of on-disk cache area, file data on SMR drives are written twice before being stored permanently in the persistent storage area. Thus, the issues of write amplification and worsened write performance has emerged.
On the other hand, to reduce the costs of moving data between host systems and storage devices, the concept of storage-centric computing has been proposed to conduct data processing within storage devices. The idea of processing data within storage devices can be traced back to the study conducted by Acharya et al. [12]. However, due to the computational limitation of on-storage processor back then, additional computational power and memory needed to be added onto storage device for accomplishing the active disk goals. Recently, the computational power of on-storage processor has grown over the years; thus, the concept of processing data directly on storage devices has been revisited, which is known as storage-centric computing. For instance, the ARMADA SP [13] storage processor family of Marvell is equipped with a Quad-core Marvell PJ4C ARMv7-MP CPU @1.2 GHz. The trend of storage-centric computing is mainly utilized to resolve the system I/O bus bottleneck and lower the latency and energy consumed by moving data between host systems and storage devices. For example, in 2016, Kim [14] tried to accelerate the key database operations, scan and join, for large-scale data analysis by moving data-intensive processing from the host CPU to the in-storage processor. Hence, the I/O requests and data transfer between the main memory of the host system and the storage devices can be eliminated. In addition, to make the performance of external sorting less dependent on the management of I/O requests, ActiveSort [15] mechanism has been proposed to offload the computations from the host system to the SSDs via the concept of storage-centric computing. Nevertheless, the performance and efficiency of external sorting could still be worsened when adapting sequential-write-constrained SMR drives as the storage devices for accommodating the large data amount of external sorting algorithms.
Sorting algorithms can be classified as internal or external ones based on whether the whole dataset can be fit in the RAM space at once or not [16], [17]. If the whole dataset can be loaded onto the RAM space during sorting, these sorting algorithms are considered as internal sorting. Examples of internal sorting algorithms in the literature are insertion sort, selection sort, bubble sort, quick sort, bucket sort, radix sort, merge sort, and heap sort [16]. On the other hand, if only a part of the dataset is present in the RAM space during sorting, this kind of sorting algorithms are known as external sorting. In other words, external sorting is conducted with only a small amount of dataset in the RAM space, while most of the dataset is kept in the secondary storage devices (e.g. hard disk drives or solid state drives). Examples of external-sorting algorithms [17] include external merge sort and external distribution sort.
External-sorting algorithms typically consist of two phases, including the run generation phase and run merge phase [18]. As summarized in Fig. 1, the run generation phase divides the dataset into small chunks for sorting in the RAM space. Then, the sorted small chunk is written back to storage devices as temporal files, which are known as runs. Each run consists of a small section of sorted dataset. Next, the run merge phase merges those sorted runs and outputs them as a single sorted dataset. Notably, since multiple I/O requests are issued to the storage devices during external sorting, the performance of external sorting is highly dependent on how the I/O requests are managed and the efficiency of the storage devices. Therefore, although the concept of storage-centric computing can be utilized to lower the I/O traffic between the host system and SMR drives, the performance and efficiency of SMR-based external sorting is still limited or worsened due to the issues of write amplification and worsened write performance of SMR drives.
To mitigate the inefficiency of performing external sorting on the sequential-write-constrained SMR drives, this study proposes a pioneer systematic solution, called SMR-based External Merge Sort (SMR-EMS) strategy, to enhance the external sorting performance via revisiting the concept of storage-centric computing for it can lower the unnecessary write traffics and deal with the write amplification issue of performing external merge sort on SMR drive. Notably, as the proposed strategy aims to enable a key–value-specific SMR drive that performs sorting within the SMR drive, the proposed strategy performs sorting as the data are written to the SMR drive for the first time and merges sorted results based on read requests. Thus, the main difference between traditional external merge sort and the proposed strategy is that the proposed strategy only writes the data once on SMR drives to avoid the issues of write amplification and worsened write performance due to the sequential-write constraint of SMR drives, while traditional external merge sort requires the dataset to be written several times during the sorting process. The proposed strategy facilitates the external sorting via sorting and storing data on SMR drives with three different approaches, including (1) the active-sort caching design, (2) the sorted runs mapping scheme, and (3) the locality-aware space allocator. Moreover, the unexpected power failure problem is also considered during performing external merge sort and the proposed SMR-EMS strategy is combined with STL as a key–value-specific SMR drive, which can be attached through the standard Ethernet port. Firstly, before data are written to the shingled storage space, the proposed SMR-EMS strategy utilizes the active-sort caching design to sort incoming data stream with the on-disk processor and the on-disk RAM space. The main advantage of the active-sort mechanism is to eliminate the data movement between SMR drive and main memory of host system. In the meanwhile, to prevent data loss during the sorting process in case of power failures or unexpected incidents, unsorted data are written to the on-disk cache area as an unsorted transaction. Then, sorted runs are stored in the persistent storage area and tracked with the sorted runs mapping scheme to record the physical location of each sorted run for facilitating the data retrieval process. Finally, the locality-aware space allocator is utilized to lower the seek latency between each sorted runs during the data retrieval process. With the proposed SMR-EMS strategy, the latency of external sorting on SMR drives can be improved by an average of 90.80% when compared with the native external merge sort on SMR drives without the proposed strategy.Download : Download high-res image (118KB)Download : Download full-size imageFig. 1. Phases of external algorithm.
The rest of this paper is organized as follows. Section 2presents the background and research motivation of this work, and Section 3 describes the design of the SMR-EMS strategy. Section 4 then analyzes the reduced amount of write amplification and sorted dataset retrieval latency for the proposed SMR-EMS strategy. Next, the effectiveness of the SMR-EMS strategy is evaluated by trace-driven experiments in Section 5. Finally, Section 6 concludes this study and the research remarks.
