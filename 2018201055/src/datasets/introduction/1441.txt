In recent years, processor manufacturers have shifted their development focus away from increasing clock speeds and single-threaded performance. The rising prevalence of multi-core and multi-processor systems adds additional importance to the quest for high-performance data structures that permit concurrent reads and writes while maintaining correct behavior.
Concurrent data structures can synchronize via several methods; the most common techniques involve locking. An exclusive lock can be used to control access to some portion of a data structure. When a thread attempts to access a portion of a data structure, it first acquires one or more locks. Multiple techniques exist offering varying degrees of performance. The performance of a technique depends upon both the number of locks which must be acquired during an operation and the granularity of each lock (the fraction of the data structure protected by each lock).
Other algorithms use atomic read–modify–write instructions in lieu of locks. These instructions, such as compare-and-swap (CAS) or load-linked/store conditional (LL/SC), can be used to provide lock-free or wait-free synchronization [13]. Efficient lock-free and wait-free algorithms are inherently more complex than lock-based algorithms; they are harder to design, analyze, implement, and debug.
The linked list is one of the most ubiquitous data structures in computer science. It implements the standard set operations: insert, remove, and lookup. A linked list is typically implemented via a sequence of nodes, each of which contains a key, possibly a data element, and a pointer to the next node in the sequence. Linked lists are of particular interest because many other data structures (such as graphs and hash tables) use linked lists as “black box” subroutines [6].
Linked lists have been well-studied from a concurrency perspective; several efficient lock-based algorithms exist. The simplest implementation utilizes single lock to protect all accesses to the list, but this does not allow for any true concurrency. Improvements have been seen with fine-grained locking, where each node contains its own lock. These fine-grained algorithms can scan the list for a node of interest and acquire the lock on that node (and possibly other nodes). Two algorithms that use this technique include an “optimistic” algorithm by Herlihy and Shavit [14] and a “lazy” algorithm by Heller, et al.[11].
Linked lists, while extremely useful, do possess several disadvantages. One major disadvantage is that any operation, on average, traverses half the nodes in the list. Each step in this traversal dereferences that node’s next pointer and accesses a memory location that may be far removed from the prior node. This access pattern makes poor use of the memory hierarchy found in today’s systems.
Several attempts have been made to increase the efficiency of linked lists by combining multiple keys into a single node. These “unrolled” lists, first described by Shao, et al. [21], improve performance in two ways. First, unrolling reduces the number of pointers which must be followed to find an item. Second, this groups multiple successive elements in sequential memory locations and better conforms to the principle of spatial locality [8], [20].
More recently Braginsky and Petrank developed a “chunked” lock-free linked list [4]. Their algorithm improves the locality of memory accesses by storing sublist of sequential key–data pairs within a contiguous block of memory. As time elapses and elements are inserted and removed from the list, their algorithm splits full chunks and combines sparsely populated ones. An operation can quickly locate the appropriate chunk, and searches within a chunk exhibit favorable spatial locality.
Our contributions.We present a new lock-based data structure for a concurrent unrolled linked list based upon lazy synchronization wherein the majority of operations complete by locking a single node. We allow our data structure to contain up to K key–data pairs per node; this improves both the storage density and locality of reference within a node [8]. Using the algorithms we present, we can traverse this data structure in O(n∕K+K) steps, where n is the number of key–data pairs stored in the list.The data structure we present exhibits excellent throughput when compared to other list-based sets. Our analysis shows that it (i) exhibits high degrees of spatial and temporal locality by accessing sequential memory locations; (ii) responds extremely well to common compiler optimizations; and (iii) increases node density by eliminating extraneous pointers. In performance testing our implementation provides up to 300% higher throughput than the list presented by Braginsky and Petrank [4]. The improvement over other concurrent linked lists is even higher.
Roadmap.The rest of this work is organized as follows. Section 2 describes prior work related to this work. Section 3 briefly describes our system model. Section 4 describes our linked list and the algorithm to implement standard set operations. The proof of correctness of our linked list is given in Section 5. Section 6 describes our experiments and analyzes the results. Section 7 describes some optimizations to improve the performance of our linked list. Finally, Section 8 consists of our conclusions and suggestions for further work.
