The speed of social development is accelerating, and new technologies are born every day. Societal developments provide people with new opportunities and conveniences. However, human beings still face new challenges and problems. At the end of 2019, a novel coronavirus (SARS-CoV-2) was detected. The virus spreads very quickly, causing substantial losses to the entire society. Issues such as how to find a cure for the virus, how to find the source of the virus, how to develop a vaccine, and how to distribute materials during the epidemic require experts and scholars to find new or more suitable methods in their research field.
Among different categories of methods, algorithms are bound to have an important role; algorithms are ubiquitous and offer precise methodologies to solve problems (Carman, 2013). Informally, an algorithm is any well-defined computational procedure that takes a set of values as input and produces some value as output (Cormen, Leiserson, Rivest, & Stein, 2009), which is needed in scientific research. Especially in the era of big data, data-driven research requires algorithms to extract, process, and analyze massive amounts of data. Therefore, algorithms have become research objects, as well as useful technologies, of scholars in different fields. In the "Venice Time Machine" project in the field of digital humanities, researchers used machine learning algorithms to reveal Venice's history in a dynamic digital form to reproduce the glorious style of the ancient city (Abbott, 2017). In the field of computer science, scientists have used machine learning algorithms to combat the novel coronavirus, including the use of algorithms to detect infections, differentiate COVID-19 from the common flu and to predict the epidemic situation (Dave, 2020).
Academic papers in many disciplines, especially in the computer science domain, propose, improve, and use various algorithms (Tuarob & Tucker, 2015). However, not everyone is an algorithm expert. For many researchers, especially beginners in a field, gaining a thorough understanding of the algorithms and finding one that is suitable for their own research are urgent problems. Scholars usually find suitable algorithms through two methods. One method is direct consultation with more experienced scholars, but this method depends on the advisers’ knowledge and does not guarantee the comprehensiveness of the algorithm suggestions. Another method is reading academic literature and finding algorithms from the research of other people, which provides scholars with more algorithms. Academic papers are a perfect source of algorithms; however, information overload cannot be ignored. The research has pointed out that the number of academic literature entries generated worldwide has reached the level of millions, and it continues to increase at a rate of approximately 3% each year (Bornmann & Mutz, 2015). If scientists only search for algorithms by reading articles, it will be a time-consuming and labor-intensive challenge. If the algorithms mentioned in papers, namely, any algorithm appearing in the papers, including the algorithm proposed, used, improved, described or simply mentioned by the author, can be identified and evaluated, it can save time for scholars and provide a solid foundation for them to sort out the algorithms of specific disciplines or research topics.
To this end, this article aims to collect algorithms in research papers in a domain and further explore the influence of algorithms. Tuarob et al. (2020) defined a standard algorithm in academic papers as one that is well known by people in a field and is usually recognized by its name, including Dijkstra’s shortest-path algorithm, the Bellman-Ford algorithm, the Quicksort algorithm, etc. On this basis, we use our experience, authors’ descriptions and other external knowledge to annotate the named algorithms in articles. In addition, we posit that, when an algorithm appears in an article, it has an influence on the article. Therefore, we evaluate the influence of an algorithm based on the number of papers that mention the algorithm in the full-text content. Mention count has proven to be a suitable indicator to measure the influence of entities in academic papers (Howison & Bullard, 2016; Ma & Zhang, 2017; Pan, Yan, Wang, & Hua, 2015). Therefore, we take the field of natural language processing as an example and explore three research questions:RQ1What are the high-influence algorithms in natural language processing?RQ2What are the differences in the influential algorithms in different years?RQ3How does the influence of the algorithm change over time?
To be more specific, we attempt to research on the influence of different algorithms in NLP domain through the first question. For question 2, we combine the influence and time to understand the changes of high-impact algorithms in different years, and try to analyze the development of NLP field from the perspective of changes in algorithm. The third question is the refinement of the second question. We will explore evolution of specific independent algorithms and give the pattern of changes in influence.
The reason for choosing the field of natural language processing is that papers in the computer science field are more likely to propose and use algorithms than papers in other fields. Furthermore, computer science is a rapidly developing discipline, and there are various algorithms that emerge in the discipline, which ensures that we can collect enough algorithms to carry out our research. It should be noted that, in the traditional named-entity recognition task, named entities refer to nouns or noun phrases representing various entities (Petasis, Cucchiarelli, & Velardi, 2000). Therefore, in this paper, the annotated algorithm refers to the noun or noun phrase representing the algorithm with a specific name, for example, the support vector machine, rather than the concept described by the author, for example, a novel classification algorithm.
