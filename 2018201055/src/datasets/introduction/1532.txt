Ceding a decision to someone else has been a canonical issue in economics, political science, and public administration and has been well studied in the name of the principal-agent theory (e.g., [65,77,85,89]). The principal-agent problem (PAP) results from informational asymmetry and the conflicts of interests (or goals) between principals and agents. PAP results in malfeasance by agents. However, existing principal-agent theories are replete with human-centered approaches, which means that they do not consider non-humans, like computer algorithms, as agents. This study poses a critical challenge to this assumption.
Computer algorithms are of late replacing human judgement to varying proportions [90], and in turn humans justify this judgement because computers “said so” [45] in algorithmic governance, which collects and analyzes big data through computer algorithms and uses them for decision-making. Algorithmic governance is used for corporate marketing, stock trading, insurance, and corporate credit evaluation [6,61]. It has been widely adopted in recent times in the public sector for predictive policing, health, and environmental management [45]; [36]; [39,70,80]. More importantly, with the development of artificial intelligence (AI), machine learning technology including deep neural networks is being rapidly tested in algorithmic governance (e.g., [44,67]; [76]).
Algorithmic governance is well suited to analyze the PAP because it embraces the basic condition of the principal-agent theory such as the delegation of tasks, informational asymmetry, and malfeasance. As agents, data scientists act on behalf of principals like bureaucrats and corporate managers, and the latter are almost oblivious of how computer algorithms work for decision-making. In this case, algorithmic governance returns to the traditional PAP [13] like the politics of technocracy. However, more than that, computer scientists also cede their decision to a computer algorithm, and sometimes, due to its opacity, even they barely understand how the algorithm works [9]; [34]; [43,45].
In this sense, this research raises a new research question: How is the PAP to be understood, if not only human principals but also human agents (e.g., experts) are not fully aware of how computer algorithms work? This research mainly focuses on the relationship between the inscrutability of computer algorithms and the PAP. To analyze this point, this research examines the PAP of algorithmic governance from the new materialism perspective [55,62]. This perspective challenges a conventional idea that an algorithm is just a representation of political ideologies ([24]; [68]), while assuming that a computer algorithm is also another agent that co-constructs this governance with humans. This view has rarely been discussed in the context of the principal-agent theory with the exception of Bostrom's [8] work. Therefore, this research probes a new material PAP between computer scientists as principals and computer algorithms as non-human agents.
This study contributes to the literature on the principal-agent theory and algorithmic governance by evoking the effect of material politics in deep learning algorithms, which are different from existing human-centered approaches like technocracy and traditional political economy. This study primarily aims at offering theoretical reflections; however, it also lays an empirical ground partly with regard to the use of algorithms in predictive policing, personnel management, health policy, and environmental management.
This paper begins with a literature review and theoretical background, with a focus on existing studies on the principal-agent theory, algorithmic governance, and the new materialism approach to public policy. Second, it examines the core elements of principal-agent theory—information asymmetry, malfeasance, and agency relationships—in the context of algorithmic governance. Finally, it discusses the implications of deep learning algorithms in algorithmic governance in terms of the limitations of existing principal-agent theories, new materialism perspectives, and potential policy solutions to PAPs.
