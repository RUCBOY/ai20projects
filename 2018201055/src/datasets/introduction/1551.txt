Historically, the press has the responsibility to publish facts of public interest. To do so, stories must pass through a series of journalistic criteria (White, 1950). The Internet, however, has a different structure that can disrupt this system. Anyone can fabricate content and spread it to the world. Social media is an example of a popular place where fake news spread, but they are not restricted to it. As a result, the need to identify fake news arises, regardless of where they are published and even in which language.
There has been a debate concerning the impact fake news can have in major events such as elections (Allcott & Gentzkow, 2017). Alongside the attention fake news has gathered in recent years, ways to detect them have motivated a wide range of works in different fields. For example, many websites dedicated to fact-checking rely on human labour to verify the authenticity of suspected news or claims. This approach has the advantage of focusing on news individually, but it is costly or even impractical at large scale considering the number of news that is published every day.
Furthermore, machine learning could be used as an ally in the task. Usually, works in the field train supervised learning models based on datasets of news that were manually annotated concerning their veracity. Then, the models infer whether unlabelled news are true or fake from extracted features from these datasets. This approach can handle a huge amount of data in a short time and can be a good start to raise alerts about suspicious texts.
Fake news detection is treated here as a classification problem under a supervised model. There are two phases (Han & Kamber, 2000). In the first one, a model is built from a training set. Each object in this set is labelled with a class cj∈C, being C=c1,c2,…,cl the set of l possible classes. In the current scenario, there are two classes: fake and true, and it is in this phase that a function is estimated. In the second phase, the estimated function is used to infer the label of unseen objects.
The main contribution of this paper is the evaluation, with the same methodology, of techniques for fake news detection in multiple platforms and languages. This is an opposed approach to what has commonly been done in the literature, in which proposed methods are tested only in a specific language and/or rely on specificities of digital platforms (usually the case of social networks) (Yang et al., 2012, Monteiro et al., 2018, Jin et al., 2016, Liu and Wu, 2018, Gravanis et al., 2019). As pointed by Zhou and Zafarani (2018), before the introduction of detection techniques to fake news, one has to answer some fundamental questions which are still unclear, such as how does fake news propagate from various domains or languages.
Here, we study the problem of fake news detection in three different languages, all of them from distinct origins: English is a Germanic language, and it is a standard choice for many natural language processing studies. On the other hand, we find fewer works on Portuguese, a Latin language, and Bulgarian, Slavic. Fake news is not restricted to any specific language or country, therefore a more generic approach for detecting them is salutary. We compared four distinct text feature sets, all of them they can be generated regardless of the source platform, i.e., they do not rely on specificities like a particular metadata from a given social network, or time information that might not be available in a website text, for example.
The remainder of this paper is organised as follows. Section 2 discusses related work. Afterwards, an overview of document representation techniques is presented in Section 3. The features we used in this work, as well as the characteristics of the datasets, are presented in Section 4. Section 5 discuss precautions to avoid data leakage when training models, with special attention when dealing with tweets. Then, experimental results for fake news detection are discussed in Section 6. Finally, Section 7 concludes the paper and points to future work.
