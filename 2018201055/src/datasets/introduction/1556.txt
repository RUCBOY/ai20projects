Globally, building energy consumption currently accounts for about 40% of total final energy consumption, making the optimization of building operational performance crucial in today’s world [1]. The building energy consumption of China, for example, which has become the second largest energy consumer after the United States [2], accounts for about 30% of the country’s total energy consumption. Therefore, the energy consumption of buildings has considerable energy savings potential. This requires the precise prediction of building energy consumption because the accuracy of the forecast will directly affect the control strategies of a building’s energy equipment and thus affect the building’s potential energy savings. For instance, the reduction of peak electricity demand, which can be classified a strategy of Demand Side Management, will definitely gain economic and environment achievements [3], since Peak demand is a major factor in the growth of investments in network infrastructure [4]. Therefore, an accurate building consumption prediction will benefit both electricity network and end users in demand management [5], which can further Reduce the operational risk of network [6].
Approaches for the prediction of building energy consumption can be divided into two types: physics models and data-driven methods [7]. Physics models of building energy consumption take into account parameters related to the characteristics of the building itself and obtain building energy data through a clear thermodynamic mechanism. Heiple and Sailor [8] divided public buildings into 11 types to construct 22 physics models for prototypical public buildings and forecast their energy consumption. However, the construction of a physics model for a building requires a large number of parameters (Building thermal physical parameters, energy equipment parameters and so on) and detailed system settings (Personnel activity schedule, air conditioning zoning and so on) related to the operation of the building, which are difficult to obtain. Besides, when using physics model for energy forecasting, model calibration is an essential and significant step to guarantee the accuracy of building models [6], [9]. However, model calibration requires a lot of measurement data, which is hard to obtain. Therefore, it is difficult for physics models to achieve ideal forecasting accuracy.
Data-driven models rely on historical data to predict energy consumption [7]. Previous studies have shown that different data-driven models are effective in the prediction of various building energy consumption, including heating consumption, cooling consumption, electricity consumption and hot water usage. For instance, Yan et al. [10] used multilayer layer perceptron neural network (MLP) and the support vector regression (SVR) to predict short-term heating consumption; Roy et al. [11] applied a hybrid model of MARS (Multivariate Adaptive Regression Splines) and ELM (Extreme Learning Machine) to forecasting heating load. As for cooling consumption, Ahmad and Chen [12] used six data mining models to predict cooling load. Those six models are - tree bagger, Gaussian process regression, multiple linear regression, bagged tree, boosted tree and neural network. In 2018, Huang et al. [13] employ a Bayesian Network model to forecast the cooling consumption in commercial buildings. In the field of electricity consumption forecasting, Mat Daut et al. [14] conducted a detailed review of the building's electrical energy consumption prediction. The result of literature review shows that the hybrid of SVM and SI (swarm intelligence) methods has indeed presented superior performance for forecasting building electrical energy consumption. Leung et al. [15] used Artificial neural network (ANN) to predict electricity demand for cooling systems in buildings. In addition, Pang and O’Neill [16] performed a large-scale Monte Carlo simulation to simulate the hot water usage in hotels. In recent years, with the continuous improvement of the dimension of building energy consumption data, deep learning, as a method that can well process high-dimensional data, has been increasingly applied in the field of building energy consumption prediction [17], [18]. Deep learning models can also be used as a separate feature extractor [19]. Fan et al. [20] compared the performance of different types of deep learning models, including convolutional neural networks and recurrent neural networks, on short-term load forecasting; Guo et al. [21] argued that a simple dense deep learning model can obtain better accuracy than the random forest or the gradient boosting model. However, according to these studies, all data-driven models require a multitude of historical data for their construction, a requirement that is difficult to meet in some new buildings or buildings with a newly constructed energy monitoring platform. Given that having historical energy consumption data for buildings is critical for the creation of accurate building energy consumption predictions [22], if a monitoring platform cannot supply the large quantities of historical data needed for data-driven models, it is hard for accurate forecasts to be obtained.
In light of these studies and the current problems with physics models and data-driven models mentioned above, the idea is to use transfer learning to address the problem of insufficient historical data when using data-driven models to predict energy consumption. Transfer learning is applied in solving real-world problems in a number of fields, including natural language processing [23], [24], face verification [25], and visual tracking [26]. In the field of energy and buildings, Grubinger et al. [27] used transfer component analysis and online transfer learning to forecast temperature in residential buildings, and Mocanu et al. [28] used a deep belief network with reinforcement learning to build an online cross-building transfer learning model. Those two papers focused on online transfer learning. With regard to off-line transfer learning, Ribeiro et al. [29] proposed a novel method, Hephaestus, for data pre-processing and domain adaptation in order to use transfer learning via traditional machine learning support vector regression (SVR). Ribeiro’s research team used four schools in Canada to verify their method. Each school used one year of data for calculating the factors of the Hephaestus method and another two years of data for training the model. The results showed that the mean absolute percentage error (MAPE) was about 10%, the best result achieved in the case study. Although Ribeiro et al.’s research is instructive, their study used an entire year of real data to calculate the trend factors for the Hephaestus method, which is a luxury given the status of energy consumption information in some buildings. In addition, Hephaestus involves complex pre-processing for transfer learning, and the prediction process of SVR model is not time dependent. Time dependent implies that the same features at two different time steps will lead to different output [30]. In other word, in SVR model, the output in the previous time step can barely affect the model output in current time step because there is no internal temporal method in SVR [31]. In order to process time series data, SVR needs external temporal methods, like add some temporal attributes in feature vector. Therefore, Ribeiro used four temporal attributes in the model, which will undoubtedly increase the feature dimensions of the whole model.
In the current research on deep learning, convolutional neural network (CNN) and long short-term memory (LSTM) network are widely used in the field of deep learning, especially in computer vision and natural language processing (NLP) [32]. The network structure of LSTM is particularly suitable for processing time series data and is widely used in the field of NLP. Since building energy consumption data is a kind of time-series data, this paper proposes LSTM to build transfer learning model. Due to the good performance of CNN model in feature extraction, especially image feature extraction in computer vision, this paper uses CNN model to extract features from data and construct high-dimensional features. Be that as it may, those two models still have some drawbacks, for instance, LSTM’s structure is relatively complex and has many parameters, so the debugging of the model needs to prevent overfitting and underfitting. Besides, LSTM could not store information in a long period [32]. As for CNN, the overall structure of CNN model is relatively stable, and the tuning time may be long. However, these problems can be solved in practical applications, for instance, adding regularization mechanism to prevent overfitting.
Finally, to address the limitations of the studies discussed above and take advantage of CNN network and LSTM network, this paper proposes two transfer deep learning models: (1) a sequence-to-sequence (seq2seq) model, which uses LSTM as encoder and decoder, and (2) a 2D convolutional neural network (CNN) model with an attention layer to improve forecasting accuracy by transferring knowledge learned from similar buildings. It is worthwhile to denote that the attention layer was only combined with CNN model in this paper. The objective of our study was to determine whether these two models could improve prediction accuracy over a conventional model.
The paper is organized as follows: Section 2 introduces related concepts concerning transfer learning, the seq2seq model, and the attention layer. Section 3 illustrates the methods and the specific network used in this paper. Section 4 presents a case study of three office buildings using the model proposed in detail. Furthermore, Section 5 introduces the results and discussion part. Finally, Section 6 delivers our conclusions.
