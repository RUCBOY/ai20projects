In today's world, whether we are transiting via public transport or walking on roads as pedestrians, a significant amount of time is being spent in our vehicles or interacting with other vehicles on the road. However, as the number of vehicles is increasing rapidly, fatalities from road accidents are also increasing. In such a world, road safety is of utmost importance. Fortunately, at the brink of the fourth industrial revolution as many scholars point out, transportation perhaps has seen the most significant advances in its technologies. Vehicles have moved from being just a mechanical locomotive to smart, fast wagons of luxury and comfort, and artificial intelligence is at the frontier of our most advanced technologies.
The safety and comfort of passengers have been the major driving forces for developing advanced driver assistance systems (ADAS) [1], [2], [3], which ultimately has led to the creation of fully autonomous self-driving cars. Self-driving car technology can be broken down into three major building blocks: perception, planning, and control. This study addresses developing and testing a perception algorithm that uses camera data and computer vision to help self-driving cars perceive the world around them.
Computer vision is at the core of perception algorithms, and cameras are the closest equivalent technology to how humans perceive the world around them. Though technologies such as Lidar [4] and radar [5] systems are used actively while developing perception technologies, cameras provide us with a powerful and cheaper way of extracting information about our environment. In this study, a robust lane detection algorithm that can determine the safe drivable region in front of a car is discussed in detail.
The first building block of the vision perception module is lane detection. The task of navigation requires determining the position of the vehicle relative to the road. In the present work, a relatively primitive approach for detecting lanes and learning from its shortcomings has been analyzed to design a more robust lane detection algorithm that can both detect and predict the location of the vehicle with respect to the road itself. This approach emphasizes extracting relevant information from the environment using only a single red, green, and blue (RGB) camera fixed to the front of the vehicle as the source of data. A series of color-space explorations is used to isolate the lanes and proceed to detecting them using a Canny edge filter [6] and the Hough transform [7].
This paper is organized as follows: Section 2 describes the minimalistic approach for lane detection. Section 3 describes the advanced lane detection approach and preprocessing. Section 4 presents a novel improved technique based on perspective transformation and histogram analysis and also discusses proposed sanity check techniques. Section 5 gives experimental results and analysis of the proposed algorithm. A conclusion and future scope of work are given in Section 6.
