Social computing can be any type of computing application, with software as the medium or focus of social relationships. Nowadays, social networks can interact with humans through artificial intelligence robots such as Microsoft Xiaobing, and the conversation model can better help intelligent robots communicate with humans by learning human conversation logic. With the improvement of computer performance and the availability of conversation data on the internet, an increasing number of researchers have turned their attention to conversation generation in open domain [1], [2]. Rule-based and template-based methods are not suitable for open domain conversation models, because they have difficulty dealing with diverse topics and understanding natural language [3]. The existing open domain conversation generation studies are roughly categorized into retrieval models and generation models.
Given an input context, retrieval models search the corpus (which contains a large number of context–response pairs) for the context most similar to it and uses the corresponding response as the final result. The retrieval model (IR) is a common technique in open domain conversation generation [4]. The disadvantage of retrieval models is that new utterance cannot be generated, as only the utterances that appear in the corpus can be used as responses [5], [6].
Using encoder–decoder framework to construct end-to-end conversation generation models has become a new research trend in the past few years [7], [8]. The encoder maps the input context into a series of vectors and the decoder further generates a new response based on these vectors. Most competitive conversation generation models use recurrent neural networks (RNNs) as the encoder and decoder, and such models are also known as sequence-to-sequence models (seq2seq) [9]. Although the seq2seq is the advanced framework in the field of conversation generation, the fact that its response could be short, meaningless, repetitive and could lack logic, makes its real world applications challenging [10]. In addition, the inherent sequence-dependent structure of RNN makes it unsuitable for large-scale parallel computing. Due to the long calculation time, this intrinsic property causes irreparable defects in the RNN-based conversation generation task.
Transformer is also a model with an encoder–decoder framework, but it only relies on the attention mechanism to capture the dependencies between input and output and completely discards the traditional RNN [11]. The attention mechanism makes the global information of the utterance directly obtainable, and its parallelizable property makes the calculation time of the transformer much smaller than seq2seq. The main component of transformer is the encoder–decoder framework based on multi-attention, where multi-head attention can find the internal relations of the utterance to encode it. Since the multi-attention cannot capture the position information of the sequence, a separate positional encoding module is used in the transformer to perfect it [12].
In order to improve the performance of the conversation model to better complete social computing, in this paper, we propose a hybrid model called The Rerank of Retrieval-based and Transformer-based Conversation Model (RRT) that takes into account both the retrieved and generated responses. For an input context, we first use the inverted index to retrieve the K contexts most relevant to the input one in the corpus, and further rank the responses corresponding to the K contexts by certain rules. The response with the highest score is used as the candidate utterance for retrieval. The generation model can generate utterances from scratch, use transformer instead of seq2seq to generate responses with the expectation to get rid of the sequence dependencies of the RNN and generate a more appropriate response in less time. The retrieved candidate and the response generated by the transformer-based generator will be further compared to select the most appropriate response. Two candidate responses are transformed into corresponding vectors using the method applied in the pre-retrieval and their similarity to the input context is calculated. Unless the length of the generated response is longer than a certain threshold or the similarity with the input context is higher, the retrieved candidate response is used by default as the final result.
We present detailed experiments on a large collection of more than 400,000 Weibo dataset and public Qingcloud dataset. We compare our RRT model with generation models and the retrieval models on various metrics, such as the classic BLEU metrics and the diversity-based Distinct metrics. The experiments show that our model outperforms traditional generation models on each metrics, and it also improves on most metrics compared with the retrieval models. We further find that both the retrieval model and the generation model contribute to the important portion of our model, and our model achieved good results with less time and computational cost than traditional models.
Generally, the main contributions of our paper are as follows:
1. We apply the transformer to conversation generation in open domain, achieving better performance than traditional seq2seq while reducing the training time of the model by five times.
2. We propose the RRT model to optimize the joint results of information retrieval model and transformer-based, which improves the performance of the response in terms of relevance, diversity and fluency.
3. We did rich comparative experiments on two datasets to prove the effectiveness of the RRT model on a variety of metrics.
The rest of the paper is organized as follows. Section 2 briefly presents the recent work in the field of neural conversation. Section 3 gives a detailed introduction to our proposed model, followed by the details of the datasets and model training process in Section 4. The relevant evaluation metrics and the results of the experiment are shown in Section 4 and our work is concluded in Section 5.
