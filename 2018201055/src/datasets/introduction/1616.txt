Semantic segmentation is a fundamental and challenging technique in numerous computer vision tasks[1], [2] like detection [3,4], human parsing [5] and autonomous driving [6]. With the recent development of the convolutional neural network, especially the Fully Convolutional Network (FCN), a lot of great works such as [7], [8], [9] based on FCN have obtained promising results on benchmarks [10], [11]. These state-of-the-art methods are generally achieved by learning very deep networks on large scale, high-quality and thoroughly annotated datasets, such as the ImageNet [12], COCO [13], Pascal VOC [14] and CityScapes [15]. However, collecting such datasets manually will entail prohibitive high labor cost. The scarcity of pixel-level annotated data has become a bottleneck to further improve performance. To address this issue, we utilize computer synthetic image dataset since it is largely available from computer games and the ground truth could be easily generated automatically. There is indeed large gap between synthetic images and real images, which results in huge performance drop, known as “domain shift” [16]. To eliminate this side effect, knowledge transfer and domain adaptation techniques have been proposed to close the gap between source and target domain. In this work, we try to address the problem of domain shift in image segmentation, seen Fig. 1. Inspired by [17], we apply domain adaptation as our methodology. Different from [17], our method adapts image in both image-level and feature-level. we start from a simple intuition: “domain shift” is caused by the variant color, texture, and illumination in images from different domains. If we can alleviate or even eliminate these differences, we can tackle the problem of “domain shift”. The image-level transfer is more primitive and concrete while the feature-level transfer is more complex and abstract. Based on this assumption, we propose a new method to solve the challenge of domain adaptation via an adversarial manner. After adaptation, we want to further improve our performance, hence we adopt a self-training strategy. [18], [19] applied self-training strategy in their segmentation work and obtained excellent results. Based on their works, we propose our self-training method via the confident value from the softmax output. Our experiments show that self-training is quite effective in our method. In summary, there are four main contributions in our work:
(1)We develop a novel generative adversarial network to conduct unsupervised image translation, which gives great sense to domain adaptation.(2)We use two generative adversarial network to close the gap between two domains from perspectives of both image-level and feature-level.(3)We adopt a self-training strategy that can significantly improve the performance on target domain, and this strategy can also be easily applied to other domain adaptation tasks.(4)We evaluate our method on popular segmentation benchmark Cityscapes, and the results demonstrate that our method outperforms other state-of-the-art methods for unsupervised domain adaptation in segmentation.
