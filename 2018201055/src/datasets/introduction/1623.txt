General definitions and concepts: One of the definitions of learning is the acquisition and refinement of one’s categorization and decision-making skills. For living organisms, learning is the basis of survival, adaptation and procreation: the more accurate a decision is, the more appropriately it relates to the environment – the fitness and success of an organism are greater. The most evolutionarily ancient decision-making cascades can be described by basic logic operators: for example, if triggered – then squirt (condition, e.g. in exploding cucumber plant Ecballium elaterium); if the light is intense – then do not advance (negation, e.g. in nematode worms); if the environment is warm and humid – then oviposit (conjunction, e.g. in parasitic mites), and so on. Although such robust logic operators are adaptive and improve the chances of survival of an individual or species, they do not qualify as learning in the strictest sense – these are purely logic functions of syntax that connect a simple input and a binary (yes or no) output. In derived species with complex neural circuitry, learning incorporates the use of abstract concepts, where it relies on memory and therefore acquires more semantic features (see text box below, and Nicaud et al. for an algebraic interpretation (Nicaud et al., 2001). Nevertheless, even complex, semantic, memory-based categorization that involves numerous independent inputs can be to some extent decomposed into smaller-scale, incremental syntactic cascades (Nicaud et al., 2001). The acquired association of neuronal circuits in the process of learning is described by the theory of neuronal plasticity (Hebbian theory) that is sometimes colloquially epitomized as “cells that fire together wire together” (Hebb et al., 1949). A comparison of syntactic and semantic categorization is illustrated in Fig. 1.Download : Download high-res image (256KB)Download : Download full-size imageFig. 1. Illustration of syntactic and semantic classification using anagrams. The pairs of phrases “sane blog”/”noble gas” and “conversation thread”/”conservation dearth” - have the same grammatical structure, and they also contain exactly the same sets of characters. Therefore, syntactic categorization separates the phrases vertically. However, this is inaccurate in terms of their meaning: from a semantic perspective, each phrase has an associated abstract “library” of connotations based on observation, empirical validation and experience. Based on the overlap of these connotations, we assign the phrases to the same semantic categories horizontally.
Syntax (in logic and computer sciences) is a set of shallow incremental rules (formulas, expressions, proofs or algorithms) applied for constructing, decomposing and transforming inputs, and for matching patterns. It is independent of semantics. Mathematics and computer sciences formally apply syntactic operations, although these can participate in semantic models (Nicaud et al., 2001).Semantics are concerned with meanings and truth-falsity relationships. Concrete or abstract objects, models, associations, connotations, concepts, insights and experiences belong to the domain of semantics.Accrual of syntactic levels may approximate semantic relationships, although there still might be a true statement that cannot be proven syntactically using axioms and incremental rules. In fact, even a seemingly accurate semantic proof of truth or falsity is contingent on the logical rigor of the operator: ”a more precise answer is only better than a less precise one if it answers a correct question”, from Ching et al. (2018).Machine learning is a domain of computer sciences concerned with development of algorithms and models that are capable of performing tasks without relying on explicit instructions. Machine learning uses syntax to derive semantic truth or falsity. A machine-learning model uses iterative optimization steps to construct a function that recognizes a pattern as an object based on a characteristic set of features, or a feature vector. Learning, in this context, means building up the capacity of the model to identify and correctly classify similar features within a different, unfamiliar dataset to the desired level of accuracy and precision.Feature is a quantifiable attribute of an object or pattern. A set of features (a feature vector) that is unique for a class of patterns, is used in pattern recognition and categorization. The pool of features and feature vectors comprises a feature space of n dimensions.Pattern recognition is classification of objects based on feature vectors, or characteristic combinations of features.Semantic segmentation is identification of all the objects that constitute a given class, and labeling them with one common label. Semantic segmentation can easily reach high sensitivity at the expense of specificity, and thus produce false-positive categorizations (Ruiz-Santaquiteria et al., 2020).Instance segmentation is identification of each object belonging to a given class as a unique entity, and then attributing a unique label to each entity. Instance segmentation may be highly specific at the expense of sensitivity, and thus produce false-negative categorizations (Ruiz-Santaquiteria et al., 2020).
Machine learning in image analysis can solve the following classes of problems: i) image classification according to the main object category (“what”), ii) object identification in an image (“what” and “where”), iii) pixel-wise semantic segmentation, (the “what” is already known, and the “where” must be very specific in terms of object boundaries and coordinates), and iv) pixel-wise instance segmentation (indefinite number of the “what” tags, and still very specific object boundaries and coordinates). Only semantic image segmentation is being addressed in this primer. However, for all these three purposes, the logical toolkit of syntax aims at semantic categorization and attribution of pixels to a finite number of classes (Nielsen, 2015). For example, a cell nucleus – a dynamic living structure housing the genetic machinery of a cell – is a semantic object. Yet, an electron micrograph of a cell nucleus is a 2D matrix of greyscale values that in-and-of-itself does not possess semantic attributes. Nevertheless, syntactic constructs of adjacent pixels form recognizable patterns that stand for example as a phospholipid bilayer membrane, chromatin, nuclear pore complexes and other characteristics of a nucleus. Thus, multiple measurable syntactic features of a pattern correspond to the semantic attributes of an object. Finding a robust and reliable association between specific and yet generalizable feature patterns, and the corresponding semantic descriptors of an object, is the staple of image processing and analysis in biological imagery.
Ground truth is a term used for a dataset that has been empirically classified by the operator. Ground truth is the expected and exact output. Ideally, ground truth that is produced by a human operator for training a machine learning model should be as unequivocal as possible in order to allow the neural network to construct a robust and precise logical path from the raw input to the interpretable output.An artificial neuron – called a perceptron – is a function that makes a binary decision analogous to an “all or none” action potential by weighting evidence (inputs) and applying an activation bias. As its inputs, a perceptron considers quantifiable features. For an output to be positive, the combination of the weighted inputs has to exceed the bias.
The multitude and the hierarchy of features in the feature space of an image is sometimes metaphorically compared to a “landscape” (Nelson, 2002). An outdoor landscape contains geologic formations, signs, navigation paths and habitats that in-and-of-themselves have no significance, but in our human context, and in certain combinations, these components are loaded with significance and organized into the abstract notions of a “homeland” or, for example, a fictitious “holy grail” or “hell”. In the context of pattern recognition and classification, an empirically validated attribution of an image pattern to an object's traits is frequently referred to as ground truth (compare to a “homeland”). The notion of ground truth relies on prior knowledge and experience, and it is therefore semantic. The ideal and expected result of image analysis incorporates an accurate establishment of truth or falsity relationships between ground truth and other observed patterns. Following this landscape metaphor, the process of finding the optimal path towards a meaningful abstract notion of an object is operationally syntactic, and therefore is susceptible to incompleteness and/or inaccuracy. For example, a visual pattern of bright pixels assembled in a circle may stand for a cross-section of a spherical extracellular vesicle, for a cross-section of an elongated cellular process, or for a cross-section of a cell itself. Here, a reliable syntactic cascade that leads to the correct categorization of the circular pattern should consider the absolute size of the pattern, its shape in all three dimensions, and the context of the image. Not only 2D shape and brightness, but also an expanded set of context features – all of which can be estimated syntactically – contribute to accurate semantic attribution.
In general, artificial neural networks attempt to approximate “intelligent” learning by emulating infinitely complex natural cascades of decision-making processes as we know of them in living organisms (LeCun et al., 2015). At the very fundamental level, natural neurons perceive multiple binary inputs through their dendrites and generate a binary output, depending on whether or not the activation threshold has been attained (Nielsen, 2015). Likewise, in certain situations a decision results from constructing a linear combination of weighted inputs and balancing it against bias. For linear separation of feature vectors by the neural network, two layers are sufficient – the inputs layer and the outputs layer – which are wired to form a shallow neural network (Ching et al., 2018, Karabag et al., 2020, Shotton et al., 2009). Shallow networks reduce the dimensionality of the inputs and construct a virtual hyperplane that separates a positive decision from a negative decision. For an intuitive illustration, consider a student who is deciding whether to go to a professional conference or not. She desires to meet with her colleagues (input n1), she speaks the local language (input n2), she applied for a travel award that would cover conference costs (input n3), and for certainty she also applied for several smaller bursaries (inputs n4, n5 and n6). These inputs are assigned appropriate weights, w, for decision making. The conference cost is 600 units of currency, and that is the bias, b. The linear combination of inputs for making her decision will thus be:Σ (w1 × n1 + w2 × n2 + w3 × n3 + w4 × n4 + w5 × n5 + w6 × n6) + b ≥ 0
Since neither seeing colleagues nor speaking the local language on their own will not make attending the conference possible, the first two weights are nil. The travel award alone is sufficient to cover the costs, and therefore w3 = 600; each of the local bursaries covers one third of the costs and therefore w4 = w5 = w6 = 200. The bias b equals −600. Now, this 6-dimensional problem (of 6 inputs) converts into a simple logic gate that combines a 3-input AND-operator (gives high output if all the inputs are high) and a two-input OR-operator (gives high output when one or more inputs are high):if n3 OR (n4 AND n5 AND n6) = 1 then go to conference
Unfortunately, linear combinations are of limited utility for most biological as well as sociological, legal, political or ethical problems. Adding another input, n7, such as having her presentation material ready, validated, approved by co-authors, relevant to the conference theme, and so on, makes this current combination nonlinear. What is the correct weight w7 assigned to this additional input n7 if for example the presentation is ready, but irrelevant? Or, if it is relevant, but not approved by the co-authors? In order to accomplish complex and/or abstract decision-making tasks, an extra level of contextualization and hierarchical conditioning must be implemented. When a given linear combination of inputs is contextualized within a framework of conditions, its former lower-level output may be inverted, or overridden by another output, which in turn is contextualized within the same (or related) framework of higher-level conditions. Abstract reasoning that incorporates local and/or instantaneous inputs into hierarchical context (which is global and/or long-term) comprises the basis of insight and acumen, and it is the goal of artificial intelligence and machine learning.
