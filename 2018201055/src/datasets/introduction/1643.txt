The family of techniques collected under the name of deep learning is responsible for the current AI Renaissance, the fast resurgence of artificial intelligence after several decades of slow and unsatisfactory advances. In 2012, the group at the University of Toronto lead by Geoffrey Hinton, the inventor of deep learning, won ImageNet, the most challenging image classification competition. In 2016, the company DeepMind, founded by Demis Hassabis and soon acquired by Google, defeated the world champion of Go, the Chinese chessboard game much more complex than chess (Silver et al., 2016). The leading Internet companies were among the first in employing deep learning on a massive scale (Hazelwood et al., 2018) and are also the largest investors in research well over their own applications. Thanks to the vast success, deep learning was featured on the covers of journals such as Science (July 2015), Nature (January 2016), and The Economist (May 2015).
The astonishing success of deep learning was totally unexpected (Plebe & Grasso, 2019). The most surprising aspect is that the technology contains minor improvements from artificial neural networks, a field that was stagnating at the beginning of this century. Hinton himself was one of the protagonists of the invention of the artificial neural networks of the ‘80s (Hinton, McClelland, & Rumelhart, 1986; Rumelhart, Hinton, & Williams, 1986). We deem one of the most distinctive differences between the first generation of artificial neural networks and the current deep learning enterprise to be related to its focus. The primary motivation for the development of the early neural networks was the study of cognition. Most of the main players in the group that gave birth to the first artificial neural networks in the ‘80s were psychologists: Geoffrey Hinton, Michael Jordan, James McClelland, and David Rumelhart. In contrast, the majority of modelers in deep learning is totally indifferent to cognitive studies, with few notable exceptions like Yoshua Bengio (see for example Bengio, Courville, & Vincent, 2013; Chevalier-Boisvert et al., 2019; Ke et al., 2019). Even if several of the protagonists of deep learning are the same scientists associated with earlier artificial neural networks – Hinton included – the scope has drastically shifted towards engineering goals.
Let us provide an example. In current cognitive science the proposal of Karl Friston about the fundamental predictive activity of the brain and the related free-energy principle is well known and discussed. At the heart of his proposal there is a formal expression of free energy, derived from Bayesian variational inference (Friston, 2010; Friston & Kiebel, 2009; Friston & Stephan, 2007). On the deep learning side, an important advancement was achieved a few years ago with an architecture known as the “variational autoencoder”, introduced independently by Kingma and Welling (2014) and by Rezende, Mohamed, and Wierstra (2014). Variational autoencoders in deep learning are a precise correlate of Friston's free-energy principle in the brain, and the mathematical formulations are almost the same. Curiously, Kingma & Welling glaringly neglect the connection between their new architecture and its cognitive counterpart, as do Rezende and co-authors. This striking connection is ignored in all the further refinement on the variational autoencoder in the deep learning community, and it is first acknowledged only by Ofner and Stober (2018). We are rather inclined to push the difference in scope between the earlier artificial neural network community engaged in cognitive explorations and deep learning even further. To the extent that modelers withdrew from pursuing cognitive investigations, the design of neural models was allowed much more freedom in adopting mathematical solutions alien to mental processes.
However, we argue that now deep learning, despite this recent tradition, can and should have its say in cognitive science. There is at least one simple reason: the engineering objectives of deep learning have been met with such success that, for the first time, we have artificial models performing complex cognitive tasks at human performance level. The era of toy worlds in which models are restricted to highly simplified versions of cognitive capabilities is over. We now have empirical examples of algorithms solving cognitive tasks at the full scale of complexity.
The resonance of the successes of deep learning has already stirred up reflections and discussions within cognitive science and philosophy (Cichy & Kaiser, 2019; Edelman, 2015; Lake, Ullman, Tenenbaum, & Gershman, 2017; Landgrebe & Smith, 2019; López-Rubio, 2018; Marcus, 2018; Ras, van Gerven, & Haselager, 2018; Schubbach, 2019). However, most of the focus of these reflections is about the chances and limits of deep learning in fulfilling the promises of artificial intelligence, in particular its possibility to reach the most coveted goal, the so-called “general artificial intelligence”. These are important themes, but the focus of this paper is different. Our reflections are on how certain empirical achievements of deep learning may illuminate crucial debates in cognitive science. An easy and immediate consideration is that deep learning may lead to a revision of old debates in cognitive science, in which the first generation of neural networks was engaged, such as symbolic/subsymbolic, or innate/acquired knowledge. Some of these issues are already discussed in a few of the works just cited, like in Marcus (2018) and Landgrebe and Smith (2019).
But, in our opinion, the results of deep learning may play a major role in debates that characterize contemporary cognitive science. There is in particular one debate that is shaking the foundations of cognitive science: the rejection of the concepts of computation and representations (Chemero, 2009; Gelder, 1995; Hutto & Myin, 2013). The antirepresentationalist and anticomputationalist stances are related to the so-called “4E cognition”, i.e., embodied, embedded, enactive, and extended, which encompasses a wide variety of positions, not necessarily committed to antirepresentationalism and anticomputationalism. Embodiment has taken center stage in cognitive science for several decades (Lakoff & Johnson, 1999). Taking the body as the locus of actions, embodiment has naturally implied enactive cognition (Noë, 2004; O'Regan & Noë, 2001), and since the body interacts with its environment, embodiment also contributes to the possibility of reconciling traditional cognitive science with Gibson's ecological psychology (Gibson, 1966, Gibson, 1979; Heras-Escribano, 2019). The concepts of embodiment, enactivism, embeddedness, have all certainly contributed to fundamental advances in cognitive science; however the assessment of their relative roles in cognition is currently highly controversial (Aizawa, 2015; Goldinger, Papesh, Barnhart, Hansen, & Hout, 2016; Mahon, 2015).
The performances of deep learning are disconcerting from the perspective of all these alternative stances in cognitive science, and we are surprised that it has gone almost unnoticed. Deep neural models are entirely based on representations and computations. Mostly, their main results are achieved with computations that disregard any action, any embodiment, any dynamics, any interaction with the environment. It is certainly necessary to be cautious in drawing conclusions: as mentioned above, we have to keep in mind that deep neural models are not intended as tools for studying cognition, and are not primarily intended to be biologically plausible models. Nevertheless, we believe the achievements of deep learning to be worthy of reflection on the aforementioned debates.
The paper is organized as follows. In Section 2 we will recap the fundamental role of the idea of computation and representation in cognitive science. We will then examine deep learning on the basis of an analysis of the two words of which its name is composed. In Section 3 we start with “learning”, because it represents the continuity with the main tenet of connectionism, grounded in empiricism. Then, in Section 4 the concept of deep has its turn in the pivot of the discontinuity between the current neural network models and its precursors. Section 5 will describe the current challenges to the foundations of cognitive science, and Section 6 will discuss the impact of deep learning results on these challenges. We mainly address results in vision, for two reasons. First, vision is a paradigmatic case used in support of 4E cognition, and also the most successful field of application for deep learning. Second, there are several recent studies claiming that the specific deep learning models used for vision have some level of biological plausibility. Finally, in Section 7 we draw some tentative conclusions on how deep learning results may illuminate contemporary debates in cognitive science.
