Orthogonal range searching is a very common problem that arises in a wide variety of applications including engineering, physics, mathematics, computational science, economics, and statistics. The problem consists of finding all the elements from a database that are contained in a given orthogonal range. In its simplest form, orthogonal range searching requires determining whether or not each element of the database is included in a given searching range. This can be done in general by checking all the elements from the database individually using a brute force approach. However, following this procedure, the time required by the algorithm quickly increases with the size of the database, making the algorithm slower as the size of the database increases. Thus, and in order to improve this limiting behavior, a wide variety of methodologies have been proposed to deal with the problem. Examples include the projection method [1], the grid files method [2], the b-tree [3], the quad tree [4], the k-d tree [5], the R-tree [6], and the Kdb-tree [7]; however, there are many others [8], [9], [10], [11]. The multitude of techniques shows that range searching is an extensively studied subject in computer science [12], [13].
In this work, we introduce the n-dimensional k-vector, a very efficient methodology for problems that require extensive orthogonal range searches in static databases with multiple dimensions. The n-dimensional k-vector is based on the idea of generating an auxiliary database during preprocessing that contains information about the element distribution in each dimension. Afterwards, during the searching process, the algorithm uses this information to provide the number of elements in the searching range for all the dimensions individually, as well as the positions of these elements in the database. That way, and for each search, the algorithm finds the sequence of dimensions that is most likely to minimize the number of range comparisons, starting with the dimension with the smallest number of elements retrieved. Then, in each subsequent dimension, the algorithm continues with a brute force approach or an intersection approach depending on the situation.
The n-dimensional k-vector is the evolution, for databases in multiple dimensions, of the so called k-vector, a range searching technique for one dimensional databases. The k-vector range searching algorithm can be thought of as a hash table like algorithm based on a bijective hash function. It was originally developed for the identification of stars observed by wide field-of-view star trackers using computationally limited processors on board spacecraft [14]. Since then, the k-vector has been repeatedly and successfully validated in space [15], [16] becoming part of the state-of-the-art algorithm, Pyramid [17]. In addition, the one-dimensional k-vector has been successfully applied to solve other problems, including: inverting nonlinear functions [18] (even Diophantine), generating random numbers with any prescribed distribution [19] (analytical or tabulated), solving for the intersection of nonlinear functions, identifying isosurfaces for level-set analysis, and finding gene sequences in long DNA chains [20].
The k-vector is based on the idea of describing the nonlinearities of a sorted database using a vector of integers of a chosen size called the k-vector [21] (a hash-like function). This is done by comparing the database distribution with a mapping function, for instance, a line. The key feature of the k-vector is that the searching time complexity of the algorithm is independent of the database size; it only depends on the nonlinearity of the sorted database with respect to the mapping function [22]. As with the binary search technique, the one-dimensional k-vector only works with sorted databases. For this reason, a direct extension of this technique to n-dimensions is not possible due to the lack of clear ordering in multi-dimensional spaces. Therefore, a different approach is required, which is the focus of this work, the n-dimensional k-vector.
This manuscript is organized as follows. First, an overview of the algorithm is introduced, which aims to provide a general idea of the methodology and its process. Then, a detailed exposition of the methodology is presented, including the structure of the database and the auxiliary databases required (the index array, the k-vector array, and the k-vector line array). Afterwards, the performance study of the algorithm is assessed in terms of complexity and speed, and compared with brute force and k-d tree, which are other common orthogonal range searching algorithms. Next some modifications to the one-dimensional k-vector algorithm are presented that show up as a result of the development of the n-dimensional k-vector. Finally, some possible modifications to the algorithm are studied that reduce the memory required while maintaining the algorithm complexity.
