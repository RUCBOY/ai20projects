A common kind of security incident is caused by the presence of malicious software (malware) in a system. As part of a security incident response process, computer and network forensics becomes a fundamental step during the detection and analysis stage. Anomalous or unauthorized activity performed by malware in a compromised system can be detected through the analysis of both the device drive and the memory of the system. Disk forensics is the part of forensics focused on the analysis of device drives. On the other hand, memory forensics focuses on the analysis of the data contained in the memory of the system under study (Ligh et al., 2014).
Although we normally have both possibilities, there are situations where the access to the physical device drives is difficult to accomplish (for instance, in Cloud computing). Furthermore, the current storage capacity in disk devices make the analysis of memory content (in the order of magnitude of gigabytes) a more affordable task that the analysis of disk content (in the order of magnitude of terabytes), as well as facilitate the initial triage. Considering these facts, in this paper we focus on memory forensics.
Memory forensics is usually carried out capturing the current state of the system's memory and dumping it into disk as a snapshot file. This file is also known as memory dump. A memory dump can then be taken offsite to analyze it with dedicated software such as Volatility (Walters and Petroni, 2007), searching for facts about the security incident.
A memory dump contains tons of data that might be of interest for analysis. Among other things, it contains a snapshot of the processes in execution, as well as other system information such as logged users, open files, or open network connections at the time of memory acquisition. Note that the memory state can be inconsistent if it was acquired in a live system, since the system itself evolves over time and system objects might be created or destroyed during the acquisition process. To assess the reliability of analysis results, the use of the temporal dimension in memory forensics has been recently proposed (Pagani et al., 2019).
Code signing helps to establish trust in computer software, since it allows to authenticate the software publisher and to guarantee code integrity through the validation of the digital signature shipped within the software (Parno et al., 2010). Several operating systems rely on code signing to warn the users about the potentially harmful actions that a piece of software may perform. For instance, the execution of a properly signed application in Windows avoids any alert box informing the user about the possible harmful consequences of its execution. Under this premise, malware developers use digital signatures to deceive users to execute their malware and thus compromise their systems, thus subverting the trust in digitally signed software.
Although the use of digital signatures in malware is not a growing trend (Ugarte-Pedrero et al., 2019; Rivera et al., 2019), there are documented cases of signed malware samples in the wild (such as Stuxnet (Langner, 2011), Duqu, or Flame, to name a few). Malware developers use trusted certificates that were either compromised or issued directly to them to sign their software. As the primary defense against these threats, we rely mainly on the revocation process of the abused certificates done by the certification authorities (CAs).
Intuitively, a forensic analyst can think of code signing as a preliminary step to prioritize the list of suspicious processes that need further analysis. The rationale for this thought is correct, but unfortunately is not very fruitful when inspecting a memory dump: a process is an inaccurate representation of the executable files1 in memory, since parts of the binary code may be paged out of memory or may change at acquisition time (Case and Richard, 2017). Furthermore, software defenses such as address space layout randomization (Bhatkar et al., 2003; PaX Team) or position-independent code may change the memory references of certain binary code instructions. But, to what extent can these issues negatively affect the signature computation? Is there any other issues affecting it? Are there any ways to overcome these problems? These questions have motivated our research. Our main research goal in this paper is to explore whether code signing brings any benefit to memory forensics.
Contributions. In this paper, we describe the limitations that memory forensics imposes to the digital signature verification process of Windows PE signed files. In particular, Authenticode is the code signing standard designed to digitally sign files in Windows, introduced in Windows 2000 (Microsoft Corporation, 2008). We focused on Windows since it is still the preferred target of malware authors (AV-TEST, 2019). We have also developed a Volatility plugin to verify digital signatures in a memory dump, named sigcheck (as the tool provided by Microsoft for verifying digital signatures on binary files (Russinovich, 2019)). When feasible, our plugin works on kernel-space file objects that represent executable files, computing the signature and verifying the certificate chain attached to the digital signature. To assess the reliability of our plugin, we tested it in different scenarios and in signed malware samples. We concluded that the longer a system runs, the fewer file objects can be acquired. Hence, given the current limitations (data incompleteness, data changes caused by relocation, catalog-signed files, and executable file and process inconsistencies), the verification of digitally-signed files does not bring any benefit to memory forensics.
Structure of the paper. The structure of this paper is as follows. Section 2 gives background on previous concepts. In Section 3, we describe in detail the plugin sigcheck that we have developed. Section 4 details the experimentation and discussion of results. Section 5 is devoted to explaining the limitations imposed by memory forensics and possible solutions. Section 6 presents related work. Finally, Section 7 concludes the paper and states plans for future work.
