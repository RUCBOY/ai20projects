Crowd counting has become an increasingly important problem due to its wide applications in supporting daily economic and social demands. For example, an accurate estimate of the crowd is critical for public activities ranging from commercial statistics to crowd control, abnormal event detection, and other security tasks. Though counting the number of people in crowd images is a straightforward problem, it still remains challenging due to large variation of crowd scales and diversified crowd distributions.
As shown in Fig. 1, people vary from several pixels to a large region in scales and from single person to several hundreds in crowd densities. The current leading methods usually estimate the crowd number via generating a crowd density map from the scene image instead of directly regressing the total crowd number. The generated crowd density map is then used for adding up to obtain the crowd count in this task, and it can also be further exploited for other related tasks like crowd behavior analysis.Download : Download high-res image (310KB)Download : Download full-size imageFig. 1. Example crowd scenes and their ground-truth density maps. There exist large variations of crowd scales in different scenes, and generating the corresponding crowd density map remains challenging.
Recently, crowd counting methods built on Convolutional Neural Network (CNN) backbones have achieved impressive performance [1], [2], [3], [4], [5], due to the powerful representation learning ability of the deep CNN models [6], [7], [8], [9], [10], [11]. These methods generally handle the scale variation problem by utilizing the multi-column architectures to enhance feature learning, where the input is processed with convolutional kernels of different sizes in each column so as to extract features on different scales. However, they suffer from certain issues. First, the large scale variation cannot be covered by the limited number of columns and blindingly increasing the column number will lead to massive parameter overload, which easily fails on diversified scales feature leaning, as revealed by [1]. Second, these networks usually generate low-resolution crowd density map while learning increasingly abstract features. A low-resolution density map is insufficient to tackle with tiny heads in crowd scenes and estimate the accurate crowd count. Third, the pixel-wise Euclidian loss between the predicted and ground-truth density maps easily leads the trained model to generate a criticized blurring density map. Therefore, they still have the problem of severe accuracy degradation when applied in challenging crowd scenes with large scale variation or high congestion.
In order to alleviate the influence of these drawbacks aforementioned, we propose a novel neural network framework, termed as Scale-Communicative Aggregation Network (SCANet), which comprehensively integrates multi-scale features and obtains high-resolution density maps for crowd counting. We introduce an effective Multi-Scale Feature Encoder (MSFE) to extract multi-scale robust feature representation. Each MSFE consists of multiple columns of stacked CNNs and exploits dilated convolutional layers to enlarge receptive fields. With different dilation rates, these columns have various receptive fields and can respectively model the appearance of people on different scales. Then more diversified scale features are aggregated through the serial connection of MSFEs. We further propose a scale communication architecture for consuming different scales of input image to obtain high-resolution density map. Each scale stream processes a different scaled version of input image and provides complemental information for each other. The whole network finally aggregates multi-stage and multi-scale features into a high-resolution representation, thereby generating a high-resolution density map for accurate crowd counting. Moreover, we exploit a multi-scale structural similarity loss to enforce our network to learn the local correlation of multi-scale patches from the density maps, which better capture the crowd density distribution than those learned from solely pixel-wise single-scale consistency loss. Our contributions can be summarized as follows:
•We propose a Scale-Communicative Aggregation Network (SCANet) to deal with the variations of people scales in complex scenes. We exploit stacked Multi-Scale Feature Encoders to extract robust multi-scale features and introduce the scale communication architecture between multi-scale inputs to generate the high-resolution density map.•We incorporate a novel training loss, named Multi-Scale Structural Similarity (MS-SSIM) loss, along with the Euclidean Distance loss to force the network to learn the local correlations of patches on the density maps, which helps generate high-quality density map and obtain accurate crowd count.•Extensive experiments on several challenging benchmarks show the remarkable performance of our proposed method in comparison with other state-of-the-art methods.
