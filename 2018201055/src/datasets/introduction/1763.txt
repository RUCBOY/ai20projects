Crowdsourcing is an outsourcing approach that relies on a large number of people via the Internet to solve problems (Howe, 2006) and address innovative tasks (Afuah & Tucci, 2012; Penin & Burger-Helmchen, 2011). Citizen science is a form of crowdsourcing that recruits volunteers to participate in scientific research (Bonney et al., 2009). In the past decades, citizen science has become a popular framework that relies on the collaboration of the general public to gather crowd wisdom for research activities (Shirk et al., 2012). Citizen science is similar to crowdsourcing in the sense that it disseminates routine activities, such as data collection, data analysis, and data interpretation (Cappa, Laut, Nov, Giustiniano, & Porfiri, 2016; Wiggins & Crowston, 2011), to external participants (Afuah & Tucci, 2012; Bogers & West, 2012; Cappa, Oriani, Pinelli, & De Massis, 2019; Penin & Burger-Helmchen, 2011). However, citizen science also has some unique characteristics that make it distinct from conventional crowdsourcing activities. For instance, citizen science projects are initiated by professional scientists, instead of companies or organizations; amateur scientists are recruited to participate in research investigations rather than business activities; the ultimate goal of citizen science projects is to assist large-scale problem-solving in a collaborative way (Cappa et al., 2016; Nov, Arazy, & Anderson, 2014). Prior research has also noted citizen science can bring out opportunities for all involved parties. One prominent advantage is the possibility to recruit participants and address large-scale scientific problems at a relatively fast pace and low costs (Cappa et al., 2016). Volunteers can benefit from the experiences of involving in science (Raddick et al., 2013) and learning more knowledge about nature (Land-Zandstra, Devilee, Snik, Buurmeijer, & van den Broek, 2016). Such collaboration among amateurs and professional scientists can promote scientific knowledge discovery and eventually enhance scientific literacy among the general public (Paul, Quinn, Huijser, Graham, & Broberg, 2014).
With the advancement of information technology, online citizen science projects have enabled public collaboration to mitigate the limitations of time and geography, thereby providing new means to solve scientific problems. However, prior research has reviewed several citizen science projects and found that only a few groups of participants actively contribute to these projects. By contrast, the majority of the participants stop after a few attempts (Boakes et al., 2016; Prestopnik, Crowston, & Wang, 2017; Sauermann & Franzoni, 2015), thereby resulting in difficulty to achieve the goal of supporting scientific research. Volunteer performance is a critical factor for the success of citizen science (Diner, Nakayama, Nov, & Porfiri, 2018; Laut, Cappa, Nov, & Porfiri, 2017; Nov et al., 2014). The quantity and quality indicators are often used to measure performance in citizen science projects (Nov et al., 2014; Prestopnik et al., 2017). Scientists are more likely to drive high quality contributions from a high volume of contributions (Boudreau, Lacetera, & Lakhani, 2011; Cappa, Oriani, et al., 2019; Cappa, Rosso, & Hayes, 2019). Therefore, how to effectively design citizen science projects to enhance volunteer performance (i.e., quantity and quality of contributions) has become a key issue to be solved.
Human behavior can be driven by intrinsic motivation and/or extrinsic motivation (Deci & Ryan, 2000; Ryan & Deci, 2000). Prior research has noted that crowdsourcing participants could be motivated by both intrinsic (i.e., enjoyment, develop skills, interest) (Brabham, 2010; Xu & Li, 2015) and extrinsic motivations (i.e., monetary reward, reputation) (Bogers & West, 2012; Brabham, 2008; Cappa, Oriani, et al., 2019; Zhao & Zhu, 2014). Recent literature in citizen science projects identified that volunteers were mainly driven by intrinsic motivations, such as meaningful, fun, personal interests, learning, and hope to contribute to society (Bowser, Hansen, & Preece, 2013; Tinati, Luczak-Roesch, Simperl, & Hall, 2017). Therefore, extrinsic motivations such as financial incentives or external rewards may not work so well to encourage volunteer participation. Motivational design is thus proposed as a potential approach to encourage volunteer participation (Burbach, Lidynia, Brauner, & Ziefle, 2019; Preece, 2016).
Providing feedback is a design mechanism that can lead positive user experience and enhanced user performance by satisfying their motivational needs (Jung, Schneider, & Valacich, 2010; Martinez, 2015; Zhang, 2008). Existing literature has examined feedback design in different ways. Some studies have explored the influences of feedback presentation, such as the timing of feedback (i.e., immediate and delayed) and design format (i.e., sound and text) (Mory, 2004; Nelson & Schunn, 2009), whereas others have focused on the contents of feedback information, such as information types (i.e., descriptive, comparative, and evaluative) and information valence (i.e., positive and negative) (Burgers, Eden, Engelenburg, & Buningh, 2015). Feedback has been found to motivate user participation in many contexts, such as learning (Kollöffel & de Jong, 2016), organization management (Song, Tucker, Murrell, & Vinson, 2017), health care (Hawkins, Kreuter, Resnicow, Fishbein, & Dijkstra, 2008), user-generated content (Huang et al., 2018), and information system (Hassan, Dias, & Hamari, 2019). Citizen science research has also found that feedback can motivate users and potentially enhance their performance (Diner et al., 2018; Laut et al., 2017). For instance, Laut et al. (2017) focused on the impact of social feedback and found that the presence of virtual peers positively influenced volunteer performance. Additionally, studies have also recognized that the effects of feedback could be affected by the recipients’ personal characteristics (Pee, Koh, & Goh, 2018; Wozniak, 2012). In existing studies, limited research has compared the differential impact of feedback type, examined the impact of feedback design and individual characteristics on citizen science research. Therefore, further investigation should be conducted to present an in-depth understanding of feedback design and its influences to improve volunteer performance in citizen science projects.
Achievement goal theory, which originated from the field of educational psychology (Ames, 1992; Dweck, 1986), states that one's focus or purpose for making achievements could be influenced by a purposely designed environment (i.e., goals are contextual and induced by users' behavioral setting) or be part of one's personal traits (i.e., goals are dispositional) (Jagacinski, Madden, & Reider, 2001; Pintrich, 2000). The contextual view of achievement goals facilitates the understanding why feedback design is vital in the creation of a behavioral setting (i.e., goal structure) to induce one's achievement behaviors. The dispositional view of achievement goals provides a theoretical lens to understand why individuals respond distinctively to the same environmental conditions with different preferences (Pekrun, Cusack, Kou, Elliot, & Thomas, 2014; Steele-Johnson, Heintz, & Miller, 2010). Hence, the current study aims to answer the following research questions:
(1)How do feedback influence volunteers' experiences and their participation performance in citizen science projects?(2)To what extent do the effects of feedback differ when volunteers have varying dispositional goal orientations?
We draw upon achievement goal theory and propose a research model to investigate the relationship between feedback design and individual characteristics and their impact on volunteers' achievement behavior (i.e., volunteer performance). We aim to advance the theoretical underpinning of feedback design and empirically examine how the feedback design matters in citizen science projects. Volunteers can participate in a variety of projects and tasks. For instance, Wiggins and Crowston (2011) found that citizen science projects vary by their organizational, participatory, and technological characteristics. Shirk et al. (2012) identified that the degree of volunteer participation would differ by type of projects. Cappa et al. (2016) focused on the specific tasks conducted by volunteers and noted two important forms of the task, namely, data analysis and data collection. In this study, we focused on the data analysis task in the area of botany classification and used an experiment method to compare the effects of three types of feedback, namely, task, self, and social feedback, and further examine how feedback interacts with individuals’ dispositional goal orientations (i.e., mastery- and performance-oriented). In particular, this study has the potential to guide future design strategies by identifying effective feedback mechanisms to match individual characteristics and enhance volunteer performance in citizen science activities.
