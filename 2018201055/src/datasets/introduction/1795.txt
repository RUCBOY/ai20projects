Crowd counting is the task of predicting the number of individuals appearing in specific scenes. It serves as a fundamental technique for numerous computer vision applications, such as in video surveillance, public safety, flow monitoring, traffic monitoring, and scene understanding. It is also a challenging problem due to the variations of density, scale, illumination and severe occlusion.
Recently, with the development of convolutional networks (CNNs), the performance of crowd counting algorithms has been greatly improved. Existing approaches use a CNN to estimate the density maps which represents both the spatial position and number of individuals and consequently couples the individuals’ localization and counting. Although great progress has been made, state-of-the-art density map estimation based methods still suffer from two problems. Firstly, the density map excessively focuses on the localization for its exhaustedly utilizing the spatial information of the individuals’ location. It is unreasonable to force the network to accurately localize the individuals in highly congested scenarios. The reason is that each individual occupies too few pixels to be localized, which consequently harms the performance. Furthermore, the size of the Gaussian Kernel, which is used to generate the density map, is hard to adapt the variation in head scale and significantly affect crowd counting performance. It is either too small to make pedestrian of different scales distinguishable or too large to separate the pedestrian from the background.
In addition, the previous approaches ignore the dependency between the regions. They adopt multiple columns or multiple regressors which major in specific regions, while regions of different density are predicted independently. Actually, the regions of different density are relevant in scenes. In congested scenes, the crowd density per square meter in the physical world is approximately constant. Due to the perspective distortion, the density changes approximate continuously along the direction away from the camera. For different views, the perspective relation varies. Moreover, the distribution of density in many scenes (such as streets, square, stadium, etc.) is governed by configurational rules. The relation can be utilized to further improve the crowd counting performance. As shown in Fig. 1. The absolute error of the attentional region decreases by utilizing the relation of regions.Download : Download high-res image (166KB)Download : Download full-size imageFig. 1. The prediction of the attentional region is refined by Region Relation-Aware Module. The first row shows the attentional region in the image and the attentional ground truth. The second row shows the attentional prediction generated with RRAM (left) and without RRAM (right). By utilizing the relation of regions, the absolute error of the attentional region decreases 14.8.
To tackle the above two problems, we propose a novel method called Relevant Region Prediction (RRP) for crowd counting, which consists of two components i.e., Count Map and Region Relation-Aware Module (RRAM). Each pixel in the count map represents the number of heads falling into the corresponding local area in the input image and the area of adjacent pixels are overlapped with each other. Thus, the network is only required to verify the presence of individuals in local area rather than accurately localize them, which forces the network to pay more attention to counting than localization. Furthermore, the system performance is robust to the area size. The Region Relation-Aware Module (RRAM) is proposed to capture the region dependency by leveraging the power of the Graph Convolutional Network (GCN). Specifically, we represent the regions by weighted global pooled feature and build a fully connected directed graph between these regions representations to explicitly model their correlations. Then a GCN is learned to propagate information between different regions and consequently generate a set of relation-aware region representation. The weight of each edge is adjusted adaptively and thus the relationships between different regions are captured. Then these region representation are remapped to the original feature space and fused with the input feature for the more accurate prediction. Experiments show that our Count Map performs better than the density map and the Region Relation-Aware Module further improves the accuracy of the prediction.
Our contributions are threefold:
•We propose a novel labeling scheme, termed Count Map, which discards the detailed spatial information and forces the network pay more attention on counting rather than localizing individuals.•We design a novel region relation-aware module, which leverages the power of graph convolution network to capture and exploit the relations between regions of different density.•We comprehensively evaluate our model on three crowd counting benchmark datasets, and our model consistently achieves superior performance over previous state-of-the-art methods.
