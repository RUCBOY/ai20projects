Quantum Computing is a computational paradigm that has been harvesting increasing attention for decades now. Several quantum algorithms have time advantages over their best known classical counterparts [1], [2], [3], [4]. The current advances in quantum hardware are bringing us to the era of Noisy Intermediate-Scale Quantum (NISQ) computers [5]. The quest for quantum supremacy is the search for an efficient solution of a task in a quantum computer that current classical computers are not able to efficiently solve. Some authors argue that given the current state of the art, we will achieve quantum supremacy in the next few years [6]. One of the approaches to achieve this supremacy and to expand the potential applications of quantum computers is through quantum machine learning [7].
Machine learning (ML) [8] aims at developing automated ways for computers to learn a specific task from a given set of data samples. ML has several applications in image classification [9], NP-hard problems [10] and others. Some of the limitations of ML are the lack of algorithms to select an ML method and to avoid local minimums.
Quantum machine learning investigates the use of quantum computing concepts to build quantum-enhanced machine learning models able to outperform the classical ones [7]. For instance, quantum computing can be used to efficiently convert a nonlinearly separable dataset into a linearly separable one by exploiting the exponential size of quantum spaces [11] and to select neural networks architectures without dependence of weights initialization [12], [13]. Quantum machine learning proposes speedups of some algorithms used in machine learning such as reinforcement learning [14] and systems of linear equations [15].
There are several works proposing quantum machine learning models such as a quantum generalization of a neural network [16], a quantum distance-based classifier [17], and quantum associative memories [18], [19], [20], [21]. In [20], [21] is introduced a Probabilistic Quantum Memory (PQM) that computes the Hamming distance from an n-bits input pattern to k n-bits patterns with computational cost linear in the number of bits, O(n).
However, the PQM [20] (and quantum associative memories in general) has received criticism from various authors. The memory state is lost in every execution of the retrieval algorithm when the memory state is measured. Memory collapse is considered to be the main limitation of this memory [22] as argued in [23] since the O(m) cost to reload m patterns in the memory using its storage algorithm jeopardizes the PQM advantages. Another author [24] claims that the probabilistic quantum memory cannot be considered as a complete model. However, in [4] we show a PQM application in which a single execution of the retrieval algorithm is sufficient to evaluate, probabilistically, the artificial neural networks architectures without the need for weights initialization. We used the PQM as a data structure to store and train artificial neural networks in superposition and to devise a quantum algorithm able to evaluate and select neural network architectures.
The objective of this work is to improve the PQM model in pattern classification tasks extending the model described in [25]. To accomplish this aim, we propose two approaches:
1.We introduce the Parametric PQM (P-PQM), where the parameter allows the PQM to compute a weighted Hamming distance and adapt the model to the given training dataset.2.We also propose a hybrid classical-quantum version of the PQM retrieval algorithm suitable for NISQ computers.
The remainder of this work is structured as follows. Section 2 gives the concepts of quantum computing to make this work self-contained. Section 3 describes related works and the probabilistic quantum memory, and Section 4 presents a quantum weightless classifier and one of its limitations. Section 5 and Section 6 show the main contributions of this work. In Section 5, we describe the proposed parametric probabilistic quantum memory and present simulated experiments to evaluate a weightless neural network based on the P-PQM. In Section 6, we present a modification of the PQM that allows its implementation in a NISQ computer. Finally, in Section 7 we draw some conclusions and list some possible further works.
