Floods are considered among the worst natural disasters occurring worldwide causing human and economic losses. Floods are present even in developed countries like Australia, Japan, and the USA, and in under developing countries like Indonesia, Pakistan, Colombia, and Bangladesh; however, it is the second group where the consequences are more severe, in accordance with the Annual Global Climate and Catastrophe Report that also indicates that of the years 2015 [1], 2016 [2] and 2017 [3] the most negative effects were seen in 2015 when the floods caused losses of 27 trillion-dollars around the world.
Colombia has large extensions of land which are susceptible to floods due to its topographic characteristics and hydro meteorological regimen, especially nearby parts of the rivers Atrato, Cauca, Magdalena, and Putumayo [4]. According to historical records of the data base of “DesInventar.org”, floods are among the main cause of losses in the territory [5]. Floods, landslides, gales (strong winds) and associated climatic events related to “La Niña” phenomena 2010-2011 left more than two million people affected, according to figures provided by the Registro Único de Damnificados (RUD) of the Unidad Nacional de Gestión de Riesgo (UNGR). The last event was characterized by floods that caused losses in infrastructure, agricultural goods, livestock, crops, and forests that are the source of income and consume of the local inhabitants in rural areas [6]. According to ECLAC (Economic Commission for Latin America and the Caribbean), the damages and economic losses reached 6.5 billion dollars, equivalent to 5.7 percent of the income of the country for that time.
In accordance with the annual report of the Global Climate Risk Index carried out by the Non-Governmental Organization (NGO) Germanwatch, from 2013 to 2018, Colombia is found among 50 countries most widely affected by natural disasters like hurricanes, floods, and heat waves; in addition, in the 2012 report the country ranked third place of the countries affected by the consequences of “La Niña” phenomena in 2011. [7].
Hydrological engineering aims to plan, analyze, design, build, and operate projects for the control, use and management of water resources [8]. Among the tools that can be used for this purpose, there is soft computing or computational intelligence that seek to understand natural phenomena for the development of algorithms. Among these are the genetic algorithms (GA), optimization of particle swarm (PSO), optimization of ant colonies (ACO), among others [9]. Some works related to this topic are described below. The objective of [10] was to handle the large variation issues of hydric data in fuzzy data by constructing a variable spread Multivariate Adaptive Regression Splines (MARS) via fuzzy regression model with crisp parameters estimation. Another work is that of [11], since shows how soft computing tools have helped the prediction of scouring characteristics as one of the main problems in hydrological engineering. The research [12] presented an Artificial Neuronal Networks (ANN) with modified multi-layer perceptron (MLP) model based on decision trees (DT-MLP), this method improved performance in forecasting velocity and water free-surface profiles in a 90° open-channel bend with respect to previous research. Those works can be grouped according to the implementation of Artificial Neuronal Networks (ANN), Artificial Neuronal Networks Auto-Regressive (NNAR) with exogenous inputs (NNARX), and with other additional techniques.
The works implementing ANN are characterized for its simple implementation to predict values since it is possible the generation of an effective model to solve different issues as these models have series of time organized including suitable variables. This is observed in studies carried out in [13], [14], [15], [16], and [17], where the authors demonstrate that using ANN to predict floods is adequate as the Root of the Square Mean Error (RSME) oscillates between 0.0007540 and 0.93. These studies were focused on those characteristics that might transform an artificial neuronal network into a more effective one; for instance, the analysis undertaken by Johannet et al. [18], concluded that the results were improved when having hidden layers in the network. Regarding the training algorithm, [13] concluded that the Bayesian Regularization algorithm presented a surpassing behavior. Additionally, the number of stations concur with the studies [19] and [14] in which only three measurement stations along the Kelantan and Phraya rivers were considered. There have been additional explorations aiming for the optimization of results thanks to the artificial neuronal networks. In [20] a Particle Swarm Optimization (PSO) was implemented for finding optimal parameters (number of hidden layers, number of inputs, and ranges in the levels of water) for training the ANN. The study [21] tested the suitability of the Lower Upper Bound Estimation (LUBE) method to construct ANN in producing prediction intervals at different confidence levels for the 6 hours ahead streamflow discharges of the Susquehanna and Nehalem Rivers in United States. The study concluded Multi-Objective Fully Informed Particle Swarm (MOFIPS) based LUBE represents a viable option for straightforward design of more reliable interval-based streamflow forecasting models. Meanwhile in [22] data is classified in different categories using the method k-means, focusing on the improvement of the capacity of a non-linear simulation; later, various Stacked Autoencoders with Back Propagation (SAE-BP) modules were adapted to simulate each category. This approach was compared to Support Vector Machine (SVM) models, Back Propagation artificial neuronal network, artificial neuronal network of Radial Basis Function (RBF), and Extreme Learning Machine. The results showed that the SAE-BP integrated algorithm performed exceedingly noticeable in regard of the other models. Likewise, [23] also implemented SVM models thus obtaining a better performance about the data peaks present in the sets of data. Moreover, the same study implemented an experiment using Adaptive Neuro Fuzzy Inference System (ANFIS), this allowed the reduction of noise, hence generated less disperse results among all the implemented techniques. Finally, the study [24] used several soft computing approaches were employed for rainfall prediction in the Zhenshui and Da'ninghe watersheds of China. They used preprocessing techniques included moving average (MA) and singular spectrum analysis (SSA). The modular models were composed of local support vectors regression (SVR) models or artificial neural networks (ANN) models. Results showed that the MA was superior to the SSA when they were coupled with the ANN.
A variation of artificial neuronal networks is given in NNARX. These networks grant the modeling of non-linear systems when considering exogenous inputs as in the case of the forecast of floods where variables like the volume of a flood, the amount of rain and overflows are considered. In this regard, [25] implemented data of the Kelang river to predict the level of water for three hours in advance; the same study compared four different cases in which the variation was given in terms of time; besides, different algorithms were carried out: Gradient Descent (GD), Levenberg-Marquardt (LM) and One Step Secant (OSS). The LM training algorithm was used in [26] showing a suitable performance, in [27] a comparison of its performance with that of the Bayesian Regularization was performed, while [28] found that the GD algorithm presented a better performance compared to the algorithm OSS.
Regarding the number of stations, [26] and [29] took the data of three stations in three rivers in a highly vulnerable point and where two of the three rivers converge. Regarding the exogenous inputs, overflow average and the registry of rains were applied; thus, from the total data 70% was taken to train the NNARX, and the remaining 30% to perform tests. Both, [28] and [29] comparison performances of NNARX together with the ANN and NNAR were made to confirm that the best results were obtained with the first technique.
Finally, research [30] used a deep learning data-intelligence model based on the long short-term memory, this was developed to forecast the streamflow of the Kelantan River in the northeast region of the Malaysia Peninsula. This research concluded that the developed LSTM model has both obvious advantages in processing steady streamflow data in the dry season, and a suitable ability to capture data features in the rainy season.
The above proves that it is necessary to determine new strategies for both preventions of disasters and to mitigate risks, which is the focus of this paper where a model that allows knowing the Magdalena River in advance is developed, starting with previously collected data provided by the IDEAM (Instituto de Hidrología, Meteorología y Estudios Ambientales).
The objective of the research is to design and implement a model that helps to predict the floods on the Magdalena River, examine different artificial intelligence techniques (Artificial Neural Network, Neuro Fuzzy Systems, Support Vector Machine), and thus determine the factors of these techniques that are more effective according to the case study, recognizing that each technique has certain particular characteristics. It is clarified that the development of a new algorithm is not within the scope of the research.
In a previous investigation, a preliminary study was made where the number of samples was smaller and only a few configurations of the model were tested in Artificial Neural Networks [31]. The research was limited only to these three types of techniques (ANN, ANFIS, SVM), due to limitations of time, data, human and financial resources, and technological infrastructure. The main advantage of the implementation of these soft computing techniques in this case is that they allow solving non-linear problems, in which mathematical models are not available. The reason is the high difficulty of making a mathematical model due to the complexity of the climatic variability in the tropics and especially in Colombia, as a result of the presence of a large number of microclimates and the influence of “El Niño” and “La Niña” phenomena [32].
But it is pertinent to continue with the research including other artificial intelligence prediction techniques such as machine learning, expert systems, Bayesian networks, among others, with the availability of greater resources for the development of the research. For example, a more robust computer system with which a greater number of experimental tests can be carried out.
The decision was made to hold the investigation on the Magdalena River, as it is the most important river in Colombia, due to its extension, the municipalities and population that are located in its basin, the relevance that it has within the Colombian economy and the data availability. Nevertheless, Colombia has a large number of rivers given its topography, thus, it is prudent that the results of this research be taken as a basis for future research in other rivers of the Colombian geography such as the Cauca river, which is the second most important in Colombia and other rivers of great importance such as the Bogotá, Atrato, Sinu, Patía, San Juan, Baudo, Arauca, Guaviare, Meta and many other rivers.
The data of this research was collected by IDEAM (Institute of Hydrology, Meteorology and Environmental Studies), which is a Colombian public institution of technical and scientific support; this entity allowed access at the time of the research to the data comprised from 1997 to 2015, unfortunately, the data from more recent years could not be accessed. Nevertheless, these will not have significant effects on the results because in recent years there have been no significant phenomena in the climate and the most relevant in the tropical zone are “El Niño” and “La Niña” phenomena, which are present within the data sample.
The proposed model starts from the analysis of external variables that may have an impact on the level of the river including: the location of the station of measurement, the presence of “El Niño” or “La Niña” phenomena, and the station where the event takes place. Each variable was used as input in the codification of the model. The results obtained display an acceptable behavior; however, they also show the relevance of the interpretability that is given to the output and also the way by which the phenomenon is generated and its causes.
The article is organized as follows: the first sections include the theoretical framework of the techniques considered; then, there is a description of the methodology. Later, the results obtained are displayed, finally, the section of conclusions that include a discussion.
