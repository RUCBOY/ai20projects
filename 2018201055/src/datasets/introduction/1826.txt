Architectural simulation is a fundamental tool for modern computing system design. If a new architecture incorporates unconventional or novel features, the designers may need to adapt an existing simulator or develop their own. The decision is not always straight-forward and this paper explores the choices available and their strengths and weaknesses.
Computer architects can choose from a large set of software-based simulators that provide robust and efficient platforms for design exploration. Recent efforts to improve simulators performance have relied on emulation [1], parallelisation [2], [3], model simplifications [4], [5], [6], [7], statistical methods [8] for detailed simulations of regions of interest for desired benchmarks [9], [10] or the use of metadata to simplify traffic management [11]. With the growing computational capability of reconfigurable hardware platforms, an alternative avenue for simulator improvement has been the use of hardware-based simulators. Until recently, the main way to achieve high performance from these platforms had been the use of Hardware Description Languages (HDLs) such as Verilog and VHDL. However, extracting all the performance using these HDLs is far from trivial because of the discrete nature of their programming models. The introduction of high-level HDLs, such as BlueSpec [12], [13], Chisel [14] or Vivado HLS [15], offers improved productivity while still providing a tool flow capable of exploiting reconfigurable hardware platforms.
The interconnection network of SpiNNaker [16], a massively-parallel computer for the simulation of neural networks, is a good example of a novel architectural feature that required detailed simulations during its development. SpiNNaker serves as a challenging case study due to its large scale and unconventional design features (asynchronous interconnect and triangular toroidal-mesh topology), while providing a ground truth in the form of prototype hardware.
Three different approaches were used to simulate the SpiNNaker interconnect during the design process. Early on, Navaridas et al. [17] adapted INSEE [18], a mature, software network simulator, to simulate the largest SpiNNaker interconnection network, consisting of 65,536 chips (over 1 million processing cores). This simulation used pre-fabrication system parameters to evaluate the effectiveness of architectural features such as default and emergency routing [16]. Later on, we looked into how to best use FPGA acceleration for our simulations and implemented FPGAsim, where the goal was to reduce large electronics systems into equivalent, simplified circuits that would fit in an FPGA and run in near real-time. More recently, in a separate line of research, we developed Tickysim, a more detailed software simulator, to explore multicast routing algorithms and their effects on network congestion and fault tolerance.
This paper analyses the modelling choices and trade-offs made during the implementation of the different models and evaluates their results. Given that prototype SpiNNaker systems are now available, a direct comparison of the simulated results with real hardware is possible and we can evaluate the differences in accuracy and speed between the simulation models and SpiNNaker hardware.
To sum up the main contributions of this paper are:
•Since SpiNNaker has a completely custom-made network architecture which is rather different from other standard interconnects, we have developed a set of tools over the years to evaluate different aspects of the system. We present a comprehensive description of each tool and discuss the differences in modelling.•We approach FPGA acceleration of network simulation using a simplified model of the rather different approach from others in the community. Rather than adapting an existing simulator to work on an FPGA, we have modelled the circuitry of the network using a simplified model which lends itself very nicely to be implemented in an FPGA. To our knowledge no previous work has presented anything like this.•For the first time, a set of similar simulators based on different technologies are compared with each other and with the system they were designed to model (SpiNNaker). This comparison is based on best-practices from the interconnection network, the software engineering and the hardware engineering communities. This paper is an exercise of understanding how the different design choices made for each of them affected the accuracy and performance of the tools to learn from these modelling decisions and improve our processes in the future.•As a side effect of our evaluation, we found a pathological case in the real SpiNNaker system that is related to the asymmetric link bandwidth and which was not captured in our simulators because of our decision to assume all links are equal. This asymmetry can create a network state in which a subset of the network saturates while the rest is still able to cope with the traffic.
