Generalizability (G) theory is a statistical framework used to model and analyze measurements (e.g., multiple-choice tests, direct observations, or ratings). G theory uses generalizability (G) studies to model the composition of assessment scores and decision (D) studies to forecast the reliability of measurements given various conditions (e.g., number of items, number of raters, number of occasions, number of stations, etc.) under which they could be obtained.1 While a G study's estimate of universe (true) score variance is commonly used to generate estimates of reliability, its ability to quantify multiple, individual sources of measurement error also yields validity evidence. Although classical measurement theory regards reliability research as addressing score precision and validity investigations as yielding evidence of accuracy, G theory renders this distinction as somewhat outdated since a G study can partition and quantify score variance in ways that simultaneously provide information regarding both precision (reliability) and accuracy (validity).
Classical test theory (CTT) suggests that for any assessment we administer, the “true score” is the only desired source of variance; yet, a score will always contain unwanted sources of error—both random and systematic—that will impact both reliability and validity. The more inconsistent the score estimate, the less reliable it is; and, the greater the magnitude of unwanted variance within a score, the less valid the interpretation becomes. Health science educators generally understood the classical relationship with the commonly cited dictum: reliability is a necessary but not sufficient condition for validity (technically: reliability sets the upper limit on the correlation between a test measure and a criterion). So, educators tended to expect that increases in score reliability would also increase score validity. However, in many assessment environments, the relationship between reliability and validity is more nuanced. In fact, within health science education, an inverse relationship between reliability and validity has often been observed. For instance, efforts to improve test validity by switching from multiple-choice tests to performance assessments have produced lower reliabilities. Similarly, initiatives to improve reliability with standardized testing procedures is thought to reduce validity. From a CTT perspective, these assessment outcomes might appear counter-intuitive. However, G theory's liberalized perspective of the classical measurement approach does model and predict the real–world relationships between reliability and validity (e.g., the reliability-validity paradox).1
Even though the developers of G theory promoted its role in validity research more than 45 years ago, it is still primarily regarded as a method for estimating only the reliability of assessments—while its ability to provide validity evidence is much less understood and established.2 This may be partially attributed to the unique and often nuanced presentation of the concepts and statistical designs that accompany each new application. Cronbach alluded to this in an early discussion of the topic, stating that G theory has “a protean quality. The procedures and even the issues take a new form in every context.“3; p.201). It is this protean nature that has made it difficult to provide widely applicable and practical guidance regarding G study validity applications and made extant advice necessarily theoretical and abstract in nature.4 Similarly, the notion of validity has been contextualized and applied somewhat differently within health science education, which has challenged commonly accepted understandings of validity.5 Fortunately, however, as the number of G theory validity applications in health science education accumulate, an opportunity is emerging to provide methodological guidance by documenting existing G theory research within a contemporary validity framework. This paper describes G studies specifically designed to investigate validity-related measurement questions and identifies how these G studies contribute to one or more of the four types of validity inference (scoring, generalization, extrapolation, and implication) as described by Kane.6 While the examples presented in this paper generally match this contemporary concept of validity, certain examples point to areas where modern validity theory might need to be expanded. It is also clear that while this paper focuses on the quantitative aspects of these inferences, there is also the potential for qualitative evidence to contribute to each of the four inferences. The eclectic set of G theory examples presented here demonstrate how a G theory analysis of score variance, usually within existing (in vivo) assessment data, simultaneously provides researchers with evidence regarding both reliability and validity and offers a more accurate portrayal of the relationship between the two.
