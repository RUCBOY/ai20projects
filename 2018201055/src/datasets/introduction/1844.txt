Emotions are a crucial element in our everyday communication. Though intuitive to humans, it remains a challenging task for a computer to perceive the emotions of its user. Affective computing, as an emerging research topic that seeks to develop emotion-aware systems to recognize, interpret and process human emotion, has received increasing attention in recent years. Early works have focused on analyzing the physiological responses to recognize emotions, such as heart rate [1], skin conductance [2], etc. These physiological responses are regulated by the autonomic nervous systems under the influence of emotions, hence the possibility to interpret emotions by measuring such responses. More recent studies have targeted the brain's role in perceiving and regulating emotions [3], giving rise to the affective brain-computer interface (aBCI). An electroencephalogram (EEG)-based aBCI is a direct communication pathway between human brain and computer by means of spontaneous EEG signals, bypassing the conventional pathways of peripheral nerves and muscles. Such an affective interface could potentially enrich the user's experience during the interaction with a computer if the computer is enabled to feel and respond to human emotions. In applications, an aBCI operates in such a paradigm that forms a loop as diagrammed in Fig. 1. In this paradigm, there are notably three core parts: signal acquisition, emotion classification, and feedback to the user. The user generates EEG signals, which are captured by the EEG device. The EEG signals are then analysed and classified, and the classification results are fed into an application which executes subroutines according to the recognized emotions. Feedback is then given to the user. Successful emotion recognition plays a key role in aBCI as it highly affects the quality of such an interface. The state-of-the-art aBCI leverages machine learning techniques which consist in acquiring affective EEG signals from the user and calibrating the classifier to the affective patterns of the user. Many studies about aBCI have reported satisfactory recognition accuracy using this paradigm [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14]. In these studies, affective EEG data were collected within a relatively short period, and k-fold cross-validations were carried out to evaluate the recognition accuracy. In a k-fold cross-validation, the EEG data are segmented into k nonoverlapping sections: k − 1 folds are used to train the classifier, and the remaining fold is used to test the recognition accuracy. However, due to the volatility of affective neural patterns, the recognition accuracy cannot be maintained if the usage of aBCI prolongs without re-calibrating the classifier. The recognition accuracy assessed by cross-validating short-term EEG data is over-optimistic and can hardly represent the system performance in the long run. On the other hand, there is little study on the long-term recognition performance of aBCI, which may partly be due to the fact that few existing affective EEG datasets contain recordings over a long course of time.Download : Download high-res image (76KB)Download : Download full-size imageFig. 1. A general affective brain-computer interface (aBCI) paradigm.
We devote this paper to presenting an EEG dataset that contains multiple recordings on the same day and different days for the same subjects, and to the investigation of aBCI performance over a long course of time. As the (re-)calibration process may be time-consuming, tedious and laborious, we are motivated to mitigate the burden of frequent re-calibrations on the user. Ideally, a stable affective EEG feature should give consistent measurements of the same emotion on the same subject over a long course of time. We presented a pilot study on the stability of affective EEG features in [15], [16], where we hypothesize that using stable EEG features may improve the long term recognition accuracy, while unstable features may worsen the recognition performance of the BCI in the long run. In [17], we propose a stable feature selection method to choose the optimal set of stable features that maximize the recognition accuracy of the system in the long run. In this paper, we aim at introducing the dataset used in our previous study [17],1 and make it available to the public. We invite other researchers to test the performance of their aBCI algorithms on this dataset, and especially to evaluate the long-term performance of their methods.
This paper is organized as follows. Section 2 reviews the existing affective EEG datasets. Section 3 documents our data collection procedures. Section 4 introduces our proposed stable feature selection method. Section 5 elaborates on the simulations to evaluate the short-term and long-term performance of aBCI. Section 6 presents the results with discussions. Section 7 concludes this paper.
