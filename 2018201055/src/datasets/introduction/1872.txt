Metro systems are vital for sustainable urban development with their high carrying capacity and eco-efficiency. Performances of metro operations are subject to a number of factors including capacity of rolling stock, availability of staff, operational protocols, and variability of passenger demand. Compared with the intercity mainline operations (see Cacchiani et al., 2016 and Chow and Pavlides, 2018), the unique challenges encountered in urban metro operations include the busy service schedules (up to 32–34 trains per hour), frequent circulation of rolling stock, unexpected perturbations, and the dynamic and stochastic variations in passenger demand (Daganzo and Ouyang, 2019). Efficient and robust metro operations require a modeling and optimization framework that has the capability of capturing the resulting complex system dynamics and deriving effective schedule control policies in real time.
There have been a number of studies presented in the literature investigating how one could improve the performances of train operations through service scheduling or rescheduling when incidents or perturbations occur. The integer programming or mixed integer programming formulations are among the most used approach in academia as they can be solved for global optimal solutions. For example, D’Ariano et al. (2007) present an alternative graph approach for rescheduling trains over a junction area and a solution algorithm based on the branch and bound method. Niu and Zhou (2013) formulate an integer programming for optimizing urban rail timetable under time-dependent demand. Barrena et al. (2014) present a set of exact integer programming formulations for scheduling train services with dynamic demand with solution algorithm based on the branch and cut method. Yang et al. (2016a) formulate a mixed integer programming model for scheduling high speed rail service with a solution algorithm implemented in CPLEX. Cacchiani et al. (2016) and Corman et al. (2017) adopt a mixed integer programming approach for real time train (re-)scheduling, and solve their optimization problems with self-designed heuristic methods. Despite their theoretical attractiveness, solving the integer or mixed integer programming models are usually computationally expensive even for medium-sized problems. Moreover, due to the complexity of the solution procedure, the integer or mixed integer programming approaches are mainly either for offline service scheduling, or for real time control for small scale service rescheduling purposes. Considering practical applications, there have also been a number of studies investigating the use of the computationally simpler heuristic approaches. This also includes use of some well-established meta-heuristics such as differential evolution (DE), genetic algorithm (GA, Niu, Zhou, 2013, Yang, Chen, Ning, Tang, 2017, Chow, Pavlides, 2018), and particle swarm optimization (PSO, Guo et al., 2017). A review and comparative study of these three meta-heuristics on train service scheduling can be found in Chang and Kwan (2004). Some other related studies can be found in Cacchiani et al. (2016), Corman et al. (2017), and Sama et al. (2017). More comprehensive review on different solution methods for train service scheduling can also be found in Yang et al. (2016b), Scheepmaker et al. (2017), and Zhang et al. (2018).
Train scheduling and rescheduling problems have been studied extensively over the past decade due to the increasing interest in green and sustainable transport modes around the globe. However, most related studies have been focusing on intercity and high speed rail trains instead of urban metro services. Moreover, most existing studies have been focusing on service scheduling for mid- or long-term average demand variation but do not respond to the short-term or real-time demand stochasticity. Existing work has not paid sufficient attention to scheduling algorithms that can be responsive to prevailing variations and stochasticity of passenger demand. With the advancements in information and communication technologies such as train positioning and smart card transaction systems, real time variations of service status and passenger demand can now be observed and reliably estimated (Shao, Lam, Sumalee, Chen, Hazelton, 2014, Zhou, Wang, Li, Yue, Tu, Cao, 2017, Noursalehi, Koutsopoulos, Zhao, 2018). This offers opportunities and also calls for innovations on real-time demand-responsive metro service scheduling with advanced data analytics and optimization techniques (Sun, Jin, Lee, Axhausen, Erath, 2014, Robenek, Maknoon, Azadeh, Chen, Bierlaire, 2016, Mo, Yang, Wang, Qi, 2019).
A demand-responsive train schedule can be derived from a Markov decision process (MDP, Bertsekas, 2019) with real time observations and estimates of passenger demand, service status, and operational constraints such as availability of rolling stock. This train service scheduling problem with respect to passenger demand variation is regarded as a dynamic optimization problem. It is known that the complexity of such dynamic optimization problem grows exponentially with the amount of decisions to make, state variables to observe, and uncertainties to consider. This issue is known as the curses of dimensionality which is a major technical challenge faced in most dynamic optimization problems (Powell, 2011, Bertsekas, 2019). There have been various techniques proposed to address the issue of curses of dimensionality. One of the prominent approaches is via the use of approximate dynamic programming (ADP) technique (Powell, 2011, Sutton, Barto, 2018). The core idea of ADP is to reduce the complexity of the original optimization problem by approximating the interaction between state-decision pairs and future costs with parametric approximators such as kernel regression models or artificial neural networks (ANNs). The optimization problem hence becomes working with parameters in the underlying approximator instead of dealing directly with the original state space. Examples of ADP application in railway operations include Yin et al. (2014) which adopt a rule-based expert system to develop an intelligent train operation algorithm that minimizes the energy consumption along the train’s progression. Yin et al. (2016b) adopt an ADP to derive optimal train rescheduling strategies through parameterizing the state space with linear kernel regression functions. Liu et al. (2018) adopt a similar technique to derive an energy-efficient metro service schedule over a unidirectional service line with use of lookup tables as an approximation of the state-decision value function. Ghasempour and Heydecker (2020) apply the ADP idea to derive an optimal sequence of trains passing over a junction. Unfortunately, train scheduling is known to be non-convex and non-concave which implies it would not be straightforward to derive an optimal solution even with an approximated state-decision function. With approximating function for future costs with respect to prevailing state-decision pair, the previously mentioned studies solve for their optimal solution by exhaustive searches, which could take significant computational time and memory for problems involving vast decision space. Referring to the previous example we raised, Yin et al. (2014) address the issue by applying a local greedy search through a rule-based decision space for an optimal control policy. Yin et al. (2016b) address the issue by confining the search space through pre-identifying affected trains in their rescheduling problem. Liu et al. (2018) adopt a local greedy search for suboptimal solution. Ghasempour and Heydecker (2020) adopt a brute force search over one single junction. We would also like to point out that these previous studies only consider the expected or average performance delivered by their optimal schedules, but do not take into account of their robustness or performance variability under stochasticity. It should be emphasized that robustness of a control design is certainly an important aspect to investigate for applications in real time situation driven by stochasticity (Chow, Li, 2014, Li, Chow, Zhong, 2019).
This study takes a significant step forward by proposing a real-time metro train scheduler for stochastic demand based upon an actor-critic deep reinforcement learning framework (Silver, Huang, Maddison, Guez, Sifre, Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot, Dieleman, Grewe, Nham, Kalchbrenner, Sutskever, Lillicrap, Leach, Kavukcuoglu, Graepel, Hassabis, 2016, Su et al., 2020, Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa, Silver, Wierstra). It is noted that the proposed study focuses on the stochasticity on the demand side but not on the operational side such as capacity loss due to occurrence of incidents. Driven by a stochastic demand profile, the control agent schedules a set of service runs over a metro loop with circulation of limited rolling stock. The control agent considered herein is multi-objective which aims to minimize both passenger waiting cost and train operating cost over the service runs. At each decision stage, the control agent has to decide the dispatching time of the service, the dwell times at each station along the service route, and the running times over each station pair en-route. The total number of service runs to be dispatched is dependent on when all passengers can be served, which gives the scheduling task an infinite horizon optimal control problem. With the large state and decision spaces encountered, the state space is parameterized and represented by an artificial neural network (ANN) known as the ’critic’ in the framework. The decision space is parameterized by another ANN known as the ’actor’ in the framework. In general, the critic ANN estimates the future states and costs given the schedule decisions made, and in return the actor ANN delivers the corresponding schedule decisions with respect to the critic’s estimates. The actor and critic ANNs will have to be trained via a series of simulated system transitions through a deep deterministic policy gradient (DDPG) learning algorithm before they can be applied for online schedule control. After sufficient training, our results show that the proposed actor-critic agent can outperform a selected set of meta-heuristics in terms of system efficiency and robustness over a range of stochastic demand scenarios. This study is among the first which integrates the emerging reinforcement learning technologies in computer science and dynamic transit system modeling in transportation.
The rest of paper is organized as follows. Section 2 presents the model formulation of the Markov schedule decision process. Section 3 presents the actor-critic deep reinforcement learning framework, including its architecture and training algorithm. In Section 4, the actor-critic schedule control agent is tested with a scenario configured with actual data collected from the Victoria Line of London Underground, UK. For benchmarking purpose, the control agent is compared against a selected set of meta-heuristics including differential evolution (DE), genetic algorithm (GA), and particle swarm optimization (PSO). The optimization algorithms are tested over a range of stochastic demand scenarios for both training and testing purposes. The results show that the actor-critic control agent can outperform the selected heuristics in terms of both system efficiency and robustness under stochastic demand-driven operational environments. Finally, Section 5 gives some concluding remarks and suggestions for future work.
