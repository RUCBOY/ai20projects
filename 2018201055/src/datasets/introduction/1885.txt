Salient Object Detection aims at identifying the most attention-drawing objects in an image and then pixel-wise segmenting these objects with binary labels, as illustrated in Fig. 1. As with the human subconscious, salient object detection generally services as the pretreatment procedure for many other computer vision tasks, such as visual tracking [1], content-aware image editing [2], [3], and weakly supervised semantic segmentation [4], [5]. Therefore, it is expected to handle with saliency inferring accurately and efficiently.Download : Download high-res image (820KB)Download : Download full-size imageFig. 1. Examples of salient object detection. The first row shows the input RGB images, and the second row presents the ground truth for salient object detection. Best viewed in color.
Recent years, with the revival of the convolutional neural networks (CNNs) [6], various CNN based models are explored for salient object detection. However, when using these models, the predicted saliency map is usually incomplete, that is, spatially inconsistent with the corresponding ground truth, because of the inherent complexity of the object and the inaccuracy of object boundary detection resulted from regular convolution and pooling operations. On the contrary, the discriminator distinguishes the authenticity of the input image and further leads to a more complete saliency detection result, which inspires us to introduce adversarial training into the visual saliency learning. At present, conditional Markov random fields (CRFs) [7], [8], [9], [10], [11] are the most commonly used post-processing methods, which directly integrate pairwise and specific higher-order potentials into the CNN based models. Despite CRFs can reinforce spatial contiguity in the predicted saliency maps, they are limited in parameter number of high-order potentials. Instead, in this paper, we utilize adversarial training to resolve this problem while improving the performance on accuracy for salient object detection.
On the other hand, the breakthrough on saliency detection accuracy of current state-of-the-art deep models [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22] comes at the expense of high computational cost, which contradicts its role as a pretreatment procedure for other computer vision tasks and thus greatly limits its pervasive application on embedded and mobile devices. To improve the performance on efficiency, we intend to explore a lightweight framework. Albeit varieties of researches delve into lightweight model designs, such as knowledge distillation [23], [24], [25] and network pruning [26], [27], [28], [29], [30], [31], connectivity learning [32], [33] and hyper-parameter optimization [34], [35], they are complicated and lacked of universality. For example, network pruning approaches necessitate pre-trained large models to obtain smaller models with the comparable performance. Moreover, these models cannot be directly applied into salient object detection, because they are not tailor-designed for capturing subtle visual contrast, which is the most significant factor [36], [37] for accuracy improvement.
Numerous strategies are used to explore local or global contrast cues for visual saliency detection. Previous works capture visual contrast through sophisticated hand-crafted low-level features, such as color, intensity and texture. As illustrated in the first two columns of Fig. 1, visual contrast of the two examples can be represented by low-level color features. On the contrary, salient objects in the last two columns hardly stand out from the background, because they have the similar appearance. Recently, CNN based models have been employed to obtain high-level semantic features, which are more robust than hand-crafted ones, achieving better results than early attempts. However, most of the current deep methods still lack efficient strategy to exploit multi-scale global contrast context. As discussed in [38], the amount of available context information depends on the size of receptive field in the deep neural network, however, the empirical receptive field of CNN is much smaller than the theoretical one, especially on high-level layers. Consequently, the networks cannot sufficiently model global context prior.
To alleviate the aforementioned issues, this work, inspired by the generative adversarial networks (GANs) [39], [40] and lightweight models [41], [42], proposes a Lightweight Adversarial Network (LANet) for salient object detection, which simultaneously improves accuracy and efficiency by enforcing higher-order spatial consistency through adversarial training and lowering the computational cost via lightweight bottleneck blocks, respectively. LANet utilizes encoder-decoder architecture based saliency predictor to generate the saliency map of an input image, where multi-scale contrast module is used to encode rich contextual information for visual saliency reasoning. During the training phase, this network is initially trained with a saliency loss over the predicted saliency maps. Afterwards, the model is finetuned with an adversarial network trained to solve a binary classification task between the saliency maps predicted by LANet and the ground-truth ones, meaning that an adversarial loss is incorporated into the visual saliency learning. It is worth mentioning that lightweight bottleneck blocks, instead of regular convolutions, are utilized in both saliency predictor and adversarial network to learn features, which has been proven very efficient in [41].
In summary, this paper has the following contributions:
•We propose an accurate and efficient network, i.e. LANet, for salient object detection, which utilizes lightweight linear bottleneck blocks to construct both saliency predictor and adversarial network, resulting in tremendous reduction in the computational cost to ensure the efficiency.•We incorporate adversarial training into saliency prediction model to improve performance via enforcing long-range spatial saliency contiguity, while consuming no additional computation cost at the test phase. Multi-scale contrast module is also used to further improve accuracy via encoding rich contrast cues.•This work presents comprehensive experiments on the trade-off of accuracy and efficiency. Experimental result demonstrates that our model significantly outperforms the state-of-the-art works on salient object detection.
