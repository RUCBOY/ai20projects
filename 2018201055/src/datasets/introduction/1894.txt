Breast cancer is the most common cancer in women, and the second most common cause of death by cancer after lung cancer. [1]. About 40,920 women in the U.S. are expected to die in 2018 from breast cancer, though death rates have been decreasing since 1989 [1]. These decreases are thought to be the result of treatment advances, earlier detection through screening, and increased awareness [1]. Early diagnosis of breast cancer continues to be the best way to save lives and decrease healthcare costs over time. Technologies to detect and diagnose breast cancer continue to advance for the purpose of giving patients less invasive options and better diagnoses [2].
Mammography is the primary factor in breast cancer mortality reduction, despite the potential drawbacks to the procedure [3]. In fact, reading a mammogram accurately is challenging for most radiologists. In some recent surveys [4], error in diagnosis was the most common cause of malpractice suits against radiologists. The majority of such cases arose from failure to diagnose breast cancer on mammography [4]. To reduce the rate of false-negative diagnoses, lesions with a 2% chance being malignant are recommended for a biopsy [5]. However, only 15 to 30% of the biopsies are found to be malignant [5]. Benign biopsies cause many negative consequences which include fear, pain, anxiety, direct financial expenses, indirect costs related to work missed, and risk of complications [6], [7], [8].
One way researchers have sought to improve the performance of mammography and increase the accuracy of the diagnoses was through a better estimation of breast cancer risk on the basis of mammography findings [9], [10].
Mammograms are normally subject to multiple annotations. The labels commonly attempt to describe the density of the breast according to the BI-RADS categories, the type of findings (masses, calcifications, etc.) and the pathology [11]. Initially, the radiologist will inspect the images looking for abnormalities in the form of masses, calcifications or other. Masses are defined as three-dimensional and occupy space with completely or partially convex-outward borders. When a new mass is identified, a diagnostic evaluation maybe warranted. Calcifications are deposits of calcium salts in the breast. Sometimes the calcifications can be associated with cancer. Certain characteristics of the calcifications help the radiologist decide if further action is needed. The Breast Imaging Reporting and Data System (BI-RADS) [12] was developed in part to improve the predictive capability of mammography. Radiologists classify density for each mammographic examination into one of four categories, as defined in the BI-RADS lexicon, fourth edition [13]. Approximately 9% of women have almost entirely fatty breasts (BI-RADS I), 40% have scattered fibro-glandular densities (BI-RADS II), 45% have heterogeneously dense breasts (BI-RADS III), and 6% have extremely dense breasts (BI-RADS IV) [13]. Dense breasts are defined as BI-RADS density categories III or IV. Thus, approximately 50% of the population who undergo mammography, have been categorized as having dense breasts [14]. The risk of breast cancer is higher for women with higher breast densities. It has been reported that women with a high breast density compared to women with a low breast density have a four to six fold increased risk of developing the disease [15], [16]. After careful annotations, the radiologist is then compelled to provide an accurate, specific, and sufficiently comprehensive diagnosis from the mammogram, to enable the clinician to estimate the prognosis and develop an optimal plan of treatment.
Computer-aided diagnosis (CAD) systems were proven very efficient in recognizing patterns in mammogram images that might suggest malignancy [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28]. Automated screening of mammograms or computer-aided diagnosis (CAD) of breast cancer is a vast field of research. In [29], [30], authors provide an extensive review on different stages of a CAD methodology for breast cancer. To the best of our knowledge, most existing works focus on single-label classification problems, where each mammogram is assumed to have only one class label from the aforementioned mammogram characteristics. On the one hand, we have those who focused on the types of findings in a mammogram to give a diagnosis. For example in some works [17], [18], [19], authors used micro-calcification to identify breast cancer. While in others [20], [21], [22], [23], [24], [25] authors focused on the morphology of the contour and shape of the breast mass lesion in mammography images, considering them the most discriminating criterions between benign and malignant masses. In other works [16], [26], [27], [28], authors relied on the mammographic density and parenchymal patterns for breast cancer risk assessment. These techniques, although working well, fail to exploit the dependencies that exist between the different annotations to be able to provide a full diagnosis. Multi-label classification is the extension of single-label classification in which the goal is to predict the set of relevant labels for a given input. The inputs used to train such a model for this type of problems have several labels. It differs with multi-class classification in terms of output label space, labels are not assumed to be mutually exclusive and multiple labels may be associated with a single training example [31], [32]. Historically, multi-label classification has primarily been applied to text categorisation [33] and medical diagnosis [34]. More recently, the use of multi-label classification has become increasingly popular for a variety of problem types [35], such as image and video annotation [36], [37], genomics [38], [39], [40] and sentiment classification [41], [42].
There are two prevailing categories of algorithms in multi-label learning, namely algorithm adaptation and problem transformation [34], [35]. Algorithm adaptation methods extend specific learning models to handle the multi-labelled data. On the other hand, problem transformation algorithms transform the multi-label learning task into either several binary classifications or one multi-class classification problem. Another category is multi-label ensemble methods [31], where models are defined as meta-algorithms based on the top of common multi-label learners. Many other methods have been proposed in the literature, some of which exploit graphical models to capture the label dependencies and conduct structured classification, including those using Bayesian networks [43], [44], [45] and conditional random fields [46].
Work on CAD for mammography [47], [48], [49] has been done since the early nineties. However, most of the proposed methods were developed on private data sets [50], [51], [52] which are not always shared and algorithms which are difficult to compare [49]. Moreover, the proposed methods for early diagnosis of breast cancer relied on only one of the indicators in the mammogram to diagnose the patient's condition. Whether it is identifying differences in shapes and patterns of the findings (i.e. masses, calcifications,…etc.) or the assessment the breast density. Based on one of these indicators, separate CAD systems are then developed to identify the disease. A drawback of such methods is that they completely ignore the interdependencies among the multiple labels, we therefore felt motivated to improve upon the state-of-the art and propose the joint learning of the tasks using multi-label image classification.
Fig. 1 demonstrates that some labels may be related to other labels. For instance, we notice that there is a connection between the findings and the BI-RADS density class IV in most datasets, which is noticeable in the bottom left corner of the co-occurrence matrices. We can also see that the masses and calcifications found in the BI-RADS I or II density tissue are most likely to be benign and this in all datasets. The matrices also indicate that most of the malignant cases are highly linked to the finding of a mass. To that end, modelling the rich semantic information contained in a mammography image and the possible label dependencies that may exit, is essential for understanding the image as a whole. Therefore, it is a practical and important problem to be able to design a framework that can accurately assign multiple labels to a suspected region.Download : Download high-res image (538KB)Download : Download full-size imageFig. 1. The co-occurrence matrices for the 8 labels in the four benchmark datasets (CBIS-DDSM, BCDR, INBreast and MIAS) obtained by simply counting all patient cases that have the same label distributions and reporting the numbers of co-occurrences between the different label categories. The goal is to highlight any relationships that may exist between the different labels. For example, we can notice that the masses or calcifications found in a BI or BII density tissue are most likely to benign than malignant, this is illustrated in all four matrices with a darker blue cell for the benign label compared to the malignant label in both columns of density BI and BII.
On a separate note, transfer learning [53], [54] is an attractive technique when dealing with little data, which is the case in the medical domain. Our last work [21] demonstrated that using transfer learning, from natural images with fine-tuning, we could efficiently learn from mammography image datasets and achieve better results than when learning from scratch. Some of the limitations of the work were due to the texture of some of the images, i.e. when examining these images, we noticed that the texture of some of the benign and malignant mass lesion images was similar and this resulted in a misclassification of the suspected region. Most of the misclassified mass lesion images were also labelled as highly dense. Accordingly, research showed that cancer is more difficult to detect, in mammograms of women with radiographically dense breasts [55]. Breasts are composed of lobules, ducts, fatty and fibrous connective tissue. The breasts are dense in the presence of a lot of glandular tissue and not much fat. On mammograms, dense breast tissue looks white, while breast masses or tumours also look white. Therefore, the dense tissue hides the potential findings. On the other hand, fatty tissue looks almost black, and on a black background, it is clearly easier to identify a tumour that looks white (see Fig. 2). Therefore, mammograms can be less accurate in women with dense breasts.Download : Download high-res image (335KB)Download : Download full-size imageFig. 2. Comparison between the markings of suspected regions in dense and non-dense mammograms; First row of the figure gives the example of a non-dense mammogram showing more “grey to black” fatty tissue and the second row illustrates a dense mammogram showing more white glandular tissue. (a), (c), (e) and (g) highlight the suspected regions marked by imaging specialists while (b), (d), (f) and (h) show the delimited region of interest to be cropped. The regions of interest in (b) and (d) the non-dense mammograms are well-targeted and easier to find compared to (f) and (h) the dense mammograms.
Inspired by the success of Convolutional Neural Networks (CNNs) in single-label mammography classification [17], [18], [21], we seek to build an end-to-end deep learning framework for multi-label breast lesion classification. We want to take advantage of the very expressive convolutional neural network architecture (CNN) [56] to build an automatic multi-labelling framework able to help assist the radiologist in giving a full report and more accurate diagnoses to his patients. This is a follow-up and improvement of our last work [21], which extends the image classification from a single-label to a multi-label problem. In this work, we compare the performance of the CNN while using different initialization and optimization procedures. When fine-tuning we propose to use the new strategy we previously presented as a preliminary proposal in [57], but this work goes in much more depth to give detailed explanations and extensive experimentations that underline the superiority of the proposed approach. The method is a new training procedure for fine-tuning when using transfer learning, the idea behind it is that when fine-tuning we don't want all the weights to change in the same manner, we want some of the layers to be more or less receptive to change, depending on their nature. Accordingly, the proposed fine-tuning strategy optimizes the model using SGD momentum with an exponentially decaying learning rate to customize all the pre-trained weights and make them more suited to our type of data. The per-layer decaying learning rate helps control the rate at which weights change in each part of the network i.e. the change will be small to non-existent as we go backwards in the network towards the first layers. The results obtained from using this approach show robustness and efficiency when predicting labels for new breast lesions, whether trained on a small or a slightly larger dataset. We also adopt a final decision labelling mechanism adapted to this task and we evaluate the proposed approach on four benchmark datasets and using many evaluation criteria.
The remainder of this paper is organized as follows: Section 2 formulates the problem and describes the methodology proposed to solve the issue at hand. In Section 3 we provide details of the experimentations lead to evaluate the proposed approach, and we give the results along with a discussion to analyze them in Section 4. Finally Section 5 concludes the paper.
