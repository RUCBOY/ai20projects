In the fields of biometrics, computer vision/graphics, and medical/surgery applications, finding key points has been a long-standing topic because of their rich semantic information. As the key points on faces, 3D facial landmarks are widely used in many face-related applications including recognition, expression analysis, semantic segmentation, rendering and relighting, and also cephalometry [1]. Therefore, an automatic and effective 3D landmark localization system is very valuable. There have been many literatures on 3D landmark detection/localization so far. Texture-based detection methods were reported to achieve decent results [2], [3]. In our work, texture information is not mandatory since we aim at detecting landmarks from pure 3D shape information. This is a more general consideration for the cases where texture information acquired is inaccurate or not available. Here below we summarize three main challenges for 3D landmark detection under unconstrained conditions:
•Expression variations. Expression changes lead to point cloud deformation, which may make the landmarks scattered and hard to locate. Perakis et al. [4] propose a method to detect landmarks using Full Face Statistical Landmark Model (FLM) and a combination of Shape Index and Spin Image. Their method is designed to handle large expression variations. However, regarding to the accuracy of the eight landmarks on FRGCv2 dataset, this method achieves a mean error higher than 6.0mm for faces having extensive expressions, while the detection success rate is only 90.4%. Such results still have large room for further improvement.•Pose variations. Pose variations may lead to the self-occlusion problem of 3D face data when viewing from an un-calibrated view, making some landmarks invisible. However, determining pose parameters without landmarks is difficult. To tackle this, Križaj J et al. [5] propose a method based on grid function and SIFT features. They use grid function to estimate the pose of a 3D face, and then with the estimated pose they fit the target landmarks by iterating on the positions of the initial landmarks. Note that this method is particularly designed for the cases where data of the invisible areas is missing. However for the cases where the invisible areas have complete data, we believe using pose correction is an essential step for subsequent landmark detection.•Detecting a large number of landmarks. Some existing methods can only capture a few points of distinctive facial areas, such as nose tip, eye corners and mouse corners. This is because they resort to hand-craft features such curvature [6] and Spin Image [4]. Unfortunately, in many face-related applications such as deformation analysis, a lot of landmarks (e.g., 68 landmarks) are needed. Gilani et al. [7] solve this problem based on dense correspondence of 3D faces. Fan et al. [3] detect landmarks on a textured 3D model by conformal mapping. However on BU-3DFE dataset, their mean errors are higher than 4.3mm and standard deviations exceed 2.5mm, which are far from satisfactory.
Recently, deep convolutional neural networks have been deployed for 2D landmark detection [8], [9], [10] and shown to obtain impressive performance. Inspired by the work of [11], [12], [13] and to tackle the above-mentioned challenges, we make the following attempts for 3D landmark detection: (1) utilize pose normalization before detection so that the latter is facilitated; (2) find a better intermediate representation of 3D data for deep convolutional networks; (3) deploy deep convolutional network for locating a large number of 3D landmarks. As a result, we propose a novel 3D Facial Landmark Localization Network (3DLLN), which is the first to introduce the UV1 position map as an effective intermediate representation for 3D landmark discovery.
Motivation. A widely-used method to convert 3D shape information into 2D representation is using depth images, whose pixel values are relative depth from a sensor. Then, facial landmark detection [14] or even face recognition [15] can be done instead on such depth images. However, we notice two shortcomings of depth images when used for facial landmark detection. First, after conversion two points that are far away in 3D space can be spatially quite close on depth images. A small detection error in such area will inevitability lead to a high localization error on the 3D shape, e.g., the nose region that varies steeply. Second, pixel values on a depth image indicate only relative depth that may be insufficient to fully characterize a 3D shape. We introduce the UV position map [11] to remedy the above two issues. UV maps are widely used to represent 3D models [3], [13]. They can fully represent 3D structures in a 2-dimensional space meanwhile avoiding self-occlusion. Position maps are recent advances [11] which go one step further upon UV maps. Position maps represent 3D coordinates as RGB information via an encoding scheme called Projected Normalized Coordinate Code (PNCC) [12]. By encoding, the coordinates of a 3D point are normalized into interval [0, 1] and can be represented as a color value on the UV map. The resultant UV map is called UV position map (as visualized in top-right of Fig. 3), which we believe is more informative and beneficial to 3D facial landmark detection.
In summary, the contributions of this paper are three-fold:
1.We propose a novel 3D Facial Landmark Localization Network(3DLLN) that detects 3D landmarks from UV position maps. To the best of our knowledge, it is the first time that UV position maps are jointly used with deep convolutional neural network to locate a large number of 3D landmarks. Besides, unlike existing 2D landmark networks which output heatmaps, 3DLLN leverages a deep regression architecture to obtain landmarks’ 3D coordinates directly. Also, unlike [11] which discovers landmarks jointly with the 3D shape by regressing an UV position map from an unconstrained 2D image, their landmarks have fixed known locations on the map (see Fig. 4 in [11]). By contrast we aim to “detect” landmarks “on” the UV position map.2.We propose an effective pose calibration scheme for 3D facial data, which employs Shape Index and Principle Component Analysis (PCA). This ensures one to perform landmark detection regardless of pose changes.3.The proposed 3DLLN is evaluated on two representative datasets FRGCv2 and BU-3DFE, which are widely-used for 3D point cloud research. 3DLLN is shown to surpass existing methods and attains state-of-the-art results.
The reminder of the paper is organized as follows. Section 2 describes related work on 3D facial landmark detection. Section 3 describes the proposed method in details. Experimental results, performance evaluation and comparisons are included in Section 4. Finally, conclusion is drawn in Section 5.
