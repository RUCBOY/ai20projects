Panorama construction [1] usually refers to image stitching, panorama mosaics and is a fundamental task in both computer vision and computer graphics, the goal of it is to composite a high-quality image with a big degree of view from a set of small-view images. The research on panorama construction has a long history and has drawn a lot of attention from both industry and academic due to its successful applications such as autonomous driving, navigation, virtual tourism, video surveillance, 3D reconstruction [2], [3], augmented reality, and virtual reality [4], [5]. In practice, it is a difficult task for constructing panorama due to challenges such as camera jittery, short baseline, and repeated features, thus, constructing a big panorama from images with a small degree of view is a difficult task.
Although no solutions on image stitching can produce big panorama, there are also many important image stitching methods worth paying for more attention. For example, Zaragoza et al. [6] propose as-projective-as-possible warps to achieve global projection for reducing ghosting effects. Like [6], Zhang et al. also propose a mesh-based framework to optimize alignment and regularity in 2D space by solving a global objective function. Gao et al. [7] propose to use seam-cut instead of estimating a geometric transform based on the best fit of feature matches to hide misalignment artifacts. Joo et al. [8] use line correspondences to assist the mesh-based-panorama construction, then resulting in a spatially varying panorama construction method. Lin et al. [9] proposed an adaptive as-natural-as-possible (AANAP) image stitching method, which incorporates several novel techniques to improve the quality of the generated panorama. Like [9], Chang et al. [10] propose a shape-preserving half-projective (SPHP) warp to preserve shapes in the non-overlapping areas. Although SPHP has an excellent result, it is sensitive to parameter selection. Among the existing methods, One of the most important methods is AutoStitch [11], which is an excellent approach to constructing panorama from image collections and has a standard pipeline that consists of camera calibration, feature tracking, motion estimation, image wrapping, bundle adjustment, and image blending for filtering visual artifacts. Although AutoStitch has many good properties, it is only able to handle camera motion in plane space, this may limit the popularization of it, and it is not capable of constructing panorama from a video sequence.
With the rapid development of cameras, capturing video becomes easy, thus researchers try to construct a panoramic image from video. For example, He et al. [12] proposed a parallax-robust video stitching method for surveillance video by the layered warping approach to aligning the background scenes. Jiang et al. [13] presented a novel method for mapping multiple synchronized videos into a single panoramic video by utilizing spatialâ€“temporal content warping. Perazzi et al. [14] proposed a novel approach for generating panoramic video from unstructured camera arrays, in which an artifact-free panorama sitting is adopted to produce a seamless panoramic image. Guo et al. [15] presented a video stitching for videos that are captured by multiple moving cameras for the same scene, this method did panorama construction and video stabilization in a unified framework, and the quality of the resulted panorama heavily depends on video stabilization. Lee et al. [16] developed a novel system to construct panoramic video from multiple cameras placed on a structured rig, which provides an as-rich-as-possible panoramic viewing experience by an optimized spherical representation. He et al. [17] presented a novel technique to create wide-angle, high-resolution looping panoramic videos, in which the constructed panorama is assembled by using gradient-domain image blending and stored as a hierarchy of video tiles. Yuan et al. [18] proposed a multi-scale camera array to capture and synthesize gigapixel videos in an efficient way. The key feature behind this method is its robustness and high accuracy for the large resolution gap, camera parallaxes, complex scene appearances, and color inconsistency among cameras. Recently, Ho et al. [19] presented a novel method for a 360-degree image by using dual-fisheye lens stitching. Although there are some impressively works on panoramic video construction, no solutions can be adopted directly to construct panorama from single video sequence [20], [21].
To address the problem aforementioned, in this paper we proposed a novel method for constructing a big panoramic image from a single video sequence captured by single-moving hand camera, in which a robust video stabilization method is adopted for producing stabilized video for image stitching, and formulating video stabilization and image stitching in a unified framework named BigPano. Specifically, the BigPano consists of feature tracking, video stabilization, and joint stitching. With regard to feature tracking, we present a deep local feature-based feature tracking approach to producing feature correspondences between consecutive video frames for both video stabilization and image stitching. For the middle one, simple video stabilization is introduced for filtering jittery video frames by camera path correction. Our work is of broad interest to the panorama construction, computer vision, and computer graphics community since many applications are urgently required to improve the quality of panorama, such as panorama-based context creation for virtual reality. The contributions of this work are summarized as follows:
(1) Joint stitching is proposed for constructing a big panoramic image from a single video captured by a single-mobile camera, which can produce a high-quality panoramic image with a wide view degree.
(2) An accurate and efficient feature tracking method is presented for generating feature correspondences, which is based on deep local feature and is capable of locating feature points in textureless areas.
(3) A simple video stabilization method is proposed for generating stabilized video for panorama construction, which can guarantee the spatial consistency of the generated panoramic image, then leading to a seamless panoramic image.
The rest of this paper is organized as follows. Section 2 briefly reviews the related works. Section 3 presents our method in detail. Results and discussions are provided in Section 4. Some conclusions are finally drawn in Section 5.
