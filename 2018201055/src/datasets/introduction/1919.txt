Images play a crucial role in the cognitive world of human life. Not only can humans recognize different objects in images, but also are able to express their information by language. It is challenging for machines to imitate humans to deliver information. Describing the contents of an image automatically is a tough issue in the field of artificial intelligence. Impressive progress has been reported in recent literature for image caption generation. Kulkarni et al. [1] presented a system to generate natural language descriptions from images automatically. They firstly smoothed the output of image vision-based detection and recognition algorithms, then chose words to construct natural language sentences based on the previous contents. Farhadi et al. [2] described a system that can compute a score, and then link an image to a sentence. It amounts to mimicking human ability to compress image contents into descriptive language.
The rapid development of deep learning technology provides new methods for image captioning. Mao et al. [3] proposed an MRNN model, combining deep CNNs with RNNs to solve the problem of image caption generation. Vinyals et al. [4] put forward a NIC model. They abandoned the traditional RNNs and use LSTM network to solve the problems of gradient vanishing. Recently most researchers concentrate on optimizing the quality of caption generation by using different models, but the core idea is still combining a more powerful VGGNet [5] with the LSTM model.
In the human visual system, visual attention is controlled by cognitive concept-driven factors, such as knowledge, expectation and current goals, and stimulus-driven factors reflect sensory stimulation [6]. The research on image caption generation is inspired by the attention mechanism of human beings. Laurent et al. [23] firstly proposed the theory of attention based on the field of image processing, while Google DeepMind [7] applied it to image classification. Cai et al. [12] proposed a novel two-archive method for solving multi-objective optimization problems, which further improves the effect of image classification. Then, Bahdanau et al. [8] completed machine translation by using the attention mechanism, and applied it to the natural language processing (NLP) field. Yu et al. [9] proposed a multimodal sparse coding method for the reranking of images, which further improves the accuracy of the prediction task. It seems extremely efficient to express the contents of an image with a highly abstract description, but it has one potential drawback of losing information which could be useful.
Aiming at the problems in image caption generation, a solution is introduced based on the attention mechanism [10], [13]. The contributions of this paper are as follows:
(1)We introduce the theory of attention in psychology to image caption generation and get good performance.(2)In the stage of image preprocessing, image features are filtered by our attention mechanism, and the image captioning is influenced by the weights of image features.(3)Our concept-driven attention model implements a classical question-guided attention mechanism.(4)We put forward a variation of LSTM combining with the attention mechanism, and verify our method on some benchmark datasets like Flickr8k [14], Flickr30K [15] and MS COCO dataset [16], which get excellent performance.
