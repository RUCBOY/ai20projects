A Brain-Computer Interface (BCI) is a system composed of software and hardware that builds a channel of communication between the subject and the computer, using only the subject’s brain signals [1]. The general process followed by a BCI can be divided into: subject’s stimulation, acquisition of brain activity, signal preprocessing, feature extraction, classification, and translation of the output’s classification into instructions to control an application or a device. One of the brain signals, captured with the electroencephalogram (EEG), of interest in the community for controlling BCIs is the Event-Related Potential (ERP). In particular, the late P300 component has a stable temporal relationship with respect to the stimulation event, an interesting characteristic to control BCIs. For instance, it is related to cognitive and attention processes and it is independent of the type of stimulation presented to the subject. The P300 is associated with the oddball paradigm, which consists in presenting a series of frequent stimuli interrupted by infrequent stimuli [2]. Thus, every time the infrequent stimulus is detected by the subject, the brain unconsciously generates a positive peak, approximately 300 ms afterwards.
Given that a BCI based on ERP signals is highly subject-specific, it requires two phases to be used: i) an offline training phase to calibrate the system for each subject and ii) an online phase to actually let the subject control the BCI. Typically, the subject has to repeat several times the oddball paradigm to increase the ERP’s signal-to-noise ratio [3]. Since the stimulation process can become unacceptably slow and tiring for the subject, much of the effort in the BCI development is to stimulate the subject as few times as possible, preferably only once (i.e., by a single-trial), while still achieving an adequate detection of the P300 component. More recently, some works have attempted to eliminate the calibration stage for each subject by using instead the information acquired previously for other subjects [4]. The P300 detection based on the information retrieved during the calibration stage by a single subject is known as within-subject classification, whereas the detection based on the information retrieved by other subjects is known as cross-subject classification.
In order to detect the P300 under these conditions, different domains have been used to represent ERP’s features, including frequency [5], time–frequency [6], space–time [7], and shape [8]. Prior to classification, feature selection is commonly applied to: i) reduce redundancy, ii) choose the features related to the mental states targeted by the BCI, iii) generate fewer parameters to be optimized by the classifier, and iv) produce faster predictions for a new sample. Among the most prominent feature selection approaches used for P300 detection are the embedded methods (e.g., Stepwise Linear Discriminant Analysis [9]) and the wrapper methods (e.g., Genetic Algorithms [6]). On the other hand, the approaches more commonly used for classification have been Linear Discriminant Analysis [10], Support Vector Machines [11], Feed Forward Neural Networks [12], [13], and adaptive classifiers [14], [15].
Recently, some methods merge feature extraction, feature selection, and classification by using matrix classifiers (e.g. [16]) or Deep Learning (e.g. [17], [18], [4]). In particular, the latter has gained a lot of interest since it has demonstrated to be very effective in fields such as Computer Vision [19] and Speech Recognition [20], not only to replace human-engineered features but also to increase classification rates. Some characteristics of these methods are their depth, the use of a large number of parameters, and the need of huge amounts of data to train. These characteristics may be a disadvantage for P300 detection, mainly due to the limited training data available [21], [22].
Although CNN architectures have been effective for single-trial within-subject and cross-subject P300 detection from EEG signals, the increase in detection rates compared to approaches based on human-engineered features has not been as impressive as in other applications [23] and might not justify such a large number of parameters. In this paper, we study the performance of state-of-the-art CNN architectures with diverse complexities for single-trial within-subject and cross-subject P300 detection on four different datasets. We also propose SepConv1D, a very simple CNN architecture consisting of a single depthwise separable 1D convolutional layer followed by a fully connected Sigmoid classification neuron. We compare the state-of-the-art architectures to both SepConv1D and a simple Fully-Connected Neural Network (FCNN) with a single hidden layer with only two neurons, in terms of detection performance and complexity.
The remainder of this paper is organized as follows. In Section 2, we review the state-of-the-art CNN architectures for P300 detection. In Section 3, we describe in detail SepConv1D and the Fully-Connected Neural Network. In Section 4, we present the experimental design and the datasets. Section 5 shows the results of the experimental evaluation and discusses the performances and complexities of the analyzed architectures. Finally, in Section 6 we provide some concluding remarks.
