High spatial and temporal resolution sensors are rapidly being developed and these advanced remote sensing sensors are capable of acquiring large volumes of images at a fast rate (Guo, 2017, Toth and Jóźków, 2016). For example, the image volumes acquired by the outdated Himawari-8 routinely exceed 0.5 Gigabytes per Full Disk image every 10 minutes (Bessho et al., 2016, Da, 2015) while the FengYun-4A satellite collects more than 1 Gigabyte per Full Disk image every 15 minutes (Yang et al., 2017). As a result, an increasing number of high spatial or temporal resolution images are currently accessible, providing abundant relevant spectral and texture information but also with increasing amounts of irrelevant image detail. This leads to challenges in handling high-resolution images (Benediktsson et al., 2012, Guo, 2017, Vatsavai, 2013).
Object-based image analysis (OBIA) was developed to make use of the spectral or texture information present in images with high spatial or temporal resolution-for example, to recognize landscape patterns accurately-and has been widely employed to analyze images in multiple applications (Blaschke, 2010, Blaschke et al., 2014, Cheng and Han, 2016, Ma et al., 2017). The OBIA basically consists of three steps-image segmentation, feature extraction and object classification (Khadanga et al., 2016), with image segmentation being the fundamental operation. The high segmentation error, along with the over- and under-segmentation errors, remain among the challenges faced in image segmentation (Su and Zhang, 2017, Troya-Galvis et al., 2015). The performance of OBIA is heavily influenced by the image segmentation accuracy because the segmentation errors can propagate and accumulate through to the feature extraction and final classification (Kavzoglu and Tonbul, 2017). Therefore, researchers are focusing more on improving segmentation quality by managing two types of segmentation error which primary influence the performance of the OBIA (Zanotta et al., 2018). Many remote sensing image segmentation models have been proposed. These methods are mostly used to segment images with a limited size within a single-machine environment.
Due to the increasing demands of real-time processing for practical applications, it is difficult for single-machine models to process composites formed from large numbers of images within a short time (Ma et al., 2015, Rathore et al., 2015, Wang et al., 2018). Ideally, the images should be analyzed immediately after acquisition and finished before the next image is acquired (Afshar and Sbalzarini, 2016). The limitations of computing capability lead to the problem that the size of these massive images can exceed the memory of a single machine (Körting et al., 2013) and so the demand for real-time processing during natural disasters cannot be met. Thus, improving the handling capacity of segmentation algorithms has become another important issue, especially in dealing with composite images. In order to deal with massive images, distributed segmentation algorithms have emerged. These models provide a powerful solution to the problem of handling large images. First, the large image is decomposed into multiple specified image tiles. The image tiles are then distributed to different computers to perform the segmentation and objects are generated in each tile. In the final step, all of the image tiles need to be reintegrated.
There are still some challenges in reintegrating image tiles. Objects next to each other are treated as adjacent objects in each image tile. Objects located in neighboring tiles are defined as broken adjacent objects if those objects are adjacent to each other in the integrated image. Broken adjacent objects cannot be combined into one unbroken object perfectly when multiple tiles are simply integrated from lots of computers without any further processing. However, broken adjacent objects usually have similar feature attributes, as most of them belong to the same landscape categories in the original image and are decomposed using a specified tile size without regard to ground patterns. Therefore, combining the broken adjacent objects into a complete object is the ultimate goal. The objects formed from the broken adjacent objects are all located at the boundaries of an image tile by definition. Therefore, the key point of distributed image segmentation is to find a solution that can handle the boundary areas between multiple parallel image tiles.
As far as the authors of this paper are aware, the proposed distributed image segmentation algorithms mainly focus on medical image processing. Corresponding distributed applications to remote sensing image segmentation are limited, although the parallel based method has been implemented in object detection (Kertész et al., 2015). Moreover, the image segmentation tasks required for medical and remote sensing images are quite different. In medical imagery, the backgrounds are relatively simple and the number of research targets is limited. Remote sensing images include massive complicated landscape features with various sizes and shapes. Different landscape patterns can also have similar texture and spectral characteristics. Therefore, it is necessary to establish an appropriate strategy for the parallel segmentation of remote sensing images.
In this paper, a distributed image segmentation strategy based on the Spark and GeoTrellis frameworks is proposed. The massive images are loaded and decomposed into specific image tiles across multiple computers. The segmentation algorithms are adopted to segment the tiles into objects on each computer. The objects are then divided into boundary objects and inner objects. Buffered tiles originating from neighboring tiles are acquired by each computer. The boundary objects within the buffered tiles are handled using the same segmentation algorithms as in the initial segmentation. Boundary objects located within the original tiles are retained. This procedure is performed on each computer and the final segmentation image is acquired after the image ingestion. The critical feature of the proposed strategy is the repeated computation. In this study, the proposed strategy was tested by comparing the use of different strategies.
The organization of this paper is as follows. Section 2 describes related works on remote sensing image segmentation, Section 3 outlines the principles behind the proposed strategy, Section 4 presents the experimental results, and this is followed by the discussion in Section 5. Concluding remarks are given in the last section.
