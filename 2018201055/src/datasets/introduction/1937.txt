A healthy diet has crucial importance to human health [1], [2]. The attributes of natural products (e.g., milk, eggs) and processed foods (e.g. cheese, bread), such as food type, composition, and method of processing, are all of particular concern in establishing a healthy diet [3]. In general, food classification plays a vital role in recording the daily diets, and the images of the food are acquired and analyzed in nutrition assessment applications as they could easily reflect the characteristics of food [4]. However, it is a challenging problem since the preparation process of the food causes large variation in shape, texture, color, and its appearance [5]. For example, Fig. 1 provides image samples from a food dataset Food101 [6]. The categories of the first row and second row of images are apple pie and pancakes, respectively. Compared to other tasks such as scene image classification [7], [8], the pivotal difficulty of food image processing lies in the fact that the intra-class variance could have more differences than its inter-class counterparts, which means that food images within the same class could appear in various forms while different foods may look similar.Download : Download high-res image (239KB)Download : Download full-size imageFig. 1. Sample images from Food-101 datasets.
To address these challenges, researchers have provided many food image processing algorithms which can be basically divided into traditional methods [1], [5], [9], [10], CNN-based methods [6], [4], [11], [12], and fusion-based strategies [13], [14], [15]. The fusion-based approaches, which can integrate and exploit multiple high-level CNN features from different models, resulting in higher accuracy, stability, and robustness over other two branches of learning schemes [13]. They have done so because the features extracted from one model could be biased and may contain uninformative details [15], the fine-grained labels in food target domain are almost impossible to categorize and distinguish by using the single channel high-level features.
However, in the works of [13], [14], [15], various feature sources are simply concatenated together into one high-dimensional vector, and the final decision is made via a classifier such as a linear classifier. This straightforward design has the following limitations: 1) they cannot obtain satisfactory results on large-scale complex datasets, and 2) they do not consider how to make use of the dimension reduction process to refine the concatenated input features. According to some successful techniques [16], [17], [18], we hypothesize in this paper that the direct use of concatenated CNN features are inefficient because there will be many redundant details in such high dimensional representation. The redundant components may deteriorate the performance of final classifier. If the data are compact and fairly in low dimensional, classifying the unknown patterns would not be difficult. Thus, in this paper, a novel fusion-based food image classification framework with dimension reduction technique is proposed. The learning diagram is depicted as Fig. 2. The paradigm contains two parts: Part I: CNN-based feature concatenation, and Part II: food classification with Wi-HSNN. The proposed dimension reduction method Wi-HSNN described as Fig. 3 is characterized by three properties:(1)It adopts subnetwork neural nodes (SNN) to search the optimal latent space. In particular, we propose a novel framework with entrance SNN (En-SNN) and exit SNN (Ex-SNN) to refine the concatenated input feature.(2)The structure is learned in an iterative way. Initially, the Wi-HSNN starts with one En-SNN and Ex-SNN. Then, the framework is gradually expanded by adding new En-SNN and Ex-SNN models. In each iteration, only one En-SNN and Ex-SNN are added, and the parameters of these added subnets are calculated with the expected output “e” derived from the previous iteration. Hence, the learned latent space is guided by the previous error term, which is continually enriched through the introduction of new SNNs.(3)This paper presents a parallel learning strategy. Existing subnet-based strategies [19], [17] are one-batch learning algorithms, the users need to calculate the optimal parameters on the entire dataset at once. The technique is uneconomical especially when handling large-scale datasets. In this paper, we used a batch-by-batch scheme to process large volumes of data.Download : Download high-res image (310KB)Download : Download full-size imageFig. 2. Structure of proposed food image classification framework. It contains two parts – Part I CNN-based feature concatenation; Part II food classification with Wi-HSNN.Download : Download high-res image (602KB)Download : Download full-size imageFig. 3. Part II - food category classification with Wi-HSNN. The framework initializes its structure (i = 1) with one En-SNN and Ex-SNN as depicted by left figure. Then, the SNN pairs are gradually added into the structure with an iterative way. In each iteration (1<i⩽L), only one En-SNN and Ex-SNN are added, where aeni and aexi are calculated with error feedback data P.
In addition, a number of evaluation experiments are adopted to compare multiple food image classification approaches and data representation algorithms over different datasets. Experimental results on 8 real-world datasets ranging the amount of samples from 14,361 to 1,839,960 show the improvement of proposed method over multiple comparison methods.
The rest of this paper is organized as follows. Section 2 provides the literature review. The proposed framework is described in Section 3. Section 4 elaborates upon the experimental results and discusses their significance. The final conclusions of the study are presented in Section 5.
