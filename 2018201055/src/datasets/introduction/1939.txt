Object detection is a fundamental research problem in computer vision. Recent years have witnessed remarkable progress in object detection algorithms catalyzed by the success of powerful deep learning techniques [1], [2], [3]. Currently, the state-of-the-art deep learning based object detection frameworks can be generally categorized into two major groups: (i) two-stage detectors, such as the family of Region-based CNN (R-CNN) [2] and their variants [1], [4] and (ii) one-stage detectors, such as SSD [5] and its variants [6], [7]. Two-stage RCNN-based detectors first learn to generate a sparse set of proposals followed by training region classifiers, while one-stage SSD-like detectors directly make categorical prediction of objects based on the predefined anchors on the feature maps without a proposal generation step. Two-stage detectors usually achieve better detection performance and often report state-of-the-art results on benchmark data sets, while one-stage detectors are significantly more efficient and thus more suitable for many real-word practical/industrial applications where fast/real-time detection speed is of crucial importance.
Despite being studied extensively, most existing object detectors are designed for achieving localization with relatively low-quality precision (e.g. Intersection over Union (IoU) threshold of 0.5 is considered good enough). When the goal is to achieve higher quality localization precision (IoU > 0.5), the detection performance often drops significantly [8]. A naive solution to address this issue is to increase the IoU threshold when selecting positive samples (e.g., from 0.5 to 0.7) during training, such that the detector is trained on only high quality examples. Unfortunately, such a strategy will lead to very few (positive) training samples, and will consequently lead to overfitting, especially for single-shot SSD-like detectors. In addition, most object detectors aim to use the strength of deep features for object localization. This can have adverse effects as deep features (while being semantically rich) lack detailed information about the spatial location of the objects.
In this paper, we aim to develop a novel high-quality single-shot detector. We follow the family of single-stage SSD-like detectors, and design an approach that makes it amenable for high quality detection. We identify two critical drawbacks of SSD-like detectors for learning high quality detectors: first, the single-shot feature representations may not be discriminative and robust enough for precise localization; and second, the singe-stage detection scheme relies on the predefined anchors which are very rigid and often inaccurate. To overcome these drawbacks for high-quality object detection tasks, in this paper, we propose a novel single-shot detection framework named “Bidirectional Pyramid Networks” (BPN). Specifically, BPN uses a novel Bidirectional Pyramid Structure, that boosts the vanilla feature pyramid [3] by reinforcing it with a Reverse Feature Pyramid to fuse both deep and shallow features to learn more effective and robust representations. Unlike Feature Pyramid Network (FPN) which aims to enhance the shallow features with semantically rich deep features, the Reverse FPN aims to enhance the deep features with spatially rich shallow features, thereby improving the representation for better localization. BPN is also augmented with a novel Anchor Refinement scheme that learns to gradually improve the quality of predefined anchors which are often inaccurate at the beginning. Specifically, we train the bounding box regressors at different levels of qualtiy (IoU thresholds), and in an incremental manner, feed the bounding box predictions of a specific quality into the predictions of the next higher quality. We conducted extensive experiments on PASCAL VOC and MSCOCO showed that the proposed method achieved the state-of-the-art results for high-quality object detection while still maintaining the advantage of computational efficiency of single shot detectors.
