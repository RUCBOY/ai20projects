Human-Machine Interaction (HMI) is used to interact with clinicians and patients through automated response and monitoring systems. It is one of the usability systems that make learning easy, diagnose and send feedback to the operator [1]. HMI technology is used in robotics and functional electrical stimulation to support the patients by monitoring and saving their lives [2]. Further, the physician communicates faster and efficiently to ensures the patient's health and gives the appropriate treatment. It is portable and easy to operate with the features; the initial step is the patient's log in and feeds the information [3]. The diagnosing is obtained by storing information and interacting directly with the patients for their health. By interacting, the data have to be secure and various types of algorithms are developed for enhancing the accuracy level [4]. HMI in the medical field carries sensitive data, therefore, there are access at the allocated time instance to avoid hacking. Timely monitoring is used to analyze the state of the patients, and data is obtained without any delay. Therefore, the interaction with the device is common for remote patients [5]. Also, the convolution neural network (CNN) is used for classifications and recognitions [6], [7]. CNN has different applications specially in biomedical applications [8], [9].
The facial expression is recognized based on classification of various expressions such as anger, fear, surprise, sadness, and happiness. Based on these expressions, the recognition of the patient's state is executed [10]. The face images are captured by the camera or any other device, and then, the features are extracted by taking the necessary information [4], [11]. The classification is carried out using the extracted features from the patient as happy or sad state [11]. The processing of expression is represented by analyzing the primary curves on the faces that are commonly seen in eyebrows, eye, lips, and nose [10], [12]. Measured movements of these four key features are used to identify the expression [13]. Based on the facial expressions, there are communication with the doctor about the standard. Various techniques are used for analyzing these expressions and obtaining comparative results [14]. The captured face is compared with the predefined database to evaluate the exact expression and find what state the patient survives. Commonly, Facial Expression Recognition (FER) techniques include the three major stages, such as preprocessing, feature extraction, and classification [15].
Computer Vision (CV) in the medical field is used to diagnosis the diseases in a faster manner that is more accurate. Both CV and HMI play important role in the field of healthcare applications. They are also used for pattern recognition in the medical environment [16]. The CV attains the input and extracts the necessary information; therefore, CV makes the matching process faster. Four movements are measured on the specified time period [17]. The CV acts as the faster and accurate technique in the medical field, the quicker processing is necessary to avoid emergencies. The monitoring is applied accurately for a fixed period and compares the input with the predefined knowledge and processes the output efficiently [18].
The scope of this paper is reducing the misdetection of facial expression and reducing the analysis time. It is achieved by introducing three layers CNN as texture classification, correlation, and facial visualization. The input face is captured and processed through HMI and if an abnormal expression is sensed, a monitoring alert is sent to the physician for further diagnosis.
