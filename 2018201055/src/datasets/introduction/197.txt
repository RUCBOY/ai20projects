Identifying aerial image categories is an important task in computer vision, especially in automatic navigation, disaster prediction, and smart cities. Recognizing aerial image from different semantic categories is necessary both in academic and industrial domain. In the literature, many aerial image understanding algorithms have been proposed and some methods are even commercialized. Nevertheless, it is a challenging task for successfully handing the task of categorizing aerial images due to the huge number of tiny components inside each aerial image, the sophisticated spatial configurations, and the possibly visual distortions during visual data acquisition. In the literature, many well-known aerial image sets have been released. Popular aerial image datasets like the NWPU VHR-10 [1], DOTA [2] contain 10 to 15 categories. Comparatively, other datasets, e.g., UCAS-AOD [3], RSOD [4] is consist of 2 to 4 categories. Generally speaking, there are a rich set of components scattered in different aerial images, e.g., roads, buildings, playgrounds, and lawns. Apparently, it is a remarkable contribution for aerial image categorization if the key components within each aerial image can be optimally identified. Take Fig. 1 as an example, the visual appearance of airport and parking are highly similar. Nevertheless, the internal components are apparently unique. The main objects within an airport is airplane while the key objects of parking lot are vehicles.
Currently, aerial image data acquisition has become more convenient due to the pervasively adopted uncrewed aerial automobiles (UAV) equipment. However, the huge number of data sources cannot be processed rapidly due to the large-scale visual data to be processed. Besides, there are different visual distortions, such as visual blur and noise during data acquisition. In this way, aerial image categorization is an essential technique in modern intelligent systems. Many researchers proposed algorithms to model the large-scale aerial image set mathematically. Conventional approaches only focused on the global and local features cannot successfully distinguish aerial images from different categories, since the key components inside each aerial image are neglected. Moreover, different from the other image classification datasets such as the ImageNet [5], Clatech256 [6], and Cifar10 [7], the objects within each aerial image are always small, which is difficult for visual recognition using the deep learning architectures. That is to say, contour-based visual recognition models cannot achieve satisfactory performance.Download : Download high-res image (625KB)Download : Download full-size imageFig. 1. Local features of airport and parking lot are visually similar while their key components (airplane and vehicles) are significantly different.
In recent years, deep learning-based visual recognition models have shown impressive aerial image categorization, where deep neural networks with various architectures have been designed. The well-known ResNet [7] has reduced the top-5 error rate to 3.46%. Nevertheless, as far as we know, there lacks an effective deep model for aerial image categories clustering. Besides, the existing deep learning algorithms have some limitations that are summarized as follows:
(1) Spatial configurations can reflect the inherent attributes of the particular types of aerial images. Such an attribute is very informative to represent the visual information within each aerial image. For example, aerial images’ star structures from the “intersection” category are unique and represent its structure. Besides, noteworthy is the linear structure of aerial images from the “parking lot” category. These topological structures are highly discriminative for characterizing the discriminative spatial features inside each aerial image. However, these topologies are with arbitrary structures and are thus difficult to be encoded by an existing machine learning tool;
(2) Compared to the traditional single spectral image analysis of each generic image, multispectral signals typically encode aerial images. Thus, it is necessary to make full use of these multispectral features. Many multi-view learning algorithms have been proposed to fuse the multispectral features from multiple channels. The weights of different spectral channels are pre-specified by a system designer. This scheme is easy to implement. However, when the number of spectral channels is large, it is difficult to manually determine the weights of different spectral channels. Ideally, we want to propose a novel feature fusion scheme. Herein, the weights reflecting the importance of different feature channels are tuned intelligently. However, how to design such an effective feature weights tuning mechanism is yet unsolved.
(3) There are typically million-scale aerial images distributed on the Internet, due to the rapid development of network transmission technologies. However, it is difficult to cluster these massive-scale aerial images into multiple clusters. Ideally, we want to construct a large-scale graph to characterize the relationships among different clusters. But building such a very large graph might be highly time-consuming. And even worse, how to efficiently cluster on such a massive-scale graph remains a tough challenge. Besides, there exist some particular aerial images that do not belong to any category. Thus, we need the clustering algorithm to support outliers. Traditional local feature-based deep models cannot effectively select a representative and discriminative visual features. In this way, the performance of aerial image clustering might be unsatisfactory.
A novel clustering-based aerial image categorization algorithm via multi-view feature fusing the multispectral aerial images is proposed to eliminate or at least reduce these shortcomings. An overview of our designed categorization architecture is shown in Fig. 1. More specifically, we first semantically segment each aerial image into a rich set of fine-grained and semantically-meaningful sub-regions, wherein each sub-region is characterized by visual features from multiple spectrums. Afterward, we construct the so-called graphlets to represent the topological characteristics within each aerial image. A graphlet edge links pairwise, spatially neighboring sub-regions. Subsequently, for each graphlet, we extract its multispectral feature descriptions. A novel multi-view learning framework is proposed to fuse the multispectral features into a representative one dynamically. Then, a massive-scale affinity graph is constructed to characterize the binary relationships between pairwise aerial images. After that, a graph-based clustering algorithm is leveraged to classify the aerial images into multiple types with modest time consumption. Comprehensive experimental results on a million-scale aerial image set have shown the usefulness of our approach. Meanwhile, some visualization results can fully support a multispectral description of graphlets, optimally discriminating aerial images from different categories.
The innovations proposed in this study can be reduced to three aspects: (1) a new multi-view feature fusion to represent graphlets, wherein both the inherent distribution of features and the weights of different feature channels can be optimally calculated; (2) a set of subgraphs to represent the multiple important local features within each aerial image; and (3) a graph-based clustering algorithm that can efficiently categorize the massive-scale aerial images into multiple types, wherein million-scale aerial images can be categorized within minutes.
