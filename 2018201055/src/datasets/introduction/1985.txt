Minimally invasive surgery has become increasingly common over the past years (Siddaiah-Subramanya et al., 2017). However, issues such as limited view, a lack of depth information, haptic feedback and increased difficulty in handling instruments have increased the complexity for the surgeons. Surgical data science applications (Maier-Hein et al., 2017) could help the surgeon to overcome those limitations and to increase patient safety. These applications, e.g. surgical skill assessment (Law, Ghani, Deng, 2017, Lin, Qin, Bly, Moe, Hannaford, 2019), augmented reality (Wang, Zhang, Meng, Geng, Wang, 2017, Burström, Nachabe, Persson, Edström, Terander, 2019), assistance robots (Amini Khoiy, Mirbagheri, Farahmand, 2016, Zhang, Gao, 2020), vision-based force estimation (Su et al., 2018) or depth enhancement (De Paolis and De Luca, 2019), are often based on the segmentation and/or tracking of medical instruments during surgery. Currently, commercial tracking systems usually rely on optical or electromagnetic markers and, therefore, also require additional hardware (Bianchi, Masaracchia, Shojaei Barjuei, Menciassi, Arezzo, Koulaouzidis, Stoyanov, Dario, Ciuti, 2019, Zhou, Rueckert, Fichtinger, 2019), which are expensive, need extra space and require technical knowledge. Alternatively, with the recent success of deep learning methods in the medical domain (Esteva et al., 2019) and first surgical data science applications (Fawaz, Forestier, Weber, Idoumghar, Muller, 2019, Nguyen, Ljuhar, Pacilli, Nataraja, Chauhan, 2019), video-only based approaches offer new opportunities to handle difficult image scenarios such as bleeding, light over-/underexposure, smoke and reflections (Bodenstedt et al., 2018). Video-only based approaches offer new opportunities to handle difficult image scenarios such as bleeding, light over-/underexposure, smoke and reflections (Laina, Rieke, Rupprecht, Vizcaíno, Eslami, Tombari, Navab, 2017, García-Peraza-Herrera, Li, Gruijthuijsen, Devreker, Attilakos, Deprest, Vander Poorten, Stoyanov, Vercauteren, Ourselin, 2016, Zhao, Chen, Voros, Cheng, 2019). In turn, the tracking information may directly affect the instructions provided to the surgeon to navigate the surgical instruments. Furthermore, unreliable algorithms potentially reduce the acceptance on the part of the surgical team, and thus, the chances for translation into the clinical routine (Panch, Mattie, Celi, 2019, Qayyum, Qadir, Bilal, Al-Fuqaha, 2020).
As validation and evaluation of image processing methods is usually performed on the researchers’ individual data sets, finding the best algorithm suited for a specific use case is a difficult task. Consequently, reported publication results are often difficult to compare (Ioannidis, 2005, Armstrong, Moffat, Webber, Zobel, 2009). In order to overcome this issue, we can implement challenges to find algorithms that work best on specific problems. These international benchmarking competitions aim to assess the performance of several algorithms on the same data set, which enables a fair comparison to be drawn across multiple methods (Maier-Hein, Eisenmann, Reinke, Onogur, Stankovic, Scholz, Arbel, Bogunovic, Bradley, Carass, et al., 2018, Maier-Hein, Reinke, Kozubek, Martel, Arbel, Eisenmann, Hanbuary, Jannin, Müller, Onogur, et al., 2019).
One international challenge which takes place on a regular basis is the Endoscopic Vision (EndoVis) Challenge2. It hosts sub-challenges with a broad variety of tasks in the field of endoscopic image processing and and has been held annually at the International Conference on Medical Image Computing and Computer Assisted Interventions (MICCAI) since 2015 (exception: 2016). However, data sets provided for instrument detection/tracking/segmentation in previous EndoVis editions comprised a relatively small number of cases (between ∼500 to ∼4,000) and generally represented best cases scenarios (e.g. with clean views, limited distortions in videos) which did not comprehensively reflect the challenges in real-world clinical applications. Although these competitions enabled primary insights and comparison of the methods, the information gained on robustness and generalization capabilities of methods were limited.
To remedy these issues, we present the Robust Medical Instrument Segmentation (ROBUST-MIS) challenge 2019, which was part of the 4th edition of EndoVis at MICCAI 2019. We introduced a large data set comprising more than 10,000 image frames for instrument segmentation and detection, extracted from daily routine surgeries. The data set contained images which included all types of difficulties and was annotated by medical experts according to a pre-defined labeling protocol and subjected to a quality control process. The challenge addressed methods with a projected application in minimally invasive surgeries, in particular the tracking of medical instruments in the abdomen, with a special focus on the generalizibility and robustness. This was achieved by introducing three stages with increase in difficulty in the test phase. To emphasize the robustness of methods, we used a ranking scheme that specifically measures the worst-case performance of algorithms.
Section 2 outlines the challenge design as a whole, including the data set. The results of the challenge are presented in section 3 with a discussion following in section 4. The appendix includes challenge design choices regarding the organization (see Appendix A), the labeling and submission instructions (see Appendix B and Appendix C), the rankings across all stages (see Appendix D) and the complete challenge design document (see Appendix F).
