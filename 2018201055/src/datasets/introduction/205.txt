Human action recognition is fundamental in a variety of computer vision applications such as video surveillance [1], human–computer interaction [2], and robotics [3]. With the great success of deep learning, recent human action recognition methods usually focus on learning deep spatial-temporal representations from video clips [4], [5], [6]. Recently, human skeleton, which is obtained by either a hardware method (e.g., Kinect [7]) or a software method (e.g., human pose estimation [8]), has attracted more and more attention in human action recognition task, especially due to the rapid development of human pose estimation algorithms [9], [8]. Though human skeleton is concise representation and is robust to complex image backgrounds, it remains a challenge in learning effective spatial-temporal representations from skeleton sequences [10], [11].
Human skeleton has been widely used in action recognition tasks, in which the coordinates of human body joints are usually organized in either joint sequences, a pseudo-image, or a skeleton graph. A variety of deep neural network architectures then have been used to learn effective deep spatial-temporal representations from different input modalities, e.g., recurrent neural networks (RNNs) for joint sequences [12], [13], convolutional neural networks (CNNs) for pseudo-images [14], [15], and graph neural networks (GNNs) for skeleton graphs [11], [16]. Notice that the skeleton data can be easily combined with heatmap [15], [17] together to improve the human action representations. In this paper, we focus on human skeleton in a pseudo-image as the input to make full use of CNNs for human action recognition. However, previous CNN-based methods usually fail to explore the movement of body parts, i.e., skeleton edge motion, by using only the coordinates of human body joints [14], [11], [16].
Human body part movement is of great importance for human action recognition using skeleton sequences, while it is non-trivial to learn skeleton edge representations directly from the coordinates of human body joints using deep neural networks. Inspired by this, we introduce a new skeleton modality, skeleton edge motion, which benefits learning effective representations by exploring the movement of body parts. An intuitive example is shown in Fig. 1, in which the proposed skeleton edge motion modality contains both the rotation angle Δθ of the body part and the moving distance Δl of its corresponding body joints. We then concatenate the new skeleton edge motion modality with the original joint coordinates in channel dimension of the pseudo-image. As shown in Fig. 2(b), the proposed skeleton edge motion modality can be easily extended to other CNN-based methods. Furthermore, considering the structure of the pseudo-image, i.e., each row of the pseudo-image contains all joints in the same video frame (spatial information) and each column of the pseudo-image contains a specific body joint across all video frames (temporal information), we develop a new spatial-temporal block to learn effective spatial-temporal representations from skeleton pseudo-images. Specifically, the proposed spatial-temporal block has two branches: 1) a spatial branch with 1×k convolutional filters; and 2) a temporal branch with k×1 convolutional filters. We then devise the proposed skeleton edge motion networks by stacking multiple spatial-temporal blocks, as shown in Fig. 2(c). See more details about the spatial-temporal block in Section 3.2.Download : Download high-res image (180KB)Download : Download full-size imageFig. 1. An illustration of skeleton edge motion for human action recognition. Here skeleton edges are pre-defined connections between body joints, which indicate different human body parts, e.g., e4,5 is the forearm and e3,4 is the upper arm. We use guitar playing as an example to demonstrate the importance of skeleton edge motion information in human action recognition. Previous methods usually use joint locations, i.e., (x,y) for 2D skeleton or (x,y,z) for 3D skeleton, while the most obvious sub-action for playing guitar is the movement of human forearm. That is, the movement of skeleton edge provides richer information than body joints for recognizing the action of playing guitar. Specifically, the motion of human body part is captured by both the rotation angle of skeleton edge and the movement of body joints, i.e., Δθ and Δl, respectively.Download : Download high-res image (460KB)Download : Download full-size imageFig. 2. The main framework contains two streams, i.e., heatmap stream [15] and skeleton stream. The proposed skeleton edge motion networks (SEMN) focus on the skeleton stream. The predictions of both streams are lately fused by averaging the classification scores. (a) Skeleton joint sequences are first derived from the video using human pose estimation algorithms, i.e., OpenPose [8]. (b) Skeleton sequences are then arranged in a pseudo-image by concatenating the original joint locations and the proposed edge motion modality. (c) Skeleton edge motion networks are proposed by stacking multiple spatial-temporal blocks to learn effective representations from the skeleton data. (d) Apart from the classification loss, a new progressive ranking loss is proposed in a self-supervised manner to encourage the network to explore temporal order information.
Temporal order information is crucial for reasoning relationships within complex actions and several reasoning structures have been developed for human action recognition [18], [19], [20], [21]. An intuitive example for temporal order information can be derived from a pair of actions such as “standing up” and “sitting down”, in which the most discriminative cue between two actions is the order of different video frames. An interesting observation is that both the deep action recognition model as well as ourselves will misclassify such a pair of actions if we flip all video frames across the temporal dimension, and this problem is also known as “the arrow of time in videos” [18]. Inspired by this, we address the temporal order information to further boost the performance of the proposed skeleton edge motion networks (SEMN) for human action recognition. Unlike previous works for novel reasoning structures, we propose a self-supervised progressive ranking loss to address temporal order information in the proposed skeleton edge motion networks. Specifically, the proposed loss function encourages the model to progressively make more confident predictions following the arrow of time in videos, e.g., given a set of video frames v1,v2,…,vt,vt+1,pt is the prediction at the time step t, and we hope that the model can make more confident predictions at the time step t+1, i.e., pt⪯pt+1. See more details about the proposed progressive ranking loss in Section 3.3.
The remainder of this paper is organized as follows. Section 2 gives a review of related work. Section 3 presents our skeleton edge motion networks. Section 4 demonstrates the experimental results. Section 5 concludes this paper. Our main contributions in this paper can be summarized as follows: 1) we introduce a new skeleton input modality, skeleton edge motion, for human action recognition; 2) we develop the skeleton edge motion networks (SEMN) by stacking multiple spatial-temporal blocks to learn effective deep spatial-temporal representations; and 3) we address temporal order information for human action recognition by further proposing a progressive ranking loss in a self-supervised manner. We evaluate the proposed skeleton edge motion networks on five popular human action recognition datasets, PennAction [22], UTD-MHAD [23], NTU RGB+D [24], NTU RGB+D 120 [25], and CSL [26], and experimental results demonstrate the effectiveness of the proposed method.
