Given that 70% of the Earth is covered by oceans, mapping of the ocean floor is fundamental to geophysical understanding of the Earth. Quantitative measurements and maps of seafloor depth – bathymetry – and related topographic metrics is far more difficult than mapping terrestrial surfaces due to the need to use sonar instead of electro-optical techniques. Publicly available bathymetric data is sparse, however, as sonar data is slow and expensive to collect. Over 82% of Earth's ocean floor in ice-free regions remains unmapped by sonar systems (Sandwell et al., 2014; Weatherall et al., 2015) in publicly available data. As a result, we know more about the topography of Mercury, Venus, Mars, larger moons of Jupiter and Saturn – and now Pluto and Charon – than we do about Earth's surface covered by water.
What mappings that we have for the remainder of Earth's deep-water (more than 1 km depth) bathymetry in ice-free regions are only predictions of bathymetry. The conventional prediction methodology uses Newtonian gravity potential theory and decades old Fourier transforms to invert measured geoid height to predicted seafloor topography (Parker, 1972; Smith and Sandwell, 1994, 1997; Hu et al., 2015). This is an ill-posed problem. Soundings (sonar measured bathymetry) that exist within inversion areas constrains possible solutions. The current maps of world bathymetry from the General Bathymetric Charts of the Oceans (GEBCO) incorporates this satellite-altimetry predicted gridded bathymetry (Weatherall et al., 2015) at 1-minute resolution, representing low-resolution (LR) knowledge of the global ocean floor.
This practice, however, has physics-based limitations on the resolvable resolution and accuracy of potentially solutions. Despite the 1-miniute GEBCO mapping, the altimetry-based portions of the grid is generally limited to 20-km resolution (Marks and Smith, 2012) (potentially 10-km with newer satellites and repeated orbits (Marks and Smith, 2016)) compared to 100-m resolution of deep-water sonar-based mapping systems. Currently, no other deep-water techniques provide 100m-resolution of seafloor bathymetry. Continued reliance on these techniques is due, in part, to the desire to obtain analytic/computation solutions based on first-principles that preserve intuition of the underlying physics and the ability to adjust approximations in the modeled conditions.
Enhancement of knowledge beyond the limitations of these methods, however, is critical to both military and civilian interests. For example, bathymetry for the area where Malaysian Airlines Flight 370 may have disappeared (Smith and Marks, 2014; Picard et al., 2017) showed nearly complete lack of sonar data at the time of the disappearance. Only the low-resolution satellite-based information existed. Furthermore, it is known that the majority of civilian air flights occur over oceanic waters that similarly are unmapped by sonar. While the Indian and Southern Oceans are now being newly surveyed as a result of the ML370 disappearance, this tragedy exemplifies how inadequate deep-water bathymetry can hinder maritime emergency, search, and recovery operations.
Thus, we turn to examining developments of new computational techniques, particularly from machine learning, that could enhance our predictions of bathymetry in these unsurveyed regions of Earth. The challenge is to maximize knowledge obtainable from LR information and available high-resolution. Super-resolution imaging (SR) is a class of techniques that enhance resolution of images by producing higher-resolution (HR) images based on given low-resolution (LR) images (Milanfar 2010). The underlying concept in SR is to use the non-redundant information in low-resolution images to produce enhanced high-resolution images. Another approach is known as single- image super-resolution (SISR) based on the concept that images usually contain redundant, repetitive content. In particular, small image patches in natural images tend to recur redundantly many times inside images, both within the same scale, and across different scales. In SISR algorithms these patches are used to enhance image resolution for natural images. These upscaling are non-unique, however, yet are satisficing for the application.
In this paper we show how to adapt single-image super-resolution techniques developed in the image-processing domain to processing deepwater (>1-km) seafloor topography. We were interested in determining whether available HR information can be leveraged to enhance LR knowledge of the seafloor. We hypothesized that SISR computer vision algorithms can enhance LR knowledge of bathymetry through upscaling. Motivating this research was success with SISR for image processing producing high-resolution details in natural images. Additionally SISR was used to enhance morphology details of galaxy images (Ball and Brunner, 2010; Schawinski et al., 2017) which have similarity to seafloor features upon treating gridded bathymetry as a gray-scale image. Additionally SISR can enable quantitative extrapolation of HR information from MBES surveys into neighboring areas covered only by predicted bathymetry. These algorithms can be trained to associate HR information onto lower-resolution versions of the surface.
Enhancement is assessed by root-mean squared error of upscaled LR bathymetry being significantly lower using SISR versus linear-invariant interpolation methods which do not leverage HR information for upscaling processes as quantified by hypothesis testing. To test this hypothesis, we performed numerical experiments of upscaling three areas of the Eastern Pacific Ocean along mid-ocean ridge systems. These areas have HR grids obtained by sonar surveys that serve for training SISR algorithms and ground-truth of upscaled LR grids for both SISR and linear-invariant interpolation methods. We tested SISR skill against our benchmark skill level of interpolation in both localized and external upscaling experiments (external upscaling here means training SISR techniques in one area to upscale other separate and distant areas). We found that four of the SISR algorithms have higher skill than interpolation under the conditions that we will discuss in this paper. It should be stressed here that the enhancement is in accuracy only, not enhancement of resolution. Being an ill-posed problem, any higher resolution fabric of the ocean floor is merely a prediction.
Section 2 of the paper provides background on previous work in topographic metrics and computer vision for digital bathymetry models and specific SISR approaches. Section 3 describes data used for experimentation and implementation details for SISR techniques. Section 4 reports on experiments that applied SISR to the bathymetry data described and discusses experimental observations including our discovery of significantly more accurate bathymetry using SISR versus bicubic interpolation. Section 5 discusses the experimental results, including conditions in which we expect SISR to be able to enhance LR bathymetry knowledge. Section 6 provides a summary and our conclusions.
