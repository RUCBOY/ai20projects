The laboratory experiment presented in this paper studies whether humans prefer to depend on states generated by a computer (Computerized Uncertainty) or other humans’ decisions (Human-Driven Uncertainty). In our lottery choice experiment, subjects can choose the exact type of uncertainty on which they depend. Different from previous experiments studying these types of uncertainty, the Human-Driven Uncertainty in our experiment does not derive from choices of others taken in a game or any other kind of strategic context, and the decisions that other humans took were not morally loaded (contrary to e.g., choosing the strategy in a Trust Game). This operationalization of Human-Driven Uncertainty allows us a clean comparison of preferences with regard to Human-Driven versus Computerized Uncertainty.
Of course, rational, expected value maximizing agents should not care about the source of uncertainty. Humans however, being far from perfectly rational, may (e)valuate both types of situations very differently in terms of subjective probabilities and emotions involved. As evidence of this, Abdellaoui, Baillon, Placido, and Wakker (2011) find that subjects prefer to depend on lotteries where the uncertainty of winning is determined by the weather (also referred to as Natural Uncertainty), compared to a stock market and McCabe, Rigdon, and Smith (2003) find that humans also care about the intentions on which a decision was based.
A clean comparison between Computerized and Human-Driven Uncertainty is hard to achieve in the laboratory. Human-Driven Uncertainty arises naturally in what is referred to as strategic interaction by economists, defined as two or more human decision makers depending on each others choices (Van Huyck, Battalio, & Beil, 1991). This is why (to the best of our knowledge) in all experiments studying Human-Driven Uncertainty, the uncertainty derives from someone’s action in a game-like setting. Section 2.1 reviews these experiments and Section 2.2 discusses potential neural and psychological mechanisms leading to different behavior under both kinds of uncertainty.
Carrubba, Yuen, and Zorn (2007) argue that strategic interaction1 – to some extent – can be seen as a lottery, where one depends on the actions of others without knowing which action others will take. Strategic uncertainty, however, differs in more than one aspect from non-human based uncertainty. While non-human sources of uncertainty involve only oneself depending on a mechanism without intentions, strategic uncertainty includes interdependence between humans, and as a consequence a decision maker forms beliefs about others intentions. Furthermore, the options that one can choose from create (often morally loaded) externalities on others, which may lead to social preferences over outcomes. Dana, Weber, and Kuang (2007) show that when subjects have to take decisions in a morally loaded context they actually prefer uncertainty on how their decision affects others. Summarized, one is not making a ceteris paribus comparison when comparing non-human sources of uncertainty and strategic uncertainty. To overcome this flaw, we designed an experiment in which the only difference between a the different types of uncertainty is the source of uncertainty. The Human-Driven Uncertainty involved in treatments of the experiment will therefore not derive from strategic interaction.
We encounter Human-Driven Uncertainty that does not arise from strategic interaction regularly. Examples are situations where we depend on decisions that others took without knowing the consequences. Often, we even depend on actions of others that are not the result of any conscious decision at all. As an example, an employee opening an email attachment that contains a computer virus may be absolutely unaware of causing harm to the employer. For the employer, the source of uncertainty is not the product of a strategic decision of the employee, although the source of uncertainty is the employee’s behavior.
In addition to the differentiation between Computerized and Human-Driven Uncertainty we also control the measurability of uncertainty (Knight, 1921). “Measurable” uncertainty (henceforth: risk) is characterized by a situation in which the probabilities with which all possible events occur are known. “Unmeasurable” uncertainty (henceforth: ambiguity2) is characterized by the absence of known probabilities. In his seminal thought experiment, Ellsberg (1961) argues that humans generally avoid ambiguous lotteries in favor of lotteries were the distribution is known. Many experiments have since found that humans usually are ambiguity averse (Camerer & Weber, 1992).
Table 1 shows the 4 possible combinations of the two dimensions along which uncertainty will be distinguished in this paper. The treatments in the experiment (presented in Section 3) correspond to the cells in the table.Table 1. Uncertainty concepts implemented.Distribution knownDistribution unknownHumanHuman-Driven Risk (HR)Human-Driven Ambiguity (HA)ComputerComputerized Risk (CR)Computerized Ambiguity (CA)
The research questions of this paper are:
1.Do humans prefer lotteries with Human-Driven Uncertainty to Computerized Uncertainty or vice versa?2.Do humans have different risk preferences in lotteries where they depend on humans instead of computers?3.Do we see ambiguity preferences under Human-Driven Uncertainty?
