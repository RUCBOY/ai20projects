In the last decades the use of computers in psychological assessment has grown enormously. In the domain of cognitive abilities, computer-based assessments have increasingly substituted paper-pencil tests and are now core elements in performance research and applied contexts such as personnel selection, admission decisions in educational contexts, or neuropsychological assessments. In these applications computer-based tests allow the assessment of cognitive abilities with high levels of standardization and offer the possibility to realize designs that could not be appropriately implemented with paper-pencil tests (Greiff et al., 2017, Tippins, 2015).
However, particularly in high-stakes settings, there are still challenges with cognitive ability tests. One is the requirement of test fairness in the sense of ensuring that all test takers have comparable opportunities to demonstrate the abilities measured by the test. With cognitive ability tests, it is of particular importance to provide examinees with equal opportunities to prepare for the test (American Educational Research Association, American Psychological Association National Council on Measurement in Education, 1999). In the interest of fairness, the materials provided should closely resemble the actual test with regards to appearance and format (American Educational Research Association, American Psychological Association National Council on Measurement in Education, 2014). Yet, the requirement of equal opportunities for test preparation is increasingly challenged by a growing market of service companies offering commercially distributed training software. Although the quality of such software may vary substantially between providers, there is evidence that training1 may result in substantial score gains in cognitive ability tests, not only in educational but also in selection settings (Chung-Herrera et al., 2008, Hausknecht et al., 2007). It can be expected that only individuals with sufficient financial resources will be able to afford such training programs, calling into question the fairness of ability assessments (Sackett et al., 1989, Stemig et al., 2015). Such training gains can be partly attributed to retest effects, i.e. score gains resulting from the mere repetition of a test (Freund and Holling, 2011, Hausknecht et al., 2007). This implies that not only individuals with training course experience but also individuals who had the opportunity to repeat an examination may have an advantage over individuals who conduct an ability test for the first time. Taken together, commercially available training and the retest policies of institutions give rise to considerable concern about the fairness of these ability assessments. To deal with this problem, several authors suggested to freely offer training and practice materials to all participants (Arendasy et al., 2016, Freund and Holling, 2011, Sackett et al., 2008, Zwick, 2002). For example, Arendasy et al. (2016) proposed that “making more informal student-centered practice opportunities accessible to all test takers could resolve issues of fairness associated with differential access to test preparation opportunities without compromising measurement fairness” (p. 54).
Today most organizations involved in high-stakes computer-based testing actually provide opportunities for test familiarization by distributing free practice items or tutorials as recommended by the International Test Commission (The International Test Commission, 2006). The range of complexity of practice materials currently offered by test-administering institutions is, however, mostly restricted to downloadable information brochures and example items in paper and pencil format. There is some slightly more sophisticated online material available. It must be expected though, that in case of cognitive ability tests, the practice gains increase as a function of the equivalence of the practice items with test items (Hausknecht et al., 2007). Therefore, to ensure test fairness, it is crucial to offer practice items that resemble the test items as closely as possible. Recently, more efforts have been made to increase fairness. In the United States for example, the College Board cooperated with the Khan Academy to offer freely available test practice programs for the SAT (formerly Scholastic Aptitude Test), a common test for college admissions. Overall, however, still only little consideration is given to the unequal opportunities to practice and training activities, for example by making effective preparation material freely available to all test takers and informing them openly about available training options.
One reason for this deficiency may be that in the context of personnel selection there is virtually no published research on the effects and consequences of using sophisticated computer-based training tools, especially on the validity of the tests. This is surprising given the great potential of computer-based training tools in this field. With computer-based systems it is possible to offer training tools with high equivalence to selection tests. Such systems allow a very standardized presentation of training items (including timing and navigation issues), complex interfaces and item-selection algorithms, a wide range of multimedia features, reliable response recording, or feedback mechanisms. Finally, computer-based training systems can be economically distributed, making them especially attractive for larger user pools.
