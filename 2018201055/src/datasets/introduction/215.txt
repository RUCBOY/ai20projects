Images captured in rainy day contain rain streaks, hiding the color and texture of objects behind. Such unexpected corruption has a negative effect on the visual quality and may degrade the performance of various computer vision algorithms. Thus, deraining has become an important task. The early works mainly focused on video-based rain removal [1], [2]. Compared to video-based methods, single-image-based task is significantly more difficult due to lack of temporal information.
In recent years, many tradition methods [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15] and deep learning based methods [16], [17], [18], [19] have been proposed to improve the performance of single-image based deraining. The tradition methods share a same basic idea that views rain removal as an image decomposition problem, with a rain streak layer superimposed on a background layer. Theoretically, it is hard to precisely recover the background layer from rainy image since it is a highly under-constrained problem. To make the problem well-posed, different techniques are utilized to add additional constraints, including sparse representation, dictionary learning [3], [4], appearance model [5], [6], [9], [12], [13]. They achieved varying levels of success. The learning-based methods sparsely approximate the two layers with a set of ‘rain components’ and ‘non-rain components’. Such methods are time-consuming due to online-learning or high optimization complexity. Instead of online learning, off-line learning is used in our method to reduce the computation time. The existing rain appearance models [5], [6], [9], [12], [13] are insufficient to describe various shapes and directions of streaks. Recently, deraining performance is highly improved with the development of deep networks, where natural image priors are explored and utilized. However, the priors are learned from synthesized rainy images, and the same priors are applied to all kinds of rainy images, namely there is no prior from rainy image itself being used. If a rainy image does not satisfy the assumed general priors, it will result in annoying artifacts. This raises a natural question: can we use the constraints produced by combining information captured from natural images and rainy image itself.
Based on the above discussion, we propose a novel two-stage rain removal algorithm, where both the external and internal information are adopted to produce powerful constraints for the under-constrained decomposition problem. The proposed algorithm is capable of removing rain streaks fast and effectively, and performs well in terms of texture details preservation. In stage I, we aim to estimate a texture constraint for the non-rain part. To this end, several images containing the coarse-scale, non-rain texture components are extracted by Gabor filters, by then, they are fused with a new proposed fusion method based on independent components analysis (ICA) [20] bases, which are learned from natural images, providing external non-rain texture information. The filtered images are extracted by considering the direction and frequency of rain, providing the internal texture information. In stage II, the texture constraint generated for background together with the low-rank constraint for rain streaks is incorporated together. The final result can preserve many image details due to the use of the texture constraint.
The rest of this paper is organized as follows. We first briefly review single image deraining methods in Section II. Section III presents our proposed algorithm including texture constraint estimate and a proposed decomposition model. Section IV discusses the experimental results. Section VI concludes the paper.
