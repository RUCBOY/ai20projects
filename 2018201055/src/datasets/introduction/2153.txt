Gastrointestinal (GI) diseases are becoming more and more common [1]. Each year in the United States 130,000 patients are diagnosed with colon cancer, making it the second most common form of cancer in the country. Recent studies show that the modern way of life, especially in the developed countries, has increased the number of cases with GI lesions. In this paper we aim to provide a computer-aided approach for abnormality detection addressing variety of diseases, such as polyps, vascular bleeding and inflammatory conditions.
The GI tract can be broken down into four sections, namely the esophagus, the stomach, the small intestine and the colon. A typical examination method of the GI tract is Flexible Endoscopy (FE) [2] and its variations [[3], [4], [5]]. Wireless Capsule Endoscopy (WCE) [6] is becoming increasingly popular as a method of capturing images from the entire GI tract due to its non-invasiveness. This method uses a swallowable camera to capture low-resolution images throughout the entire GI tract which are afterwards examined by a clinician. A lot of manual human effort is required, which is typically interpreted into 45–90 minutes work, demanding undisrupted concentration. Thus, the review of an entire WCE video is prone to human errors, since the video reviewers can become tired over the time. This raises the need for a computer-aided diagnosis methodology that could increase the overall diagnostic accuracy, and reduce the required examination time.
Computer-aided abnormality detection in endoscopic images of the GI tract has been an active research subject over the last 15 years [[7], [8], [9]]. Abnormality detection refers to the ability of discriminating abnormal tissues from normal image contents. Normal image contents include non-pathologic tissues and intestinal content, such as debris and bubbles. First approaches were aiming to the detection of abnormalities in FE [7,8]. In that context, abnormality detection systems contribute in the early detection of life-threatening conditions such as cancer. Their use can contribute in speeding up the FE procedures, which are generally uncomfortable for the patients. An added benefit is that cost reduction can be achieved by the use of such systems, as they could enable less experienced personnel to perform the examination.
The abnormality detection methodologies that have been proposed in the context of GI FE [8] and WCE [9] can be grouped into two main categories, according to the type of features used to describe the images. The methodologies of the first category are based on hand-crafted features for the representation of image properties, including color, texture and shape [[8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19],59]. However, such features are usually selected based on considerations about the modality used to acquire the images or about the abnormalities to be detected. In the second category, which comprises more recent methodologies, the feature extraction process is automatic. This is usually implemented through adaptation on the annotated dataset used for training of the overall system. State-of-the-art approaches of this kind are based on Convolutional Neural Networks (CNNs) [[20], [21], [22], [23], [24]]. CNNs are Artificial Neural Networks (ANNs) [25,26] that consist of multiple convolutional layers, with a neuron arrangement that resembles the biological visual cortex, forming deep feed-forward architectures.
Recently, supervised methodologies based on weakly annotated images have shown promising results for the classification of endoscopy images. The so-called weak labels are essentially keywords, only semantically describing image content. Therefore, weak labeling constitutes a time-efficient approach to obtain image annotations from the experts [27,28]. In this context we proposed a MIL-based approach following the Bag of visual Words (BoW) model, for classification of GI endoscopy images [19]. More recently, we proposed a methodology for weakly supervised detection and localization of abnormalities in GI endoscopy images [29]. This includes Weakly supervised CNN-based (WCNN) classification of the endoscopic images, followed by the detection of salient points, which were subsequently filtered by a clustering process to enable within-frame localization of the abnormalities. Specifically for bleeding detection and segmentation, a two stage approach has been proposed by Jia and Meng [30]. Initially the images obtained from WCE, are classified as active or in-active subgroups based on handcrafted statistically derived color probability features. Then the segmentation is done using a deep FCN architecture [31], i.e., an architecture composed of only convolutional layers.
Other CNN architectures for classification of weakly labeled images, proposed in the context of GI endoscopy, include a CNN that receives RGB images along with their Hessian and Laplacian transformations as input [32]; a cascaded CNN architecture for the recognition of the different organs of the GI tract and normal intestinal content [33]; and, a CNN architecture for blood detection, using an SVM instead of the fully-connected layer of the conventional CNNs [34]. A recent, generic CNN-based approach to abnormality detection in GI endoscopy has been proposed in [35]. It utilizes a pre-trained CNN architecture, and more specifically the CaffeNet [36], as a feature extractor. The features are extracted from the intermediate layers of the network. The extracted feature-maps are then used to train an SVM classifier. A remarkable aspect of that approach is that it was trained solely on ImageNet [37], which is a large dataset of natural images that does not include any endoscopic or other relevant images.
Recent CNN architectures that, to the best of our knowledge, have not been yet applied in the context of abnormality detection in endoscopy, include ResNet [38], ResNeXt [39] and Inception-v4 [40]. All three of them are state-of-the-art networks tested for natural image classification. The key contribution of ResNet is the introduction of residual learning by utilization of residual blocks (convolutional layers with a shortcut connection). ResNeXt follows the same principle of residual learning, yet instead of an increase in the depth of the network, introduces the concept of cardinality which defines the number of paths in a ResNeXt block. Through multiple experiments, cardinality meta-parameter proved to be more effective in enhancing the classification performance, than going deeper or wider in a network. Furthermore bottleneck residual blocks are used to reduce the number of feature maps of the network. By lowering the width of each convolution layer and increasing the cardinality number, ResNeXt achieves higher classification performance than ResNet while maintains similar number of free parameters. Inception-v4 provides a uniform design for three inception modules and a new stem block, which defines the initial set of operations performed before the Inception modules. Furthermore Inception-v4, introduced the “Reduction Blocks” which are used to adjust the width and height of the input and output volume of the Inception modules. Although this network outperformed ResNet and ResNext architectures in natural image classification, it has a larger number of free parameters.
While the usage of CNNs, including FCNs, has provided superior results compared to other conventional approaches, they generally require large training datasets. A drawback of current CNN approaches is that the use of smaller training datasets limits their generalization capacity. This derives from the fact that, as the number of the free parameters of the network increases, the need for more training examples also increases, in order to avoid overfitting [41]. However, the availability of such large training datasets in the medical domain is usually limited; thus, CNN training can become challenging. The challenge is to develop an architecture that generalizes well, even with smaller datasets. Furthermore, the increase of free parameters, increases the needs for computational resources, with a consequent deterioration of the time-performance of the system for both training and testing [42,43]. Considering that the access to high-end Graphical Processing Units (GPUs) can become costly, the development of a less resource-demanding architecture is a challenge that needs to be addressed.
To address these challenges in the context of abnormality detection in GI endoscopy we propose a novel CNN architecture. The proposed architecture is a Fully Convolutional Network (FCN) [31] designed for supervised binary classification of endoscopic images using weakly labeled images, i.e., it is a CNN without fully-connected layers that can be trained using entire images as input, labeled as either abnormal or normal. An image is labeled as abnormal if it includes tissues clinically characterized as abnormal; otherwise, it is labeled as normal. Once trained, it is capable of classifying unlabelled input images as abnormal or normal. Its novelty relies on the use of consecutive blocks of parallel convolutional layers with different filter sizes, enabling multi-scale feature extraction. These blocks are connected to each other by Look-Behind (LB) connections, so that their features are combined with features from behind layers. This way the respective information from the previous layers is preserved, propagated and enriched with information from the next layers of the deep architecture. The proposed LB-FCN architecture involves a smaller number of free (weight) parameters than conventional CNN architectures [44,43], and it can be trained so that it generalizes well on smaller datasets. This makes it particularly attractive for medical image analysis, where the availability of large datasets is usually limited due to ethicolegal constraints. Due to the multi-scale feature extraction procedure followed, the proposed architecture is also capable of detecting abnormalities of different sizes without the need of applying an extensively deep architecture. This is essential for endoscopy, considering the diversity of the abnormalities, and also the fact that the abnormalities may be visualized from different distances (further from the endoscope head, the abnormalities look smaller, while closer, they look larger). In the context of WCE this aspect is even more important, since the frame rate of the capsule endoscopes is usually very low. Thus, given a WCE frame sequence acquired from a location of interest, an abnormality may be present only in a few frames, whereas it is not rare to have only a single frame with that abnormality. The information extracted at different depths of the proposed architecture undergoes consecutive multi-scale transformations as it propagates forward along the network, while part of this, is preserved through the LB connections and aggregated with the rest. This way, a richer representation of the endoscopic images is achieved. The proposed architecture can be considered as an evolution of ResNet [38], ResNeXt [39] and Inception-v4 [40] architectures, which combines their advantages to deliver enhanced binary classification accuracy in the context of abnormality detection in endoscopy.
The rest of the paper consists of five sections. Section 2 presents the proposed CNN architecture. Section 3 presents the datasets used and the experimental evaluation methodology, and Section 4 presents the results of the experiments performed on publicly available datasets, in comparison with the most relevant state-of-the-art approaches to GI abnormality detection. Section 5 discusses the results obtained, and the last section summarizes the conclusions that can be derived from study.
