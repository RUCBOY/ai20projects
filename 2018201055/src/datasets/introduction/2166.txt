The implementation of a computerized physician order entry (CPOE) has proven to be a significant improvement on medication safety by reducing errors related to the prescription of medication (Maat et al., 2014; Van et al., 2009; Zenziper et al., 2014). However, it was found that unintended ‘system related’ (Ash et al., 2004) or ‘computer related’ (Walsh et al., 2006) errors had generated new types of prescribing errors, which would be unable to occur in a paper-based medication order system (Westbrook et al., 2012). Previous studies have provided narrative accounts of CPOE-related errors, and broad classifications have been proposed (Ash et al., 2004; Campbell et al., 2006). These errors include incorrect selection of order components from drop-down menus, duplicate ordering, and a failure to discontinue drugs due to poor information displays (Westbrook et al., 2013).
The design and implementation phases of CPOE did not fully integrate human factors, meaning that human error could easily exist in CPOE. Westbrook et al. (2013) found that system-related errors were most frequent when prescribers needed to select information from drop-down menus, edit information within the system, and perform new tasks not previously required. An observational quantitative study in a large tertiary care center over three years after CPOE implementation identified that the two main types of error related to CPOE were medication selection (20.9%) and improper data placement (20.3%) (Villamañán et al., 2013). A computer mouse was one of the most frequently used input devices for computer users (Jensen et al., 2002). Computer mouse usage comprised between one-third and two-thirds of total computer usage time (Cook et al., 2000; Müller et al., 2010), and this held true for clinicians inputting orders in CPOE. Clinicians used the computer mouse to move through the CPOE manually, point to the target, and left-click to select an option within a drop-down menu. Even in Clinical Decision Support Systems (CDSSs), in which a clinician inputs data and presses buttons to go through the decision process, the number of clicks selecting check boxes may be large (Tsopra et al., 2014). With the development of CPOE, more interfaces have used WIMP (windows, icons, menus, pointers) graphical user interfaces (GUI), and menu- or form-based GUIs for data entry. Such systems currently require clinicians to navigate deeply nested menus, browse through long pull-down lists, and perform tasks requiring multiple points, clicks and scrolls (Street et al., 2014).
Although existing studies have examined mouse operation, the majority of those studies stress the difference between accuracy and pointing time with other inputting devices (Straker et al., 2000). As of late, researchers have begun to discuss finger behavior and new functions for mouse (Feathers et al., 2013; Jung, 2014; Lee and Lee, 2010). Studies have shown that computer input device size, including mouse size (length, width, height, switch location) and mouse-button activation forces have been affecting computer mouse use (Hughes and Johnson, 2012). In the past, most software functions had to be triggered by ‘mouse clicks’ rather than a single mouse click. However, in CPOE, the typical mouse operation of the drop-down menu selection involves a click instead of ‘mouse clicks’. This key difference in using a typical mouse button has not yet been observed in practice.
Health care workers often interact with computers during time-sensitive situations. Erroneous keystrokes are prone to occur, and may be caused by an operator's psychophysiological state, specifically in terms of a lack of attention, external distractions, and fatigue (Wang et al., 2011). Researchers have found that a high rate of potential prescription errors, which commonly affect hospitalized patients, were associated with a large volume of drug prescriptions, and may lead to significant morbidity, mortality rates, and financial costs (Zenziper et al., 2014). Magrabi et al. (2010) examined the effects of task complexity and interruptions on prescription error rates, and found that complex tasks took significantly longer to complete. Additionally, the study found that when execution was interrupted, physicians took almost three times longer to resume complex tasks as compared to simple tasks. The simulation of emergency situations taking place in actual medical environments was difficult to achieve for the purposes of laboratory testing; however, a recent study in numeric typing succeeded in using different monetary rewards to manipulate levels of urgency realized by users (Lin and Wu, 2011).
In this study, we explored the possibilities of mouse trigger design by focusing on the mouse movements on drop-down menu selection: the click strategies, release strategies and their interaction with level of urgency. Several experiments were conducted to compare the error rate and completion time needed for inputting physician orders into CPOE with different mouse trigger designs. The goal of this study was to address two research questions through an experimental design in which confounding factors in speculation and practice were eliminated. First, do clinicians perform differently using the different mouse trigger design in the context of CPOE drop-down menu selection? Second, is urgency level an influential factor to consider when it comes to choosing a mouse trigger method?
