Malignant tumors are a serious threat to human health. According to relevant statistics, cancer in single tissues is the main cause of human mortality and morbidity, and it is increasing yearly (Siegel, Miller, & Jemal, 2012). Medical images combined with biopsy have gradually become an important basis for accurate cancer diagnosis. Medical imaging refers to the technology and process of acquiring images of internal tissues in a non-invasive way for medical treatment or research of a human body or part of it. Medical imaging is decisive in the detection, qualitative evaluation, efficacy evaluation, and prognosis prediction of disease, and it is an indispensable auxiliary in clinical practice. With the rapid development of science and technology, medical imaging technology has also made rapid progress. A variety of medical imaging methods have been gradually formed, such as X-ray (including CT), magnetic resonance imaging (MRI), ultrasound, and nuclear medicine. These medical imaging techniques have become an important means of tumor detection, staging, and follow-up. A large number of imaging data and functional imaging data analysis can improve the accuracy of disease diagnosis. However, it also increases the complexity of disease diagnosis and the dependence on doctors’ experience. Therefore, when analyzing these medical imaging data, doctors are affected by subjective and objective factors such as knowledge, emotions, prejudice, and diagnostic methods, which lead to a relatively high rate of misdiagnosis.
In recent years, the rapid development of artificial intelligence (AI) technology has led to its increasing application in various fields. In the medical field, its applications include: virtual assistants, medical imaging, auxiliary diagnosis and treatment, disease risk prediction, health management, hospital management, and auxiliary medical research report. What is more, medical imaging plays an important role in clinical diagnosis and surgical treatment. More than 90% of medical data comes from medical imaging, but most of these data need to be manually analyzed. If AI can be used to analyze medical images, it will be of great significance for clinical diagnosis. At present, the application of a medical AI model based on the deep learning of medical image processing includes: image classification, target detection, image segmentation, and image retrieval (Wang et al., 2019). The deep learning technology abandons traditional artificially designed prior information of image and uses a completely data-driven approach. Model training is conducted through a large number of annotated image data, and the model automatically learns important low-level features (such as lines and edges) directly from these data. Then, it iteratively extracts more complex and high-level features (such as shapes) from low-level features. This end-to-end design provides more space for the model to be automatically adjusted according to the data and increases the overall fit of the model. The combination of the advantages of deep learning technology and medical images makes computer-aided diagnosis (CAD) increasingly superior, with clear advantages over traditional methods. Therefore, an increasing number of researchers are applying deep learning techniques to computer-aided diagnostic tasks. CAD can provide assistance and reference for doctors to read and delineate medical images; save doctors’ time; improve the accuracy of diagnoses, radiotherapy, and surgery; and reduce the rate of misdiagnosis and missed diagnosis.
With the development of medical imaging technology and the advancement of CAD algorithms, methods for classification, localization, segmentation, and detection of medical images can be used to assist analysis and decision-making related to 2D and 3D medical image data. Image segmentation is one of the key technologies in the process of medical image and plays an increasingly important role in imaging medicine. Segmenting the region of interest (ROI) accurately, robustly, and quickly is the most important step before subsequent procedures such as quantitative analysis and 3D visualization. It also lays the most fundamental foundation for image-guided surgery, radiotherapy planning, treatment evaluation, and other important clinical applications. Traditional segmentation algorithms based on edge, region, and shape models rely heavily on the quality of hand-crafted features or the introduction of prior knowledge, and these methods cannot achieve an ideal performance (Skalski, Lagwa, Kedzierawski, Zielinski, & Kuszewski, 2014). Based on the current generative adversarial networks (GANs) that show superior performance in various computer vision problems, we propose a new deep learning model to construct our CAD and decision-making model. As shown in Fig. 1, prostate magnetic resonance (MR) images were taken as examples. After image pre-processing, we trained our deep model based on adversarial learning with a large number of prostate MR image data manually segmented by radiologists, which allowed the model to learn to automatically segment regions of interest. The model also attempted to segment the images more accurately and quickly than traditional CAD algorithms. Finally, the model was evaluated with different metrics. The model aims to assist doctors in making more accurate decisions and provide patients with more reliable diagnostic results. For radiologists, it can reduce the time needed to read images, significantly improve work efficiency, and reduce misdiagnosis rates. The model would also systematically reduce costs for hospitals.Download : Download full-size imageFig. 1. Proposed computer-aided diagnosis and decision-making system.
The contributions of this work are summarized as follows: (1) We used a deep learning method to build our CAD and decision-making system; (2) We used adversarial learning to train the segmentation model to improve accuracy of medical image segmentation; (3) We proposed a novel segmentor network using a receptive field block (RFB) module to improve the capability of feature extraction. In addition, dense upsampling convolution (DUC) was used instead of traditional bilinear interpolation upsampling to avoid the loss of fine-detailed information.
The rest of this paper is organized as follows: Section 2 describes the related work. Section 3 introduces the CAD and decision-making model in detail. Sections 4 Model evaluation, 5 Discussion present the model evaluation and discussions, respectively. Finally, Section 6 concludes the paper.
