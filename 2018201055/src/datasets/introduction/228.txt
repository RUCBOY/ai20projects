1.1. Objective and rationaleConsider a learning scenario in which a student views an instructional video showing an instructor standing next to a slide as she lectures, such as exemplified in Fig. 1. An interesting issue in affective science and affective computing involves the degree to which the emotional state of the instructor affects student learning, but before we can address that issue, a preliminary question concerns whether students are even able to recognize the emotional state of the instructor. The primary goal of the present study is to determine whether people who view a short video lecture on a statistical procedure are able to detect the degree to which the instructor exhibits a happy, content, frustrated, or bored emotional state. To address this goal, we created four versions of a lecture on statistics--involving the same instructor, script, and slides--in which the instructor (an actor) exhibited either a happy, content, frustrated, or bored emotional tone through her body stance, gestures, facial expression, and voice. We asked adult participants to view two clips from each version and rate the degree to which the instructor appeared to be happy, content, frustrated, or bored. If participants are able to recognize the instructor's emotional state, this should be reflected in their ratings: the happy instructor should be rated higher on the happy scale than on each of the other scales; the content instructor should be rated higher on the content scale than on each of the other scales; the frustrated instructor should be rated higher on the frustrated scale than on the other scales; and the bored instructor should be rated high on the bored scale than on the other scales.Download : Download high-res image (544KB)Download : Download full-size imageFig. 1. Image from Human Instructor Video.A secondary goal of the present study is to determine whether participants are equally able to recognize the emotional state of human instructors in instructional videos and virtual instructors in animated lessons, when they say the same things and refer to the same slides. To address this issue we created animated pedagogical agents who mimicked the facial expressions, body stance, and gestures of the human instructor and used the same voice. An example frame is shown in Fig. 2. We asked a different group of adult participants to view the same two clips from each version and rate the degree to which the instructor appeared to be happy, content, frustrated, or bored. If participants treat virtual instructors like human instructors, we expect them to show the same pattern of ratings as was reported for human instructors and we expect the level of ratings to be equivalent for human and virtual instructors (i.e., the happy rating for happy instructor, the content rating for the content instructor, the frustrated rating for the frustrated instructor, and the bored rating for the bored instructor should be indistinguishable for human and virtual instructors). Alternatively, if people see the virtual instructors as somewhat less human-like, their emotional state ratings of the instructor's emotional state may be lower than for human instructors.Download : Download high-res image (172KB)Download : Download full-size imageFig. 2. Image from Virtual Instructor Video.
1.2. Research and theory on the Instructor's emotional stateAlthough there are several systems for classifying emotional expression, especially facial expression (Ekman & Friesen, 2003; Ekman et al., 2013), we focus on Russell's model of core affect (Russell, 1980, 2003) because it has been useful in classification of achievement emotions (Harley et al., in press; Pekrun, 2016; Pekrun & Stephens, 2010) and in the instructional design of onscreen characters (Loderer et al., in press; Plass & Kaplan, 2016) and thus has potential relevance for categorizing the perceived emotional states of instructors. Fig. 3 shows an adapted version of Russell's (1980, 2003) model of core affect, which is based on two orthogonal dimensions: valence, running from displeasure on the left to pleasure on the right (or more simply, from negative valence to positive valence); and arousal, running from activation on the top and deactivation on the bottom (or more simply, from active to passive). These dimensions generate four quadrants from which we abstracted four emotional states that could be relevant to an instructor: happy (which represents positive valence and active arousal), content (which represents positive valence and passive arousal), frustrated (which represents negative valence and active arousal), and bored (which represents negative valence and passive arousal). Other descriptors also apply to each quadrant (Loderer et al., 2019; Pekrun, 2006, 2016; Pekrun & Perry, 2014; Russell, 1980, 2003), but we use these four as representatives in our study.Download : Download high-res image (164KB)Download : Download full-size imageFig. 3. Model of Core Affect Adapted from Russell (2003).Although classic theories of e-learning such as Cognitive Load Theory (Paas & Sweller, 2014; Sweller et al., 2011) and the Cognitive Theory of Multimedia Learning (Mayer, 2014, in press-a) focused mainly on the cognitive processes during learning, some investigators have also attempted to incorporate affective processes during learning such as Plass and Kaplan's (2016) Integrated Cognitive Affective Model of Learning with Media and Moreno and Mayer's (2007) Cognitive-Affective Model of Multimedia Learning. These attempts are in line with calls to incorporate emotion into theory of multimedia learning (Mayer, in press-b; Plass & Kalyuga, 2019). As an example, Fig. 4 presents an example of an adaptation of Mayer's (in press-b) cognitive-affective model of e-learning that consists of five basic components: (1) an e-learning episode (such an online multimedia lesson with an instructor displaying positive emotion) causes (2) the learner to recognize the instructor's emotional stance, (3) which primes an affective response in the learner towards the instructor (such feeling positive about the instructor), (4) which affects cognitive processing during learning (such as the degree to which the learner is motivated to engage in deep processing), (5) which, in turn, affects the learning outcome (as measured by posttest performance).Download : Download high-res image (192KB)Download : Download full-size imageFig. 4. An Example of the Cognitive-affective Model of e-Learning, When the Instructor Displays Positive Emotion Such as Being Happy.As research on the role of emotion in e-learning is now becoming a larger field of investigation, the research has produced some ambiguous findings, making more research necessary (i.e., Knörzer et al., 2016; Loderer et al., in press; Loderer et al., 2019; Mayer, in press-b; Plass & Kalyuga, 2019; Schneider et al., 2016). One encouraging strand of research on emotion in e-learning involves the emotional design of online learning material (Brom et al., 2018; Mayer & Estrella, 2014; Plass et al., in press; Plass et al., 2014; Plass & Kaplan, 2016; Um et al., 2012; Wong & Adesope, in press). For example, in multimedia lessons on how viral infection works, students gave more positive affective ratings and scored higher on posttests when the characters in the lesson (such as a virus or host cell) were portrayed in warm colors with facial expressions (Mayer & Estrella, 2014; Plass et al., 2014; Um et al., 2012). In this case, the emotional stance of the instructor in e-learning materials (corresponding to the first box in Fig. 4) affects the learner's perception of the instructor's emotional stance (corresponding to the second box in Fig. 4) improves the learner's feelings about the instructor as measured by ratings (corresponding to the third box in Fig. 4) and motivation to engage in deep cognitive processing as measured by ratings (corresponding to the fourth box in Fig. 4) which, in turn, improves learning outcomes (corresponding to the fifth box in Fig. 4).A recent review of emotional design of multimedia lessons confirmed that adding emotional design features intended to portray positive emotional tone had a positive effect on improving learning, with an effect size of d = 0.33 for transfer test performance (Brom et al., 2018). An updated and broader meta-analysis also found a positive effect of emotional design on transfer test performance with g = 0.27 based on 38 comparisons (Wong & Adesope, in press).In a study that focuses mainly on the first link in cognitive-affective model of e-learning, Plass et al. (in press) varied the emotional tone of game characters for an online computer game by varying their facial expression and color. Students reported happy emotions for characters with happy facial expressions and warm colors, whereas students reported sad emotions for characters with sad or neutral facial expressions and cold colors. These findings encourage the proposal that people can recognize the emotional tone of onscreen characters.Exemplary evidence concerning the first link involving student recognition of the emotional tone of a lesson comes from a study by Uzum and Yildirim (2018) in which students displayed stronger positive emotional arousal via biometric measures for multimedia lessons containing onscreen characters who displayed positive rather than neutral facial expression. Another piece of evidence concerning the first link is that students who receive multimedia lessons spend more time looking at onscreen agents that display positive emotion than those that display neutral emotion (Park et al., 2015). Finally, Kramer et al. (2013) reported that people who engaged in an 8-min conversation with an agent who smiled (thereby indicating positive emotional stance) spent more time smiling themselves than people who had a communication with an agent who did not smile. These studies provide encouraging preliminary evidence that people are able to recognize and respond to the perceived emotional state of the instructor in a multimedia lesson. However, this previous research has focused on understanding how different pedagogical stimuli can elicit certain emotions in the learners. The current research expands on this by attempting to understand more deeply if and how learners recognize emotions of pedagogical stimuli.
1.3. Research and theory on leaning with human and virtual instructorsPeople can easily form a social relationship with a computer and treat a computer as if it is human. This is the thesis underpinning the media equation hypothesis concerning communication (Reeves & Nass, 1996) as well as social agency concerning multimedia learning (Mayer, 2014, in press-a). For example, Nass and Brave (2005) show how machine interfaces are capable of expressing emotions such as happiness just as well humans can. When the focus is on learning from multimedia lectures, research shows that people learn better from an animated pedagogical agent that engages in human-like gesturing, uses conversational language, and speaks in an appealing human voice while lecturing (Mayer, 2014, in press-a). When onscreen agents have these features, learners tend to report liking the agent and feeling they have a social connection (Mayer, 2014, in press-a). In the present study, we are interested in a direct comparison between how participants relate to human and virtual instructors who are teaching the same content with the same emotional tone. These findings encourage the prediction that people will show equivalent ratings of emotional tone for video lectures with equivalent virtual and human instructors.
1.4. HypothesesIn the present study, students are shown a set of clips from a video lesson on the statistical concept of binomial probability; the clips contain the same script being rendered by the same instructor but displaying a happy, frustrated, content, and bored emotional tone, respectively. In addition, there are versions of each of these clips in which the instructor is a human and in which the instructor is an onscreen agent mimicking the same gestures, body stance, facial expression, and voice as the human instructor. This project involves an initial step in determining the role of the instructor's emotional tone in video lessons by examining the extent to which learners are aware of the instructor's emotional tone.According to the emotional awareness hypothesis, based on the first link in the cognitive-affective theory of e-learning, learners recognize the emotional tone of instructors in video lectures. This hypothesis leads to the prediction that participants will give higher ratings to the emotion displayed by the instructor than each of the other three emotions (hypothesis 1). In particular, for the happy instructor, participants will give higher ratings of happy than each of the other three emotions (predication 1a); for the content instructor, participants will give higher ratings of content than of each of the other three emotions (hypothesis 1b); for the frustrated instructor, participants will give higher ratings of frustrated than of each of the other three emotions (hypothesis 1c); and for the bored instructor, participants will give higher ratings of bored than of each of the three emotions (hypothesis 1d).According to the media equation hypothesis, people accept computers as social partners as if they were human. This leads to the prediction that participants' ratings for the emotional tone of human instructors will be equivalent to participants' ratings for the emotional tone of corresponding virtual instructors (hypothesis 2). In particular, participants will rate the happy virtual instructor as just as happy as the happy human instructor (hypothesis 2a); participants will rate the content virtual instructor as just as content as the content human instructor (hypothesis 2b); participants will rate the frustrated virtual instructor as just as frustrated as the frustrated human instructor (hypothesis 2c); and participants will rate the bored virtual instructor as just as bored as the bored human instructor (hypothesis 2d).
