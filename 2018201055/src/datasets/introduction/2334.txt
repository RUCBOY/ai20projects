1.1. Robotic arm control with BCIsBrain–computer interface (BCI) is a control and communication option between human and external devices, which does not depend on the peripheral nerves and muscles [1]. For people with paralysis due to trauma, stroke, etc, BCIs are conceived to hold promise for increasing self-sufficiency in their daily lives. In order to restore movement control in paralysed people, it has always been an ambitious goal to design a brain-actuated robotic arm for reach and grasp activities in a three-dimensional (3D) space.Most advances in BCI-controlled robotic arms are achieved using invasive BCIs, which can acquire higher-quality of signals than that of non-invasive BCIs. Subjects have learned to control the robotic arm to perform complex functional tasks by decoding signals acquired by implanted electrodes [2], [3], [4]. However, the technical difficulties and clinical risks of the invasive BCIs remain the major limitations toward the practical applications. Additionally, ethical concerns exist widely among the invasive technologies [5].In contrast, the non-invasive BCIs which record the electroencephalography (EEG) over the scalp are easier and safer. Previous studies have validated that human subjects could control the planar movement of a robotic arm using BCIs with three [6] or four [7] different mental tasks. Regarding more complex movement, a non-invasive BCI system using P300 potentials was developed to realize the control of a robotic arm with multiple degrees-of-freedom (DOFs) [8]. A main drawback with the evoked BCI is the requirement of external stimulus, which restricts its practical applications [5]. Moreover, subjects are required to look at a screen to elicit the evoked potentials during the control, which can distract them from observing the realtime state of the robotic arm [8]. It is preferable to use a non-invasive BCI extracting spontaneous features which does not depend on the external stimulus. A related research was reported recently, in which a motor imagery-based (MI-based) BCI was utilized to move a robotic arm in a 3D space [9]. The 3D movement was completed with a sequential movement strategy, which enabled the subjects to achieve the 3D movement by utilizing only four discriminative mental tasks. Despite of this, user training is required before the realtime control of the robotic arm. The subjects have to learn to generate four different mental states. Also, they need to adapt to the sequential movement strategy, which brings more cognitive burden.In control of a dexterous robotic arm, one tremendous challenge is the limited capacity of the non-invasive BCIs based on spontaneous brain activities. The independent control commands generated from the non-invasive spontaneous BCIs are not sufficient to control a dexterous robotic arm. The most advanced one can just output three pairs of independent commands, which corresponds to six different mental tasks [10]. However, six or seven pairs of independent control commands are needed theoretically, if the open and close of the end gripper is included, to perform reach and grasp activities in a 3D space. Besides, intensive user training is required to master the usage of a spontaneous BCI even though there are just two [9], [11] or three [10] pairs of independent commands, which brings more cognitive burden over the disabled users. Facing the practical applications in the daily life, as long as the functional activities can be achieved, it is preferable that the BCI system is simple enough and easy to use.
1.2. Shared controlShared control can be a solution for the problem of limited capacity of non-invasive BCIs in control of a robotic arm with multiple DOFs. The intelligent device and the subject collaborate to control the whole system when shared control is used. By reducing the requirements of the BCIs, it may improve the usability of the BCI-controlled robotic arms in practice. This control strategy has been applied in some brain-actuated applications to enhance the performance of the systems, including wheelchair [12], [13] and helicopter [14].In case of robotic arm control, shared control strategy has been used to improve the grasping performance (e.g., the adjustment of the gripper orientation to grasp the target accurately) for the invasive BCIs while the 3D movement of the robotic arm is under control of the subjects [15], [16], [17]. However, it is still difficult now for the spontaneous non-invasive BCIs to finish the 3D movement. The number of output commands is limited because of the poor quality of the EEG signals recorded from the scalp. Although it was demonstrated that people can learn to move the cursor in a virtual 3D space through a spontaneous non-invasive BCI by producing three pairs of independent control commands [10], long-term user training is required and the system has not been verified with a real robotic arm yet. Thus, with the shared control, should not only the realization of steady grasping function be considered for the spontaneous non-invasive BCIs, the possibility of performing 3D movement with less than three pairs of independent control commands is also worthy of exploration. If less independent commands are required, the output accuracy of the BCI system holds the potential to be higher [18], [19]. In addition, it may also decrease the time of user training before use, which will help a lot in applying the spontaneous non-invasive BCIs in the daily life.In the present study, we apply a shared control strategy to an MI-based BCI for reach and grasp tasks in a 3D space. Due to the introduction of machine autonomy, only binary output from the BCI is required during the tasks, which makes the potential of this system extend beyond a laboratory study.
