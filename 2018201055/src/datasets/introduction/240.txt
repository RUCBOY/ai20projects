Recently, methods in medical biometrics have been developing at an accelerated rate and have already achieved promising performances [1], [2], [3], [4], [5], [6], [7], [8]. Some diseases for example, such as diabetes mellitus, significant achievements have been made by incorporating pattern recognition and image processing techniques [9] along with Traditional Chinese Medicine (TCM) theory to form a detection method known as medical biometrics [10], [11], [12]. Different from modern disease diagnostic methods like the FPG test (in the case of diabetes mellitus), medical biometrics performs non-invasive detection, which does not require bodily fluid extraction or injections. Therefore, medical biometrics methods can reduce the pain of patients as much as possible. According to TCM, changes in a person’s condition caused by diseases will be reflected on the organs such as the face, tongue, or sublingual vein. Based on this idea, the applications of various artificial intelligence methods ranging from feature engineering to the classification of medical image profiles is a feasible way to perform disease detection.
In reality, medical biometrics (in terms of analyzing the human surface characteristics such as the face, tongue, and sublingual vein) borrows from the idea of TCM diagnosis, making judgments jointly in terms of the characteristics from different surfaces of the human body, which can be seen as a multi-view disease diagnosis problem between a particular disease and healthy individuals. To computerize these features, there are different devices designed specifically for capturing the images of these specific organs [2], [13]. However, previous methods either focus on diabetes mellitus only [4], [5] or used a single view [1], [14], [15], indicating the lack of breadth. Furthermore, these methods run in a manual or semi-automatic way.
As mentioned above, since multiple views of the human body are jointly considered when performing disease diagnosis in medical biometrics, the multi-view learning strategy is involved in our proposed system. We used the late fusion strategy to fuse the information of three views (face, tongue, and sublingual vein) in order to disambiguate the result made by one single view. We designed a coding procedure integrating the highest probability class label from each view in a coding vector for further decision making. Since the coding vector integrates information from the three views, we termed it as the collective representation.
Given the advantages of multi-view disease detection and deep learning, in this paper we propose a multi-view disease detection system which takes a tuple of images containing the face, tongue, and sublingual vein as input and directly outputs the predicted label (healthy or a specific disease). To realize the automatic detection, we build a structure of View Classification–Deep Region Segmentation–Feature Representation–Coding-DecisionMaking in this system. To extract effective feature representation with more complete information, we propose a Deep region-based feature representation. Furthermore, to perform the multi-view disease diagnosis, we propose a Collective Deep Region-based Feature Representation method, termed as CDRFR. The pipeline of our proposed system is shown in Fig. 1. In our proposed system, an image instance (multi-view images containing views of the face, tongue, and the sublingual vein) is first input. Since the system receives one image at a time, we place a View Classification network in order to ensure the system can automatically extract the features from an arbitrary image without any prior knowledge of the view information. Besides this, View Classification avoids any possible human errors caused by an operator manually classifying each image. The View Classification network will perform classification precisely on each image of a given instance and later transmit it to a corresponding Deep Region Segmentation network for further processing. As previous state-of-the-art works mentioned above [1], [3], [4] used local information from each view by cropping pre-defined blocks. Here, we make a distinction by extracting a ‘region’ which contains more information than ‘blocks’ for each view. The segmentation networks (FaceNet, TongueNet, and SublingualNet) are in charge of extracting the ‘deep region’ from the corresponding view image. The deep learning architecture can learn the most informative regions for disease diagnosis. After all the region extraction works are done, we perform Feature Representation by considering every single view to output the effective representation. First, we extract the color, texture, and geometry features based on the deep region using conventional feature extraction methods. Then, the extracted features will be concatenated together to form a single feature vector. Afterwards, in the collective representation step, the coding procedure will produce a coding vector whose entries are the highest probability class label from the three views based on the feature vectors of all three views (face, tongue, and sublingual vein). Next, to fuse the information from the three views, a coding vector (which only contains 0 or 1) whose entries are from the highest probability class label of the three views will be generated. After that, a classification algorithm is designed in the Decision Making unit and will be introduced in the subsequent Section 3. Finally, the system will output the Prediction Result of the given instance. Overall, there are three real innovations in this paper:
(1) Automated end-to-end medical biometrics system. This work proposes an automatic end-to-end system to perform disease detection in an automatic way all through the necessary procedures (including segmentation of ROIs, feature extraction, and classification) based on the medical biometrics.
(2) Deep region-based feature representation. In this work, we proposed a deep region-based feature representation for disease detection. We produced the feature representation based on the ‘region’ of each view extracted by the deep segmentation networks.
(3) Multi-view multi-disease medical biometrics diagnosis. In this work, we focused on multi-view multi-disease diagnosis based on the medical biometrics rather than a single view and/or a single disease detection.
Our proposed system achieved high efficiency and state-of-the-art disease detection results. The remaining parts of the paper are organized as follows. In Section 2, we describe the medical images and the dataset used. In Section 3, we present the automatic multi-view disease detection system as well as the proposed CDRFR method. In Section 4, extensive experiments are performed, which includes testing on View Classification, Deep Region Segmentation, and diseases diagnosis, to evaluate the effectiveness and efficiency of the proposed system and proposed method. In Section 5, we reach some conclusions.
Download : Download high-res image (417KB)Download : Download full-size imageFig. 1. The pipeline of the proposed multi-view disease detection system. The input is an image tuple consisting of the face, tongue, and sublingual vein coming from the same patient. Then, the image of each view is converted to a novel representation via our proposed CDRFR method. Inside the CDRFR, there are four sub-procedures (View classification, Deep region segmentation, Feature representation, and Coding). Afterwards, a decision making procedure is performed based on the combination of the three representations. Finally, the system outputs the Prediction results.
