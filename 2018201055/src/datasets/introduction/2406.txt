The modern flight deck designs focus on human-computer interactions (HCI) studies as they are central to the operating and functioning of the whole system. The primary flight display (PFD) contains the basic flight information on the state of the aircraft and the autopilot modes including measures of airspeed, altitude, attitude, heading and characters present in the flight mode annunciator (FMA). The navigation display (ND) acts like a radar gathering information on the relative position of the aircraft to the flight path, beacons, other aircrafts or waypoints. The engine indication and crew alerting system (EICAS) display shows information on the engines and displays alert messages if needed. Although the necessary information is given to the pilots, the displays also help them in the piloting and the decision-making process with messages, such as a “PULL UP” message that will appear on the PFD if the aircraft is too low on altitude. These functions are strongly related to the three levels of Endsley’s (1995) model of situation awareness. The level 1 of situation awareness is the perception of the elements in the current situation, the level 2 is the comprehension of the current situation and the level 3 is the projection of the future status. The perception of the elements is necessary to the comprehension of the situation as a whole. Similarly, the correct projection of the future status can only be achieved by understanding current situations. The design of alerting messages should help operators in the understanding of the situation and the projection of the future state (Kearney et al., 2016). Pilot's mental workload is strongly correlated to their situation awareness. An excessive mental workload may lead to a poor situation awareness due to pilot's inability to process the relevant information (Ahlstrom and Friedman-Berg, 2006). It has been argued on previous research that increasing the volume of information, even when it is accurate and task relevant, is not necessarily beneficial to the quality of decision-making. Moreover, it may even be detrimental to SA and trust among team members due to high mental demand (Marusich et al., 2016).
Visual attention is a precursor to initiating the cognitive process involved in attention distribution, situation awareness, and real-time decision-making (Lavine et al., 2002). The path of visual attention can reveal the cognitive process of human-computer interaction between operators and machines (Allsop and Gray, 2014; Kearney et al., 2016). How attention is related to information process for operation control in the context of task performance is a challenging measurement (Strayer, 2016). Therefore, an operator's eye movements on the displays can reveal human information processes and how the interface design impacts operator's performance (Goldberg and Kotval, 1999). Eye tracking has potential not only for pilot's training but also for flight skill analysis and evaluation (Peysakhovich et al., 2018). The fixations are the reflections of information processing. They are defined by a stability of the gaze position. Two main characteristics are used to identify them. Either the low velocity of the gaze point or the low spatial variation. Therefore, two of the most largely used algorithms to distinguish them are velocity-based or dispersion-based (Salvucci and Goldberg, 2000). There are two thresholds to determine in order to implement the algorithm: a dispersion threshold and a duration threshold. In order to be considered as a fixation, the gaze point has to stay within the dispersion threshold for longer than the duration threshold. Goldberg and Kotval (1999) proposed that the minimum duration of a fixation to be considered is 100 ms. Although Kilingaru et al. (2013) acknowledged that a fixation time of 200 ms is required to actually perceive information, they called the fixations below 200 ms as “glances”, which represent brief looks with not enough time for recognition. They also distinguished the fixations with longer duration than 600 ms as “stares” which are signs of misperception. For the dispersion threshold, the areas chosen are more diverse in the literature. It is possible to use a circle with a radius of 0.5° (Hoffman and Subramaniam, 1995) or 1° (Liang et al., 2007). Salvucci and Goldberg (2000) described a new way to calculate the dispersion as the sum of the vertical and horizontal dispersion and recommended to use a threshold between 0.5° and 1°, though it can also be adjusted during the data analysis.
Knowing where an individual is looking, it is possible to determine where they direct their attention. Recent research findings have provided evidence that attention can be allocated to multiple spatial positions simultaneously (Bay and Wyble, 2014). Just and Carpenter (1976) assumed that the object being fixated is the reflection of “what is at the top of the stack” of the information processing. As a consequence of this, they proposed the eye-mind assumption, stating that “there is no appreciable lag between what is being fixated and what is being processed”. Although this hypothesis could be argued because objects can be perceived with the peripheral vision, Posner (1980) highlighted how the peripheral vision is used to direct the attention, thus the point of gaze, more than to simply process the information. It is noted that in a demanding operation environment, the maintenance of attention to preview for next operation task could be accompanied by withdrawal of attention for the task in hand (Jagacinski et al., 2017). Heatmap is the major application to analyse the positions of gaze and corresponding operator's attention distributions among the areas of interests (Takahashi et al., 2017). A heatmap of fixation can be created from the positions of fixation points. The hot zones with higher density designate where pilots focused their gaze with higher frequencies (Pfeiffer and Memili, 2016). Horn, Li and Braithwaite (2018) proposed that pilots distributed their attentions significantly among airspeed indicator, altitude indicator, attitude indicator and Autopilot Flight Director System (AFDS) status (Fig. 1) during landing phase shown by heatmap based on eye tracking technology. Previous research on flight deck design had demonstrated that the integrated human-centred design did facilitate pilot's situation awareness and reduced cognitive loads on information processing (Li et al., 2017).Download : Download high-res image (272KB)Download : Download full-size imageFig. 1. Pilot's visual scan patterns shown as heatmap reflected to attention distributions among Primary Flight Display (PFD) including digital numbers (airspeed/altitude), texts (flight mode annunciator), and symbol (attiutdue indicator).
The task of handling emergency situations in flight deck can be simplified as a single cognitive process by identifying cues from the external environment to search for a specific solution. If a new design could reduce search space and time, crews will have more time left for solving the problems in the external world. It is possible to make representations of Quick Reference Handbook (QRH) more active in order to help crews see what is most relevant to deciding what to do next (Hollan et al., 2000). The QRH contains all the procedures applicable for abnormal and emergency conditions in an easy-to-use format and is designed with the intention of allowing flight crews to minimize the need for a lot of effortful analysis when time may be limited and workload is high (Burian, 2004). Wickens and Carswell (1995) proposed the Proximity Compatibility Principle (PCP) for information integration, which suggests that two pieces of information need to be processed together should be placed in close spatial proximity.
Pilots have to interpret the cues available to them and find the appropriate checklist to solve problems (Burian, 2006). By applying eye tracking devices to evaluate the relation between a human and a design, which contains eye movement, including gaze, fixation and saccade, is controlled by ongoing cognitive processing, so that it is possible to analyse human behaviour by examining eye movement. This assumption has been validated by many previous researchers in reading (Just and Carpenter, 1980; Rayner et al., 1989; Rayner and Pollatsek, 1992), cognitive tasks (Salvucci and Goldberg, 2000; Ahlstrom and Friedman-Berg, 2006; Stanton et al., 2017; Ryffel et al., 2018), information processing tasks (Rayner, 1998; Chi et al., 2018), scanning behaviour (Allsop and Gray, 2014; Yang et al., 2018), interface evaluation (Goldberg and Kotval, 1999; Kunze et al., 2018), human-computer interaction (Yu et al., 2014), and a monitoring task on remote tower operation (Kearney et al., 2018). Pilots have to manually go through the QRH and identify the relevant checklists for the situation at hand and then act accordingly. This research is focusing on the evaluation of visual parameters on a proposed integrated EICAS design type in the flight deck. To achieve this objective, the three displays including PFD, ND and EICAS are evaluated in a holistic context for human-computer interactions in the flight deck.
