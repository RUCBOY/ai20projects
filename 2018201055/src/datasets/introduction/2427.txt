Over the last ten years, online courses have become prevalent in higher education, particularly at community colleges (Parsad and Lewis, 2008, Allen and Seaman, 2013). Today, one-third of students take at least one course online (Allen & Seaman, 2013). Studies comparing online to face-to-face courses have found predominantly negative effects of online classes on grades, test scores, and progress in college, with larger negative effects for students with lower levels of academic preparation (Figlio et al., 2013, Xu and Jaggars, 2013, Bettinger et al., 2017, Alpert et al., 2016). While online courses can potentially reduce the cost of administering courses (Deming, Goldin, Katz, & Yuchtman, 2015), these savings appear to come at a cost to student success.
Blended learning interventions, which mix aspects of online and in-person instruction, might allow colleges to capture some of the cost-savings without worsening students’ outcomes. In this paper, I estimate the effect of adopting a lab-based blended learning model in remedial college math courses, compared to in-person instruction, on course pass rates, progress in college, and degree attainment in a midsize, state community college system. Approximately half of all four-year public colleges and two-thirds of all two-year public colleges offer hybrid or blended learning courses (Parsad & Lewis, 2008). However, the literature on the use of blended learning in college is limited to a handful of studies from microeconomics and statistics courses in four-year colleges. This paper will extend this literature by examining the use of lab-based blended learning at scale in a state community college system for a group of students who have less academic preparation.
If entering college students are unable to pass a placement test in math, reading, or writing, they can be assigned to as many as three remedial courses in a given subject, which they must complete before beginning college-level work. Remedial college courses are common. In a study of students beginning college in the 2003–2004 school year, 68% of two-year college students and 40% of four-year college students took at least one remedial course in reading, writing, or math (Chen, 2016). Math is the most common remedial placement, but also has the highest rates of failure, with only one-third of students completing the sequence of remedial math courses that they have been assigned to (Bailey, Jeong, & Cho, 2009). With the average remedial student taking 2.6 remedial courses, the estimated cost of providing these courses nationally is US$7 billion per year (Scott-Clayton, Crosta, & Belfield, 2014). In order to improve pass rates, increase the speed of remediation, and reduce costs, colleges have begun to experiment with different approaches to integrate technology into remedial courses.
This paper will examine a model of blended learning called the emporium model which consists of online instruction in a lab setting.1 Under this approach, students spend class time working at their own pace in a computer lab on a series of modularized lessons, practice problems, and assessments. Instead of providing lectures, instructors and teaching assistants are available onsite to provide personalized assistance to students as questions arise (Twigg, 2011).2 This model is unique from purely online courses, in which students typically do not come to campus or interact in-person with instructors, and is unique among blended learning approaches in that the online work is performed on-campus with instructors available to students. The emporium model was created at Virginia Tech in 1997 for introductory college math courses, but has spread more widely over the last decade to institutions ranging from state flagship institutions to community colleges (de Vise, 2012, National Center for Academic Transformation [NCAT] 2016). While blended learning models like the emporium model have grown in popularity, there is little evidence on how computer-based approaches to remediation affect students’ success in college (Rutschow & Schneider, 2011).
One reason colleges adopt the emporium model is that it can lower the costs of delivering remedial instruction by allowing colleges to raise class sizes, switch to less expensive instructors, or increase the number of sections faculty teach. While not all institutions choose to adopt cost-saving measures while switching to the emporium model, one estimate from 28 institutions found it reduced the cost per student by 20% on average.3 Advocates for the emporium model also argue that it can improve students’ outcomes through several channels (Twigg, 2013). First, the emporium model is modularized and mastery-based. If a student demonstrates proficiency in one part of the course, she can skip that portion and focus on other areas which are more challenging. This could help students to more efficiently address weaknesses. Second, students are allowed to complete the courses at their own pace. A motivated student could complete multiple remedial courses per semester, unlike under the traditional remediation approach. One the other hand, a student who has not mastered all of the material in the first semester can pick up where he left off in the second semester. Third, an alternative mode of instruction which is student-led and encourages students to take ownership of their own learning may help students who struggle with traditional lecture-based courses.
Between 2009–2010 and 2012–2013, eleven colleges in the Kentucky Community and Technical College System (KCTCS) adopted the emporium model in at least one of three math courses in the remedial math sequence. I exploit variation in the timing of the adoption of the emporium model across math courses and across institutions.4 Using a difference-in-difference-in-differences (i.e. triple difference) identification strategy, I estimate the change in outcomes for cohorts of students within the same college and same level of math remediation before and after the adoption of the emporium model while differencing out the change for students in the same level of remediation in comparison colleges and the change for students in different levels of remediation within the same college.
Across KCTCS colleges, students can be required to complete up to three (sequential) remedial math courses before they can begin college-level work. Since students assigned to different levels of remediation are likely to have different outcomes regardless of their remedial course experiences, this design compares students who begin taking the same level of remedial coursework to one another. In addition to controlling for time invariant differences between students in different levels of remediation and students in different colleges, this design also allows me to difference out changes that affected all remedial courses within an institution (e.g. a change in the supports available to students in remedial courses) and changes within a given level of remediation across institutions (e.g. a change in the placement criteria used by KCTCS) that may have occurred at the same time as the introduction of the emporium model.
I find that using blended learning in a course reduces students’ ability to progress through remediation to credit-bearing courses. Students who are taught using the emporium model are ten percentage points less likely to pass their courses in one semester and are five percentage points less likely to take a college-level math course within three years of enrolling. Students are also six percentage points less likely to be enrolled in college by their second year than students taking the same remedial course under traditional instruction. Within three years of enrolling, students taught using the emporium model are five percentage points less likely to earn a degree. Effects were generally consistent across all three levels of remediation, suggesting there is little variation by students’ incoming placement test score.
One concern is that it may not be random which courses switched to the emporium model, and that if these differences were time-varying, they could bias estimates of the effect of the emporium model. For example, if colleges adopted the emporium model in a particular course in response to falling pass rates, this could pose a problem. To address this concern, I conduct event study analyses to test if the adopting courses have similar trends to the comparison courses in the pre-adoption period. I find evidence that suggests the timing of the adoption of the emporium model was likely exogenous.
Another concern is that students might switch their level of remediation in response to the introduction of the emporium model. When students first arrive on campus, they are typically given a placement test (or can use scores from a test they took previously) to determine their placement. However, students sometimes can retake the tests or are otherwise able to avoid remedial courses. If students are more (or less) likely to take these steps to adjust their level of remediation or avoid remediation entirely with the introduction of the emporium model, this could bias the results. To address this, I test for changes in enrollment in remedial courses and test for changes in the observable characteristics of students enrolled at each level of remediation and do not find evidence that these change systematically in response to the introduction of the emporium model.
While it is clear that students perform worse in remedial courses with the emporium model, it is not clear why. In the conclusion, I consider reasons why blended learning might have had such a large effect on a student's likelihood of passing their courses, including the possibility that students struggle with self-management and self-pacing. Because the assessment criteria were not necessarily aligned before and after emporium adoption, it is also possible that students were being held to a higher standard of understanding under the emporium model than before. Because the model typically standardizes assessments across classes and requires students to demonstrate their understanding before moving to the next topic, the new approach may have raised the bar on what is required for passing.
This paper contributes to a growing literature on blended learning. Three randomized studies comparing blended learning to purely in-person instruction have found few differences in students’ outcomes (Alpert et al., 2016, Joyce et al., 2015, Bowen et al., 2014). These studies have been limited to introductory microeconomics or statistics courses at large, four-year public colleges. Given that approximately two-thirds of community colleges report using blended or hybrid online courses, this study will expand the literature to a group of colleges that is highly policy relevant (Parsad & Lewis, 2008). Second, while these studies have strong internal validity, two of the three studies use a sample that is limited to students who volunteered to be randomized into a blended learning course – a group who is likely more amenable to taking a blended learning course than the average student. In contrast, this study examines the introduction of blended learning for all students without the option to participate. Third, most blended learning interventions have mixed students’ time in a course between an online component that the student can perform off-campus and an in-person section for either a lecture or a discussion section (Alpert et al., 2016, Joyce et al., 2015, Bowen et al., 2014). This paper examines a model in which students spend all of the course time working online in an on-campus computer lab with instructors available to answer questions.
One working paper to date has examined a computer-based intervention in remedial college courses. Boatman (2012) estimates the effect of three Tennessee colleges’ redesigns of their remedial math programs by comparing regression discontinuity estimates of the effect of assignment to remediation before and after the redesign. Two of the colleges’ redesigns used modularized, computer-based remediation reforms, similar to the emporium model. In one of these colleges, students were less likely to persist to their second semester after the redesign went into effect; at the other, there were no differences in students’ outcomes. This study builds on this study by examining the introduction of the emporium model at scale in a state community college system.
