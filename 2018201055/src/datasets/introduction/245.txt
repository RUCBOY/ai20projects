With the booming development of new applications and technologies in datacenters, datacenters host massive number of servers that communicate with each other using high speed network links. This requires the network to provide a variety of transmission services (Humeida et al., 2018). For example, bulk transmission services, like backup and file sharing applications, need reliability and high throughput, while online services, such as web search and video streaming, require low end-to-end latency (Benson et al., 2010, Chowdhury et al., 2016). Currently, most of the applications use the Transmission Control Protocol (TCP), which is popular in the Internet, to transmit data. However, it has been reported that TCP substantially underutilizes network bandwidth over the datacenter networks (DCNs) (Alizadeh et al., 2010, Shan et al., 2018). A typical problem is referred to as the TCP incast (Nagle et al., 2004).
TCP incast is essentially caused by buffer overflow resulting from simultaneous many-to-one transmission pattern which is common in DCNs. Therefore, recent years have witnessed a surge of interest in TCP incast. DCTCP (Alizadeh et al., 2010) is the first congestion control protocol designed specifically for the DCNs. DCTCP leverages marking scheme which is based on Explicit Congestion Notification (ECN) to provide congestion feedback from the switch to the sender. Using this ECN feedback technology, the sender can adjust its congestion window and maintain a low end-to-end delay. After that, many protocols, such as D2TCP (Vamanan et al., 2012), L2DCT (Munir et al., 2013), and DEMT (Lu et al., 2018), are proposed as an enhanced DCTCP to control the switch queue length for achieving low-latency transmission. However, these ECN-based TCP protocols face two crucial issues. First, due to the highly dynamic traffic load, it is difficult to set a proper threshold for marking scheme despite a guideline for choosing threshold (Alizadeh et al., 2010). Second, it introduces significant challenges in the actual deployment because it requires ECN support, which is not universally available in the switch, and modifications at both senders and receivers. Some efforts have been proposed to address first issue by setting appropriate thresholds including dynamical threshold (Lu et al., 2018, Wang et al., 2020), dual thresholds (Majidi et al., 2020a), and Multi-Queue threshold (Majidi et al., 2020b). But, these methods only take into account the queue length or global share buffer without considering the characteristics of flows. For the second issue, the latency based congestion feedback methods are proposed.
The end-to-end delay is a popular congestion feedback to detect network congestion in the wide area network (WAN) (Brakmo and Peterson, 2006, Wei et al., 2006). In the beginning, this congestion signal is supposed to be unsuitable for the datacenter networks since the round-trip time (RTT) in DCNs is the orders of magnitude of the microsecond granularity and it is too sensitive to distinguish the network congestion (Alizadeh et al., 2010). With the in-depth researches in recent years, a great deal of work (Mittal et al., 2015, Lee et al., 2017, Kumar et al., 2020) based on the delay feedback has been proposed by using either software low latency scheme or hardware technology. However, the protocols mentioned above need high-precision timer and complex computation. Moreover, DC-Vegas (Wang et al., 2015) points out that the delay-based congestion control algorithm performs well for decreasing end-to-end delay but poorly in incast scenarios because of not having enough time to collect adequate queue samples. Therefore, we argue that it is not suitable to use end-to-end delay alone to design the TCP congestion control for DCNs.
Besides, as we know, DC-Vegas is a good attempt to combine delay feedback and ECN marking scheme to solve the TCP incast in DCN. However, DC-Vegas also leverages fixed ECN threshold which will lead to poor network performance.
Inspired by DCTCP and DC-Vegas, we combine the end-to-end delay, the concept of ECN marking scheme, and the characteristics of flows to design a new TCP protocol for mitigating incast in DCN environment. To this end, in this paper, we propose a Flow-Aware Marking and Delay-based TCP algorithm in DCNs, referred to as FAMD, to maintain a stable transmission delay in the context of the highly dynamic traffic load. FAMD deploys ECN-like mechanism in the sender stack using end-to-end latency. But due to the drawback of the fixed ECN marking threshold, we further propose a flow-aware adaptive threshold adjustment algorithm, referred to as FATA, to achieve good generality for our FAMD in different scenarios. FATA not only exploits adaptive and dynamical threshold method to suit for dynamic DCN traffic, but also makes this threshold aware of the characteristics of flows. Finally, we discuss how to choose appropriate parameters for FATA through a theoretical analysis. The deployment of FAMD only needs to update senders’ TCP stack based on delay-based protocols, i.e., TCP vegas. Compared with DCTCP and DC-vegas, FAMD takes into account both end-to-end delay and dynamic marking scheme, thus relieving TCP incast problem and achieving high throughput as well as low flow completion time (FCT).
The main contributions of this paper are summarized as follows.

1.To provide the high throughput and the low-latency transmission with the highly dynamic and burst traffic, we propose FAMD, which is deployed at sender and integrated with the advantage of marking scheme and end-to-end delay.2.To eliminate the drawback of fixed threshold scheme, we propose FATA by tuning the marking threshold dynamically and flow-aware to avoid the unnecessary queueing delay and maintain high link utilization at the same time. Besides, theoretical analysis demonstrates how to choose appropriate thresholds.3.We evaluate FAMD based on ns-3 simulator and the results manifest that our proposal can keep good throughput and low packets loss ratio while it decreases the average flow completion time.
The rest of paper is organized as follows. Section 2 reviews related work. Section 3 presents our basic idea and design details of FAMD algorithm. Section 4 conducts extensive simulations to validate the performance of FAMD. Finally, Section 5 concludes this paper.
