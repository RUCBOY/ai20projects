Multimodal learning is applied in many fields [1], [2], [3], [4], [5], [6]. Multimodal machine translation (MMT), which is a branch of multimodal learning, aims at combining text data with information from other modes, e.g. image or text in distinct languages during the translation process. However, how to combine those multimodal information is still a challenging issue.
For machine translation, it will help to learn underlying semantic representation across modes by thinking multiple pair encoding–decoding tasks as MMT and thus improve the performance of translation. If we can learn the aligned semantic relationship among different modes, the performance of translation will be improved. A naive approach is to concatenate the word embedding with the image embedding [7]. Many applications have demonstrated that joint learning multiple tasks can enhance the performance on the single related tasks. There are already efforts on multitask machine translation [8], [9], but they can hardly obtain the shared semantic alignment relationship across different modes. From the view of [10], domain invariance is necessary for a learned representation. In the MMT context, synonymous data from multiple modes, represented by various domains, should contain consistent information.
The ambiguity brings semantic uncertainty, which is regarded as a key organizing principle throughout language [11]. Variational models are successfully applied in neural machine translation to model uncertainty, most of which introduce a continuous latent variable to explicitly model underlying semantics of source sentences [12], [13], [14], [15]. They trained an end-to-end variational encoder–decoder model. However, these works try to approximate the posterior distribution p(z|x,y) where z, x and y respectively denote the latent representation, source sentences and target sentences, and cause a discrepancy between training and prediction, since y is not available during the prediction stage.
In MMT, another problem worth noting is that semantic richness of image data may lead the directly learned latent representation to contain too much redundant information. For example, the photos depicting a little boy running may differ in the background. Some backgrounds are grass, and some are streets. The redundant background information may be encoded into the underlying semantic representation, which influences the effect of MMT systems. Therefore, from our perspective, a reasonable encoder–decoder framework should be bottleneck-like and filter out irrelevant information. This urges us to design the model based on information bottleneck theory [16], [17], which suggests finding a compressed mapping of the input variable that only preserves useful information on the output variable.
In this paper, we propose a novel variational multimodal machine translation model with the following benefits:

•The proposed model is designed as multitask learning and encodes different source data in corresponding tasks into a shared constrained latent representation space that models the underlying semantics. The divergence of latent representations for various modes is reduced as much as possible to enhance domain fusion.•Information bottleneck theory is adopted in the encoder–decoder framework, and thus the learned latent representations contain as little redundant information as possible. We adopt Bernoulli distribution as the variational distribution to approximate the posterior of underlying semantics and use batch normalization (BN, [18]) to construct its prior.•The proposed model eliminates the discrepancy between training and prediction in existing variational translation approaches. It is solved by constructing the encoders to only rely on the source data and thus it is unnecessary to introduce extra inference networks [13], [15] or specific prediction algorithms [14]. Consequently, our approach improves the training and prediction efficiency compared to these variational models. In addition, we use Bernoulli instead of Gaussian as the variational distribution to avoid additional fully-connected layers for obtaining mean and variance of Gaussian approximation posterior.
