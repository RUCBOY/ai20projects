This paper devotes to the task of radiologist-level report generation based on spinal images in the field of spine radiology directly and automatically. Automated spinal medical report generation is a novel yet fundamental task in the domain of artificial intelligence (AI) in healthcare. Nowadays, multiple spinal diseases not only have deteriorated the quality of life but have high morbidity rates worldwide. For instance, Neural Foraminal Stenosis (NFS) has attacked about 80% of the elderly population  (Rajaee et al., 2012). In daily radiological practice, radiologists still rely on laborious workloads to prepare tedious medical diagnosis reports through analyzing spinal medical images manually. Time-consuming medical report generation leads to the problem of the delay of a patients’ stay in the hospital and increases the costs of hospital treatment  (Vorbeck et al., 2000). In contrast, automatic report generation systems would offer the potential for faster and more efficient delivery of radiological reports and would accelerate the diagnostic process  (Rosenthal et al., 1997). Therefore, automatic report generation is pivotal to expedite the initiation of many specific therapies and contribute to relevant time savings. It could help spinal radiologists from laborious workloads to a certain extent.
To date, Computer-Aided Detection (CADe) and Computer-Aided Diagnosis (CADx) techniques in the medical image analysis community have made significant achievements and even can be on par with human experts  (Esteva, Kuprel, Novoa, Ko, Swetter, Blau, Thrun, 2017, Han, Wei, Zheng, Yin, Li, Li, 2017). However, most of them cannot achieve radiological report generation, let alone the most-related spinal image analysis approaches  (Han, Wei, Leung, Chung, Li, 2018a, Han, Wei, Leung, Nachum, Laidley, Li, 2018b, He, Landisa, Leunga, Warringtona, Shmuilovicha, Lia, 2017a, He, Lum, Sharma, Brahm, Mercado, Li, 2017b, Yao, Burns, Forsberg, Seitel, Rasoulian, Abolmaesumi, Hammernik, Urschler, Ibragimov, Korez, et al., 2016). Thus, the topic of automated spinal medical report generation based on medical images is still under-explored. Besides, magnetic resonance imaging (MRI) is one of the most practical examinations in the clinical diagnosis of spinal diseases as it is better to demonstrate spinal anatomy  (Kim et al., 2015). Therefore, this paper is devoted to the radiological report generation based on spinal MRI images to support clinical decision making.
However, automated spinal report generation is incredibly challenging because it is an extremely complicated task. Like the manual spinal report generation, the automated way mainly involves two subproblems: (1) analyze spinal MRI images to detect all the spinal structures and (2) discover the causal effect between detected spinal diseases to write final diagnostic reports. On the one hand, the subproblem of analyzing spinal MRI images faces two main difficulties from structural complexity and ambiguous correlations. Furthermore, spinal structures have complexity and variability, as illustrated in Fig. 2. More specifically, each lumbar spine MRI image at an average has 17 target structures composed of six neural foramina, six intervertebral discs, and five lumbar vertebrae. Each type of spinal structure has various scales across normal and abnormal structures  (Han et al., 2018b). Spinal structures also exist ambiguous spatial correlations that impede predicting consistent detection results. On the other hand, the subproblem of casual effect analysis mainly faces the difficulty of inexact supervision due to the lack of annotated data. This weak supervision pushes us to conduct unsupervised causal effect analysis, which contributes to the difficulty in discovering the pathogenic factors of target spinal diseases precisely  (Han et al., 2018d).
To solve these problems, we formalize the task of spinal medical report generation as a human-like learning process that involves semantic visual perception and high-level symbolic reasoning. More precisely, we propose the Neural-Symbolic Learning (NSL) framework that combines deep neural learning and symbolic logical reasoning in a mutually beneficial way, as shown in Fig. 1. NSL learns to detect complex spinal structures through an adversarial graph network as deep neural learning to imitate human visual perception. Based on these discoveries of neural learning, NSL reasons out the causal effect, and further generate unified spinal medical reports through symbolic logical reasoning. The proposed NSL framework can resolve the facing challenges point-to-point. For handling the structural complexity and ambiguous correlations, we design the adversarial graph network that interpolates a symbolic graph reasoning module into a generative adversarial network to segment complex spinal structures with a wide variety and variability accurately. The symbolic graph reasoning module embeds prior knowledge graph into the network to perform reasoning over a group of symbolic nodes whose outputs explicitly represent each spine structure’s different properties. For treating the inexact supervision, we use symbolic logical reasoning approaches that include meta-interpretive learning and first-order logic programming by bringing in background knowledge to remedy the lake of supervision information.Download : Download high-res image (319KB)Download : Download full-size imageFig. 1. An illustration of the proposed neural-symbolic learning framework.Download : Download high-res image (535KB)Download : Download full-size imageFig. 2. A spine image with target structure of analysis, which includes intervertebral disc (D), vertebral (V), and neural foramen (NF).
Combining neural learning and symbolic reasoning for the medical report generation is proper and novel. As we have shown, it is appropriate because this combination imitates the process of manual spinal report generation in the clinic. Theoretically, it is innovative because this combination endows the superiority of the NSL framework that integrates the advantages of neural learning on noisy data processing and the logical reasoning on knowledge representation. In the history of AI research, neural learning and logical reasoning have almost been separately developed  (Zhou, 2019). Neural learning is adept at low-level perceptual tasks but is unable to support secondary reasoning. Simultaneously, logical reasoning does well in high-level symbol reasoning, but it is hard to handle uncertainty knowledge on noisy data. Modern neural learning adopts a probability and connection mechanism for representing over noisy implicit data. In contrast, classical symbolic AI utilizes expressive first-order logic for reasoning over explicitly represented knowledge  (Russell, 2015). For example, neural learning techniques can recognize target spinal structures, while logical reasoning algorithms can reason out the causal effect by integrating human knowledge. Unifying neural learning and logical reasoning would integrate the low-level perceptual ability and high-level reasoning towards robust spinal medical report generation. Accordingly, we formalize the problem of report generation similar to the human decision-making process that bridges perceptual and reasoning strengths in a mutually beneficial way.
In this work, we advance our preliminary attempt (Han et al., 2018a) in the following aspects: (1) propose a new framework that integrates neural learning and logical reasoning in a mutually beneficial way; (2) carry out more extensive experiments on performance analysis, validating the significant advantages of the proposed NSL over existing compared state-of-the-art methods; (3) make a more comprehensive review on medical report generation, providing a technique review on the statistical machine learning and logical reasoning.
The contributions of this paper include:
•We propose a novel framework achieving automated spinal medical report generation. The framework provides, for the first time, a reliable solution by integrating deep neural learning and logical reasoning in the medical image analysis community.•We propose a new graph adversarial network that embeds prior knowledge graph into generative adversarial networks. The proposed network dynamically models the high-level semantic correlations between spinal structures to enhance segmentation accuracy. It can also extend to various medical image segmentation tasks.•We propose a symbolic logical reasoning model that leverages meta-interpretive learning to induce the causal effects between spinal diseases for discovering valuable pathogenic factors, which are beneficial for the pathogenesis-based diagnosis of spine diseases.
We organize the rest of this paper as follows. In Section 2, we review the related works in terms of medical image analysis and involved methodology. We introduce the NSL framework in Section 3. We then present the details of validated datasets, experiment settings, and exhaustive results in Section 4. Finally, we conclude this work in Section 5.
