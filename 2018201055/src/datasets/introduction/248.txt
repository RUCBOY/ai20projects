Software-Defined Networking (SDN) [1], [2] has emerged as a response to the limitations and complexity of the legacy network management. The basic idea of the SDN paradigm is that it separates the control plane from the data plane by offloading control plane functionalities from all network devices (i.e., routers, switches, and Access Points (AP)) to a logically centralized controller. However, due to budget constraints and SDN maturity level, organizations are often reluctant to adopt SDN in practice. For example, Google [3] spent about 8 years to replace its data center infrastructure with SDN devices. Some of the reasons behind the slow migration to an all SDN infrastructure and its implications are discussed in [1], [4]. Instead, the researchers proposed an incremental approach to deploy SDN, replacing gradually the legacy devices with SDN-enabled devices. This strategy is termed hybrid SDN [1] and is a promising avenue that paves the way to a wide adoption of SDN in practice [4], [5].
A hybrid SDN is comprised of both legacy and SDN devices [6]. The legacy network devices are running the legacy network protocols, and the SDN devices run SDN protocols. Due to its unique nature, the hybrid SDN approach offers several challenges, in terms of traffic engineering (TE), loading balancing (LB), energy-efficient routing, SDN nodes deployment, link failure management, and implementation of access control list (ACL) policies [7], [8], [9], [10], [11], [12], [13], [14], [15], [16].
ACL is a filter mechanism deployed at switches’ (or routers’) interfaces and end-system firewalls in order to enforce security. ACL filters the data flows based on predefined rules. One or more predefined ACL rules define the flow matching provisions based on some packet header values (e.g., source/destination IP addresses, transport layer port number, and transport protocol value). Based on the implemented ACL policy, a switch discards or forwards the flow. Moreover, ACL policies enable filtering of unauthorized flows early and adequately protecting the core services. Efficient implementation of ACL policies at switches’ interfaces also helps increase network throughput, reduce end-to-end delay for data flows, and effectively distribute the flows at the edge and backbone network, contrary to other ACL (i.e., end-system firewalls) [17].
Existing approaches have addressed different challenges by proposing various alternative solutions to implement the ACL policies in hybrid SDN efficiently and correctly. Some of these challenges are summarized next.

i.ACL policies disclosure: In a SDN architecture, policies can be declared either by general-purpose or domain-specific languages, e.g., Frenetic [18] and Pyretic [19]. These languages allow operators of diverse types, i.e., parallel and sequential, to make ACL policies. A parallel operator checks the same set of packets against multiple ACL policies simultaneously. In contrast, a sequential operator reviews one ACL policy at a time.ii.Overlapping and conflict in ACL policies: At the controller, declared ACL policies in a network may lead to unforeseen ACL policy violations [20], [21], network reachability problem, packet loss [22], [23], and overlaying and conflict in ACL policies [24] due to different network administrations or even under the same administrator over time.iii.Storing ACL policies at controller: ACL policies can be held at the controller using various methods, like PGA [21]. PGA uses a graph to keep network ACL policies. When a packet arrives, PGA traverses through the graph and generates flow rules from the predefined ACL rules. Additionally, PGA detects redundancy and identifies conflicts among the ACL policies declared at the SDN controller.iv.Where to deploy?: To minimize the unwanted traffic in the network, the ACL policies can be installed as flow rules at the different sets of switches using various criteria. Rashid et al. [13], [14] implement the ACL policies at optimum locations (i.e., switches’ interfaces) in the network such that it minimizes the total number of both implemented ACL policies and unwanted transmissions.v.Proactive or reactive ACL policies installation: The controller can install the ACL policies in either a proactive or reactive manner  [25]. In proactive manner, the controller installs the ACL policies for all users, active or passive, leading to the Ternary Content Addressable Memory (TCAM) memory problem. In contrast, in a reactive way, the controller installs the ACL policies only for active users. Therefore, the reactive approach uses more efficiently the limited TCAM memory at the switches.
We believe that the existing approaches still have limitations. For example, Rashid et al. [13] state that when a link fails, the SDN controller recomputes the locations for the implementation of ACL policies placements to ensure the network behaves correctly. They have assumed that the link failure was received in real-time to the controller in hybrid SDN, which is often not the case in such settings when legacy link failures are considered. The links connected to legacy switches are called legacy links, while the links connected to SDN switches are called SDN links. SDN controller directly gets the real-time link-state information from SDN switches. However, using a legacy routing protocol like OSPF [1], [6], the legacy switches periodically broadcast their link-state information to all the nodes, including the SDN switches in the network.
When an SDN switch receives the link-state information of legacy switches, it sends them to the SDN controller. Thus, it takes a long time to send legacy links information to the SDN controller [4], [6], [7], [26] and the legacy link failure information may not be received at the SDN controller in real-time. When a legacy link, which is far away from a SDN switch, fails and the link failure causes incorrect network behavior (i.e., either a violation of ACL policies by the network traffic or a network reachability problem due to implemented ACL policies on devices’ interfaces) then the network behavior will persist for a longer time until the SDN controller receives the link failure notification and, subsequently, recomputes and implements the ACL policies according to the updated network topology. We attempt to address this problem by predicting the link failure before its occurrence, computing and implementing ACL policies, link failures.
To the best of the authors’ knowledge, the state-of-the-art literature for hybrid SDN (e.g., [13], [14], [21], [27], [28]) overlooks the ACL policy configuration in advance for the case of legacy link failures. This paper proposes the use of Machine Learning (ML) algorithms to predict link failure and, subsequently recompute the ACL policy configuration considering the link failure. More particularly, we propose the use of two ML algorithms (i) Logistic Regression (LR) [29], (ii) Support Vector Machine (SVM) [30] to enable high resiliency to link failure and reduce the number of ACL policy violations. Recent studies show that ML techniques are resilient, flexible, and applicable in the communication network. They can be employed to manage critical issues such as fault management, traffic predication, traffic routing, and network security [31], [32], [33], [34].
The main contributions of this paper are summarized as follows.

•In a hybrid SDN, the SDN controller receives legacy links failure information with delay, creating inconsistency at the SDN controller. The inconsistency leads to network reachability and ACL policy violation problems. PrePass-Flow is proposed to address these problems.•In order to minimize the impact of a link failure in hybrid SDN, PrePass-Flow uses historical link information and predicts the potential link failure. The prediction module in PrePass-Flow employs two supervised ML algorithms, called Logistic Regression (LR) and Support Vector Machine (SVM).•Following failure prediction, PrePass-Flow recomputes the optimum locations for ACL policies considering the link failure and installs the ACL policies such that the network behaves correctly as the link fails.
The remaining paper is organized as follows. The related work is reviewed in Section 2. We present the problem definition and challenges in Section 3 and our proposed PrePass-Flow in Section 4. Section 5 describes the performance evaluation of the proposed PrePass-Flow solution and conclusions are drawn in Section 6.
