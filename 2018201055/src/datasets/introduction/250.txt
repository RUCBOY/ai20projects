In the era of big data, video has become one of the most important carriers of data as the number and the volume have both increased rapidly in daily life. Video summarization as a good way to manage these videos (e.g., video searching and video browsing) [1], [2] has received much interests in the field of computer vision and pattern recognition. It essentially selects the key shots of a video as the summary, and these key shots are expected to convey the most important information of video. To obtain the summary, traditional methods often use hand-crafted features which are then processed by unsupervised models [3], [4] or supervised models [5], [6]. Nevertheless, these models can not be trained efficiently in an end-to-end manner and hand-crafted features are incapable of encoding high-level semantic information of video, so they may not work well for those videos with diverse and complex scenes in the real-world applications.
In the last decade, many contributions have been devoted to exploring the recurrent encoder-decoder architecture which utilizes Recurrent Neural Networks (RNNs) [7] and Long Short-Term Memory (LSTM) models [8], [9]. These models are able to learn high-level feature representation of data, thus generating video summary with high quality. Actually, recurrent neural networks can inherently capture temporal dependency by encoding sequence information of video frames, and enjoy the widespread success in practical tasks, e.g., machine translation [10] and action recognition [11]. However, there are several following drawbacks: (1) it is difficult for RNNs to make full use of GPU parallelization, due to the fact that the generation of its hidden state ht for the t-th frame depends on the previous hidden state ht−1; (2) gated RNN models like LSTMs cannot well model long-range dependency across video frames since the gated mechanism will lead to serious decay of the history information inherited from those frames appearing at early time; (3) in some scenarios, e.g., the video news broadcast on one topic usually consists of several edited videos from different sources, there may exist semantic discontinuity within video sequences, which is very challenging and RNNs cannot well resolve this problem.
To alleviate the above problems, we exploit the temporal context relations among video frames from the pairwise relation perspective. In particular, a pairwise similarity matrix is designed to model multi-scale temporal relations across frames by storing the context information. The rationale behind this idea is that temporal relations of video frames can be modeled by the pairwise similarity between two frames regardless of their distance. That is to say, unlike RNNs that model long-range dependency using history information of early frames, it is unnecessary for our scheme to go through all the intermediate frames between source frame and target frame. Instead, we compute the pairwise similarity matrix directly at limited computational cost, which makes it quite efficient and suitable for GPU parallelization.
In another aspect, a good video summary should include those shots with the most diversity and the most representativeness, i.e., the selected key shots with higher importance scores should reflect diversified semantic information of video. Our human beings always tend to summarize video after scanning all the frames, which inspires us to imitate this process and summarize video by fully attending to the complete video as attention mechanism is prevailing and successful in sequence modeling [12]. Therefore, we develop an efficient video SUMmarization model with Global Diverse Attention called SUM-GDA using pairwise temporal relation, to quantify the importance of each video frame and simultaneously promote the diversity among these frames. In concrete, the proposed GDA mechanism is used to model the temporal relations among frames by leveraging the pairwise similarity matrix, where each row vector is closely related to the attention level and its lower entry indicates a higher dissimilarity weight. Hence, more emphasis should be put on the corresponding pairwise frames in order to promote the diversity among video frames. As a result, all stacked row vectors can reflet different attention levels of the whole video from a global perspective.
The overview of SUM-GDA is depicted in Fig. 1, where the key shots of input video are selected according to the frame scores that reflect the importance of the frame to the whole video. These scores are obtained by score regression with global diverse attention mechanism, which is the core component of the proposed model. In this work, we have explored both supervised and unsupervised variants of this model, which are evaluated by conducting a lot of interesting experiments on several video data sets including SumMe [6], TVSum [13], and VTW [14], in different data settings, i.e., Canonical, Augmented, and Transfer. Empirical studies demonstrate that the proposed method outperforms other state-of-the-art approaches in both supervised and unsupervised scenarios. Furthermore, the selected key shots for some randomly sampled videos are visually shown to further validate the effectiveness of the global diverse attention mechanism.Download : Download high-res image (504KB)Download : Download full-size imageFig. 1. The Overview of SUM-GDA. It exploits the global diverse attention mechanism to diversify the selected frames as the final summary. In Row3: The heights of colorized bars represent different measurements of frames, i.e., attention weights, which are computed as dissimilarity scores based on pairwise information within video. Such kind of different attention weights can reflect the diversity of frames in a global view. These diverse attention weights are utilized to predict the importance score of each frame in the video. In Row2: The light blue bars represent the predicted importance scores of video frames, and the dark blue bars indicate the frames selected for generating summary.
In short, the main contributions of this work can be highlighted in following aspects:
•A global diverse attention mechanism is developed to model the temporal dependency of video by using pairwise relations between every two frames regardless of their stride magnitude, which helps well handle the long-range dependency problem of RNN models.•By directly calculating the pairwise similarity matrix that reflects the relations between source frame and target frame, SUM-GDA only needs very limited computational costs so that it is inherently much more efficient than other competing approaches.•The proposed SUM-GDA model is explored in supervised, unsupervised and semi-supervised scenarios. Empirical studies in terms of both quantitative and qualitative views are provided.•The diversity of generated summaries and the influence of optical flow features are both investigated.
The remaining parts are organized as follows. Section 2 generally reviews some closely related works and Section 3 introduces the global diverse attention mechanism and the SUM-GDA model in two scenarios. Then, Section 4 describes a number of experiments carried out on several data sets and reports both quantitative and qualitative results as well as rigorous analysis. Finally, we conclude this paper.
