The amount of image data is growing rapidly in real-world and so is its growth rate. Recently, Infotrends presented a study, revealing that during 2016, camera and mobile device users captured more than 1.1 trillion images (InfoTrends InfoBlog, 2019) and according to this study, this number will increase to 1.4 trillion by 2020. Most of these images are now stored in cloud servers and published on the internet. Similarly, another research demonstrates that over 1.8 billion pictures have been uploaded to the social platform such as Facebook and Instagram (Firstpost, 2019). On the other hand, there are several other cameras installed which are used for various tasks such as traffic monitoring, and visual surveillance etc. This type of image data is widely used in various real-time applications such as visual surveillance, object identification, detection and classification using computer vision techniques. In order to automatically manage this data, image content information plays an important role for better understanding of digital image content. In this field of computer vision applications, the object detection is considered as one of the most important task which can significantly improve the performance of computer vision based applications such as object tracking, and license plate recognition etc. In order to develop the complete model for image understanding, object detection, localization and classification are the main objectives where object detection consists of various subtasks such as face detection (Ohn-Bar and Trivedi, 2016), pedestrian detection, tracking (Dollar et al., 2012), & skeleton detection (Bai et al., 2009). Fig. 1. shows a pictorial difference between object classification in Fig. 1(a), localization in Fig. 1(b) and detection in Fig. 1(c). For this task of image understanding, image content information is a useful paradigm which can bridge the sematic gap between image pixel information and human understanding of the same images. For this semantic gap analysis, object detection is a promising technique which provides semantic understanding of diverse images and videos for various computer vision tasks such as face recognition (Yang et al., 2002), crowd behavior detection (Mehran et al., 2009), image classification (Harzallah et al., 2009) and autonomous driving vehicles (Chen et al., 2017) etc.Download : Download high-res image (200KB)Download : Download full-size imageFig. 1. Representation of image classification, object localization and detection.
Object detection is a challenging task due to image complexity and multiple object classes present in the image. Generally, the object recognition techniques can be divided into three main categories as top-down, bottom-up and combination of these two approaches. According to the concept of top-down approaches, generally it uses training process to model the class-specific features and defines the configurations (Zhang et al., 2008, Vidhya and Itti, 2006). Apart from this, the bottom-up approaches computes the features starting from low-level or mid-level from the input image based on the edges and segments (Goferman et al., 2010, Harel et al., 2007). Top-down approaches suffer from more number of false positives because the features are extracted and matched locally. Similarly, the bottom-up approaches require efficient techniques for segmentation. Hence, a third approach is developed which combines top-down and bottom-up approaches to maintain the consistency in segmentation and minimizes the grouping tasks.
Recently, several computer vision system based object detection models are introduced such as Deep saliency (Li et al., 2016), scalable object detection (Erhan et al., 2014), and Pvanet (Kim et al., 2016) etc. These systems suffer from various issues such as viewpoint variation, occlusions, pose variations and lighting conditions which increases complexity in localization. Generally, object detection and localization are used for identifying the object and localizing the identified object in the given image and finding its corresponding category is the sub-task of object classification. Based on these tasks, the conventional object detection process is categorized into three main categories such as region detection, feature extraction and classification.
Region detection process is used to identify the region of interest in which object detection scheme is to be applied. The feature extraction phase extracts the features to obtain the semantic and visual information about the object present in identified region. Several feature extraction processes are present in literature such as SIFT (Alhwarin et al., 2008), Haar features (Lienhart and Maydt, 2002) and HoG features (Geismann and Schneider, 2008). However, designing the robust feature extraction for all types of objects is a tedious task due to the illumination variations and background complexities. Apart from this, the object classification models are required to distinguish the object categories to perform visual recognition of the objects. The traditional methods of object detection and recognition are based on the local features and follow a poor learning architecture. In these approaches, bounding boxes are generated using sliding window model which provides inaccurate and inefficient results and these methods are based on the local features and follow a poor learning architecture thus the semantic gap cannot be mitigated efficiently.
In recent years, object detection performance has improved significantly due to the success of convolutional neural network (CNN) in the computer vision field. Current techniques adopt the CNN for object detection and various other real-time applications such as R-CNN (Szegedy et al., 2015), deep CNN (Simonyan and Zisserman, 2014, He et al., 2016, Ioffe and Szegedy, 2015), Deep Neural Network (DNN), and DeepID (Ouyang et al., 2015). DNNs and CNNs are the most effective solution for object detection compared to existing techniques because these models have deep architecture which can learn features efficiently, moreover, the learning algorithms are more robust in these models which do not require any manual feature designing models. Similarly, other variants of CNN such as R-CNN delivered the great performance by combined optimization of classification and bounding box regression tasks (Kang et al., 2017), Fast R-CNN utilizes additional sub-network to generate the region proposals, similarly, YOLO approach uses fixed-grid regression (Redmon et al., 2016) for object detection. All these approaches shows significant improvement in the object detection and recognition.
As discussed before these techniques are widely used for various applications such as face detection, recognition, autonomous driving, surveillance systems, pedestrian detection, etc. These techniques achieve better performance but the variable dimension of output is a main issue which can degrade the training performance because the machine learning tasks requires fixed dimension of input and output for training. There is a trade-off between accuracy and system performance according to the applications. Hence, achieving the robust performance and complexity is the key component which need to be addressed. Similarly, camouflaged objects also degrade the performance because the object foreground and image background texture are similar and thus it is difficult to identify the foreground objects (Babaee et al., 2018). Camouflaged objects can be identified by applying efficient segmentation techniques such as subSENSE (St-Charles et al., 2015). Several techniques are presented in the past to segment the camouflaged objects from the video sequence using motion segmentation approaches but less amount of works have been carried out for camouflaged object detection in images (Singh, 2013).
1.1. Problem definitionIn multiple online and offline applications, computer vision-based methods are commonly embraced. Recently, deep learning (including deep neural networks, deep belief networks, recurrent neural networks, and convolutional neural networks) based systems have enhanced computer vision applicationâ€™s precision. On the other side, the detection and classification of image-based objects is a tedious job that has attracted research community because of their varied applications. Convolutional neural network based schemes are presented to address this issue but accuracy of detection and recognition is a key issue. In addition, identification of camouflaged objects is also a severe problem that can degrade the efficiency. The camouflaged objects have comparable background and foreground, and the differences in pose and lighting conditions causes the detection module to be additionally more complex.
1.2. Contribution of workIn this work, we used computer vision-based systems to focus on object detection and recognition. Several methods have been described in the past, but it is difficult to achieve the required precision for identification and recognition. In addition, camouflaged object detection, owing to its difficult complexity has received enormous appeal from the research community. We present a novel strategy based on saliency detection, Faster-RCNN model and generations of proposals for object detection to solve this problem. The proposed approach uses saliency detection method for proposal generation whereas bounding box regression and loss are computed later to detect the object. Finally, a CNN-based training strategy for object recognition is integrated. The proposed approach is called as saliency guided faster RCNN for object detection and recognition.
1.3. Article organizationThe rest of the manuscript is organized as follows: Section 2 presents brief literature review about recent techniques of object detection and recognition, Section 3 presents proposed solution, experimental study and comparative analysis is presented in Section 4 and finally, Section 5 presents concluding remarks.
