With the dramatic increase in the size of collected and stored data that is known as big data, the need for building data-driven applications for analyzing large datasets becomes increasingly essential in many areas of science and business. The current Internet-based applications such as Internet of Things (IoT), smart cities, and social networks produce huge amount of data and the processing has to be fast. The input data for many of these applications are often distributed in different locations. Moreover, in many cases, the geo-distributed data is generated at even much higher speed compared to the actual data transfer speed [1], [2], for example, data from modern satellites [3].
There are three common reasons for having geo-distributed data: (i) many organizations work in different countries and create local data in different parts of the world; (ii) organizations may prefer to use multi-clouds to enhance their reliability, security, and processing [4], [5]; (iii) data is often stored close to where it is produced and needs to be processed in other locations, for example, sensor data is stored close to the sensors and needs to be processed in the cloud infrastructure.
The ability to analyze and process geo-distributed data has become an important and challenging mission in many domains. Many applications need to process and analyze a massive amount of geo-distributed data [6]. For example, a bioinformatics application that analyzes existing genomes in different laboratories, a smart surveillance application that analyzes video feeds from distributed cameras, a monitoring system that inspects log files from distributed servers, or a social networking application that finds common friends of its users.
Processing massive amount of data can be done best by running many parallel tasks operating on various parts of the dataset. Several frameworks have been proposed for big data processing, for example, Hadoop [7], Spark [8], Storm [9] and Flink [10]. Thus, in this paper, we focus on the MapReduce programming model, a well-accepted model for big data processing. The traditional frameworks supporting MapReduce (e.g., Hadoop and Spark) are not designed to process geo-distributed data. For instance, Telegram servers are spread worldwide or Facebook maintains a growing number of data centers across the world and both of them use the MapReduce for processing their batch data [11], [12]. In practice, a naïve solution of gathering all raw data in a single cluster to process geo-distributed data is used, which is not scalable. In such a naïve solution, data transfer between clusters can become a bottleneck. Moreover, it is also unreasonable to move the raw data to a single location when the output results of the computation in each cluster is smaller than its input data [13], [14], [15]. Thus, two other approaches to facilitate geo-distributed MapReduce are proposed in the literature which we call them Hierarchical and Geo-Hadoop approaches [16].
The Hierarchical and Geo-Hadoop approaches are far from perfect since they require a large amount of data transfer over the Internet. In the Hierarchical approach, each cluster processes data independently, then the entire results are transmitted to a single cluster (global reducer), and the final process is executed on a single global reducer. This approach requires a significant amount of data to be transferred to a single cluster. In the Geo-Hadoop approach, all required inter-cluster transfers are performed in the shuffle phase of the MapReduce process. It is needless to say that in the geo-distributed MapReduce the inter-data center data transfer is much slower than the data transfer among the cluster nodes of a single cluster. Therefore, this approach, in particular, increases the processing time for many applications whose intermediate results are more than the final results. For example, the invertedindex application with an input data of 1.4 GB generates 4.5 GB intermediate data, as shown in [15].
The use of frameworks which support only the originalMapReduce model do not provide acceptable performance for processing geo-distributed data in multiple data centers. The MapReduce model needs to be extended in order to provide appropriate solutions for processing data scattered across multiple data centers. Therefore, in this paper, we aim to tackle this issue and address the research problem of “how to reduce the total data transfer over the Internet in processing big data volumes scattered over multiple geographically distributed data centers?” We develop Cross-MapReduce to answer three important questions: (i) How many clusters should be selected as global reducers and which clusters should be selected? (ii) What fraction of the results should be sent to the global reducers? (iii) What are the best parameters for selecting a global reducer?
Cross-MapReduce is inspired by the integration of Hierarchical and Geo-Hadoop approaches to reduce inter-cluster data transfers. Cross-MapReduce runs jobs in each cluster independently, similar to the Hierarchical approach. In the next step, instead of transferring all the results to a single cluster, like Geo-Hadoop approach, it shuffles the results that are required between clusters. The primary purpose of Cross-MapReduce is to cover the weaknesses of both Hierarchical and Geo-Hadoop approaches. Moreover, Cross-MapReduce is a framework-independent approach that can work with any other frameworks supporting MapReduce such as Spark and Hadoop. In fact, Cross-MapReduce is a framework which manages several clusters each capable of supporting MapReduce.
Our key contributions in the Cross-MapReduce framework are as follows:

•Gshuffling: We present a novel process called Gshuffling to distinguish between inter-cluster traffic over the Internet and intra-cluster traffic within the cluster. In MapReduce jobs, the volume of intermediate data is often greater than or equal to the volume of the final results. Thus, in Cross-MapReduce, the data transfer in the shuffle phase of MapReduce is divided into two phases. The first phase is between nodes of each cluster (intra-cluster), which is performed independently within each MapReduce cluster. The second phase that includes the inter-cluster transfer over the Internet which is performed via Gshuffling. Gshuffling finds multiple global reducers in a way that the amount of data transfer between clusters is reduced.•GRG: In order to transfer the required data between clusters, as part of Gshuffling process, we propose and build a novel graph called Global Reduction Graph (GRG). GRG represents the required inter-cluster data transfer and determines the number and the locations of global reducers. For the subsequent reduce cycles, instead of transferring the entire results, Cross-MapReduce identifies the portion of the results which is required by the global reducers.•Load balancing: We propose a new load balancing algorithm to increase performance and spread tasks among clusters. All the existing Hierarchical methods select a single global reducer for the final processing. However, Cross-MapReduce selects multiple global reducers to reduce overall data transfer and balance it between global reducers.
The rest of the paper is organized as follows: Section 2 describes the MapReduce programming model. In the next section, we discuss the problem tackled in this research. The Cross-MapReduce framework is proposed in Section 4. Section 5 presents the experimental results. Section 6 covers the study of existing methods and related work, and the final section concludes the work.
