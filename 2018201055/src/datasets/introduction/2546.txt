Head pose estimation has been applied to broad applications in human-computer interactions, e.g. gaze detection, driving assistance, disabled assistance, and entertainment. Head pose is also used to understand human attention, behavior or intention, which has been studied and examined extensively in cognitive psychology and neurophysiology community [1].
Over the past several years, head pose estimation remains an attractive research topic, since it is still challenging due to the diversity of the head appearance caused by the head motion and various head pose changes, such as facial texture, inhomogeneous illumination, partially occlusion, etc. A number of algorithms have been proposed to address the head pose estimation problem, and a good survey can be referred to [2].
In general, the existing approaches can be divided into two streams: classification and regression. Classification approaches aim to classify the head pose into a discrete space, that is, estimating the head pose by assigning a discrete pose category label to each input. These approaches are relatively robust to large head pose variation but with sparse solution space, e.g. 15∘ intervals for each category. On the other hand, regression approaches usually estimate head pose by fitting a regression model on training data to output continuous angles. The results of these regression approaches can reflect small changes of head pose. However, employing individual regression model for accurate continuous head pose estimation increases model complexity.
To address the challenge, we approach our method in a coarse-to-fine manner, which leverages the robustness of the classification method and the sensitivity of the regression method to small changes of head pose. In particular, we first determine the specific category of the input image, thus narrowing down the solution space. Then a regression network is selected on the basis of the output category to estimate accurate pose parameters. The coarse-to-fine cascade enables our approach to increase the robustness of head pose estimation without increasing the model complexity and the difficulty in training process of the traditional regression networks. The two sub-networks are achieved via a deep learning model and share the same full-image convolutional feature map and perform joint learning, thus achieving computation efficiently.
Although, CNN techniques have shown good performance on a number of tasks, a major challenge on their application for head pose estimation is obtaining sufficient annotated head pose data, especially the data with variations of head appearance (e.g. expression, race, age, and gender), and environmental factors (e.g. occlusion, noise, and illumination). Previously released head pose datasets, such as Biwi Kinect Head Pose Dataset [3] and Pointing’04 dataset [4], consist of around 15k and 3k images, respectively. The limited amount of annotated head images in these datasets makes it hard to apply CNN techniques. We devise an approach for synthesizing realistic head pose images with annotations to overcome the obstacle of insufficient annotated data in head pose estimation.
Our main contributions are summarized below:
(1)A new deep learning framework following the coarse-to-fine strategy for estimating head pose. We model the estimation with a cascade Coarse-to-Fine process, where the accurate pose parameter estimation is followed by rough pose classification. Both tasks are achieved via deep learning models, which share the same full-image convolutional feature map and perform joint learning. The proposed method spread the network complexity and training burden of traditional regression networks.(2)Synthetic head pose image generation. A synthetic head pose image rendering pipeline is introduced in our approach for breaking the limitation of head pose image quantity, increasing the diversity of the head pose images with high resolution (e.g., different illumination conditions, motion blur, and occlusion), and helping to improve the performance of estimation results. In addition, we conducted an experiment to verify the compatibility between synthetic data and real data. We generate a dataset with a collection of 310k head pose images.(3)Easily expandability and promising head pose estimation results. The trained head pose estimation network yields very promising results on both synthetic dataset and real dataset. Moreover, the proposed deep learning framework and image rendering pipeline can be easily extended to handle the task of depth head pose image estimation.
