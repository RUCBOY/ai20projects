In the era of big data, with streaming applications such as social media, surveillance monitoring and real-time search generating large volumes of data, efficient Data Stream Processing Systems (DSPSs) have become essential. More than 30,000 GB of data is generated every second and the rate is accelerating [2]. According to IBM,2  90% of the data that existed in 2012 was created in the two years prior. These data sources need to be analysed to gain insights, and find trends such as determining the most frequent events for a continuous dataflow occurring over a certain period of time. DSPSs are designed to process such dataflows, by operating on data streams, which are a continuous, unbounded sequence of data items, with a number of data attributes, processed in the order in which they arrive. In comparison, batch processing systems store the data before performing ad hoc queries, which is not suited for real-time analysis. A general purpose DSPS faces a number of competing challenges, such as task allocation, scalability, fault tolerance, QoS, parallelism degree, and state management, among others. It is not possible to optimise for all of the challenges at the same time as there will be tradeoffs. The specific streaming application requirements determine which challenges need to be addressed. While each of these challenges are current areas of research, we focus on scheduling in this paper as low latency response times are a consistent priority across many streaming applications. The scheduling policy determines how tasks are distributed in the DSPS, which can have a significant impact on the performance metrics of the system such as tuple latency (the time taken to process a tuple) and system throughput (the number of tuples processed in a given time) [3]. A scheduling policy needs to strike a balance between system performance, the use of system resources and run-time overhead.
Finding an optimal placement for DSPSs is NP-hard [4], [5], [6]. Thus, approximate approaches are required to improve the performance of DSPSs [7]. An efficient task scheduler will adapt to changes in the communication pattern of a streaming application, ensuring that the communication between compute nodes, referred to as inter-node communication, is minimised. Specifically, by placing highly communicating tasks on the same node, communication between compute nodes can be reduced [8], [9], [10], [11]. The term “highly communicating tasks”, which is used throughout this paper, refers to a pair or group of tasks which exchange a larger amount of data than other neighbouring tasks. Additionally, prioritising the use of higher capacity compute nodes allows more highly communicating tasks to be co-located within a compute node, requiring fewer nodes to be used, which helps to further reduce inter-node communication. To achieve this, the scheduler monitors the run-time communication of a streaming application, logging the communication rates between tasks and tasks’ load, which is then used when rescheduling.
Existing work on task schedulers that aim to minimise the inter-node communication have a number of limitations. Firstly, the compute nodes might be underutilised, which results in using more compute nodes than required. Secondly, many of the schedulers are not designed for heterogeneous clusters, which is an important requirement for many deployments, as they evolve over time, as new hardware is added. Further, a multi-user homogeneous cluster where not all of the system resources are available can be viewed as a heterogeneous system. Finally, offline schedulers are incapable of adapting to the run-time changes in the traffic patterns of streaming applications. In this paper, we aim to address these limitations and propose I-Scheduler, for DAG-based DSPSs, which partitions the DAG in order to minimise the communication between each part, such that inter-node communication is minimised when each part is assigned to a compute node. The contributions of this paper are summarised as follows:

•We propose I-Scheduler, for homogeneous and heterogeneous DSPSs, which reduces the size of the task graph by fusing highly communicating tasks, allowing mathematical optimisation software to be used to find an efficient task assignment. A fallback heuristic is also proposed for cases where the optimisation software cannot be used, which iteratively partitions the application graph based on the capacity of the heterogeneous nodes and assigns each partition to a node with a relative capacity.•We evaluate the communication cost of I-Scheduler by comparing it to a theoretically optimal scheduler, implemented in CPLEX, when run on three micro-benchmarks, each representing a different communication pattern. The results show that I-Scheduler can achieve results that are close to optimal in a number of different cluster configurations.•We implement the proposed scheduler in Apache Storm 1.1.1 and through experimental results, show that our proposed scheduler can outperform state of the art R-Storm [9] and Aniello et al.’s ‘Online scheduler’ [8] (for brevity we refer to this scheduler as OLS in this paper). The results show that I-Scheduler outperforms OLS, increasing throughput by 20%–86% and R-Storm by 3%–30% for the real-world applications.
The rest of this paper is organised as follows. In Section 2, we discuss key related work. We then present the problem definition in Section 3. Section 4 describes our proposed scheduler, which is then followed by a comparison with an optimal scheduler in Section 5. Section 6 evaluates our proposed scheduler with two real world applications. Finally, Section 7 concludes the paper.
