Visual object tracking is an important and fundamental problem in computer vision and pattern recognition area [1], [2], [3], [4], [5], [6], [7], [8]. It has wide applications such as video surveillance, robotics, human computer interaction, and medical image analysis [1], [2]. Recent years have witnessed rapid advancements in visual tracking, but it is still a challenging task partly due to the large changes of object appearance caused by a lot of challenge factors, like pose, illumination, deformation and occlusion. Most visual tracking methods mainly adopt the tracking-by-detection paradigm, which aims to conduct target tracking by classifying the target object against its background from frame to frame. The key issue for this kind of method is how to maintain a classifier during the tracking process. Usually, the classifier is trained in the first frame using the ground truth bounding box, and updated in the subsequent frames using tracking results. However, the bounding box can not describe the target object accurately due to irregular object shapes, scale variations and occlusions, and the trackers will be disturbed by the introduced background information, which makes the tracker undertake the risk of model drifting.
In order to overcome the above challenges, a lot of efforts have been developed to alleviate the undesirable effects of background information [3], [4], [5], [6], [7], [9], [10], [11], [12], [13], [14], [15], [16]. For example, some methods [4], [5], [6], [9] update the object classifiers by further considering the distances of candidate bounding box with respect to the bounding box center and assigning higher weights to the candidate bounding box when they are close to the center. This setting is unreliable when the object shapes are irregular. The methods proposed in [17], [18], [19] conduct object segmentation in the tracking process to exclude the background information. The results of these methods are usually affected by the unreliable segmentation process. The methods proposed in [20], [21] use the sparse coding to build a discriminative appearance model. These methods are limited in dealing with cluttered backgrounds which may lead to bad segmentation results. To improve the robustness, Kim et al. [10] recently proposed to define an image patch based 8-neighbor graph to represent the tracked object, in which the 8-neighbor graph denote that if two nodes are 8-neighbors, they are connected by an edge, and the edge weight is computed by their low-level feature distance. However, it only considers the spatial neighbors, and cannot capture the intrinsic global relationship among patches. A dynamic graph learning approach is proposed by Li et al. [22] to make the best use of the relationship among patches, but they ignore the local cues in graph learning and the optimization is also complicated, resulting in long latency.
To handle the above issues, we aim to learn a robust object representation for object with deformation and partial occlusion to lead effective visual tracking. In general, our tracking approach contains three main steps. First, we partition the target bounding box into a set of non-overlapping image patches, which are described with color and gradient histograms. Then, to mitigate the effects of noisy patches of background, we associate each patch with a weight to reflect how likely it belongs to the target object, and integrate it into patch feature descriptors to construct a robust weighted feature descriptor. Finally, the constructed weighted features are combined with the structured SVM [4] to perform object tracking. Fig. 1 shows the overflow of the proposed tracking approach.Download : Download high-res image (1MB)Download : Download full-size imageFig. 1. Flowchart of the proposed tracking algorithm. Our tracking algorithm contains four main parts: Patch generation, LRWR weight computation, Multi-scale weighted descriptor for each bounding box and structured SVM localization.
To improve the robustness and effectiveness of patch weight computation, we propose a novel model, called Laplacian Regularized Random Walk Ranking (LRWR), to compute the patch weights to reflect how likely the patches belong to the target object. One main benefit of LRWR is that it integrates both local spatial and global appearance cues simultaneously in its weight computation process, which thus leads to more robust and effective object feature representation for visual tracking. Also, LRWR has a closed-form solution and thus can be computed efficiently. The learned features are incorporated into the traditional structured SVM to perform object tracking. This is because in structured SVM, the candidate samples are generated around the target bounding box. Thus, we can incorporate LRWR based patch weights into each candidate sample to alleviate the undesired effect of background information. Extensive experiments on standard benchmark datasets show that the proposed tracking approach outperforms several state-of-the-art tracking methods.
