Cloud computing has been widely adopted by businesses, individuals, and large enterprises. However, energy consumption has become a big concern in the last decade since cloud data centers consumed significant power and generated giant power bills. According to the data disclosed by The New York Times in 2012, Facebook data centers consumed about 60 million watts and Google data centers consumed as much as almost 300 million watts [1]. In 2013, data centers in the United States collectively consumed 91 billion kWh of electrical energy and generated 97 million metric tons of carbon dioxide (CO2) [2]. In 2014, more than 2% of the United State’s electricity usage was consumed by data centers [3]. Furthermore, by 2020, the annual electricity usage in the United States is expected to be as much as 140 billion kWh which is the output of about 50 power plants [4]. The carbon dioxide emission generated by Information and Communication Technology (ICT) is expected to exceed 1.4 billion metric tons. It is estimated that data centers are responsible for about 18% of the total energy consumed by all ICT systems in the world [5]. Therefore, many energy-efficient approaches have been explored at facility level, in cooling systems [6], [7], in data center network [8], and by using computing resource allocation strategies. Among those methods, the computing resource allocation is considered as the most achievable and cost-effective approach since it does not require any hardware modifications or upgrades. Virtualization is a key technology to achieve energy efficiency in data centers. VMs can be created, deleted, and migrated among host computers depending on power-aware decisions [9]. Energy-efficient VM management has been explored in task scheduling  [10], workload consolidation [11], [12], temperature-aware capping [13], request batching [14], local or remote clouds choosing [15], mobile service selection [16], etc.
Gelenbe et al. showed that energy consumption in ICT is related to workload, and concluded that the optimal energy consumption and processing time trade-off could be achieved by tuning workloads in computer systems [5]. Their work also indicated that computing systems should turn on more servers when the workload is sufficiently high in order to achieve energy efficiency and acceptable levels of Quality of Service (QoS) [17].
To the best of our knowledge, our work is the first to leverage the Performance-to-Power Ratio (PPR) of computing nodes in VM allocation and migration to achieve the optimal balance between host utilization and energy consumption. Performance-to-Power Ratio is calculated as the number of Server Side Java operations, or ssj_ops, completed during a certain time period divided by the average active power consumption in that period. Most of the current VM placement and migration policies are based on primitive system characteristics like power, utilization, network bandwidth, or storage space. However, in this paper, we propose an energy-efficient VM allocation and migration strategy based on PPR which is not a primitive characteristic of host computers. Our proposed framework is able to dynamically allocate VMs to and migrate VMs among hosts so that host computers can operate at the most power-efficient utilization levels, i.e., at the utilization level with the highest PPR. Specifically, this paper has the following contributions:

•We propose a novel VM allocation and migration framework which allocates and migrates virtual machines in clouds based on host performance-to-power ratios. Under thisframework, host computers run at their optimal or near-optimal utilization levels so that the energy consumption can be significantly reduced without much sacrifice of cloud-end computation performance.•We propose the exact and approximate methods to determine the ranges of gears for a specific host type. Thanks to our sampling strategy, the proposed approximate method is able to efficiently derive the range of each gear and estimate the whole system energy cost. Without loss of generality, in our verification experiments, we assume that each host computer maintains 11 gear levels (from gear 0 to gear 10) that corresponds to distinct utilization levels (from 0%, 10%, …to 100%).•We develop the VM allocation and migration modules under our proposed PPRGear framework based on the calculation of the Performance-to-Power Ratio (PPR) on host computers. These two modules have been designed seamlessly to trigger virtual machine allocation and migration automatically when a host is overutilized or underutilized in order to achieve the optimal balance between host utilization and energy consumption.•Our extensive experiments on CloudSim [18] with real-world traces show that compared with ThrRs, MadMmt, and IqrMc [19], our framework is able to reduce the energy consumption significantly for various host computer types. More importantly, the SLA violation rate of our framework is almost the same as that of Dynamic Voltage and Frequency Scaling (DVFS), indicating that our framework results in ignorable performance degradation.
In our design, each host computer maintains 11 gear levels (from gear 0 to gear 10) that correspond to distinct utilization levels (from 0%, 10%, …to 100%). The gear with the highest PPR is chosen as the best
gear. The top n gears with the highest PPRs are chosen as preferred
gears. When the current working gear of a host is not in the range of the preferred gears, the current host is considered as either overutilized or underutilized. Before executing any tasks energy-efficiently, we evaluate the characteristics of computing node at different utilization levels. This evaluation finds the best gear with the highest PPR and the n preferred gears with the n highest PPR values. By allocating and migrating VMs in clouds, we aim to keep computing nodes working at the best gears. When a computing node is working at a gear higher than any preferred gears, the computing node is considered overutilized. When a computing node is working at a gear lower than any preferred gears, the computing node is considered underutilized. If a computing node is overutilized, one or multiple VM(s) in this host will be selected and then migrated out. If a computing node is underutilized, the cloud will either migrate VMs from other hosts to this host or migrate out all VMs on this host then shutdown it to save energy consumption.
The remaining part of the paper is organized as follows: Section 2 introduces the motivation and observation, Section 3 presents the preferred utilization and the energy model, Section 4 presents the overview of our approach, Section 5 details the algorithmic design, Section 6 compares PPRGear with the baselines and shows our simulation results, Section 7 presents the related work, Section 8 concludes the paper.
