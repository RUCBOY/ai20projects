Currently, we are in an unprecedented and historic era of deep learning research in which waves of deep neural networks have swept through several application domains, ranging from autonomous driving [24], computer vision [29], [134], and natural language processing [18], [28] to recommendation systems [34]. The popularity of deep learning promoted the development of DNN architectures, including fully connected neural networks (FCNN), convolutional neural networks (CNN), recurrent neural networks (RNN) and its variants (LSTM [61], GRU [28]). These neural networks have achieved state-of-the-art performance across various domain-specific tasks. Taking computer vision as an example, well-designed DNNs, such as GoogLeNet [109] and ResNet-50 [58] trained on ImageNet [97] dataset, have beaten humans on image classification tasks.
Regarding good performance, DNNs tend to be deeper and more sophisticated and are trained with the larger datasets. The rapid increase of data volumes and model sizes has resulted in large number of computations, indicating that DNN training is time-consuming and can extend over several days or weeks. High-performance hardware, such as graphics processing units (GPU) [79] and tensor processing units (TPU) [67], are applied to accelerate the training time.
Beyond using high-performance hardware, paralleling and deploying DNN training tasks on multiple nodes (consisting of one or more machines) is another practical approach. Under these conditions, each node only executes part of an entire computation task. However, due to the frequent communication requirements for exchanging large amounts of data among the different computation nodes, communications overhead is a critical bottleneckin distributed training. With the growth of the cluster scale, communications overhead has increased explosively. Such a phenomenon considerably diminishes the advantage of parallel training, as a majority of the training time is spent on transferring data. When high-performance hardware accelerators are used, the proportion of time spent on communication increases further because they only decrease the computation overhead, whereas the communications overhead is unchanged.
In this paper, we primarily investigate how to deal with communications overhead for distributed DNN training. Because distributed deep learning is a cross-disciplinary field, both deep learning and distributed network communities have proposed communication optimization strategies from their own perspectives. In this survey, we bring together, classify, and compare the large body of work on communications optimization for distributed DNN training from the different research communities that contribute to this area. An overview of optimization strategies is shown in Fig. 1.Download : Download high-res image (370KB)Download : Download full-size imageFig. 1. Overview of communication optimization strategies. We divide optimization strategies into two categories: communication reduction and scheduling algorithm part (referred to as algorithm level) and network traffic execution part (referred to as network level).
Previous studies have covered many research domains ofdistributed deep learning. Ben et al. [13] provided a detailed concurrence analysis of DNNs from different levels. Various training algorithms and modern state-of-the-art training frameworks were studied by Chahal et al. [19]. A recent review by Mayer et al. [83] discusses the challenges of managing large deep learning systems on a distributed infrastructure. Mittal et al. [86] reported optimization techniques for deep learning applications of GPUs from an architecture and a system-level aspect. Some surveys have discussed communication optimization issues in distributed deep learning, but we provide a broader investigation. In particular, we discuss optimization from high algorithms level to low network level, which is a perspective that was missing from previous surveys.
The rest of this paper is organized as follows: In Section 2, we introduce deep learning’s background and provide an overview of distributed DNN training. In the next two sections, we discuss the optimization of algorithms and networks, respectively. Section 3 discusses communication rounds reduction, gradient compression and computation–communication overlap, whereas Section 4 introduces logical communication architectures and network protocols. Finally, we conclude the entire paper and highlight potential challenges and research directions in Section 5.
Download : Download high-res image (206KB)Download : Download full-size imageFig. 2. DNN parallelism schemes.
