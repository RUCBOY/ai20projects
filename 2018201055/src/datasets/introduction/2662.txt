The rapid growth of seniors generally exists not only in developed countries but also in developing countries, which drives society to build various healthcare systems. These systems are drawing increasing research attention from both academia and industry, aiming at enhancing the quality of seniors later life. Falling on the ground is reported as one of the most dangerous factors that threatens the lives of the seniors who are living alone, which requires timely rescue [1]. Falling often causes serious injuries such as fracture and coma which make seniors unable to call for help. In light of this, automatic human fall detection systems have emerged focusing on detecting fall events in indoor environments.
Fall detection system enjoys a promising market which helps elderly people to live by themselves without nurses. According to [2], the mainstream fall detection systems can be divided into two categories: wearable sensors based and computer vision based systems. Wearable devises generally use acceleration sensor [3], gyroscopes [4] or help buttons [5] to collect motion and posture data of human bodies. The alarm will sound if abnormal data is collected. The great advantages of wearable fall detector are its simplicity, stability and accuracy. However, despite these merits, the weaknesses are also obvious which is fourfold: first, seniors need to replace or charge the batteries of sensors regularly, which is simple but extremely easy to be forgotten; second, many seniors have a poor memory due to advanced age, which makes them forget to wear safety equipment; third, wearing the equipment for a long time may cause discomfort; fourth, the help button is meaningless if fallen person is unconscious. Vision-based system hence has many merits including safety, high flexibility and less intrusion. The greatest advantage of visual surveillance system is that no sensors need to be worn. All a visual fall detector needs to do is detect fall events from camera data. Surveillance cameras could be mounted on the wall or ceiling. Moreover, video camera captures not only persons information but also environmental information, which also provides promising way for other home monitoring systems.
Convolutional neural network (CNN) is an artificial neural network architecture, with its strong capabilities of learning feature representations, has recently been widely used in computer vision [6]. CNNs are effective in dealing with the problem of image understanding under complex conditions. In several challenging vision tasks such as face detection [7], [8], action recognition [9], [10] and object tracking [11], [12], CNNs have achieved great successes. Human fall detection is essentially a special case of action detection (or localization) which has shown remarkable performance gain by employing various CNN architectures (e.g., 3D CNNs [13], two-stream CNNs [14], FCN [15]). However, few attempts have been made to employ CNNs in visual surveillance system. In this paper, a fall detection method is proposed that incorporates spatiotemporal features to represent the fall and other human activities in surveillance videos. The motivations of our study are summarized as follows:
(1)Since the daily life activities in surveillance video are varied, better event features can be obtained by incorporating appearance and motion information of the target person. Training a video-level CNNs model can fulfill this requirement.(2)The image features of the same event will be very complex due to different video background. Using human silhouettes instead of standard frames to represent appearance information makes sense.(3)Single camera surveillance systems are limited in their ability to capture complete information of the target person under occlusions. Multi-camera surveillance systems are therefore more reliable, which can offer different views.
The proposed method is applicable to single camera as well as multi-camera fall detection systems. In the single case, we construct a fall detector for one camera view, which consists of two major steps: representation modeling and event classification. Specifically, we start with background subtraction to obtain human silhouettes as appearance representation. Then we use pixel intensity and rank pooling techniques on silhouettes and frames at a proper temporal scale, to obtain motion history image (MHI) and dynamic image (DI) as temporal representations. Subsequently, we extend CNNs into spatiotemporal level by building a three-stream architecture, where the network inputs are silhouette, MHI and DI respectively. Fall detection is formulated as the problem of event classification, which is achieved by training the three-stream CNNs model. In the multiple case, the fall detector is designed for different views, where the CNNs classifier is view-independent. Fall detection is performed by combining the classification results of different views via voting mechanism. Up to the best of our knowledge, it is the first time that spatiotemporal CNNs are employed for fall detection task. Invasion of privacy is a controversial issue in the field of visual surveillance. The proposed method can avoid this problem effectively. Because we model video representations as information carrier instead of using raw video data. Therefore, the individual privacy will not be exposed.
In summary, the main contributions of this paper include:
(1)An effective silhouette extraction technique is presented, which is crucial to the performance of MHI representation learning.(2)A novel three-stream CNNs architecture is proposed, which takes full advantage of appearance and motion representations that are complementary to each other. The CNNs classifier is view-independent and therefore can be used in both single and multiple camera applications.(3)MHI and DI are introduced to represent motion information. We demonstrate that they can be successfully used in multi-stream CNNs. Moreover, taking such representations as inputs has low computational requirements compared to current multi-stream models, which facilitates real-time detection.(4)A simple yet effective voting classifier is employed, which is beneficial in the case of multi-camera surveillance.
The remainder of this paper is organized as follows. Section 2 gives a review to the related works on vision-based fall detection. Section 3 illustrates the proposed method in detail. Experimental evaluation and results on standard fall datasets are reported and discussed in Section 4. Finally, Section 5 concludes this paper.
