Thoracic diseases are common and serious health problems that plague a large number of people worldwide. The pneumonia alone, for instance, affects approximately 450 million people (i.e., 7% of the world population) and results in about 4 million deaths per year (Ruuskanen et al., 2011). Chest radiography, colloquially called chest X-ray (CXR), is one of the most common types of radiology examinations for the diagnosis of thoracic diseases (Schaefer-Prokop et al., 2008). Each year, a myriad number of chest radiographs are produced globally and analyzed almost entirely through human visual inspection. This requires a high degree of skills and concentration, and is time-consuming, expensive, prone to operator bias, and unable to exploit the invaluable information embedded in large-scale datasets (Dunnmon et al., 2018). In many countries, the shortage of expert radiologists who are competent to read chest radiographs is a major challenge for public health (Williams et al., 2002). Therefore, it is significant to develop automated algorithms for the computer-aided diagnosis (CAD) of thoracic diseases on chest radiographs. Wang et al. (2017) recognized such significance and shared the ChestX-ray14 dataset to compare automated algorithms for the diagnosis of 14 thoracic diseases using chest radiography.
Intuitively, the diagnosis of thoracic diseases consists of three successive steps the detection of pathological abnormalities, feature extraction in abnormal regions, and classification of diseases (Wu, Aguilera, Shultz, Gudur, Rubin, Loo Jr, Diehn, Li, 2016, Lee, Li, Cui, Sun, Wu, Zhu, Yu, Gensheimer, Loo Jr, Diehn, et al., 2018). Due to the complexity of disease pathologies, automated abnormality detection on chest radiographs is challenging, particularly when the pixel-level annotations of pathological findings are seldom available in most hospital-scale chest radiograph datasets such as the ChestX-ray14 (Wang, Peng, Lu, Lu, Bagheri, Summers, 2017, Fleishon, Bhargavan, Meghea, 2006). Meanwhile, it is also challenging to extract visual features that can characterize the detected pathological abnormalities and to classify those abnormalities according to extracted features. Although there are many features which can measure the shape, size, and textures of those abnormalities (Hogeweg, Mol, de Jong, Dawson, Ayles, van Ginneken, 2010, Van Ginneken, Katsuragawa, ter Haar Romeny, Doi, Viergever, 2002, Jaeger, Karargyris, Candemir, Folio, Siegelman, Callaghan, Xue, Palaniappan, Singh, Antani, et al., 2013, Karargyris, Siegelman, Tzortzis, Jaeger, Candemir, Xue, Santosh, Vajda, Antani, Folio, et al., 2016), many features engineering methods (Chen et al., 2016), and many classifiers (Santosh and Antani, 2017), it is almost impossible to find a way to extract optimal handcrafted features and to construct an optimal classifier. Therefore, it is a crucial step to design end-to-end models for this CAD task.
Recent years have witnessed the impressive success of deep convolutional neural networks (DCNNs) on medical image classification (Zhang, Xie, Xia, Shen, 2019, Xie, Xia, Zhang, Song, Feng, Fulham, Cai, 2018, Jia, Xia, Song, Zhang, Huang, Zhang, Cai, 2020, Kermany, Goldbaum, Cai, Valentim, Liang, Baxter, McKeown, Yang, Wu, Yan, et al., 2018). However, it is still challenging to classify thoracic diseases on large-scale chest radiographs using DCNNs due to following issues. First, it is difficult for DCNNs to learn discriminative representations for the complex appearance of pathologies of thoracic diseases, since there are similar organs and tissues in each chest radiograph. The visual similarities could confuse DCNNs and bias the allocation of their available computational resources (i.e., channels) towards the less informative components. Second, the pathological abnormalities could be found at different locations. As shown in Fig. 1(a), the region of pneumonia could appear at different locations of the lung field. Such location variability makes it hard for DCNNs to focus on relevant regions on chest radiographs. Third, there is a significant scale variance among the pathological abnormalities of different types of thoracic diseases. A typical example was shown in Fig. 1(b), where the cardiomegaly almost covers the whole heart, but the nodule is much smaller than it. Consequently, DCNNs may fail to adapt to scale change when classifying different thoracic diseases. Many works (Zhou, Khosla, Lapedriza, Oliva, Torralba, 2016, Selvaraju, Cogswell, Das, Vedantam, Parikh, Batra, 2017) have demonstrated that the attention mechanism renders DCNNs the ability to allocate more processing resources to important information during the learning process, which makes it possible to strengthen the discriminatory ability of DCNNs via adapting to variances in appearance, location, and scale of thoracic abnormalities. Therefore, we reason that we can address these difficulties by comprehensively introducing the channel-wise attention, element-wise attention, and scale-wise attention mechanisms to a DCNN, respectively. The channel-wise attention is able to reinforce the informative channels and to suppress irrelevant channels of feature maps, while the element- or scale-wise attention enables the network to dynamically concentrate information processing at the location or scale of interest. In this way, the discriminatory power of the model can be strengthened, and the diagnostic performance can be further improved.Download : Download high-res image (380KB)Download : Download full-size imageFig. 1. Four chest radiographs from the ChestX-ray14 dataset. Pathological findings are highlighted by green bounding boxes. (For interpretation of the references to colour in this figure legend, the reader is referred to the web version of this article.)
In this paper, we propose the triple-attention learning network (A 3 Net) for the CAD of thoracic diseases using chest radiography. We adopt DenseNet-121 (Huang et al., 2017) as the backbone network and incorporate the channel-wise attention, element-wise attention, and the proposed scale-wise attention into it for the classification of thoracic abnormalities. Our model is novel in simultaneously (1) learning the channel-wise attention to determine which feature channels provide discriminative information, (2) learning the element-wise attention (i.e. spatial attention) to identify the spatial locations of pathological abnormalities, and (3) learning the scale-wise attention to decide which scale plays a major role in the diagnosis. We evaluated our A 3 Net against six state-of-the-art deep learning models on the ChestX-ray14 dataset (Wang et al., 2017) and achieved the best overall performance.
