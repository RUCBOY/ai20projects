Humans readily think, reason, and communicate in symbolic terms, whether through natural language, mathematical formalisms, or computer programs. Designing neural networks that can represent, execute, and learn these types of symbolic processes is a long-standing research topic in artificial intelligence. It has been known for some time that in theory, universal computation can be implemented in neural networks (Pollack, 1987, Siegelmann and Sontag, 1991). There also exist practical-purpose methods for “compiling” human-authored programs into neurocomputational representations (Dehaene and Changeux, 1997, Gruau et al., 1995, Neto et al., 2003, Siegelmann, 1994, Sylvester and Reggia, 2016). Most recently, neural architectures have been developed that can learn algorithmic behavior from training data (Bošnjak et al., 2017, Bunel et al., 2016, Devlin, Bunel et al., 2017, Graves et al., 2016, Neelakantan et al., 2016, Reed and De Freitas, 2016, Rocktäschel and Riedel, 2017, Sylvester and Reggia, 2016).
Most of these approaches involve one or both of the following paradigms:Download : Download high-res image (253KB)Download : Download full-size imageFig. 1. The Neural Virtual Machine (NVM) workflow. First a blank NVM instance is constructed according to user-provided specifications (supplied as parameters to an API call). Thereafter, human-authored programs can be “assembled” and “loaded” into the instance via local learning rules. The instance can store new programs without forgetting previously learned programs, and execute existing programs at any time (only two programs are shown here for brevity). Program execution is emulated by running the underlying neural activation dynamics, which involves additional fast local weight updates. A “codec” converts between neural representations and human-readable input/output, as described further in the text.

•Local representation. For example, program stacks may be represented by arbitrary-precision values in single artificial neurons (Pollack, 1987, Siegelmann and Sontag, 1991); individual variables or symbols may be assigned individual artificial neurons (Abdelbar, Andrews, & Wunsch II, 2003); data structures may be represented by distributed patterns at a single time-step, rather than temporal sequences of patterns (Plate, 1995); different programs may require different program-specific circuitry (Dehaene and Changeux, 1997, Neto et al., 2003); or working memory is activation-based, wherein each item currently stored in memory must remain simultaneously active in separate neural populations (Graves et al., 2016). From a scientific standpoint, many brain mechanisms are thought to employ distributed, not local, representation of information, and from an engineering standpoint, local representation lacks fault tolerance and graceful degradation.•Non-local learning. In particular, most recent work relies heavily on error back-propagation throughout the network, with unlimited repeated access to offline training examples. Further, many older works use hand-crafted program-specific circuitry and weights. Non-local learning is generally more computationally expensive and less biologically plausible than local learning, in which changes to a synaptic weight only depend on the recent activity of the neurons directly connected by that synapse.
There are some exceptions that break this mold, such as Sylvester and Reggia (2016). However, as yet these exceptions do not fully address universal computation: more work is needed to confirm their Turing completeness, and from a practical perspective, they do not support many constructs and toolchains typically available in traditional programming languages (e.g., instruction operands, pointers, sub-routines, user-friendly “compilation” to neural encoding, etc.).
The main contribution of this paper is an approach to universal neural programming based on non-local representation and local learning, wherein synaptic weight changes depend only on information that is nearby in time and space. In this approach, working memory uses a novel local learning rule, and represents structured programs and data using temporal sequences of distributed neural activity patterns. We explain how our neural model can emulate a Harvard computer architecture (Rosen, 1969) that stores multiple arbitrary programs simultaneously. Harvard architectures use separate physical storage for programs and data and form the basis of many computing systems today. We also explain how our model can asymptotically simulate any Turing machine. Emulating a von Neumann architecture might also be possible with a similar approach, but we target the Harvard architecture because separate program and data memory is more readily implemented using separate neural layers, and avoids the complexity of coordinating program and data segments within a single memory.
We refer to our model as a “Neural Virtual Machine” (NVM). A reference implementation is open-source and freely available online.1  The high-level NVM workflow is shown in Fig. 1. First, the NVM is initialized with a one-time non-local procedure, to meet user-provided specifications (layer sizes, activation functions, etc.), which are supplied via an API (Application Programming Interface) call. Subsequently, any human-authored program, written in an assembly-like language we designed, can be “assembled” and “executed” in the underlying neural network solely by virtue of local weight updates — with no rewiring of connectivity required. New programs can be added without erasing previously stored programs. An assembly-like language was chosen for greater simplicity and because assembly is a proven platform for any higher-level language feature.
Each human-readable symbol in a specific NVM program is represented by randomly chosen neural activity patterns. The symbol-to-pattern mappings are stored in an external non-neural lookup table that we call a “codec”, borrowing the portmanteau of “encoder–decoder” from the field of video processing, since symbols are “encoded” by neural activity. During program execution, a human can use the codec to convert NVM input from, or NVM output to, human-readable symbols. However, the NVM itself is a purely neural system that can emulate programs from start to finish without relying on a codec.
The NVM is not intended as a veridical model of the brain, but rather a neuroengineering system that can emulate traditional computer programs using artificial neural computation. Our specific contributions include a novel local learning rule for emulating computer memory, the NVM architectural designs, some theoretical analysis that helps characterize our approach, and empirical validations using hand-written and randomly generated programs. We conclude with an assessment of the NVM and discussion of future research directions.
