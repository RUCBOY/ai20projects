In recent years, deep convolutional neural networks (DCNNs) have revolutionized machine vision and can now outperform human vision in many object recognition tasks with natural images [1], [2]. Despite their outstanding levels of performance, the search for brain inspired computational models continues and is attracting more and more researchers from around the world. Pursuing this line of research, a large number of models with enhanced bio-plausibility based on spiking neural networks (SNNs) have emerged. However, SNNs are not yet competitive with DCNNs in terms of recognition accuracy. If DCNNs work well, what is the reason for this increased interest in neurobiological inspiration and SNNs?
To begin with, energy consumption is of great importance. Thanks to the millions of years of optimisation by evolution, the human brain consumes about 20 Watts [3] – roughly the power consumption of an average laptop. Although we are far from understanding the secrets of this remarkable efficiency, the use of spike-based processing has already helped neuromorphic researchers to design energy-efficient microchips [4], [5].
Furthermore, employing embedded and real-time systems for artificial intelligence (AI) is important with the advent of small and portable computing devices. In recent years, specialized real-time chips for DCNNs have been released that are capable of fast simulation of pre-trained networks. However, online on-chip training of DCNNs with exact error backpropagation is not yet practical, due to the high-precision and time-consuming operations. In contrast, biologically inspired learning rules such as spike-timing-dependent plasticity (STDP) [6], [7] can be hardware-friendly, and appropriate for online on-chip training [8].
These reasons, together with the natural ability of SNNs to handle spatio-temporal patterns, have led researchers to try a range of methods for applying SNNs to visual tasks. The use of hierarchically structured neural networks is a common approach, yet configuring other parameters such as the number of layers, neuron models, information encoding, and learning rules is the subject of much debate. There are shallow [9], [10] and deep [11], [12] SNNs with various types of connectivity structures, such as recurrent [13], convolutional [9], [14], [15], and fully connected [16]. Information encoding is the other aspect of this debate, where rate-based [17], [18], [19] and temporal coding [9], [10], [16], [20] are two of the main options. Different learning techniques are also applied to SNNs, from backpropagation [14], [21], [22], [23], tempotron [10], [24], and other supervised techniques [18], [19], [20], [25], [26], to unsupervised STDP and its variants [16], [27].
Regarding the pursuit of brain inspiration, STDP-based SNNs are the most biologically plausible ones. Using STDP, the network can successfully extract frequently occurring visual features. However, an unsupervised learning rule alone is not sufficient for decision-making, where external classifiers such as support vector machines (SVMs) and radial basis functions (RBFs), or supervised variants of STDP, are usually required. Digit recognition is one of the well-known pattern recognition problems which has became a standard task to examine the newly proposed methods [28], [29], [30]. There are several STDP-based SNNs that have been applied to MNIST dataset for digit recognition. For example, Brader et al. [31] with 96.5%, Querlioz et al. [32] with 93.5%, and Diehl and Cook [16] with 95% of recognition accuracies are successful models the use shallow structure in digit recognition. With a deeper structure, Beyer et al. [33] achieved a not so good performance of 91.6%, however, Kheradpisheh et al. [34] trained a deep convolutional SNN (DCSNN) and increased the accuracy to 98.4%.
Researchers have started exploring the potential of using reinforcement learning (RL) in SNNs and DCNNs [35], [36], [37], [38], [39], [40], [41], [42]. By RL, the learner is encouraged to repeat rewarding behaviors and avoid those leading to punishments [43]. Using supervised learning, the network learns at most what the supervisor knows, while with RL, it is able to explore the environment and learn novel skills (unknown to any supervisor) that increase the fitness and reward acquisition [44].
We previously developed a shallow SNN with a single trainable layer [45], where the plasticity was governed by reward-modulated STDP (R-STDP). R-STDP is a reinforcement learning rule inspired by the roles of neuromodulators such as Dopamine (DA) and Acetylcholine (ACh) in modulation of STDP [46], [47]. Our network made decisions about categories of objects solely based on the earliest spike in the last layer without using any external classifier. Together with rank-order encoding and at most one spike per neuron, our network was biologically plausible, fast, energy-efficient, and hardware-friendly with acceptable performance on natural images. However, its shallow structure made it inappropriate for large and complex datasets with high degrees of variations.
In this research, we designed a 3-layer DCSNN with a structure adopted from [34], mainly for digit recognition. The proposed network does not need any external classifier and uses a neuron-based decision-making layer trained with R-STDP. First, the input image is convolved with difference of Gaussian (DoG) filters at various scales. Then, by an intensity-to-latency encoding [48], a spike wave is generated and propagated to the next layer. After passing through multiple convolutional and pooling layers with neurons that are allowed to fire at most once, the spike wave reaches the last layer, where there are decision-making neurons that are pre-assigned to each digit. For each input image, the neuron in the last layer with the earliest spike time or maximum potential indicates the decision of the network.
We evaluated our DCSNN on the MNIST dataset for digit recognition. First, we applied R-STDP only to the last trainable layer and STDP to the first two, achieving 97.2% of recognition performance. Next, we investigated if applying R-STDP to the penultimate trainable layer is helpful. We found that when there are frequent distractors in the input and limitations on the computational resources, using R-STDP instead of STDP in the penultimate layer is beneficial.
The rest of this paper is organized as follows. A precise description of the components of the proposed network, synaptic plasticity, and decision-making is provided in Section 2. Then, in Sections 3 and 4, the performance of the network in digit recognition and the results of applying R-STDP to multiple layers are presented. Finally, in Section 5, the proposed network is discussed from different points of view and the possible future works are highlighted.
