The era of accelerated computing started in the mid-2000s, when CPU clock speeds approached the 4 GHz barrier and a further increase beyond this barrier would have required enormous efforts for cooling the processor to prevent spurious malfunctioning and even permanent hardware damage from overheating. All major chip vendors followed the paradigm shift from chasing ultimate single-core performance towards developing parallel high-performance computing (HPC) technologies and flooded the market with multi-core CPUs and many-core accelerator cards like programmable GPUs and dedicated co-processor devices.
1.1. Accelerated computingThe key idea of accelerated computing is to offload computationally expensive tasks from the host, a classical multi-core and possibly multi-socket CPU-based computer, to the attached accelerator devices, which altogether form the so-called compute node. Modern HPC systems consist of hundreds and thousands of compute nodes, which are interconnected by high-speed networks.In classical accelerated computing, the role of the host computer is threefold: Firstly, tasks that do not benefit from the compute capabilities of the accelerator devices such as in- and output of data from and to the global filesystem and intrinsically sequential (parts of) algorithms are executed by the host. Secondly, the host is responsible for orchestrating the interplay of accelerator devices among each other and with the CPU and for managing the communication between the distributed compute nodes. Finally, since modern CPUs have up to 20–32 cores with integrated vector-processing units, heterogeneous HPC systems also use the massive compute power of the host to perform actual computations.Most of today’s many-core accelerators are designed for executing parallelizable and/or vectorizable instructions of SIMD-type (single instruction multiple data) exceptionally fast. Consider, for instance, the multiplication of an m × n matrix with a column vector of length n. Each matrix row gives rise to a separate dot product, i.e. an accumulated multiply-add operation that can be carried out in a parallel and, ideally, vectorized loop over all rows even on multiple devices with distributed memory architecture. This so-called divide-and-conquer approach is a common building block in classical HPC applications and it is supported by most programming models like OpenMP [1] and MPI [2].Recently, application-specific accelerator technologies are emerging, which offer extra functionality that is not available in commodity hardware. Consider, for instance, Google’s tensor processing units [3], which is an application-specific integrated circuit (ASIC) for accelerating machine learning applications. To fully exploit its compute power, the part of the application that benefits from using the AI accelerator needs to be identified and implemented in the vendor-specific programming model, which often requires code refactoring.
1.2. Quantum-accelerated computingIn our opinion, quantum computing has the potential of becoming a disruptive application-specific acceleration technology that might have a significant impact on future developments in high-performance scientific computing [4]. However, this variant of accelerated computing is so much different from existing technologies, that it needs radically new algorithmic concepts rather than the continuation and extension of traditional approaches to achieve quantum supremacy, that is, the potential ability of quantum computing devices to solve problems that cannot be solved efficiently by classical computers [5].Consider, for instance, the aforementioned matrix-vector multiplication that can easily be accelerated in classical computing by adopting the divide-and-conquer approach. The very limited number of qubits in today’s (50-qubit processor [6]) and mid-future (72- and 128-qubit processors [7], [8]) quantum devices makes this strategy of parallelizing along the problem size unattractive.Another concept, which is widely used for solving boundary value problems (BVP) that are modeled by partial differential equations (PDE), are so-called domain decomposition methods (DDM) [9]. The key idea is to split a single large problem into multiple smaller ones that can be solved in parallel on multiple distributed compute devices. Data is regularly exchanged between the different sub-domains to ensure that the global solution that is made up from local parts solves the original problem. The straightforward application of DDMs on quantum devices is ruled out by the no-cloning theorem [10], which states that it is impossible to create an identical copy of an arbitrary unknown quantum state. Of course, measurements could be performed in order to exchange classical state data between sub-domains but that will most likely stop quantum supremacy.It should be noted that direct communication between quantum devices is possible without destroying the superposition of quantum states via quantum teleportation [11] and quantum channels [12], but this requires a conceptual redesign of the DDM, which typically performs simple averaging of the non-unique data available at the sub-domain interfaces. The above is not meant to discourage practitioners from looking into quantum-accelerated computing but aims to identify some of the many challenges that one might encounter.In what follows, we sketch a conceptual framework for accelerating the solution of simulation-based automated design optimization (ADO) problems with the aid of quantum devices. Our theoretical scenario is based on existing quantum algorithms for solving linear systems of equations and for finding the minimum of a quadratic form. The rest of this paper is organized as follows: Section 2 establishes an abstract mathematical framework for solving ADO problems and gives two illustrative examples. Section 3 reviews existing quantum algorithms that can be used to realize the suggested ADO framework in practice. Finally, a brief discussion of remaining open questions, recommendations for further research and main conclusions are given in Section 4.
