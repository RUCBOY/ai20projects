Alzheimer’s disease (AD) is the most severe form of dementia and often begins in people over the age of 65 [1]. According to the World Health Organization (WHO) [2], currently, there are 50 million people who have AD, and this number is expected to triple by 2050. Unfortunately, there is no cure for AD at this time, and current treatments can only reduce the future progression of the disease [3]. Early diagnosis of Alzheimer’s disease (AD) is essential because AD treatment options tend to be most effective during the early stages of the disease [4]. Mild cognitive impairment (MCI) has been commonly viewed as a transitional stage between healthy aging and AD [5]. Studies have shown that 10%–15% of patients with MCI progress to AD per year [6]. A patient who converts from MCI to AD is called pMCI, whereas a patient who does not progress to AD is called sMCI [7]. One of the most difficult challenges is distinguishing between sMCI and pMCI. To date, many machine learning (ML) methods, such as support vector machine (SVM) have been applied to differentiate between sMCI and pMCI [8], [9], [10]. AD is a chronic disease, where multiple modalities are always used to describe patients. These heterogeneous data collected over time can be referred to as time-series multimodalities [6]. The majority of AD diagnosis and progression studies are based on a single modality, usually neuroimaging data such as magnetic resonance imaging (MRI) [11]. Mostly, these studies often transform the AD diagnosis or prediction problem into a binary classification task (such as AD vs. MCI) to ease the training process. Bron et al. [12] organized the CADDementia1  challenge to compare ML algorithms for AD diagnosis, 29 algorithms were evaluated based on single-visit MRI data only. The problem was formulated as a three-class classification problem (i.e. CN vs. MCI vs. AD). The best algorithm achieved an accuracy of 63.0% based on voxel-based morphometry features. Jiang et al. [13] built an interesting CNN-BN-DO-DA deep learning model for AD classification based on an eight-layer convolutional neural network with batch normalization and dropout techniques. This advanced model is based on the neuroimaging modality, and the authors achieved a high accuracy of 97.76% using a dataset of 7399 AD and 7399 normal subjects. Zhang et al. [14] proposed a novel machine learning system for automatic and fast AD diagnosis. This binary classifier is based on the volumetric MRI data of 196 subjects collected from two sources including the Open Access Series of Imaging Studies (OASIS) [15] and local hospitals (Affiliated Nanjing Brain Hospital of Nanjing Medical University, Children’s Hospital of Nanjing Medical University, and Zhong-Da Hospital of Southeast University). The MRI data is processed by an accurate pipeline of skull stripping and spatial normalization, one axial slice, and stationary wavelet entropy. Based on the resulting texture features, a simple one-hidden layer neural network is used as the classifier, where the network parameters were trained using the particle swarm optimization. The resulting model is fast and achieved an accuracy of 92.73 ± 1.03%. Although these models are highly accurate and promising, building an AD progression detection system based only on neuroimaging data is not highly recommended in the medical domain because real domain experts usually analyze complete patient profiles. Further, these imaging data are expensive to collect, which delays the AD diagnosis. In addition, according to standard AD clinical practice guidelines, neuroimaging is optional for AD diagnosis, and only required in specific situations like a history of carcinoma, bleeding disorders, and gait disorders; recent head trauma; age < 60 years; and rapid unexplained decline [16]. Recently, it has been proven that the fusion of multiple modalities improves the performance of the resulting models, where additional data such as position emission tomography (PET), neuropsychological battery, cognitive scores, symptoms, and demographics could enhance the model’s confidence and reduce noise [17], [18], [19], [20]. In addition, any resulting model becomes more acceptable in real medical environments. Zhang et al. [18] combined MRI, FDG-PET, and cerebrospinal fluid (CSF) modalities to distinguish AD, MCI, and normal controls patients. Xu, et al. [21] used the volumetric MRI, fluorodeoxyglucose PET (FDG-PET), and florbetapir PET modalities to classify AD vs. MCI in a binary classification task. Tong et al. [21] fused the volumetric MRI, voxel-based FDG-PET, CSF biomarker, and genetic modalities. Bouwman et al. [19] suggested incorporating the two modalities of MRI and CSF to distinguish CN patients from MCI. Gray et al. [22] used a random forest (RF) algorithm and four modalities (i.e., MRI, FDG-PET, CSF, and genetics) for the 3-class classification of AD vs. MCI vs. CN. All these studies were based only on the baseline data and did not study the role of time series data to enhance the classification process. In addition, they were based on advanced and expensive modalities such as MRI and PET. The technologies used to collect these data are unavailable in the majority of the medical clinics, which means that these classifiers are only applicable to limited patients. Furthermore, the results of using these modalities are not good. Donnelly-Kehoe et al. [23] concluded that the maximum accuracy achieved by MRI features did not reach that of using the mini-mental state examination (MMSE) alone.
Time-series data analysis is intuitive and crucial for the management of chronic diseases. However, in the AD domain, little work has used time-series algorithms for AD progression detection. In this context, Chincarini et al. [24] utilized a time-series MRI dataset from the Alzheimer’s disease neuroimaging initiative (ADNI) to predict AD progression. These data have four scans (i.e. twice at baseline, one at 12-months, and one at 24 months). The study concentrated on analyzing the role of bilateral hippocampal volume to track AD progression. The problem was formulated as two binary classification tasks, and the study achieved an area under the ROC curve (AUC) of 0.93 for CN vs. AD and AUC of 0.88 for CN vs. MCI. Moradi et al. [7] predicted MCI-to-AD conversion in the period between one to three years based on novel MRI data using a semi-supervised learning technique. Moore et al. [25] used the random forest to study the relationship between pairs of data points at various time separations. Demographic, physical, and cognitive data were used to predict Alzheimer’s disease. Huanget et al. [26] used a random forest regression algorithm to predict cognitive scores by utilizing the longitudinal scores of previous time points. To build accurate, stable, and medically intuitive models, multimodal time series data should be analyzed using suitable ML models. The usage of multimodal time series data for AD progression detection modeling is expected to improve model performance. In addition to MRI, PET, CSF, there are other crucial data sources, which are either have not been studied at all or have had few studies in the literature: (1) Cognitive score modalities like MMSE, CDRSB, FAQ, and ADAS 13 have only been studied at baseline, (2) drug modalities including brain disorders medications and other medications taken during the patient monitoring period, (3) comorbidity modalities which include the other diseases that the patient was suffering from during the monitoring period. These data have a great effect on a medical expert’s decision to diagnose AD or predict its next stage [27]. For example, the ADNI collected drug modality determines the currently or previously taken medicines for the treatment of AD and other diseases [28], [29], [30]. These medicines have chemical substances that may be accumulating in the body in some form, so studying the effect of these drugs on the progression state of the disease is important. However, to the best of our knowledge, these types of modalities have not been studied individually or in combination.Table 1. Patient statistics at baseline.CN (n = 249)sMCI (n = 363)pMCI (n = 106)AD (n = 318)Combined (n = 1036)Gender (M/F)144/105210/15344/62142/176483/553Age (years)73.84 ± 05.7872.92 ± 07.7673.89 ± 06.8475.01 ± 07.8173.82 ± 07.18Education (years)16.43 ± 02.7015.80 ± 02.9716.13 ± 02.7115.13 ± 02.9815.85 ± 02.90FAQ00.28 ± 00.8202.64 ± 03.3107.63 ± 04.4916.42 ± 06.5906.81 ± 08.01MMSE28.91 ± 01.0427.62 ± 01.9525.46 ± 01.8420.95 ± 03.9525.66 ± 04.17ADAS 1308.13 ± 03.6314.69 ± 06.7122.69 ± 05.2933.59 ± 09.3919.73 ± 12.24* Data are mean ± standard deviation.
In this study, we build a cost-effective and medically oriented AD progression detection system based on conventional ML techniques. The model is based on the information fusion of three-time series modalities of comorbidities, medications, and cognitive scores to predict four patient diagnosis classes: CN, AD, pMCI, and sMCI. In addition, basic demographics, including age, number of education years, and gender, are considered. Each modality is represented by four-time steps (i.e., baseline [bl], month 6 [M06], month 12 [M12], and month 18 [M18]), and the model predicts patient progression after 2.5 years (i.e., at month 48 [M48]). To select the optimum model, we optimize and test a set of five popular ML models, namely, SVM, RF, KNN, logistic regression (LR), and decision tree (DT), using the real world ADNI dataset. The preparation of medication and comorbidity datasets is a challenging task because the names of drugs seem to have been entered manually. Besides, there is a huge number of medications used by patients. Building a hot vector to encode these names created sparse datasets with many 0’s. The resulting datasets are thus not suitable for ML algorithms. To semantically manipulate these data, we utilized the semantics of the WHO’s anatomical therapeutic chemical classification (ATC) ontology.2  The drugs are grouped based on their chemical substances into a smaller number of classes, which significantly reduces the number of features used to encode drug data. The contributions of the paper can be summarized as follows.

•We propose a cost-effective, accurate, and medically intuitive AD progression detection model. The model is based on the early fusion of a set of new time series multimodalities to predict a 4-class classification task (i.e., CN, sMCI, pMCI, AD).•We propose a novel methodology to encode the medication time-series data based on the standard ATC ontology.•We implement, evaluate, and optimize a set of five models that are based on popular machine learning algorithms: SVM, RF, LR, DT, and KNN. These models are optimized to classify the 4-class problem (i.e., CN, sMCI, pMCI, AD), the 3-class task (CN, MCI, AD), and a set of binary classification tasks, including CN vs. AD, CN vs. MCI, sMCI vs. pMCI, etc.•The models are trained and tested using real, time-series dataset of 1029 patients from the ADNI dataset.•The results highlight the significant role of medication and comorbidity datasets to improve the performance of AD prediction models. The resulting models are more accurate compared to those in existing studies; besides, all models are less expensive because these models are based on well known efficient machine learning algorithms and are built using easy to collect and cheap historical data from patients.
The rest of this paper is structured as follows. Section 2 explains our methodology and the architecture of the proposed framework. Section 3 explains the experimental results, and Section 4 concludes the paper.
