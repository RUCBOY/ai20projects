In criminal cases, comparative forensic sciences are often used to infer the identity of the perpetrator. For example, a nuclear deoxyribonucleic acid (DNA) sample or fingerprint left at a crime scene may be compared to a known sample or print to determine whether they come from the same individual or not. Until recently, the validity and reliability of these forensic techniques had gone unquestioned and criminal courts have allowed examiners to testify that two prints or samples “match” to the exclusion of all other people despite no empirical basis for these conclusions [2].
Understanding jurors’ prior beliefs and perceptions about forensic science is necessary, as these beliefs may influence jurors’ understanding of (and decisions about) forensic evidence presented at trial. The present study aims to build on previous literature examining beliefs about forensic evidence by exploring people’s beliefs about error and human judgment involved at each stage of the forensic science process — from evidence collection, storage, and testing to reporting and presenting the evidence in court. To our knowledge, no prior research has investigated perceptions of human judgment involved in forensic science. Investigating people’s perceptions of human judgement involved in forensic science may provide a richer account for their perceptions of error and forensic science overall. Furthermore, prior research has typically looked at error involved in forensic science as a whole; the current study is the first to look at perceptions of error and human judgment involved in each stage of the forensic science process.
1.1. Wrongful convictions on the basis of forensic scienceIn 2004, an American lawyer, Brandon Mayfield, was wrongfully accused of committing the Madrid Train Bombings that killed 192 people and injured another 2050 [3,4]. A fingerprint found on a bag of detonators was wrongly attributed to Mayfield’s print, which was in the FBI’s database due to his prior military service. Despite Mayfield being in the United States during the time of the bombings and with no other evidence to link him to the crime, three FBI fingerprint experts concluded that the two prints “matched.” Two weeks after Mayfield was arrested, the Spanish National Police informed the FBI that they had identified an Algerian man, Daoud Ouhnane, as the source of the fingerprint. The FBI then withdrew their identification of Mayfield and released him from custody.Errors of this kind happen more often than people tend to think. Saks and Koehler [1] analyzed 83 DNA exoneration cases and found that forensic science testing errors occurred in 63% of cases and false or misleading forensic testimony occurred in 27% of cases. Furthermore, The Innocence Project found that misapplication of forensic science occurred in nearly half (46%) of all DNA exoneration cases [5]. In reality, it is impossible to know just how many wrongful convictions have occurred on the basis of forensic evidence, particularly because the processes for preserving and maintaining such evidence have not been mandatory [6].In response to these wrongful convictions, the U.S. National Academy of Sciences (NAS) issued a report heavily criticizing the current state of forensic science, concluding that “with the exception of nuclear DNA analysis … no forensic method has been rigorously shown to have the capacity to consistently, and with a high degree of certainty, demonstrate a connection between evidence and a specific individual or source” (2009, p. 7). The NAS report recommended that research be conducted to establish the reliability and limits of performance for each technique, as this research is lacking in most of the forensic disciplines [7]. Most recently, the U.S. President’s Council of Advisors on Science and Technology (PCAST) issued a report questioning the scientific validity and reliability of various feature-comparison methods (2016) and made recommendations to strengthen forensic science and promote rigor.
1.2. How reliable is forensic evidence?Prior to these reports, the validity and reliability of forensic science techniques had largely gone unquestioned. As the forensic sciences encompass a broad range of disciplines, it should not be surprising that there is also a great deal of variability in terms of methodology, reliability, error rates, and evidence-based practice. Calls from the NAS and PCAST have helped to kickstart research into accuracy and error rates of forensic sciences, however it is still largely unknown for most techniques. Here we will discuss three key forensic techniques — DNA, fingerprint analysis, and bite mark analysis.1.2.1. DNADNA is considered the gold standard of forensic techniques due to its impressively small random match probabilities, suggesting that errors are extremely unlikely [8]. However, even DNA evidence is not infallible; contamination or mislabeling during collection, handling, and testing can lead to incorrect results [9] and samples containing multiple sources require more subjective judgment, leaving the potential for human error or bias [10]. However, no proper validation experiments have been conducted to determine these error rates [8].1.2.2. FingerprintsFor more than 100 years, fingerprint experts have claimed that they can make a positive identification to the exclusion of all other persons — with some examiners even claiming that identification is infallible [11,12]. Tangen et al. [13] conducted the first study comparing the performance of fingerprint examiners to novices using ground-truth stimuli. They demonstrated that fingerprint examiners possess genuine expertise, performing far better than novices by making only 0.68% false positive decisions and 7.88% false negative decisions. Fingerprint experts are able to perform exceptionally well even under time constraints and with difficult visibility [14]. However, studies have revealed that fingerprint examiners can disagree about the number of identifying features in fingerprints [15] and are susceptible to contextual bias [16,17].1.2.3. Bite marksIn contrast to DNA and fingerprint analysis, bite mark analysis is considered the most controversial of the forensic techniques [18]. Like fingerprint analysis, bite mark analysis relies on the assumption that each individual person has a unique bite mark. There are a number of methods that can be used to analyze bite marks, but there is no evidence for the reproducibility of any of these methods either between experts, or by the same expert at different times [7,19]. As such, the PCAST [20] report concluded that bite mark analysis does not meet the standards of scientific validity and reliability.
1.3. Why do prior beliefs about forensic science matter?Despite wrongful convictions and a number of authoritative reports scrutinizing the current state of forensic science, the criminal justice system has continued to admit forensic evidence that is unreliable, unvalidated, and untested. Allowing forensic evidence into court that has not been empirically tested perpetuates the faulty assumption that all forensic sciences are valid and should be given considerable evidentiary value [21]. As a result, jurors are not necessarily aware of the challenges and controversies the forensic sciences face [6].If jurors are not aware of the controversies surrounding forensic science, they are likely to interpret forensic testimony through the lens of the knowledge and beliefs they already have about forensic science prior to entering the courtroom. The Story Model of jury decision-making suggests that jurors may incorporate evidence presented to them at trial with their pre-existing general knowledge to form a narrative representation of the evidence [22,23]. Despite being provided with the same testimony at trial, individual jurors may construct different narratives from one another and perhaps even reach a different verdict. If jurors’ beliefs about forensic science are strongly held, they could have difficulty setting aside these beliefs to evaluate the evidence [6]. Thus, it is important to identify jurors’ prior beliefs, particularly misbeliefs, about forensic science in order to minimize their effect prior to trial and help improve jurors’ ability to evaluate expert testimony.Although many researchers have acknowledged that jurors’ beliefs about forensic science may impact their evaluation of the evidence [[24], [25], [26]], little research has directly explored these beliefs. Arguably, the largest body of literature that has explored beliefs about forensic science, albeit indirectly, is research into the CSI effect.
1.4. The CSI effectPopular television crime series like CSI: Crime Scene Investigation (CSI), Law & Order and most recently True Detective tend to portray forensic science in an over-exaggerated fashion — using high-tech equipment to solve crimes in a matter of hours, even minutes, without error. The following exchange between CSI’s main characters helps to illustrate the faith placed in forensic science on television [27]:Catherine Willows: The evidence is wrong.Gil Grissom: No, it isn’t. You can be wrong. I can be wrong. The evidence is just the evidence.This exchange depicts a view of forensic science that can speak for itself, free from any human involvement or error [28]. But, as several authoritative reports have now explained, this is not the case for forensic science in the real world. According to one forensic scientist, around 40%of forensic science on the show is completely made up, with the remainder conducted quickly and effortlessly in ways that real forensic laboratories could only dream of [29].Ward [30] suggests that forensic science is misrepresented in three distinct ways: division of labor, the facilities and equipment used, and the ease of solving cases. In crime television, forensic analyses are typically conducted by a single technician in an in-house laboratory, just a stroll away from the detective’s own office. Despite their large workload, the forensic examiner appears to manage seemingly without much difficulty [31]. The forensic laboratories are often portrayed as being equipped with state of the art technology and equipment [32]. Examiners conduct their analyses quickly and effortlessly, often in a matter of hours ready for criminal trial the next day [31]. Throughout this process, the examiners rarely make a mistake. In a content analysis of the first seasons of CSI and CSI: Miami, Smith et al. [33] found that errors were very rare and only ever occurred before any serious consequences, such as a misidentification.The effect that these misrepresentations of forensic science may have on jurors’ beliefs and perceptions is referred to as the “CSI effect.” Scholars and legal professionals typically point to the CSI effect literature to demonstrate that beliefs about forensic science can impact the outcomes of criminal trials [34]. The CSI effect is thought to influence jury verdicts by either: (a) burdening the prosecution due to jurors’ unrealistically high expectations that forensic evidence is available and necessary, resulting in higher rates of acquittal when forensic evidence is not present and making it more difficult for prosecutors to win convictions, or (b) by burdening the defense due to unrealistically high faith in the accuracy and reliability of forensic science, resulting in higher rates of conviction when forensic evidence is present [35]. These two possible outcomes are often referred to as the pro-defense and pro-prosecution biases.In response to anecdotal claims in the CSI effect literature [36,37], developed a new scale, the Forensic Evidence Evaluation Bias Scale (FEEBS), to assess jurors’ pre-trial bias towards forensic evidence. In line with the CSI effect literature, principal components analysis revealed two distinct constructs in the scale relating to pro-defense (example item: “no forensics means investigators did not look hard enough”) and pro-prosecution biases (example item: “forensic evidence is enough to convict”). They found that the pro-prosecution subscale of the FEEBS was positively correlated with other juror bias measures: the Juror Bias Scale [38] and the General Belief in a Just World scale [39]. They also found that the FEEBS pro-prosecution subscale significantly predicted participants’ perceived strength of DNA evidence in a mock trial, demonstrating support for the scale’s ability to tap into jurors’ bias towards forensic evidence.Anecdotal evidence from legal professionals indicates that they believe the CSI effect to be a genuine effect [40,41], however empirical research has produced mixed results supporting the nature of the CSI effect [35,42]. One potential explanation for these mixed results is that measuring participants’ crime show viewing habits does not adequately capture their beliefs, perceptions, and attitudes towards forensic science and forensic evidence. Pre-existing attitudes and beliefs have been shown to influence verdict preferences in a number of studies — from rape cases [43], capital offences [44], and civil litigation [45] to the insanity defense [46]. However, the CSI effect literature essentially uses crime show viewing as a proxy measure for beliefs and perceptions about forensic science; it makes the assumption that people who view crime shows will have different beliefs and perceptions about forensic science than those who do not. No research to date has directly tested this assumption or investigated people’s beliefs and perceptions about forensic science and forensic evidence. Further, at present it is also unclear whether people blindly believe that all forensic sciences are accurate or, rather, whether people believe that some techniques are more accurate than others.
1.5. Directly assessing beliefs about forensic scienceOnly a handful of studies have directly assessed jurors’ beliefs about forensic science. These studies suggest that people do hold beliefs about the reliability and validity of different forensic techniques, which tend to be overestimated [6,9,47].Hans et al. [47] asked a sample of jury pool members to rate the reliability of DNA evidence alongside expert witness evidence, police evidence, victims’ evidence, and eyewitness evidence. They found that DNA evidence was thought to be far more reliable than the non-scientific evidence types, with the majority (95%) of participants rating DNA evidence as extremely reliable or very reliable, compared to 66% for expert witness evidence, 67% for police evidence, 37% for victim evidence, and 25% for eyewitness evidence. In their first study, Lieberman et al. [9] directly compared students and jurors’ beliefs about the reliability of DNA, fingerprint, and hair/fiber evidence. DNA evidence was considered most reliable (94–95%), followed by fingerprints (90–91%) and then hair and fiber evidence (88–89%). Lieberman et al. [9] also found that greater pre-trial trust in DNA evidence significantly predicted a guilty verdict, suggesting that prior beliefs about forensic science can influence trial outcomes.Similarly, Lawson [6] asked participants to rate the reliability of DNA, fingerprint, tool mark and bite mark evidence, and found that DNA evidence was considered to be the most reliable, followed by fingerprint, bite mark, and tool mark evidence. While these studies provide some initial understanding of jurors’ beliefs about forensic science, they only scratch the surface. Firstly, these studies have only assessed a few of the many different forensic techniques. The current study aims to build on this previous literature by examining beliefs about a wide range of forensic techniques. Furthermore, these studies only ask participants to provide an overall judgment about the reliability of the technique and have not investigated their beliefs about what happens throughout the forensic science process. Thus, the current study will investigate beliefs about error and human judgment throughout each stage of the forensic science process.
1.6. Specific versus global error in forensic scienceOne of the benefits of investigating people’s beliefs about error at specific stages throughout the forensic science process is that we can determine whether their overall impressions (i.e., beliefs about accuracy) of forensic techniques reflects their beliefs about errors that occur at each stage. As most people have difficulty understanding and combining probabilistic information [[48], [49], [50]], it is possible that people might fall prey to base-rate neglect when assessing the overall accuracy of various forensic techniques.Base-rate neglect (also known as the base-rate fallacy) happens when people ignore relevant base-rate information (i.e., general information) in favor of more specific, but irrelevant information (i.e., information relating to a particular case; [51,52]). One reason why we tend to neglect base rates is due to the representativeness heuristic [53], where we make intuitive judgments of probability based on how similar to (or representative of) a prototype. In Kahneman and Tversky’s [51] well-known engineer-lawyer problem, participants disregarded the base rates of engineers and lawyers in favor of the description of the individual; even though the base rate suggests that the individual is more likely to be a lawyer, the description tended to fit that of a prototypical engineer rather than a lawyer.No prior research in the forensic science field has examined how people arrive at estimates of accuracy or error. Coming to an accurate estimate of the overall accuracy of forensic techniques would require participants to override their intuitive judgments and appropriately combine the base rates of error at each stage of the forensic science process. However, it is possible that participants may fall prey to base-rate neglect and the representativeness heuristic when making estimates of accuracy for forensic techniques. Therefore, their global estimates of accuracy for the sixteen forensic techniques are unlikely to be informed by their more specific estimates of error at each stage of the process.
1.7. Current researchThe purpose of this exploratory study is to identify the beliefs and perceptions people hold about forensic science and forensic evidence. To build on the previous literature, the current study will investigate beliefs about error rates and the degree of human judgment involved in forensic science. Furthermore, the study will not only examine these aspects for each forensic technique, but will identify beliefs about error and human judgment at each stage of the forensic science process including: collection, storage, testing, analysis, reporting, and presenting the evidence. Crime television shows tend to depict forensic evidence at different stages, therefore this study aims to determine people’s perceptions of error and human judgment at each of these stages. In doing so, we can also determine how people’s estimates about the overall accuracy of forensic techniques relate to judgments of error at each stage of the process.In this study, participants will be asked to think about forensic science generally, freely describe their opinion of what happens at each stage of the forensic science process, provide an estimate for the level of human involvement, judge how likely it is for an error to occur at each stage of the process, and then rate the accuracy and level of human involvement for sixteen different forensic techniques.1.7.1. HypothesesH1: We expect that estimates of error for each stage of the forensic science process would be low (i.e., less than 5%; H1a) and estimates of human judgment involved in each stage of the forensic science process would also be low (i.e., a mean value below the mid-point of 4; H1b). We chose 5% as the threshold for low error because in most scientific domains we generally accept an alpha level, or the probability of rejecting a true null hypothesis, to be 5% (α = .05). We also expect that there will be significant positive correlations between estimates of error and estimates of human judgment involved at each stage of the forensic science process (H1c).H2: If the CSI effect is robust, we expect that participants’ crime show viewing would be negatively correlated with estimates of error for each stage of the forensic process and with their estimates of human judgment for each stage of the forensic process.H3: For the individual techniques, we expect that estimates of accuracy for each technique would be high (i.e., more than 90%; H3a) and estimates of human judgment involved in each forensic technique would be low (i.e., a mean value below the mid-point of 4; H3b). We also expect that there will be significant negative correlations between estimates of accuracy and estimates of human involvement for each forensic technique (H3c).H4: If the CSI effect is robust, we expect that participants’ crime show viewing would be positively correlated with estimates of accuracy for each forensic technique, but negatively correlated with estimates of human judgment involved in each forensic technique.H5: Finally, in line with previous research investigating base-rate neglect and the representativeness heuristic, we expect that participants will be unlikely to consider the previous base-rates they provided about likelihood of an error occurring at each stage of the forensic science process when making their estimates of the overall accuracy of different types of forensic evidence. That is, the cumulative error for all stages of the forensic science process is likely to sum to more than 100.
