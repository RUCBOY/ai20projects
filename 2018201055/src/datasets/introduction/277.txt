The Cloud paradigm has introduced utility computing as a cost-effective way to ship software services to their final users by substantially reducing the operational effort required by service providers [1]. Meanwhile, in the last years, the Internet of Things (IoT) has grown constantly, and it is currently generating about 2.5×1018 bytes of data per day [2], often relying upon resource-constrained computing devices at the edge of the network to support IoT-enabled applications [3], [4], [5]. Consequently, existing deployments of IoT applications can be categorised [6], [7] into

•IoT+Cloud deployments [4] where IoT devices send data to Cloud data centres for further processing/analytics purposes, possibly awaiting for a response to act upon, and only minor computation happens in situ, or•IoT+Edge deployments [8] where data is processed locally at the edge of the Internet to determine reactions to sensed events.
On one hand, the IoT+Cloud deployment model relies on virtually unbounded computing capabilities but often produces high latencies and network congestion [9], which are not tolerable whenever the deployed application must meet stringent Quality of Service (QoS) requirements being, for instance, life-, business- or mission-critical. On the other hand, the IoT+Edge deployment model enables prompter reactions to sensed events by processing data closer to the IoT and it does not require transferring (possibly huge amounts of) data through the Internet, as computation is performed directly on edge devices (e.g., access points, routers, personal devices). This produces lower latencies and faster response times at the price of increased complexity to collect data across different systems and to run software on limited computing capabilities (e.g., resource-constrained or battery-powered devices) that cannot always suitably satisfy application requirements in terms of hardware capabilities, software dependencies and QoS-assurance.
To overcome these limitations, Fog computing has been proposed in support of IoT applications running over a seamless IoT-Cloud continuum of computing, storage and networking resources [6], [10]. The Fog relies on the assumption that application (micro-)services should be deployed wherever their (functional and non-functional) requirements can be satisfied at best [11]. Recently, a few data-aware approaches have been proposed to decide where to process data, i.e. whether in the Edge or the Cloud layer, or by suitably coordinating both according to the Fog paradigm (e.g., [12], [13]). Overall, the Fog makes it possible to reduce network traffic by processing and filtering IoT data before sending it to the Cloud and to substantially reduce response times by suitably placing latency-critical application (micro-)services in proximity of the edge of the Internet.
In [14], Bonomi et al. proposed an architecture of Fog computing platforms characterised by the presence of an orchestration layer for Fog services, as depicted in Fig. 1. The Monitor-Analyse-Plan-Execute (MAPE) loop embedded in the proposed orchestration layer should support the dynamic, adaptive life-cycle management of multi-service next-gen Fog applications. Implementations of such a MAPE loop should, therefore, enable the QoS- and context-aware management of Fog applications by repeating some well-defined phases:

Analyse– process data about the application, the infrastructure and its monitored performance so to make informed decisions on how to (re-)distribute application services,Plan– identify the sequence of actions needed to (re-)distribute services to different Edge or Cloud nodes based on QoS data and specified policies,Execute– orderly perform the deployment of all services or redistribute part of the application, andMonitor– monitor QoS performance of both the infrastructure and the running application to check whether it complies to some target metrics.
In the last years, a large amount of research contributed to devise models and methodologies specifically targeting the Analyse phase (e.g., [15]) and some work studied the Plan and Execute phases combined together (e.g., [16], [17], [18]). However, as highlighted in [10] and [19], way fewer works contributed to the design and prototyping of methodologies for enabling the Monitor phase in Fog computing orchestration platforms (e.g., [20]).
Indeed, monitoring is crucial to properly orchestrate Fog services, via next-gen application management systems [21], and it is challenging to design and implement. It is crucial because its output will be used both to choose where to deploy application services for the first time and to decide when and where to migrate them in case their requirements cannot be satisfied by the current deployment in the current infrastructure state. Factually, all proposed approaches for the Analyse phase require the availability of historical or real-time monitoring data about the available Fog infrastructure to output (sub-)optimal multi-service application (re-)deployments. Monitoring is also challenging to implement because it has to deal with various peculiarities of Fog infrastructures, such as (possibly) limited hardware resources and unstable connectivity at the Edge, platform heterogeneity, and node failures.Download : Download high-res image (123KB)Download : Download full-size imageFig. 1. Fog orchestration layer [14].
In our previous work, we proposed FogMon as a first distributed, cross-platform and lightweight C++ prototype monitoring tool for Fog computing infrastructures [22]. FogMon measures and statistically aggregates data on hardware capabilities (viz., CPU, RAM, HDD) at the monitored Fog nodes, end-to-end network QoS attributes (viz., latency and bandwidth) between those nodes, and available IoT devices. FogMon can be configured by its users and it exploits a two-tier Leader–Follower peer-to-peer (P2P) architecture and gossipping protocols to reduce the overhead due to spreading monitoring data across the monitored network.
In this paper, we extend the methodology (and the open-source prototype) of [22] with a new mechanism, based on the k-medoids algorithm [23], for (re-)structuring the P2P overlay network that FogMon exploits to monitor Fog infrastructures. The proposed extension enables to adaptively and automatically select, increase or decrease, Leader nodes in the P2P overlay, based on current network conditions, so as to maintain monitoring accuracy and scalability invariants. Besides, the new extended prototype features a new mechanism to handle nodes that leave and join the network, and it relies on differential monitoring updates to reduce the overall network overhead. We prove that the amortised time complexity of this new step remains sub-quadratic in the number of infrastructure nodes, and we run new experiments to assess its effectiveness in guaranteeing the reorganisation of the FogMon monitoring system in case of node failures and churn. Scalability of the new prototype to large-scale networks is also discussed by relating its network overhead to the maximum number of Followers a single Leader can handle. Finally, we thoroughly extend the analysis of the related work to better detail the relation between our research effort and those targeting the Analyse phase of Fog orchestration.
The rest of this paper is organised as follows. We first detail the design and the extended implementation of FogMon in Section 2, with a focus on the newly introduced mechanism for topology self-organisation. Then, we illustrate a real case study deployment of FogMon in Section 3, and we discuss some related work on predictive analyses for Fog orchestration and on existing Fog infrastructure monitoring tools in Section 4. Finally, we draw some concluding remarks and highlight directions for future work in Section 5.
