Deep Convolutional Neural Networks (CNNs) have shown great success in many vision tasks. There are several successful networks, e.g., VGG [1] and ResNet [2]. Driven by the emergence of large-scale data sets and fast development of computation power, features based on CNNs have proven to perform remarkably well on a wide range of visual recognition tasks. Liu et al. [3], and Babenko and Lempitsky [4] demonstrated that convolutional features can be seen as a set of local features which can capture the visual representation related to objects. To make better use of deep convolutional features, many efforts have been devoted to aggregating them, such as max pooling [5], cross-dimensional pooling [6], sum pooling [4], and bilinear pooling [3], [7]. However, modeling these convolutional features to boost the feature learning ability of a CNN is still a challenging task. This work investigates a more effective scheme to aggregate convolutional features into a robust representation via a Symmetric Positive Definite (SPD) manifold network in an end-to-end framework.
The SPD matrix has shown the powerful representation ability and been widely used in the computer vision community, such as the face video recognition [8], 3D face recognition [9], medical image processing [10], [11], and metric learning [12]. Through the theory of the non-Euclidean Riemannian geometry, the SPD matrix often turns out to be better suited in capturing desirable data distribution properties.
The second-order statistic information of convolutional features, e.g., the covariance matrix or Gaussian distribution, is the commonly used SPD matrix representation endowed with CNNs [13], [14], [15]. The dimensionality of convolutional features extracted from CNNs may be much larger than that of hand-crafted features. As a result, the covariance matrix or Gaussian distribution is inferior to precisely model the real convolutional feature distribution. When the dimensionality of features is larger than the number of features, the covariance matrix and Gaussian distribution are Symmetric Positive SemiDefinite (PSD) matrices. The PSD matrix representation has an unreasonable manifold structure and may lose some high-level variation information among convolutional features and be less discriminative than the real SPD representation. Moreover, most covariance matrices embedded into deep networks only contain the linear correlation between features. Owning the ability of capturing the nonlinear relationships between features is indispensable for a generic representation.
It is thus desirable that a more discriminative and suitable SPD representation aggregated from deep convolutional features should be established in an end-to-end framework for visual analysis. To this end, we design a series of new layers to overcome the existing issues aforementioned based on the following two observations.
•Kernel functions possess an ability of modeling nonlinear relationships of data, and they are easy and flexible to be computed. Wang et al. [16] have witnessed significant advances of positive definite kernel functions whose kernel matrices are real SPD matrices, no matter what the dimensionality and the number of features are. Since many kernel functions are differentiable, such as Radial Basis Function (RBF) kernel function, Polynomial kernel function, and Laplacian kernel function, they can be readily not only utilized to aggregated features but also embedded into a network to carry out end-to-end training. The kernel function is well aligned with the design requirement of a deep network.•Many works [17], [18], [19] showed that a learnable mapping from the SPD matrix to another makes the representation become more discriminative and task-specific. The mapped matrix is still an SPD matrix which not only has characteristics of a general SPD matrix that captures desirable properties of visual features but also is more suitable and discriminative for the specific visual task.
Motivated by empirical observations mentioned above, we introduce a convolutional feature aggregation scheme which consists of the SPD generation and the SPD transformation. Three new layers, i.e., a kernel generation layer, a matrix transformation layer, and a vector transformation layer are designed to replace the traditional pooling layers and fully connected (FC) layers. In particular, we deem each feature map as a sample and present a kernel generation layer using a nonlinear kernel function to generate an SPD matrix. The proposed kernel matrix models nonlinear relationships between feature maps and ensures that the SPD matrix is nonsingular. The proposed matrix transformation layer can be employed to transform the SPD matrix to a more compact and discriminative one by learnable parameters. It can not only capture the real spatial information but also encode high-level variation information. Thanks to the symmetry property of the SPD matrix, the vector transformation layer carries out the upper triangle vectorization and normalization operations on the SPD matrix. Through these layers, a robust vector representation is got under an end-to-end framework. The proposed SPD aggregation scheme can also be utilized under a non-learnable process only with a pre-trained network, except the matrix transformation layer, since the matrix transformation layer needs to be optimized. The SPD representation actually acts as a mid-level representation bridging convolutional features and high-level semantics features. In this paper, we apply it to visual search and classification tasks to show the effectiveness of our method in both non-learnable and end-to-end frameworks, and the applied network architecture is shown in Fig. 1.Download : Download high-res image (529KB)Download : Download full-size imageFig. 1. The flowchart of our SPD aggregation network. We focus on obtaining an robust SPD matrix representation from convolutional features via the SPD generation and transformation. The PCA and 1 × 1 convolutional layer are applied to preprocess convolutional features from a pre-trained CNN. Then, the kernel generation layer, matrix transformation layer, and vector transformation layer are employed successively. Several visual search tasks are utilized to demonstrate the power of our method only using a pre-trained network, and visual classification tasks are under an end-to-end framework by finetuning the network.
In summary, our contributions are three-fold.
(1)We formulate the convolutional feature aggregation as an SPD matrix non-linear generation and transformation problem on the Riemannian manifold to obtain a robust representation. Our middle-level SPD representation can well characterize the underlying structure of convolutional features.(2)We carry out the nonlinear aggregation of convolutional features under an end-to-end Riemannian deep network architecture, where three novel layers are introduced. The state-of-the-art performance of our SPD aggregation network is consistently achieved over visual search and visual classification tasks.(3)We exploit the faster matrix operation to speed up the computation in the kernel generation layer. In addition, we present the component decomposition and retraction of the orthogonal Stiefel manifold to carry out the backpropagation in the matrix transformation layer.
The remaining sections are organized as follows. We review recent works about feature aggregation methods in both the Euclidean Space and Riemannian Space in Section 2. Section 3 presents details of our SPD aggregation method. We report and discuss experimental results in Section 4, and conclude the paper in Section 5.
