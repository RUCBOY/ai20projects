Person search is an extended form of person re-identification (re-id). Person re-identification (re-id) is an important research issue, whose goal is to match the same person in different camera views or across time in the same camera [1], [2], [3], [4], [5]. It has many video applications included but are not limited to finding criminals [6], cross-camera person tracking [7], human activity analysis [8], content-based video retrieval, video monitoring and human–computer interaction. Due to its importance in these applications, it has attracted more and more attention in recent years. However, due to varying poses, lighting conditions, occlusions and other reasons, there are still some challenges and unresolved issues.
Despite considerable progress, person re-id is still not directly applicable to real-world applications. Most existing re-id benchmark datasets and methods focus on matching cropped person images from multiple non-overlapping cameras [9], [10], [11], [12]. Although these methods have achieved good results, they have great limitations in practical application due to the assumption of accurate detection of person. In real-world applications, precise border boxes are either unavailable or expensive.
The concept of person search was first proposed by Zheng et al. [13], and the author also provides a large-scale person search dataset. The task of person search requires us localize the target person from the gallery of whole scene images. It is a new and challenging task that requires to address detection and re-identification simultaneously, which is more realistic. For that real-world scenarios where the bounding boxes of pedestrian are unavailable and the target person needs to be searched from a gallery of whole scene images, as shown in Fig. 1.Download : Download high-res image (766KB)Download : Download full-size imageFig. 1. Comparison of person search and person re-id. The first line is the scene of person search, where the person searches the entire image without cropped persons, and use the highest rated candidate box as the target to be searched. However, the second line of re-id directly uses the cropped image and compares and sorts the similarity with the search query. The left column is the probe/query image, and the other columns are the gallery images. The green tick represents the successful selection of the search target, and the green bounding boxes in the person search are the correct search results.
Inspired by Zheng et al. [13], many other works [14], [15], [16], [17], [18] have also been proposed for person search. The first to joint detection and identification is [18], the author adopted the end-to-end person search model based on a random sampling softmax (RSS) loss layer to train network. Generally, most of the previous person search methods are based on such a simple two-stage search strategy: first detect all candidates in the image, and then perform a detailed comparison between all possible query pairs and candidates to output the search results that rank first in the search image. In [15], the re-identification feature learning exploits Online Instance Matching (OIM) loss, which is more suitable for the task of person search.
At present, it is still under discussion to separate person search into independent tasks or training jointly. Typical methods of person search track detection and re-identification sequentially via separate supervised networks. It can effectively alleviate the interference of two tasks. However, when separating the two tasks, separated model may remove the useful contextual information for the re-id network because the query is cut from the query image. In addition, detection and localization tasks cannot take advantage of information from queries, since the detection network runs independently before re-id network.
End-to-end model optimizes the detector and the re-identification networks jointly. The detector classification loss may interfere with the re-id classification loss, resulting in a weakening of the performance of person re-id, which is the price of end-to-end. But it has the advantage of reducing manual pre-processing and subsequent processing, and as much as possible from the original input to the final output. At the same time, the model provides more space that can be automatically adjusted according to the data, thus increasing the overall performance of the model.
The pedestrian detection part of the most of end-to-end person search network [14], [15], [16], [18] is based on Faster-RCNN [19]. However, they did not change some of the parameter properties in the Faster-RCNN. Because Faster-RCNN was not originally designed for pedestrian datasets, the most important part is the size and ratio of the anchor. So changes to the object of the pedestrian are needed. By analyzing two large datasets, according to the properties of the pedestrian box, our work designs structure-aware anchor for person search based on Faster-RCNN.
From the whole scene picture to find pedestrians, due to the fixed camera shooting pictures, there must be pedestrian-intensive areas, such as the exit of the mall, the zebra crossing of the road. Finding pedestrian-intensive areas can be helpful in improving the performance of the person search network. So our work introduces the latest development of self-attention [20] in computer vision technology, non-local neural network [21].
Person search faces the same challenges as re-identification. Especially in the face of large datasets, the differences in visual appearance of a particular person owing to occlusions, viewpoints, and varying poses. Therefore, we need to learn more distinguishing individual features. Sun et al. [22] reduces the intra-personal variations by pulling features extracted from the same identity together. Inspired by this, OIM loss and center loss [23] are jointly used for feature learning, leading to better performance than the only OIM loss [15].
Traditional re-id feature learning primarily needs to organize positive and negative sample pairs. However, they are not efficient as the pedestrians appearing in each image are sparse, random and unbalanced. It is difficult to organize a certain number of positive and negative pedestrian pairs in the image-based re-id. We propose the Online Instance Aggregation Matching (OIAM) loss, which does not need to organize a certain number of positive and negative sample pairs in each image. OIAM loss aggregate the OIM loss and the center loss, both of which do not require to aggregate positive and negative verification samples. More details we will explain in Section 3.3.
In summary, the main contributions of the proposed method can be listed as follows:
-We employ non-local module in our person search network, which effectively helps the deep network better integrate non-local information. Make our network model more closely pay attention to the area where pedestrians gather in the scene picture.-We propose structure-aware anchors in the pedestrian detection framework Faster-RCNN. Adjust the ratios and scale of the anchor according to the properties of the pedestrian box.-We propose a novel Online Instance Aggregation Matching (OIAM) loss, which can accurately localize persons by not only learning to minimize intra-person feature variations but also being scalable to datasets with numerous identities.-We conduct experiments on the large-scale CUHK-SYSU dataset and PRW dataset and achieve significant improvements over the compared approach in both mAP and top-1 evaluation protocols.
