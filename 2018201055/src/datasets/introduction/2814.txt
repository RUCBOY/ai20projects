The human vision system intends to extract the most informative objects and regions in a scene naturally, and then combines these local information to efficiently understand the whole scene. But why and how can human beings detect and locate the salient object in a cluttered scene rapidly and immediately? This kind of visual attention mechanism has prompted many researchers to stimulate this ability in computer vision tasks. Salient object detection aims at finding the most important objects in a scene in order to simulate the functionality of biological vision systems. Salient object detection algorithms usually offer a saliency map to measure the saliency value for each pixel, which can provide more evidence for numerous computer visions tasks, including object detection, image categorization, and video compression, to just name a few [1], [2], [3], [4], [5].
The earliest bottom-up saliency model proposed by Itti et al. [6] is based on linear center-surround operations on multiscale low level features. The center-surround mechanism is inspired by visual receptive fields under the assumption that visual neurons are most sensitive to the center region of a scene. Diversion of visual attention is also simulated in the earliest work. Theories behind this classic saliency-based visual attention framework include feature integration theory, guided-search model, and computational attention architecture. This work influenced the development of bottom-up methods by generating saliency maps based on series cognitive priors.
However, saliency detection can also be treated as a pixel-wise classification problem. With the development of top-down methods, perspectives on understanding this problem are evolving. Saliency detection has thus become an image segmentation task with specific purposes. In other words, this task attempts to segment (predict) the most attractive parts, regions, or objects in an image in line with the function of the human visual attention system. From this point of view, salient object detection, to some extent, in a combination form comprising both saliency detection and object segmentation. Moreover, with the growing interest in object-driven computer vision tasks and their real-world applications, researchers have been focusing more on the objects in an image, which is another factor in this conversion.
This conversion also brings salient object detection closer to other related fields, e.g., fixation prediction, image segmentation, object proposal generation, etc. Fixation prediction models rely on understanding human visual attention through eye movement prediction, while image segmentation attempts to segment images into several parts by assigning each pixel to sub-regions without considering whether or not the region is salient. Object proposal generation aims to predict which part of an image should be an object instead of classifying them into specific categories [7]. Many hybrid methods, by combining the aforementioned techniques, have been proposed in recent years[8], [9], [10], [11].
In this paper, we propose a bottom-up method for salient object detection by both considering objectness and saliency detection under the Graph-based Manifold Ranking (GMR) framework. Specifically, we firstly use the superpixel algorithm to over-segment the original image, and then extract color (mean CIELAB and color histogram) and Normed Gradient (NG) features [12] for each superpixel. We calculate geodesic distance to measure the similarity between any two superpixels. By using one-stage manifold ranking algorithm [13], we obtain a rough saliency map for each type of feature. For each saliency map, we employ a saliency optimization method to refine the one-step manifold ranking result. Finally, a multilayer cellular automata mechanism is utilized to fuse the saliency maps to achieve the final saliency detection result. To sum up, the main contributions of this paper include three aspects: (1) a new methodology is introduced to integrate saliency maps produced from different feature spaces by considering multiple detection cues (i.e. saliency and objectness); (2) a method for producing manifold ranking results is developed by using the geodesic distance matrix based on boundary connectivity prior; (3) a strategy based on multi-layer cellar automata is designed to obtain the final saliency map by considering different features. Experimental results demonstrate that our method can deliver promising performance in comparison to several state-of-the-art bottom-up methods on many benchmark datasets.
The rest of the paper is organized as follows. In Section 2, we briefly overview related works. Section 3 provides an overview of our proposed framework, including introduction of preliminaries, implementation details etc. Experimental results on validating our proposed method are illustrated in Section 4. Finally, in Section 5, we conclude the paper with future work propositions.
