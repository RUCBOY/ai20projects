Alzheimer’s disease (AD) is the most common form of dementia. Dementia is a general term that describes a set of symptoms associated with a decline in memory or other thinking skills severe enough to reduce a person's ability to perform ordinary activities. Alzheimer’s disease accounts for 60–80 percent of cases of dementia. In early stages of disease, also known as mild cognitive impairment (MCI), memory loss is mild, but with late-stage Alzheimer’s, the patient loses the ability to even carry on a conversation. According to a recent report (Fargo, 2014), the annual number of new cases of AD and other dementias is projected to get doubled by 2050.
AD, being one such disease for which currently there is no cure or treatment that slows or stops its progression, therefore requires robust and accurate methods for its early diagnosis (Bron et al., 2015). The diagnosis of Alzheimer’s disease requires a variety of medical tests which leads to huge amounts of multivariate heterogeneous data. It can be certainly exhausting to manually compare, visualize, and analyse this data due to the heterogeneous nature of medical tests.
The success of deep learning algorithms at visual object recognition tasks and competitions such as ILSVRC (Russakovsky, 2015) intersects with a time of dramatically increased use of electronic medical records and diagnostic imaging. Although the terms machine learning and deep learning are relatively recent, their ideas have been applied to medical imaging for decades, perhaps particularly in the area of computer aided diagnosis (CAD) and medical imaging applications such as breast tissue classification (Sahiner et al., 1996); Cerebral micro bleeds (CMBs) detection (Dou et al., 2016), Brain image segmentation (Chen et al., in press, Hemanth et al., 2016) and classification (Hemanth et al., 2012, Hemanth et al., 2011), CT liver image segmentation (Zidan, Ghali, Ella Hassanien, Hefny, & Hemanth, 2012).
Deep CNNs are most popular these days amongst computer vision researchers due to their recent performances in certain tasks such as visual object recognition, detection and segmentation. Some of the advantages of CNNs over ANNs (Artificial Neural Networks) are that they operate over volumes, unlike regular neural networks where the input is a vector, here the input is a multi-channelled image (e.g. RGB Image).
CNNs have concept called as parameter sharing i.e. same weights are shared by multiple neurons in a particular feature map. Local connectivity is the concept of each neural connected only to a particular region of image unlike ANNs where all neurons are fully-connected. Basic building blocks of CNNs are discussed in Section 3.1.
Even though CNNs have performed exceptionally well for computer vision tasks in medical field recent couple of years, however training these huge architectures from scratch has few limitations (Tajbakhsh et al., 2016):
(1)Proper training of deep neural networks requires huge amount of annotated data, which can be a problem especially for medical imaging field where it is expensive and sometimes difficult to acquire sufficient data.(2)Training of such architectures requires huge amount of computational resources.(3)Deep learning requires careful and tedious tuning of hyper-parameters, optimal tuning, which otherwise can lead to overfitting/underfitting, resulting in overall poor performance.
To resolve these issues, researchers have come up with a successful alternative approach called transfer learning (Yosinski, Clune, Bengio, & Lipson, 2014). Transfer learning is a machine learning method where a model developed for a task is reused as the starting point for a model on a second task.
In practice nowadays, very few people train an entire CNN from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a CNN on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories) (CS231n Convolutional Neural Networks for Visual Recognition).
For our 3-way classification problem AD vs MCI vs Cognitively Normal (CN), Classification model is built by performing transfer learning using a state-ofthe-art CNN architecture, VGG16 (Simonyan & Zisserman, 2014). VGG16 is a 16-layer network built by Oxfords Visual Geometry Group (VGG). It participated in the ImageNet competition in ILSVRC 2014. It is one of the first architectures to explore network depth by pushing to 16 layers and using small (3 × 3) convolution filters.
In this paper, VGG16 is taken as the base model for applying transfer learning. The base model is used as a feature extractor and additional fully-connected layers are added on top of it. The resultant mathematical model obtained PFSECTL is then trained on most informative brain MRI slices keeping the layers of the base model non-trainable.
Our main objective in this paper is to show how instead of training a completely new model from scratch, we can utilize transfer learning approach to build a classification model. Training a CNN which is as big as VGG16 requires huge computational resources and takes weeks to get trained, on the other hand performing transfer learning using same pretrained CNN takes much lesser time, typically few hours. Thus, we use transfer learning and show how a CNN because of its state-of-the-art generalization of local features can be used for medical images, even though medical images are from different domain than the actual images on which CNN is trained. Also, large CNNs require large corpus of data, sometimes in millions for their training while availability of medical images is comparatively lesser which is one more reason we were prompted to use transfer learning. Moreover, we also use only those sMRI slices of subjects that has most amount of information in it by comparing their entropy, hence strengthens the overall robustness of the model. As a result, we have a mathematical model PESECTL which is capable of correctly distinguishing between 3 different classes of different subjects with promising performance. The highlights of our paper are:
•MRI scans are 3D in nature therefore can also be considered as stack of 2D MRI slices. We can select a set of most informative slices from this stack to do the classification.•Using CNN eliminates the task of manual feature extraction.•Through transfer learning we can use a model trained on natural images to classify medical images.•Transfer learning effectively reduces computational cost and advantageous when data available is in less amount.•Overfitting of the model is main concern that is taken into account while building the model and dropout regularization is used to avoid it.•MCI is the most difficult class to classify since it is intermediate stage between AD and CN.
The rest of the paper is organized as follows: Section 2 discusses the related work in the field of Alzheimer’s disease prediction. Section 3 gives the complete explanation of the proposed methodology. Section 3 has been divided into 7 subsections, in which first Section 3.1 discusses the components that are used in building a CNN, 3.3 Alzeihmer classification mathematical model – P, 3.6 Classification using transfer learning (C, 4 Experimental results discusses the steps followed to prepare the training data for the classification task. In Section 3.3 – the mathematical model is explained with subsequent Section 3.6 discusses how transfer learning has been used to perform classification. After this, Section 4 lists Experimental results, accuracy and loss function plots of our classification model and comparisons with other existing techniques. Finally, Section 5 depicts the final conclusion for the method also emphasizing its application with the future scope of it.
