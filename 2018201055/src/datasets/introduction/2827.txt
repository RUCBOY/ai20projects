Low-light is a challenging environment for human vision as the lack of visibility affects a person’s ability to perform tasks. Therefore, computer vision algorithms that can provide assistance in such conditions are highly valuable. However, current research works related to the low-light domain are mostly on image aesthetic enhancement instead of applications, like object detection, that can be developed into practical intelligent vision systems, such as visual surveillance and autonomous car driving [1].
The motivation of our work is to shift the focus of low-light image1  enhancement research from the aesthetics driven studies towards a functional practice, i.e. enhancement in support of computer vision applications. For this reason, a change is necessary not only in the formulation of enhancement frameworks but also the evaluation schemes. Hence, in this paper, we set out to achieve two objectives, (1) to propose a low-light image contrast enhancement framework that primarily retrieves features that were degraded by low illumination and contrast, while visual quality is secondary, and (2) to propose new evaluation metrics that would assess the ability of enhancement algorithms to retrieve features.
Low-light image enhancement is a non-trivial task because of the non-uniformity of scene luminance, as shown in Fig. 1. It can be seen that Fig. 1(a) is a uniformly dark low-light image, however, there are others with weak light sources in the dark environments, such as Fig. 1(b), or reflected from surfaces, as shown in Fig. 1(c). Researchers mostly seek to counter the over and under enhancement problems caused by such phenomenon through increasingly sophisticated methods of manipulating the illumination of the image. However, to the best of our knowledge, none has explicitly considered the prospects of restoring features that could be used as a result of the enhancement. As we will demonstrate, state-of-the-art low-light image enhancement algorithms produce results with good visual quality but do not necessarily retrieve the most features.
In this paper, we make two major proposals. First, is a framework that addresses the challenge of low-light enhancement from the perspective of features retrieval. Based on our analysis of low-light image characteristics, we noted that the enhancement functions has to be localized within an image for optimal results, i.e. individual functions to brighten, maintain, or darken, specific regions or pixels. To this end, we employed Gaussian Process regression to construct a distribution of such functions with the support of a Convolutional Neural Network to introduce feature enhancement functions into the distribution. Secondly, we propose two new evaluation metrics that focus on features retrieval to demonstrate the usability of image enhancement algorithms for high level computer vision tasks. Namely, the precision, recall, andF-score of local features matching, and l1-norm distance measure of intensity histogram.Download : Download high-res image (881KB)Download : Download full-size imageFig. 1. (Top) Low-light images, and (Bottom) our contrast enhancement results, with their respective intensity histograms. The low-light images are not only brightened, but the details of the image content are also visibly improved, such as the (a) poster design, (b) text, and (c) cat. More details are provided in Sections 5.2 Qualitative evaluation, 5.3 Quantitative evaluation. These sample images are from the MS COCO dataset.
Experimental results showed that our proposed framework outperformed the state-of-the-art [2], [3], [4], [5], [6], [7] in our newly proposed feature matching evaluation while comparable in the l1-norm distance of histogram as well as the standard image quality measure, the peak signal-to-noise ratio (PSNR). Moreover, qualitative evaluation of enhancement on real low-light images from the ExDark dataset [1] showed that our proposal is able to overcome problems such as color distortion, saturation, over-enhancement, and noise.
