With the development of online social networks (OSNs), we are facing a revolutionary way of social interactions and communications. Notably, the Twitter, as a kind of OSN, is becoming pervasive because of its effectiveness. The Twitter possesses a significant amount of social data, which can be viewed as a social network with the particular graph structure composed of individuals (or organizations) and connections among these individuals. In this graph, each individual or organization possesses its profile, like gender, age, and political affiliation for personal, and band, features, and specialized services for organizations, etc.
Massive social media data have a critical potential economic valuation for many real-world applications. Puschmann and Burgess (2013) proposed a social data selling model, in which the Twitter first sells social data to the third-party data service provider (like Gnip and DataSift), which then resells such data to data users for commercial or academic data mining.
However, many black stores show that the data service provider may collude with advertising companies to add/delete/modify its social data to achieve business profits. For instance, Google was deemed to manipulating search suggestions to support Democratic presidential hopeful Hillary Clinton when she was stuck in “Email Controversy” (Richardson, 2016). Specifically, when someone types “Hillary Clinton cri”, Google provides search suggestions, like “Hillary Clinton crime reform” and “Hillary Clinton crisis”, while Yahoo or Bing suggests “Hillary Clinton crimes”. Another example is that the famous review website Yelp forced businesses to manipulate reviews to achieve business profits (Richardson, 2013). Similarly, the data service provider in this paper also may tamper social data by launching adding/deleting/modifying attacks or returning fake query-results. These behaviors violate the interests of data users and have severe effects on our daily lives and our legal right seriously. To guarantee the integrity of query results, some methods have been proposed to verify the correctness and completeness of query results, like Merkle hash tree (Bertino, Carminati, Ferrari, Thuraisingham, Gupta, 2004, Li, Yi, Hadjieleftheriou, Kollios, 2007, Mouratidis, Sacharidis, Pang, 2009, Pang, Mouratidis, 2008, Papadopoulos, Yang, Papadias, 2007, Yang, Papadopoulos, Papadias, Kollios, 2008, Zhang, Zhang, Zhang, 2012) and signature aggregation (Narasimha, Tsudik, 2006, Pang, Tan, 2008, Pang, Zhang, Mouratidis, 2009). However, such schemes did not take into consideration friendships among vertices in social networks. To verify the completeness of query graphs, Goodrich et al. (2003) proposed a scheme to verify whether two nodes are connected in the graph, and Yiu et al. (2010) proposed the landmark-based verification method (LDM) to verify whether the query result is the shortest path on the original graph. Nevertheless, these previous studies focus on the completeness of social networks while ignoring the profiles of vertices.
In this study, we are among the first to describe the definitions of correctness and completeness of social data. For the correctness aspect, social data, received by users, are all correct (refer to Definition 1). While for the completeness of social data, we define it as the following three aspects: Vertex Completeness, Profiles Completeness, and Friendships Completeness (refer to Definition 2). To verify social data, we first propose a deterministic basic scheme FakeDetection to implement the above correctness and completeness verification. However, the Twitter needs to take a large overhead to generate auxiliary information. To further make our scheme efficent, we propose a probabilistic scheme FakeDetection+ to check whether the data service provider tampers the original social data before selling to data users.
Here, our contributions are listed as follows:
•Aiming at real applications, we consider the correctness and completeness verification of social data.•To address the verifiable problem, we first propose a deterministic verifying method, FakeDetection, which can detect fake activities.•To further reduce the computation overhead, we propose a probabilistic scheme FakeDetection+, which takes nearly 3.8% computation overhead of the FakeDetection to achieve the detection probability of 99% for 1.6M twitters.•To demonstrate the performance of our schemes, we conduct the experiment on real social data (Twitter data), and the results demonstrate our schemes are very efficient for the current data size.
The rest of this paper is organized as follows. We first describe related work in Section 2. We then introduce the system and adversary models in Section 3. Section 4 presents the problem definitions. Next, we present our basic scheme in Section 5 and our enhanced scheme in Section 6. In Section 7, we analyze the detection results. Section 8 analyzes the performance of our proposed methods. Sections 9 and 10 present our experimental results and conclude our study.
