Virtual reality technology uses computer to construct a virtual environment in three-dimensional space, providing users with a high-fidelity, immersive visual, auditory and even tactile experience through display devices such as screens and helmets. Users can use interactive devices to interact with objects in the virtual world to achieve an immersive feel. Nowadays, with the rapid development of virtual reality technology, virtual reality has been widely used in many fields such as industry and entertainment.
The modeling and rendering of virtual scenes, namely the construction and representation of virtual objects in 3D virtual environment and the rendering of free viewpoint images during user roaming, are fundamental problems of virtual reality technology. Depending on the application scenario, the virtual environment can be a completely fictional three-dimensional scene, or it can be a reproduction of a real-world scene, or a three-dimensional environment created by adding fictitious elements based on real-world scenes. With the development of the internet, sensors, drones, etc., people can collect image data or video data from a large number of real-world scenes more easily. Therefore, how to use such data to reconstruct the information of the real scene in the virtual environment, so that users can roam the virtual scene from any viewpoint, has become a concern in virtual reality technology.
The traditional way to simulate real scenes is 3D modeling and rendering. The modeling part is to recover the geometric information of the scene and the illumination information. Common modeling methods include manual modeling using geometric modeling software, reconstruction of the geometry from multiple photographs capturing real-world scenes using structure-from-motion and texture mapping1, 2. The rendering part including geometric cropping, illumination calculation and element simplification of the reconstructed scene according to the user’s viewpoint, is to generate the image observed from the current viewpoint. This traditional process based on 3D modeling and rendering can fully express the geometric information of the scene, so that users can flexibly change the external conditions such as illumination to obtain different rendering effects, and can easily roam the scene freely. However, the complexity of this modeling and rendering process is very high. The time required for modeling and rendering will increase significantly, when the scale of the scene is larger and the surface details of the objects in the scene are richer. In addition, the rendering results obtained by this traditional 3D modeling and rendering process are usually not photo-realistic without high computational cost.
Due to these limitations of traditional 3D modeling and rendering methods, people are more concerned about whether they can roam the scenes directly using the collected image dataset. Google Street View captures street scenes using street view cars, and provides 360° panoramic photos for users so that they can see the street scenes from different directions[3]. However, users can not look at the scene from arbitrary viewpoints because the image seen from uncaptured viewpoints can not be rendered, which is much easier using traditional 3D modeling and rendering process. Therefore, how to use finite and discrete captured image to obtain continuous and arbitrary viewpoints becomes an important issue. This is called image-based rendering. More specifically, image-based rendering technique is a technique of generating a rendering result of an unknown viewpoint by interpolating through discrete input images or re-projecting pixels in input images. This rendering method uses images as the fundamental elements, which requires no more complicated geometric modeling processes and rendering processes but only some analysis and processing of images. The complexity does not increase with the complexity of object relationships and surface details in the scene, which can significantly save computing resources. Moreover, since the results are directly rendered from photos, it can be photorealistic.
The essence of image-based rendering technology is to obtain all the visual information of the scene directly through images. Previous image-based rendering techniques can be classified into three categories according to how much geometric information is used: rendering without geometry, rendering with implicit geometry, and rendering with explicit geometry[4]. Likewise, we classify previous techniques into two categories, rendering with or without geometry, to introduce some classic approaches and some new algorithms. We also analyze the limitations and key issues of these approaches.
