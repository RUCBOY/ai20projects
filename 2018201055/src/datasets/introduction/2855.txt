Cloud computing enables an economically promising paradigm of computation outsourcing [1]. Immense computation power and storage capacity of computing systems enable everyday Internet users to store and process large-scale data on a “pay as you go” model [2]. As more users move their activities to the Cloud, the number of data centre nodes increases as well. The global data center market is estimated to reach revenues of around 174 billion by 2023, growing at a Compound Annual Growth Rate (CAGR) of approximately 4% during the forecast period.1
The demand for data centres processing capacity is expected to increase by 7 to 10 times in the next 5 years [3]. However, as the scale of Cloud data centres increases, the physical servers cause high power consumption and environment problems. Today, the annual power consumption of global data centres is about 3000 TWh, equivalent to the total power generation of 300 nuclear power plants [4]. For example, the annual power consumption of Google’s Cloud data centres is up to nearly 203,000,000 kWh [4]. The inefficient utilization of resources causes unnecessary waste of energy. Kurnik et al. [34] show that the current under-utilization rates of many servers in data centres are around 90%.
The effective virtualization of resources can be used to solve the low energy efficiency problem. In Cloud systems, nodes are virtualized in a unified and on-demand resource pool, which improves the utilization rates of resources and reduces the required number of computing nodes to a certain extent [5]. De Assuncao et al. [6] suggest that during an infrastructure’s high energy consumption period, for each 1 kWh power used for computing, there is an additional 0.5–1 kWh power used for cooling. A physical node with low utilization rate of resources can switch to a sleeping state, or even shut down by migrating its VMs dynamically to other data nodes, in order to attain the better energy-saving effect. In order to effectively improve the service performance of Cloud computing systems, while at the same time also reduce the cost of service and energy consumption, we suggest that efficient VM monitoring management, scheduling and migration algorithms and strategies are essential.
Many research results have been proposed in this field, such as the migration cost-aware locally optimal placement algorithm (pMaP) [7], the peak clustering-based placement (PCP) [7], the minimum migration time cuckoo optimization algorithm (COA-MMT) [8], the minimum migration time imperialism competitive algorithm (ICAMMT) [9], etc. However, three major problem-specific challenges make the solution a complex task:
1.The virtual machine scheduling and migration are only conducted on data, such as CPU utilization and RAM remaining space. Due to the random distribution of active nodes in Cloud data centres, it is difficult to implement regional precise temperature control.2.VM scheduling and migration requirements are considered logically, while the actual data node deployment scenarios, the heat distribution, and the operation mode of the temperature control system of Cloud data centre are not. Due to the poor linkage between data nodes and the temperature control equipment, it is difficult for these algorithms to be applied in actual Cloud data centres.3.Data center overheating is problematic, which makes it difficult to solve, compromising the maintenance of the system’s stability. The local overheating problem of data centre affects the lifetime of computing, storing and communication equipment. The throughput and latency in future data centre networks must be significantly improved to sustain the increased network traffic and the total power consumption inside the racks must remain almost the same due to thermal constraints [10]. If a node’s dataset involves heavy computing tasks with relatively poor thermal performance, it might lead to abnormal behaviour (e.g. shut down due to local overheating) [11].
In order to achieve the goals of load balance, energy efficiency, service-level agreement (SLA) and stability, Cloud data centres need more reasonable algorithms for scheduling, migration and management of VMs. Considering the actual server deployment and the temperature control mode of real Cloud data centres, we propose a novel VM scheduling algorithm based on the gravitational effect (VMSAGE).
The contribution of this work is that VMSAGE creatively utilizes the concept of physical gravitational effect and defines various attributes, including the thermal repulsion factor between the physical node and a virtual machine, the logical gravitation and the modified gravitation, along with their calculation functions. Specifically, our approach is based on the following three novel elements:
(a)Thermal repulsion factor. The thermal repulsion factor not only does it achieve the diffusion of the VMs from overheated data nodes in order to stabilize both the entire system and the local systems, but also prevents data nodes from collapsing and from further damage. This guarantees quality of service (QoS) while keeping SLAs.(b)Logical gravitation. The logical gravitation aggregates VMs to specific data nodes. We shut down those data nodes when a low resource utilization rate is observed.(c)Accord priority to heat dissipation. Accord priority to heat dissipation, the modified gravitation analyzes the heat distribution in Cloud data centres and makes the virtual machines migrate to the data nodes with good heat dissipation performance to achieve the balance of heat distribution and avoid overheated server racks.
In Section 2, we describe previous work in the area. Section 3 describes the scheduling algorithm, while Section 4 contains the implementation details of VMSAGE. In Section 5, we conduct our performance evaluation and finally, in Section 6, we conclude.
