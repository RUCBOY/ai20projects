In recent years, deep CNNs have been shown as a powerful solution to resolve the detection problem mentioned above. It is noteworthy that the current state-of-the-art two-stage object detection approaches based on object proposal framework, such as RCNN [1] and Faster-RCNN [2], outperform traditional hand-crafted based methods due to their high performance on feature extraction. Also, many large image datasets, such as ImageNet [3], PASCAL VOC [4], and MSCOCO [5] datasets, have been published to help CNNs learn more object representations. Thus, it is not surprising that CNNs can show an impressive performance on object detection tasks. However, two-stage methods are complex and the involved models are hard to train, because they need to handle proposal generation, object classification, and localization within their framework. Also, for real-world tasks, the computation consumption of the system is a big concern. The overhead of generating object proposals makes the above-mentioned model hard to speed up which consequently makes it hard to be implemented on embedded system. To solve the issue caused by limited computation power, some CNN based one-stage detectors [6], [7] are proposed. They reframe object detection as a single regression problem and predict the result by single network forward. Without the complexity of combining two networks, CNN based one shot detectors are more efficient and easier to train.
On the other hand, there are several studies which focus on scene recognition. Similar to the ImageNet, there are some other published large scene-centric image datasets, such as place [8] and sun [9], [10], which allow us to train a deep CNN. Besides, many studies show that CNNs can also well perform on scene recognition tasks. Thus, we should have sufficient confidence that CNNs can also learn scene-centric information from large labeled scene image dataset.
As we have mentioned, most of state-of-the-art object detectors are based on the two-stage framework which can achieve high accuracy on several datasets. In addition to the accuracy, time consumption is also an important consideration for us when we would like to apply it to real life scenarios. Based on these factors, we decide to choose one-stage detector as our base framework, which allows our system to run at real time. Nevertheless, these kinds of methods are stuck with insufficient accuracy on small objects due to the lack of feature representations.
Because the Deep CNN has a large amount of parameters which need to be trained, the relevant approaches will not perform well when data is lacking. In order to extract robust feature representations, most of the state-of-the-art CNN object detectors, no matter if it is one-stage framework or two-stage detection framework, use model that pre-trained on ImageNet dataset as their base network and fine-tune for target data. However, feature representations learned from object-centric data (e.g., ImageNet) may not be sufficient for all objects in object detection tasks.
In this research, we propose a novel real-time object detection framework which can combine both object-centric and scene-centric information. To validate our work, we will evaluate it on MSCOCO and PASCAL datasets, which contain objects in general scenes. The experimental results show that feature representations extracted by the CNN trained on image-level scene-centric dataset can improve overall object detection performance, especially the small objects.
