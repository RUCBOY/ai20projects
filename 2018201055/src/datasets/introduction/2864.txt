Conversation systems which can be traced back to Turing test [1] are significant tasks in artificial intelligence. Recently, researchers build conversation models in two methods. Some are retrieval-based methods while others are generation-based methods. Retrieval-based methods select a proper response from a predefined repository [2]. These methods are severely constrained by a pre-defined index. Different with retrieval-based methods, generation-based methods generate responses according to the conversation history. With the development of deep neural networks, Seq2Seq models [3] become a popular technique of generation-based methods [4], [5], [6]. However, vanilla Seq2Seq models suffer from generating generic and meaningless responses (e.g. “I don’t know.”) [2], [4], [5] due to the high frequency of these patterns in data [4]. These responses will lead the conversation with human to an end quickly [4]. Researchers propose a number of methods to generate more diverse and informative responses in order to alleviate this problem. These methods can be generally divided into two categories. Some researchers propose variants of Seq2Seq models without integrating external information [5], [7], [8]. Other researchers integrate external information into models [4], [9], [10].
In existing works, researchers only use a single encoder in their models. Therefore, models tend to learn high frequency patterns among the whole dataset. However, these patterns are always generic and meaningless. According to our observations, we find that human conversation are always topic related. Therefore, we make use of topic information by dividing conversation data according to their topics. Our idea is described in Fig. 1. In Fig. 1, the left part is the whole dataset. We divide conversations into different clusters according to their topics which is shown in the right part of Fig. 1. High frequency patterns are always generic (e.g. “I don’t know”) among the whole dataset. However, if the conversation data are divided according to their topics, high frequency patterns in each cluster will be topic related rather than generic. In Fig. 1, the high frequency pattern of Topic1 is a phrase “a good football player”, while the high frequency pattern of Topicm is a word “song”. A model trained in different clusters of data can generate more patterns which are topic related and meaningful. Inspired by this idea, we propose a Multi-Encoder Neural Conversation (MENC) model.Download : Download high-res image (697KB)Download : Download full-size imageFig. 1. Topic clustering in conversation data.
The contributions of this article can be summarized as follows:
•We propose a Multi-Encoder Neural Conversation model to make use of topic information. To the best of our knowledge, it is the first work which applies multi-encoder structures into conversation models. In MENC, each encoder corresponds to a specific topic on the dataset. Therefore, MENC can be trained in different clusters of data with a multi-encoder structure. Topic distributions are obtained by topic models. MENC can learn the high frequency patterns among different topics so that it can generate more topic related and meaningful responses.•We propose three encoder selection methods which can be applied into MENC. There are multi-encoder structures in MENC. It is necessary to propose methods to select encoders according to the topic distributions. We compare the performance of different methods in this article.•We conduct experiments to compare the differences between MENC and mainstream models. Our experiments demonstrate that MENC can get a better performance than mainstream models on both object (automatic) and subject (manual) evaluation metrics among two datasets.
This article is structured as follows. In Section 2, we give an overview to conversation models. In Section 3, we elaborate MENC which contains three modules in details. We introduce our experiments and analyze experiment results in Section 4. Finally, we draw a conclusion in Section 5.
