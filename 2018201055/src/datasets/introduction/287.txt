Since the appearance of photographs technologies, taking photographs becomes an effective way to keep people’s daily life into memory. In the age of economic underdevelopment, people generally leave a few photographs keeping precious memories for the future. However, with time passing, many factors spoil photographs, such as creases, spots, water, light, or human-made factors. Consequently, spoiled photographs restoration has become a significant thing and has been widely concerned by academia and society. One usually uses image processing software, such as Photoshop (PS) and Metuxiu, to repair old and damaged photographs, at the cost of a long time and a lot of human resources.
In recent years, artificial intelligence (AI) and deep learning (DL) have been widely applied in the field of image processing [1], such as object detection [2], image segmentation [3], super-resolution [4], image denoising [5], and image deblur [6]. Compared to the traditional image processing method, the image processing method based on DL has achieved excellent performance [7]. However, DL generally requires a large number of training data for building an effective and powerful model [8]. In practice, only a small number of data is available for DCPs restoration. It implies that the first thing of photograph restoration is to collect a large number of training data.
In this work, we propose a novel generative adversarial network (GAN) architecture to address the lack of training data and restore DCPs [9], [10]. To the best of the authors’ knowledge, there are few works employing the DL theory to restore real DCPs instead of images that are artificially polluted. The proposed architecture is divided into three-step: collect clear character photographs (CCPs), real DCPs, and dirty masks; learn the spoiled manners of real DCPs and construct fake DCPs generation model via employing CCPs, DCPs, and dirty masks; building a DCPs restoration learning model via paired CCPs and fake DCPs. The main contributions of this work are summarized as follows.
•A residual U-Net GAN (RUGAN) is proposed to generate fake DCPs via exploiting real DCPs, unpaired CCPs, and dirty masks.•A residual U-Net conditional GAN (RUCGAN) that is trained by paired fake DCPs and CCPs is built to restore real DCPs, which saves a lot of time and energy for restoring DCPs.•To increase the visual perception of restored results, a weighted multi-features loss function is adopted to improve the quality of generated photographs. In particular, we define a multi-features loss by using different visual geometry group (VGG) layers to extract features and minimize the distance between repaired images’ features and target images’ features.
The structure of this work is organized as follows: Section 2 reviews some related works. We introduce our method in detail in Section 3. Section 4 illustrates the experiment results. Finally, in Section 5, the conclusion of this paper is stated.
