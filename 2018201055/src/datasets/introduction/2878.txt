Person re-identification is to re-identify the same person across different cameras, and it has attracted increasingly more interest in recent years  [1], [2], [3], [4], [5], [6], [7]. The emergence of this task is mainly stimulated by (1) increasing demand of public security and (2) widespreading surveillance camera networks among public places, such as airports, universities, shopping malls, etc. The obtained images from surveillance cameras are usually with some characteristics, e.g., low-quality, variable, and contain motion blur. Traditional biometrics, such as face, iris and fingerprint, are generally not available. Thus, many person re-identification applications exploit the reliable body appearance.
Technically, a person re-identification system for video surveillance consists of three components, including person detection, person tracking, and person retrieval. While the first two components are independent computer vision tasks, most person re-identification studies focus on the third component. Numerous re-identification algorithms as well as datasets [8], [9], [10], [11], [12], [13] have been proposed during the past decades and the performance on these benchmarks have been improved substantially. All these algorithms focus on the third component of the pipeline, assuming the person/pedestrian detection are already available. In other words, a query person is matched with cropped pedestrians in the gallery instead of searching for the target person from whole images. In reality, perfect pedestrian bounding boxes are unavailable in surveillance scenarios. In addition, existing pedestrian detectors unavoidably produce false alarms, misdetections, and misalignments. All these factors compromise the re-identification performance. Therefore, current re-identification algorithms cannot be directly applied to real surveillance systems, where we need to search a person from whole images, as shown in Fig. 1.Download : Download high-res image (670KB)Download : Download full-size imageFig. 1. Person search from whole images without cropping out persons. The left column is probe/query image, other columns are gallery images without cropped pedestrians. The green bounding boxes are searching results. To find the right person in the gallery images, we need to detect all the persons within the image, and compare the detected persons with the probe image.
While majority of person re-identification works engage boxes manually annotated or produced by a fixed detector in their applications, it is necessary to study the impact of pedestrian detectors on re-identification accuracy. Specifically, [14], [15] showed that considering detection and re-identification jointly leads to higher person search accuracy than optimizing them separately. To the best of our knowledge, end-to-end deep learning for person search (E2E-PS) [16] is the first work to introduce an end-to-end deep learning framework to jointly handle the challenges from both detection and re-identification. Thereby, the detector and re-identification parts can interact with each other so as to reduce the influence of detection misalignments.
In E2E-PS [16], the re-identification feature learning exploits a modified softmax loss. Early works show that such kind of identification task could greatly benefit the feature learning [17]. Meanwhile, it is found that the identification task increases the inter-personal variations by drawing features extracted from different identities apart, while the verification task reduces the intra-personal variations by pulling features extracted from the same identity together [18]. Inspired by this, softmax loss and contrastive loss are jointly used for feature learning, leading to better performance than the sole softmax loss [18]. But we cannot directly introduce such verification tasks into the person search faster R-CNN framework [19] used in E2E-PS [16], since the pedestrians appearing in each image are random, sparse, and unbalanced. It is difficult to organize equivalent amount of positive and negative pedestrian pairs within the faster R-CNN framework.
To address this critical issue, we propose a novel Individual Aggregation Network (IAN) that can not only accurately localize pedestrians but also minimize feature representations of intra-person variations. In particular, IAN is built upon the state-of-the-art object detection framework, i.e., Faster R-CNN [19], so that high-quality region proposals for pedestrians can be produced in an online manner for person search. In addition, to relieve the negative effect caused by various visual appearances of the same individual, a novel center loss [20] that can increase the intra-class compactness of feature representations is introduced. The center loss encourages learned pedestrian representations from the same class to share similar feature characteristics. The IAN model can be embedded in any CNN-based person search framework for improving the performance.
In particular, center loss is able to increase intra-class feature compactness without requiring to aggregate positive and negative verification samples. Center loss tracks the feature centers of all classes, and these feature centers are constantly updated based on the recent observed class samples. Meanwhile, it manages to pull the sample features towards each class center that this sample belongs to. This process is illustrated in Fig. 2. During the model development, we found that neural networks with dropout [21] are not compatible with center loss [20]. We study this phenomenon in both analytic and experimental ways. We believe this finding could be useful guidance for neural network framework design in the community, which is one of our contribution.Download : Download high-res image (495KB)Download : Download full-size imageFig. 2. The objective of center loss is to reduce the intra-class distance by pulling the sample features towards each class center. Left side: feature distance without center loss; right side: feature distance using center loss.
Finally, it is encouraging to see that our proposed IAN achieves 77.23% mAP and 80.45% top-1 accuracy on the CUHK-SYSU person search dataset [16], which is the new state-of-the-art for this dataset. Meanwhile, we also obtain state-of-the-art performance on the PRW dataset [15].
The remainder of this paper is organized as follows. Related work is presented in Section 2. The proposed person search method is described in Section 3, with implementation details described in Section 4. We present and discuss the experimental results in Section 5. Finally, conclusions are draw in Section 6.
