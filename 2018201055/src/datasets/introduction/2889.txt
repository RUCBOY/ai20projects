In forensic pattern comparison areas, such as fingerprints, toolmarks, footwear marks or handwritings and signatures comparisons, the examination follows a four-step process named ACE-V for Analysis, Comparison, Evaluation and Verification. First formalised by Huber [18], several authors further refined and detailed this process [3,6,34,35]. Some even scrutinized it through experimental research (e.g. [20]). In the first part of this paper, this framework will be briefly introduced, focusing on the Verification step. In spite of existing definitions of this step, advice is scarce regarding the way differing opinions between forensic examiners in the verification stage can be resolved.
Indeed, every expert has faced at one time or another of his career this situation: one expert reaches a different conclusion than the one reached by his colleague. For example, in a pattern comparison case (involving for example toolmarks, footwear marks or fingermarks), a first expert may reach an inconclusive conclusion, while the other may support the proposition of common source. The difference between the two conclusions can be even more marked, for example, if one expert is more inclined towards a common source while the other is guiding towards different sources. A few case examples of differing conclusions between two experts are illustrated in Fig. 1. All throughout this paper, the strength to be attached to the forensic findings – named generically strength of the forensic findings or SFF) – is expressed by a likelihood ratio (LR), which is now generally accepted among forensic scientists as a rigorous and logical framework [1,4,14,33,36]. The likelihood ratio is the metric that, when expressed in log10 form, gives the weight of evidence (WoE) to be associated to the forensic observations [15]. This approach clearly identifies the roles and responsibilities of the forensic examiner and of the Court. In this approach, the findings are evaluated in the light of competing propositions that generally reflect the views of the parties at trial [9].Download : Download high-res image (139KB)Download : Download full-size imageFig. 1. Differing conclusions reached by two experts (expert 1 and expert 2) in three cases. In Case 1 (diamonds), both experts point towards the same proposition but with different strength. In case 2 (crosses), the first expert leans strongly towards H1 as opposed to H2, whereas the second expert does not guide in any direction. In Case 3 (stars), the first expert indicates that the observations would support H1 as opposed to H2, the second expert does just the opposite.
The key question that we explore in this paper is how are these cases with differing conclusions between the two experts resolved? One of the two experts can try to convince the other that his logic is better, he could invoke experience, or that he spent more time on the case, and so on. But if we restrict to a scenario where the two experts have similar training and experience, have spent the same amount of time on the case, and are more or less equal in other aspects relevant to the examination process, how can their differing conclusions be resolved?
Furthermore, the development of automated tools in the forensic pattern evidence examination requires a formalization of the examination process (including the verification) in order to be able to seamlessly integrate these technological developments. Indeed, in most areas of forensic science, automated or semi-automated computer-based tools have been developed to support experts during the examination of pattern evidence. In the near future, in fields essentially based on human judgement, an increased development of computer-based techniques is expected leading to a higher level of distributed cognition between machine and human [12].
That increase is not only a consequence of improved machine learning techniques but also a response to the call for more user-independent techniques in the forensic pattern comparison areas (e.g. [29,30]).
According to Atanasiu [5] “computing is expected to play a central role in shaping the expert opinion” (Atanasiu, pp.75–76). Recent computing developments applied to forensic science indeed concentrated on the evaluation process. Presently, knowledge-based systems already operate in the evaluation phase of forensic examination, especially in the field of glass and DNA evidence [10]. Interesting developments have also been published in the area of fingerprints (e.g. [13,26,27]), firearms (e.g. [31]) and handwriting evidence (e.g. [11,16,22,25]).
While the expert of tomorrow will undoubtedly be assisted with technological systems that will help appreciate the strength of forensic findings, little effort has been made to enable forensic examiners to combine model outputs with opinions resulting from a traditional approach in a coherent and rigorous manner. If such a model is developed to be ubiquitously used, then the expert must possess a logical and documented strategy to integrate the model's findings into his own reasoning process. Indeed, without a clear structure clarifying how to embed the two examinations, the addition of each taken individually is worth less for the expert than the two put in combination with each other. Thus, in the third part of this paper we will try to address how to link both the traditional holistic examination expertise and a developed quantitative model.
A framework will be proposed and may be used as a general guideline to help handle conflicting scenarios between two experts or between an expert and a model. This will also be useful for forensic examiners to transparently structure and communicate their views. Examples will be proposed and discussed in forensic fields where human visual perception takes an important part in the ACE-V approach, i.e. for pattern evidence, with a focus on two disciplines: handwriting and fingerprint evidence.
It is important to stress the difference between the use of computed-based assessment techniques in a field such as DNA profiling compared to pattern recognition areas such as handwriting or fingerprints. Models developed to assign WoE to DNA findings are not used in conjunction with an appraisal by the expert of that weight. As soon as the model underpinning the calculation is accepted as validated for casework, the value obtained from the model will be the value quoted in the DNA statement. There is no competition between a holistic assessment of a DNA expert and the model. In pattern comparison areas however, the assignment of the WoE has been entirely left for years to the expert's judgement without any computer-based support. Experts developed specific recognition expertise based on a large set of features [32]. The computer-based models developed in these areas are largely based on a limited (but tractable) subset of features. It means that the computed WoE cannot stand alone as the only guidance towards the overall weight but will have to work in concert with the holistic judgement of the expert.
