The details of facial features play crucial roles on distinguishing subjects in surveillance applications. However, the captured facial region of interest generally has low-quality because of the restraints of hardware storage, long distance to the interested object and other constraints in electric imaging system. Thus, the limited discriminative details extracted from these low quality faces significantly affect the system performance of face recognition [1], [2], [3]. Face super-resolution, also called face hallucination, is the solution that predict high-quality images from low-quality query images to provide rich facial features in the recognition system. Learning-based face super-resolution has been a very active research topic, which motivates us to work on it with more advanced algorithms.
The earliest learning-based face super-resolution work was developed by Freeman et al. [4] to predict the potential relationship between low-resolution (LR) and high-resolution (HR) patches via a Markov network. After that, some machine learning-based approaches have been exploited. Shi et al. [5] designed a unified framework that combines global consistency, local sparsity, and pixel correlation to super-resolve the desired faces. A two-dimensional manifold learning based technology was presented in [6] to maintain the latent relation between the LR and HR faces in their original 2D form. By using domain knowledge and sparse recovery algorithms, Abiantun et al. [7] proposed to super-resolve faces with very low resolutions.
Although these aforementioned global models have achieved satisfactory results in most cases, they will fail in preserving some distinct individual details of the query LR faces sometimes. Ma et al. [8] presented a least square-based face hallucination method through position patch. Then, many researchers integrated the position prior to face image reconstruction [9], [10], [11] based on a fact that human faces have distinct structures. To alleviate the trouble that the least square representation may generate a nonunique solution in case that the training dictionary has bigger size, Jung et al. [12] desired to automatically choose principal training patches to improve the reconstruction results. Jiang et al. [13] proposed a local patch-based model using neighbor embedding (NE) scheme to restore more facial details. Li et al. [14] introduced the sparse prior, which is then adopted to guide the reconstruction procedure. Jiang et al. [15,16] added the locality-constrained regularization and then obtained state-of-the-art hallucination results. Later, the similar idea is further introduced into quaternion space to hallucinate color faces [17]. Two robust locality-constrained representation models are presented by Liu et al. [18,19] to acquire the target HR faces and eliminate noise simultaneously. Shi et al. [20,21] learned the reconstruction coefficients in the kernel space and synthesized the HR image patches in the spatial domain. By exploiting the subdivided contextual sub-patches, Chen et al. [22] proposed a joint learning framework for face super-resolution.
Recently, deep learning-based models have demonstrated remarkable performance in image super-resolution applications. Dong et al. [23] did the pioneer work to introduce the convolutional neural network into image super-resolution (SRCNN) task. Cao et al. [24] resorted to deep reinforcement learning and then proposed an attention-aware face super-resolution framework. Motived by deep CNN denoiser, Jiang et al. [25] presented a two-step face hallucination method. Yu et al. [26] developed an attribute-embedded upsampling network to reduce the ambiguity in face image super-resolution. These aforementioned deep based approaches does not take the highly structured facial prior into consideration and may be failed in face super-resolution with noise.
In previous local patch-based approaches, the core procedure can be summarized into two aspects: firstly, the LR input patch is coded as a weighted (linear or nonlinear) representation over the same position LR training patches; the desired HR patch is then rendered by integrating the corresponding HR training patches with the same reconstruction weights. The basic assumption is that the latent embedding geometry between the target HR patch and its LR counterpart is consistent in respective image space. However, this manifold assumption will not be true when the acquired LR face images are severely degraded (e.g., noisy, blurred). Furthermore, previous methods stacked the representation error into a vector and characterized them in the pixel level, neglecting the structural characteristic of the error image.
To tackle above issues, we present a multilayer locality-constrained matrix regression (MLCMR) framework in this work to capture the intrinsic structural characteristic of the representation error and keep the geometrical consistency between LR and HR manifolds simultaneously. In brief, the main contributions of our method are highlighted in the following:
(1)We design an adaptive neighborhood selection scheme, which aims at adaptively exploiting the intrinsic geometry (similarity) of the target HR manifold to regularize the more accurate reconstruction coefficients learning in the LR manifold.(2)Distinguishing from existing methods imposing pixel level constraint (e.g., l1 or l2-norm) on the representation error, MLCMR applies the image level regularization (i.e., nuclear norm) scheme to reveal the intrinsic structure of the error, to achieve more robust results.(3)MLCMR iteratively updates the LR training images to simultaneously learn the representation of the LR input patch and preserve the manifold structure of the primitive HR space, with the goal of achieving the super-resolution of the desired HR patch in a much more consistent space.(4)To better evaluate the efficiency of our MLCMR approach, besides comparable results on controlled face images, we also conduct experiments and give some in-depth analysis on real-world faces.
This paper is a further extension of conference version [27]. In this extension, we provide more experimental comparisons and more deep-going analysis. The rest of this paper is organized as follows. Several related approaches are briefly reviewed in Section 2. In Section 3, we detail our multilayer locality-constrained matrix regression framework. Furthermore, the computational complexity and convergence analysis of the MLCMR method are also provided. Experiments performed on controlled face images and real-world face images are shown in Section 4. Section 5 shows the conclusion and future work.
