Image denoising refers to the task of removing the measurement noise from an input image. It is not only of practical importance with the prevalence of photography using mobile devices, but also serves as a key component in most image recovery tasks; see e.g. [1], [2]. Inspired by the great success of deep leaning in many computer vision applications, in recent years, there have been extensive studies on deep-learning-based image denoising methods. Most of these methods are built upon convolutional neural networks (CNNs). Such CNN-based approaches showed promising performance, provided that the training samples fit well the characteristics of test data, in terms of both image content and noise characteristics.
1.1. MotivationsAll the existing CNN-based methods for image denoising are built upon real-valued CNNs. In recent years, complex-valued neural networks (NNs) have started to receive increasing attention. Many works suggest that using complex numbers in NNs could enhance the representational capacity [3] and lead to other advantages, e.g. easier optimization [4], better generalization performance [5], and noise-robust memory mechanisms [6]. In many recognition tasks, the performance of complex-valued NNs has been very competitive against that of their real-valued counterparts. However, to the best of our knowledge, complex-valued NNs have not been investigated for their potential applications in image processing, which contradicts the wide adoption of many well-known complex-valued transforms in image processing. To list some, discrete Fourier transform, Gabor transform, and dual-tree complex wavelet transform.Indeed, complex-valued transforms have deep connections to biological vision and visual perception. It is known that the primate’s area V1 (visual cortex) is dominated by complex cells (see e.g. [7]), i.e., the cells whose responses are characterized by the selectivity to orientation and frequency. Most cells of area V4 were also found to be more similar to V1’s complex cells rather than simple cells (see e.g. [8]). The receptive fields and responses of complex cells are usually modeled by Gabor wavelets [9]. Furthermore, the so-called phase introduced by the complex-valued representation dominates the perception of visual scenes [10]. Recall that a signal f under a complex-valued transform, denoted by F(f), can be interpreted in terms to two quantities: magnitude |F(f)| and phase ϕ(f):(1)F(f)=|F(f)|eiϕ(f).It is also known in computer vision, the phase of an image provides sufficient information of objects on shapes, edges and orientations. It is sufficient to recover most information of an image only using the phase of the Fourier transform of this image [11]. The benefits of complex-valued transforms motivated us to investigate the potentials of complex-valued NNs for image recovery, and this paper focuses on one core problem: image denoising.
1.2. Merits of complex-valued representationThe main mathematical operations to build a CNN for image recovery include convolution, activation and residual learning. In the next, we discuss some merits of the complex-valued versions of these operations for image denoising.Convolution.   A 2D complex-valued filter has its special structure which is different from its real-valued counterpart. The filters with orientation selectivity are usually preferred in image processing, as local image edges are oriented in different directions. These filters are usually non-separable such that they cannot be expressed as the tensor product of two 1D real-valued filters, except the ones with the horizontal/vertical orientation. In contrast, the tensor product of two 1D complex-valued filters, denoted by a1+ib1 and a2+ib2, is not separable regarding its real part and imaginary part:(2)(a1+ib1)(a2+b2i)⊤=(a1a2⊤−b1b2⊤)+i·(a1b2⊤+b1a2⊤).In other words, complex numbers allow using the tensor product of two 1D complex-valued filters to simulate 2D non-separable filters with different orientations. See Fig. 1 for an illustration using 1D Gabor filters. Such a property leads to a more compact form of 2D non-separable filters with fewer freedoms. More specifically, the tensor product of two 1D complex-valued filters defined in CL, will lead to two 2D real-valued filters defined in RL×L: one is from the real part, and the other is from the imaginary part. Thus, complex numbers enable using 4L freedoms to generate two 2D non-separable filters defined in RL×L, which needs 2L2 freedoms when using real numbers. As a result, complex numbers allow a more compact representation for the operation of 2D convolution, which helps avoiding overfitting. This could be important when designing CNNs for image denoising. In image denoising, the training samples include both truth images and their noisy versions. Although the set of truth images can be sufficient for training, their noisy counterparts could be insufficient, especially when the distribution of noise is complex or is spatially-varying. The amount of noisy data could be overwhelming in order to train a CNN with good generalizability.Activation function. There are many candidates of activation functions for complex-valued NNs. One is the generalization of the widely-used Rectified Linear Unit (ReLU) function from the real domain to the complex domain, which is defined as CReLU [12]:(3)CReLU(z)=ReLU(ℜ(z))+i·ReLU(ℑ(z)),where ℜ( · ) and ℑ( · ) denote the real part and imaginary part respectively. Recall that one key quantity introduced by the complex-valued representation is the phase, which the real-valued representation lacks. Consider a complex number in Fig. 2. The CReLU not only has the same activation mechanism as the real-valued ReLU in terms of magnitude, but also has a quite complicated non-linear activation on the phase of the input. The concatenation of such non-linear operations on phase enables the definition of very sophisticated mappings in the phase domain. In other words, complex-valued NN allows defining the mapping between noisy images and noise-free images in both the amplitude domain and the phase domain.Residual learning.The complex-valued representation is also related to the residual learning of NNs. It is shown in [6] that using complex numbers in the memory units could facilitate noise-robust retrieval mechanisms on the associative memory. In fact, the widely-used residual block [13] shares a similar architecture with the memory unit, in the sense that in each block the residual is computed and inserted into the “memory” provided by the identity connection [6]. Such a similarity implies the possible better robustness of the complex-valued residual block over its real-valued counterpart. It also implies the potential of complex-valued representation in residual learning for better robustness to noise model inconsistencies, i.e., the noise characteristics of training samples are different from that of test images.Download : Download high-res image (273KB)Download : Download full-size imageFig. 1. Complex-valued 2D filters generated by the tensor products of all pairs of seven 1D Gabor filters in C7.Download : Download high-res image (230KB)Download : Download full-size imageFig. 2. Activation on the amplitude and the phase of the input using CReLU.
1.3. Contributions and significanceThe contributions of our paper are three-fold:•First work that studies complex-valued CNN for image denoising. In the past years, real-valued CNNs are the prominent choices of designing deep-learning-based methods for image recovery. In contrast, complex-valued representations and transforms are also widely used in image processing, including Gabor transform and dual-tree complex wavelet transform. The research in biological vision also showed the connections between complex-valued transforms and low-level processing in visual perception. This paper is the first one that investigates the potential of complex-valued CNN for low-level vision tasks, such as image denoising. Our study showed that the complex-valued CNN has its merits for image denoising.•New design of complex-valued essential mathematical operations involved in a denoising CNN. It is known that the success of NNs to solve a problem lies in both the careful design of NN architecture and the appropriate choice of essential operations. In this paper, we developed a complex-valued CNN for image denoising, as well as defined several basic operations in the complex number field to exploit possible advantages over their counterparts in the real number field. Namely, (i) a compact representation of 2D filters via the tensor product of 1D complex-valued filters, which is helpful to avoid overfitting; (ii) non-linear activation on phase, which helps improving denoising performance; and (iii) residual blocks with better robustness to the noise model inconsistencies that often occur in practice.•A practical denoising CNN with state-of-the-art performance and good robustness to noise model inconsistencies. The experimental results on standard datasets show that our complex-valued CNN offers an alternative approach to designing effective denoising CNNs. The proposed complex-valued CNN showed competitive performance to the state-of-the-art real-valued denoising CNNs in the setting where the noise model of training samples exactly fits that of test images. Moreover, it has its advantages over other methods on the robustness to noise model inconsistencies, including the case where the noise levels of test images are unknown, where the standard deviation of noise varies among different pixels, and where the noise is a mixture of different types of noise.
1.4. Organization of the workThe remaining part of the paper is organized as follows. In Section 2, we give a literature review on related image denoising methods and existing complex-valued NNs designed for different applications. The proposed complex-valued denoising CNN is presented in Section 3 with all details. In Section 4, the experiments are conducted for the evaluation of the proposed method and the comparison to other closely-related methods. Section 5 concludes the paper.
