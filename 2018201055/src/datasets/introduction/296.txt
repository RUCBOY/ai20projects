With the increase in size and the distribution of available datasets, enormous challenges have been brought to frequent itemset mining (FIM). Traditional sequential FIM methods become inefficient to mine frequent itemset over big data due to the limit memory capacity and computation capability of a single node[1]. Thereby, parallel mining[2], [3], [4], which seamlessly integrates parallel computing and data mining technology, has been widely used in various applications.
In this study, we address parallel frequent itemset mining. We show that an items grouping strategy can significantly improve frequent itemset mining performance by dividing items into groups through items correlations. The dataset to be processed is projected into independent and balanced data subsets according to these items groups to perform mining tasks. We articulate the design of HBPFP-DC - a High Balanced Parallel Fp-Growth Considering Data Correlation running on the Spark platform.
1.1. MotivationsParallel FIM mining investigated in this study is motivated by the following four observations.Motivation 1. Apriori and Fp-Growth algorithms are the most classic two types of frequent itemset mining algorithms[5]. Apriori requires to iteratively generate and test candidate sets level-by-level by repeatedly scanning the entire dataset[6], which will cause high computational and I/O cost. To reduce the time required for scanning databases, Han etal. proposed a novel approach called Fp-Growth, which avoids generating candidate itemset by compressing the original data into a tree structure[7]. Most previously developed parallel FIM algorithms were built upon the Apriori algorithm[8]. Unfortunately, in Apriori-like parallel FIM algorithms, each processor has to scan a dataset repeatedly and to exchange an excessive number of candidate itemsets with other processors. Therefore, Apriori-like parallel FIM solutions suffer poor scalability due to high I/O and synchronization cost. Therefore, we studied the parallelism and load balancing of the Fp-Growth algorithm.Motivation 2. MapReduce is a popular paradigm for parallel computing[9]. Many big data processing can be transformed into a set of MapReduce tasks and get efficiently executed in a cluster infrastructure. Hadooop[10] and Spark[11] is the famous implementations of MapReduce that are widely used in the big data industry. Before the term big data was coined, MPI/OpenMP that is high-performance oriented and exploits multi-machine/multi-core infrastructures has been the dominant model in high performance computing[12]. MPI/OpenMP mainly addresses High-Performance Computing (HPC) problems. From a computational point of view, the MPI/OpenMP implementation is much more powerful. Nevertheless, Hadoop and Spark may be preferred, especially in the field of big data, because they[13]:•offer a distributed file system with failure and data replication management.•allow the addition of new nodes at runtime.•provide a set of tools for data analysis and management that is easy to use, deploy and maintain.
Spark extends the MapReduce programming model to efficiently deal with iterative computational procedures. The main performance advantage is due to the fact that the data to be processed and intermediate results are saved directly to memory to avoid repeated reading and writing of HDFS like Hadoop[14]. Therefore, we take full advantage of Spark’s support for iterative calculations and propose a Spark-based parallel FIM algorithm.Motivation 3. In distributed systems, load balancing provides the means to achieve high efficiency and good scalability of distributed execution in large clusters. Thus, the performance of data-parallel computing heavily depends on the load balancing among the nodes in the cluster. Existing load balancing solutions of FIM aim at balancing computation load by equally distributing data among nodes. However, the data correlation is often ignored which will lead to excessive computation and the network overhead. We develop HBPFP-DC, an efficient parallel FIM algorithm, in which data correlation is considered when grouping items to speed up the process of FIM.
1.2. ContributionsWe summarize the main contributions of this study as follows:•We designed an accurate node computation workload estimation model to measure the calculation workload of each node in the cluster.•We presented an items grouping strategy by considering data correlation to further improve the ‘compression factor’ of Fp-tree. Thereby mining overhead is greatly reduced.•We developed a High Balanced Parallel Fp-Growth Considering Data Correlation algorithm in Spark cluster, called HBPFP-DC.•We conducted extensive experiments using a wide range of real-world and synthetic datasets to show that HBPFP-DC is efficient and scalable in Spark cluster.

1.3. OrganizationThe remainder of this paper is organized as follows. Section2 discusses the related work. Section3 introduces the background knowledge. Section4 overviews the design idea of HBPFP-DC built in Spark cluster, and the specific algorithms are given in Sections5 High balanced parallel Fp-Growth–HBPFP, 6 HBPFP-DC: HBPFP considering data correlation. Section7 evaluates the performance of HBPFP-DC on a real-world cluster. Finally, Section8 concludes the paper.
