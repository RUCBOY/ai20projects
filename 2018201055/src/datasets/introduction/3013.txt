Over the last 30 years, many new technologies, making extensive use of human vision as a computer input and control system, have been developed in areas as diverse as health services and patient evaluation (Gold et al., 2016; Asan and Yang, 2015), security and biometrics (Galdi et al., 2016), web usability (Cutrell and Guan, 2007; Penkar et al., 2013), interfaces (Yeoh et al., 2015), interactive systems (Milekic, 2003; Kiefer and Giannopoulos, 2012; Krassanakis, 2011), and cognition and neuroscience (Starr and Rayner, 2001; Johansson et al., 2001; Mrotek and Soechting, 2007). In particular, the development of applications for those with some degree of motor difficulties has been especially useful, since these facilitate the use of a mouse cursor and/or virtual keyboard and provide alternative access during the integration and rehabilitation processes (Biswas and Langdon, 2011; Adjouadi et al., 2004; Perini et al., 2006; Majaranta and Räihä 2002; Majaranta, 2009; Zhai et al., 1999; Ward et al., 2000).
In spite of the growing amount of development, there are still several factors that impede precision in these systems; for example, a lack of standard for the quality of data obtained by such devices (Holmqvist et al., 2012; Lutteroth et al., 2015). Furthermore, and especially relevant, is the correct evaluation of the points of regard, or observer gaze, since this must be predicted precisely to determine the point or button selected. This prediction capability depends on the type of application that is being developed (Biswas and Langdon, 2015; Barz et al., 2015). This is a field in continuous growth, and is mainly focused on facilitating the usability of applications, as well as diminishing cognitive overload in the observer.
Before the spread of the eye-tracker as a Human-Computer Interaction tool, the mouse (and its variants) was the defacto tool for communicating with computers; however, many studies have demonstrated the difficulties this device has as a control method, even when systems have been implemented to facilitate its use (Trewin et al., 2006; Keates and Trewin, 2005; Hwang et al., 2004). For those patients with some degree of motor deficiency, such as amyotrophic lateral sclerosis, complete paralysis, or pyramidal syndrome (motor neuron disease), with normal cognitive skills, sight is the best available communication option -the lack of a mechanism that will allow them to write or read easily, among other things, becomes a serious barrier to patient access to knowledge and decreases their chances for autonomy and personal development-. Currently, there are many commercial devices available for people with disabilities: these include LC technologies, Tobii, and EagleEyes, which have developed systems that allow for the use of human vision as the exclusive method for controlling a computer (Biswas et al., 2012; Biswas, 2016). In this line, our research seeks to integrate different technologies to develop a low-cost, head-mounted eye-tracker add-on that can be connected to any eye-tracker.
Although the focus of our research is directed at people with serious motor difficulties (in particular, those with complete immobility), we have developed our tests with volunteers that have average visual, cognitive, and motor skills. The above is due to the fact that we center the evaluation of this study on measuring system control capability, which isolates the user motor skill variable. As we will discuss ahead, even when taking the paralysis factor into consideration, previous studies on cognitive processes do not allow for inferences to be made about perceptive processes that occur in the observer, independently if they have a motor condition or not. The visual movement patterns that currently exist allow for the estimation of where an observer is looking, but not necessarily what the observer wants to do (Hayhoe, 2004), which is why we focus this work on system performance for people that can fully follow basic system instructions.
