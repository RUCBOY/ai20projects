Constructing human-computer conversation systems that can converse meaningfully with humans using natural language has been a long-standing goal of Artificial Intelligence. Human-computer conversation systems can be broadly divided into two categories: task-oriented systems which work in vertical domains to assist people to achieve specific goals, such as travel arrangements [1], restaurant recommendations [2], online shopping [3], and chat-oriented systems which focus on talking like a human and engaging in social conversation regarding a wide range of issues. Recent previous research has focused on task-oriented systems, with a large amount of conversation data being gained through social media websites (e.g., Twitter and Weibo) and community question answering (CQA) websites (e.g., Yahoo Answers and Baidu Zhidao), resulting in chat-oriented systems becoming a major focus of both academia and industry.
Existing approaches to designing a chat-oriented system fall into two categories. (i) Generation-based methods [4], [5] usually leverage an encoder-decoder framework to generate a response R^ based on an utterance Q, where R^ can be a word sequence that has never been seen before. Lack of fluency and naturality is one drawback of generation-based methods. Another disadvantage is they tend to generate safe but boring responses such as “I don’t know” and “me too”. (ii) Retrieval-based methods [6], [7] retrieve candidate utterance-response (or Q-R)1 pairs from a pre-built index, rank the candidates, select the top ranked 〈Q^,R^〉 pair, and then use R^ as Q’s response. The capability of retrieval-based methods depends heavily on existing Q-R pairs. However, collecting such Q-R pairs is intractable for many specific domains.
To overcome the aforementioned issues, we propose DocChat, a response selection method to retrieve responses from documents. It is easier to retrieve responses from unstructured documents than to collect semi-structured Q-R pairs. Using documents rather than Q-R pairs can greatly improve the adaptability of human-computer conversation systems. Conversely, responses retrieved from existing human generated documents are guaranteed to have their fluency and naturality. We separate the response selection approach into three cascaded steps to make a trade-off between efficiency and accuracy. In the first step (i.e., response retrieval), the proposed method finds a small set (e.g., 50 or 100) of candidate sentences based on a basic similarity measurement. In the second step (response ranking), a learning to rank model with features at four different levels of granularity is used to measure the semantic relevance between an utterance and a candidate response. The biggest challenge in utterance-response matching is that users often express similar meanings with different but semantically related expressions. Machine translation-based methods can help bridge such lexical gaps by extracting synonym words and phrases from parallel corpus such as bilingual sentence pairs. We present representation learning-based models, both sentence and semantic-levels. In the last step (i.e., response triggering), a triggering strategy determines whether the top-ranked sentence is a sufficient response.
We conduct comprehensive experiments on both real human-machine conversation scenarios and sentence selection benchmarks. Side-by-side evaluation between DocChat and a famous chatbot demonstrates that DocChat performs better on domain related queries. In addition, the performance of the proposed method is comparable to that of state-of-the-art methods on sentence selection task.
The primary contributions of this study are as follows.

•We propose DocChat, an information retrieval approach for human-computer conversation systems. DocChat can leverage unstructured documents to respond to utterances. The proposed method is based on learning to rank, that ranks candidate sentences using well-designed matching features at different levels.•We evaluate DocChat on both answer sentence selection datasets and response sentence selection datasets. The results show that our method performs comparably with state-of-the-art methods. A comparison of DocChat and Xiaoice demonstrates that DocChat is a good complement to human-computer conversation systems using Q-R pairs as the source of responses.•We create a large scale manually labeled corpus for sentence selection, which is released to the public domain.2
