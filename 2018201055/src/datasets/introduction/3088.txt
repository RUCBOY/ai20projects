When we needed a standard “off the shelf” algorithm for the design of sequential experiments, we found it was quicker to invent a new one from scratch than get published algorithms to work. It was hard to find a working solution for the problem in the literature — even when we had searched both peer reviewed publications and textbooks.
Reproducibility, or rather, lack of reproducibility is a widespread problem affecting many algorithms, especially long, complex or unusual algorithms. Often such algorithms are left as “exercises for the reader” or are merely analysed for their properties, rather than presented with correct code.
This paper introduces our elegant new algorithm for sequential experiments and its use and application for sequential experiment design (specifically, it generates randomized (N,2) de Bruijn sequences). The algorithm is much briefer than theoretically faster algorithms that have been outlined in the literature though not so reproducibly described. The algorithm will be useful for experimental scientists (who can parameterise it for their specific research) — exactly the sort of people who need working algorithms but rarely have the time or resources to invent correct algorithms from the far-too-often inadequate descriptions in the literature.
We use our reproducible presentation of the algorithm as a full and thorough case study of a new tool-based approach for easily and rigorously explaining and documenting reproducible algorithms in published papers. A key contribution of the paper, then, is our tool-based approach to reproducibility and our discussion around reproducibility.
Finally, this paper relates our new, lightweight tool-based approach to Richard Feynman's exhortation to avoid what he calls “cargo cult science” [10]: when we have the right tools to help us, his challenge becomes easy. We show how our approach makes publishing correct working software easier and more likely. It helps improve the quality not just of publications but also of the underlying algorithms themselves: authors can now easily improve their algorithms and their papers in a tightly integrated, even enjoyable, process.
1.1. Reproducible research versus reproducible publicationScience is based on reproducibility: if an idea or theory is not reproducible, it is not science, or at least the lack of reproducibility uncovers a boundary case that refines the science. A common reason for lack of reproducibility is that a published paper does not disclose enough details or contains mistakes: what is published is inadequate for another scientist to reproduce the work. (Fraud and multiple publication are further reasons — papers may deliberately fail to disclose enough to reproduce the work.)Algorithms and programming more generally have the interesting property that in principle everything is reproducible: programs run on computers, and programs are text that can be fully disclosed. There has been recent increasing interest in making reproducibility a criterion for accepting papers in the field, such as the ACM Artifact Review and Badging policy [1] and its use in conferences such as the ACM Multimedia Systems Conference [49] or the ACM Symposium on Principles of Programming Languages since 2015, popl.mpi-sws.org/2015 (see also our discussion in Part III).We further make the distinction between reproducible research and reproducible papers: Reproducible researchA paper discloses enough for a reader of the paper to reproduce the research. For example, everything in this paper is available on GitHub, at github.com/haroldthimbleby/relit. The material is also available at the Science of Computer Programming page for this paper, at doi.org/10.1016/j.scico.2017.12.010.Some journals and conferences have started asking or requiring authors for “artifacts,” documents and other evidence intended to support the scientific claims made in a paper. Papers with quality artifacts are badged, so that the additional value can be recognised by the community.Reproducible paperA paper as published discloses enough for a reader to reproduce the claims of the paper, with essentially no further effort than copying the details. For example, this paper introduces a new algorithm, and that algorithm is completely disclosed in this paper, in fact as source code in standard programming language that can be copied directly from Part I of the paper.Semi-reproducible paperA paper as published discloses enough for a reader to reproduce the claims of the paper, but perhaps to reproduce it exactly will involve substantial further work. For example, this paper introduces a new approach to reproducibility that is thoroughly disclosed in this paper. However none of the code to implement the approach is disclosed in the paper itself, although the idea can be copied from Part II of the paper. (As it happens, the documentation and complete source code of relit are available on GitHub, so the research is reproducible.)To be complete, one should also add papers that are not intended to be reproducible or fully reproducible. While there is an important place for non-reproducible research (for instance in inspirational writing or in papers that expound new research challenges) a serious problem is non-reproducible research seeming to be reproducible. In particular, many papers present algorithms for analysis, which may be reproducible, but as the papers look like they are also presenting actual algorithms they are misleading. Such papers look like they solve problems, but they do not. A reader may want to run an algorithm to solve a problem; in this case, an algorithm as shown may not run correctly. A concrete example would be an algorithm implemented using arrays: most analysis of its behaviour will not depend on exact subscript values, and out-by-one errors would probably be irrelevant, but in implementing it, the subscripts and array bounds need to be correct. There are many papers that provide code listings of algorithms that do not work as printed [41].Sometimes this problem may result from bad practice or even deliberate fraud; maybe the author wants to achieve another publication with some withheld details? Sometimes there may be commercial or intellectual property concerns, as the author may be unwilling to disclose the correct algorithm because their business depends on its remaining proprietary.One would hope that simple, easy-to-use tools that facilitate and promote reproducibility will ease some of these problems.
1.2. Relit: A tool for reproducible papersWe built a tool relit, so called because it implements “reverse literate programming.” Relit helps write clearly about any algorithm or algorithms, and is intended to be particularly useful to help write reliable, reproducible papers about algorithms.In conventional literate programming, the literate program source file drives the entire process and generates a program and structured documentation for it; in reverse literate programming the main relationship is reversed, being driven by a paper (such as the one you are currently reading) from which source code is derived. Another contrast is that conventional literate programming aims to produce a program and full internal documentation; reverse literate programming aims to produce a paper (or book or other publication) that describes algorithms or program code, at the same time providing assurance that the code is correct. Fig. 1 explains the “reversed” concept further, and how it turns the conventional literate programming approach around.Download : Download high-res image (173KB)Download : Download full-size imageFig. 1. Conventional literate programming tools work as illustrated in Fig. 1(a), which is based on a diagram in the paper on the literate programming tool noweb [31]: as shown, the author edits a source file (e.g., wc.nw) and the tool generates two files: a compilable program (wc.c) and a stylised  documentation file (wc.tex). Contrast this with Fig. 1(b), which shows the comparable diagram for relit. With relit, the author edits a file (now wc.tex) from which relit can generate many files, including wc.c, which is compilable. Additional files generated by relit can be used for any purpose; for instance, in the present paper one of the generated files is a makefile so generated files were compiled and executed with their outputs inserted back into this paper.Here is a very small but complete, self-contained example:Download : Download high-res image (47KB)Download : Download full-size imageThe reverse literate programming approach does not impose any formatting or style conventions on the author, so — to try and emphasise the flexibility — we typeset this example in a gray box to help make it stand out as an example. Code does not have to be syntactically complete, and can be written however best suits the author's needs; for instance, in this example, we chose to omit the final semicolon strictly required by Java. Indeed, this paper has several unrelated concrete examples in it (in several programming languages) and relit imposed no conventions or restrictions on the authors to achieve this.Our tool relit extracted the actual code shown above from the  [23] source for this paper, and inserted it into a complete Java program (which also provided the hidden semicolon) that was also in the  source file. The makefile [25], also defined in this paper's  source file, compiled and ran the Java program, saving its output to a temporary file, which was input into the paragraph above. Hence the output of the program shown above really is the output of running the actual Java code shown. In fact, the complete source code for the Java program (as well as the makefile) is in the single  source file for this paper, though the rest of it is hidden from sight beyond the end of the published paper. (It appears after 's \end{document}, though relit could have extracted it from a separate file just as easily.) As an option, relit can summarise all the invisible (or otherwise) code to help check that nothing critical to the paper has been accidentally hidden from the reader.As a test, the authors edited the for loop and the example changed as expected; this reassured us that the example above is accurate and not broken by typesetting (e.g., by some idiosyncrasy in ). In other words, both the authors of this paper and therefore the readers of this paper have assurance that the code above does exactly what we say it does.In a more critical situation than publishing code in a paper, it would be desirable to design the makefile (or other run time script) to ensure that any errors in the program result in visible warnings, perhaps no paper at all, until all errors are corrected — in our simple example, if we introduced a syntax error in the Java code, the compiler would generate no code at all, so the last successful executable file would be used instead. Running it would then misleadingly generate obsolete output from some earlier successful compilation. Tools like expect [24] can help assure that the right code is used reliability in a systematic way. However, both Java and  are powerful programming tools, so an author so intent could program any effect they want, but which might accidentally end up being misleading regardless of safeguards like expect; thus it is critical that tools like relit are very simple and elegant so that the author is not tempted into trying complex, possibly unreliable, tricks to get the effects they want.Using relit, there is no notation at all to get going, and very little notation to learn to start using features as they are needed. Even when all the features are used, everything can be done with only two simple commands that are  comments, so they have no unintended interaction or side-effects on the meaning of the original document. No writing needs to be structured or re-structured to make use of it (e.g., into an outline or set of sections as in conventional literate programming [19], [31] and in systems like Mathematica [48], org-mode [33], etc.).Another important difference between conventional literate programming and reverse literate programming is that literate programming is motivated by documenting programs or algorithms (even if they end up being book length) whereas reverse literate programming is motivated by helping write reproducible papers (which are usually brief) about programs or algorithms. One focuses on the program, the other focuses on the publication.We used relit throughout the present paper: the new algorithm we present in this paper works exactly as shown. The discussion about the new algorithm therefore combines three roles: its intrinsic interest as a useful algorithm, the discussion about the algorithm literature, and the algorithm as a complete worked example presented reproducibly using relit. Apart from our assurances that the code shown is real, there is nothing unusual in the style or format of the present paper: while giving many advantages to authors, reverse literate programming is invisible to the reader.It is notable that with the relit approach we advocate, an ordinary, conventionally-written, paper gradually morphed into the present paper that now accurately generates the code it talks about. The original paper was written conventionally, but relit features were incrementally introduced to “pull out” the existing code embedded in the paper's  source document. Additionally, in the same file, but hidden from the reader as the details are not relevant to the paper, are the full run-time resources to make the code work. In other words, the code and program results shown in this paper has been generated from the paper itself, and it works as described — this is reproducible research. All other related approaches to improving reproducibility of which we are aware require either some sort of special notation or structure for files, or they generate the paper from a specification. Furthermore, most impose typographic and stylistic constraints on the papers that can be published.1.2.1. Relit: Basic useHere is an illustrative and basic development cycle using relit:1.Write the initial paper as usual. (Of course, anticipating using relit one can do better than just writing an ordinary paper.)•In conventional literate programming, one has to start with a special “web” file. No web files are in formats suitable for conventional publication.2.Edit the paper so program code snippets are preceded by simple relit commands, written as comments so they do not affect the published paper at all.•In conventional literate programming, the code has to be structured to make it possible to document. The structuring decisions are hard to change later.3.Optionally, somewhere that is ignored — in another file, or beyond the  \end{document} — add relit commands to add any support code or housekeeping that is needed.•Conventional literate programming has no way to hide code that is distracting or needs no explanation.4.Running relit now generates the specified files from the contents in the paper. Compile and run or otherwise test the generated files.5.Concurrently edit the original paper to improve the code so it works better and edit the text of the paper so it more accurately describes the code.•You cannot edit the original paper in literate programming; you have to edit the structured web file that generates the paper. This is made clear in Fig. 1.6.Repeat until everything works as intended. At all times, the submitted versions can be used to automatically reconstruct the algorithms to ensure they work correctly.7.Submit to a journal or conference.•If the publishers have stylistic or formatting requirements, conventional literate programming hits a wall — the paper will require substantial editing, which undermines one of the key advantages that the code should be correct and coherent with the description. Editing the submitted paper will introduce inconsistencies with the original documents, and hence will compromise reproducibility.1.2.2. Relit: An example of its real useAt the last moment while writing this paper, our colleague Paul Cairns pointed out a worked example we had used explaining our algorithm erroneously confused wine regions (e.g., Chianti) for grape varieties (e.g., Pinotage and Merlot).In the conventional approach to writing about algorithms, we would probably have edited the paper alone to fix the error … and the paper and the programs we had written about would have diverged, or at least we would have needed to edit several files and do a lot of careful cross-checking — if we could be bothered to do it. We might have decided it was not worth the trouble. We might have fooled ourselves: the original program works even if it has the names mixed up; we would probably have persuaded ourselves that, surely, the program used to work, and then we would edit the paper alone to fix the errors. It is then but a short step to justifying to ourselves not doing the cross-checking properly because it more easily imagined than done. If we had gone down this route, the paper and the program would have been different. If we had corrected any other errors or polished — which is always very tempting — any aspect of the paper, potentially the published paper and the algorithm would have become very different. If we made any clerical slips editing the paper, the paper and the program could be critically different. Worse, neither we the authors nor the readers would be aware of the bugs and inconsistencies introduced by these well-intentioned “corrections.”Instead, because we were using relit, to fix the wine naming issues we did a very trivial edit in just one place in a single file, that is, in one place in the paper you are reading right now. With no further editing, thanks to using relit, we then automatically had a new C program that correctly used Shiraz, and the output from running the actual program was then inserted back into this paper. The example output (used in Section 2.5 below) also, of course, was automatically updated to say varieties instead of regions.Everything remained consistent with negligible effort. There was no need for any tedious or error-prone double-checking, because all the necessary edits needed were in exactly one place — the program code that is explicit in the source text of this paper. If there is only one object, it is necessarily consistent! And, finally, everything (all the code examples and the outputs from running the code) is obviously consistent with the code published in the paper because it was generated by running exactly the code in the paper you are now reading.In fact, doing the change (with the help of our tool relit) was much easier than explaining how easy it was to do!
