Having in place an efficient and effective workforce is key a determinant of time and cost performance of construction projects [1]. Statistical evidence demonstrates that productivity in the construction industry, worldwide, has been declining over several decades [[2], [3], [4]]. An issue that has stymied the ability to engender and enact a program of productivity improvement during construction is a lack of data to establish a ‘base-line’ of worker performance. If, however, the productivity of workers' is to be accurately monitored in real-time, then construction managers and their teams need to directly put in place mechanisms to address those issues that impact operations to ensure a project's desired performance levels are sustained. The corollary being the ability to control and maintain a project's predetermined deliverables and acquire a much-needed understanding and knowledge of issues that adversely affect productivity.
There has been a plethora of studies that have sought to monitor and analyze worker activity on-site using a variety of methods (e.g., direct observation, surveys, and interviews) [[5], [6], [7], [8]]. While such methods have been useful in creating a body of knowledge that has been used to monitor worker activity, they are time consuming and labor intensive to undertake and have tended to produce subjective results [[9], [10], [11]]. In addressing these limitations, there has been a shift toward monitoring individual worker's activity and tracking their location and equipment by using non-visual sensors such as radio frequency identification (RFID) tags [12], ultra-wide band [[13], [14], [15]], and global positioning system (GPS) sensors [16, 17]. Several existing methods based on non-visual sensors generally track a worker's location and therefore do not measure key operational parameters of a process of such as the working sequence and cycle time. Moreover, the accuracy of the data required obtained to determine the location and productivity levels of workers often varies and can contain considerable noise rendering it difficult for performance assessments to be undertaken.
To address the limitations of location-based methods that have been used for activity recognition, computer vision has been widely used to automatically monitor workers on-site [[18], [19], [20]]. Computer vision essentially enables rich information (e.g., locations and behaviors of project entities and site conditions) to be extracted from images and videos. A large family of video action recognition methods is based on shallow high-dimensional encodings of local spatio-temporal feature, such as Histogram of Oriented Gradients (HOG) and Histogram of Optical Flow (HOF). Despite the success of the research undertaken by Yang et al. [21], several challenges remain unresolved in construction engineering, which include the recognition of:
•Activities in complex and changing conditions: Worker activities are typically recorded in various and changing backgrounds that are subjected to occlusions, illumination variance, and viewpoint changes.•Multi-subject interactions and group activities: Workers perform interactive activities with one or more people and objects (e.g., materials). Therefore, more powerful methods to understand the construction scene would still be an issue.
To overcome these issues, a convolutional neural network (CNN) can be applied to automatically recognize the activities of workers [22]. The deep three-stream CNN can accommodate complex activities, as it can simultaneously capture static spatial features, short-term and long-term motion in a video [23]. Against this contextual backdrop, the research presented in this paper develops a deep three-stream CNN that integrates Red-Green-Blue (RGB), optical flow, and gray stream CNNs to automatically recognize worker activity on construction sites. At the same time, we use a reinforcement fusion strategy to fuse the results of the three stream CNNs. The technical challenges of the developed three-stream CNN and implications for future research are then identified. Prior to introducing the three-stream CNN, a review of extant literature on activity recognition methods in construction is presented.
