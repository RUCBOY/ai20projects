The growing interest in autonomous cars demonstrated by the huge investments made by the biggest automotive and IT companies [1], as well as the development of machines and applications able to interact with persons [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], is playing an important role in the improvement of the techniques for vision-based pedestrian tracking. In fact, autonomous machines able to act in not-controlled environments represent an high risk for any person who may be in their range of action.
In 2015, in the United States, more than 5000 pedestrians were killed due to traffic crashes [14]: one pedestrian dies every 1.6 hours due to car accident. Additionally, in the same year, almost 130000 pedestrians were treated in emergency departments for non-fatal crash-related injuries. Pedestrians are 1.5 times more likely than passenger vehicle occupants to be killed in a car crash on each trip [14], [15], [16], [17]. The statistics reported in [14] state alarming numbers for EU too, even though the general trend of pedestrians’ deaths is reducing thanks to the introduction of driving supports, such as auto-breaking system. For these reasons, in the last decades, people detection and tracking has become an important research area in computer vision.
From 1990 to 2016, scientific community has shown an ever-growing interest in human detection and tracking. As reported in Fig. 1, more than 5000 publications in this topic have been published and indexed in Web of Science, ranging from human detection to pedestrian tracking using 2D and 3D vision systems, or considering indoor and outdoor environments.Download : Download high-res image (253KB)Download : Download full-size imageFig. 1. Total Publications from 1990 to 2016 with Keyword: Human Detection and Tracking - Source:Web of Science.
Some other surveys regarding pedestrian detection have been presented in the literature so far. In [18] and [19] the authors focused the topic of the survey on a taxonomy of system functionalities considering the structure of the motion capture system and the different information to be processed.
Solichin et al. have focused the work on the steps needed in the process of pedestrian detection, including input devices, datasets and methods for detection and, finally, on some open issues related to pedestrian detection [20].
Zhou and Hu have written a survey on the human detection and tracking systems from a clinical and diagnostic point of view, highlighting the differences between visual tracking (marker-based or marker-less) and non-visual tracking using magnetic sensors, inertial sensors and others [21].
In [22], the authors have presented a survey concerning monocular pedestrian detection systems focusing on the methodologies for the selection of Regions Of Interest (ROIs), classification methods and tracking.
In [23] and [24], the authors have discussed two surveys focused on pedestrian detection and tracking systems related to the Pedestrian Protection Systems (PPSs). Specifically, while in the first survey the authors consider and review general pedestrian detectors, in the latter the authors focus only on systems dedicated to PPSs.
Dollar and his colleagues [25] have focused on the main methods for pedestrian detection in monocular images performing an accurate ranking on benchmark datasets, while in [26] the authors have collected and reviewed some works, marginally introducing deep architectures.
The above-mentioned surveys report the state-of-the-art about pedestrian detection and tracking systems in terms of acquisition technologies, e.g. 2D and 3D configurations, and processing methodologies; however, recent adoption of Deep Learning (DL) methodologies and, in particular, Convolutional Neural Networks (CNNs) for pedestrian detection and tracking deserves a dedicated state-of-the-art survey.
Generally, the process of vision-based pedestrian detection can be considered constituted by three fundamental steps, as depicted in Fig. 2: (i) Image Acquisition, (ii) Feature Extraction and (iii) Classification. As will be discussed in the following sections, the introduction of DL architectures, or deep structures inspired to the human visual cortex, in the context of object recognition, allowed the removal of the feature extraction step (Fig. 3), preserving the other ones.Download : Download high-res image (43KB)Download : Download full-size imageFig. 2. Steps needed for pedestrian classification following a features-based model.Download : Download high-res image (32KB)Download : Download full-size imageFig. 3. Steps needed for pedestrian classification following a model based on Deep Learning strategy.
As pointed out by the reported figures, the two approaches differ for the removed step only. However, the extraction of features is not completely removed from the workflow, but it is an automatic procedure performed by the deep classifier which is generally constituted by several processing layers that, taking images as input, compute features at different layers of abstraction [27], [28], [29], [30]. In this way, the design of a such a kind classifiers is considerably simplified since the design of procedures for the extraction of the so called ”hand-crafted features”, able to perform an accurate classification, is the most difficult step. Nevertheless, the incorporation of feature extraction in the classification process, allowing a faster run-time execution, lead to a longer training time respect to the hand-crafted features based approach [31].
Video tracking is a complex process which allows to locate and follow single or multiple objects over time using several sensors. Due to the need of a remarkable improvement in both acquisition and processing systems, a lot of works dealing with tracking could be found in literature. In fact, each moving object in the world could be potentially tracked regardless the tracking system. For example, complex systems based on radar or GPS are widely studied and used currently in different contexts, e.g. aviation industry or ground movements tracking [32], [33], [34], [35], [36].
Among the variety of traceable objects, human tracking is the most interesting since the processes of human detection and segmentation in images and videos are difficult due to the large variety of conditions and variables to take into account for this task, besides the well-known problems related to images segmentation, such as noise [37], [38], [39], [40], [41].
The automatic tracking of humans in video has always been an interesting research topic, as it is a cross-domain research area with infinite applications in different fields. In fact, the potential applications of human motion capture led to the development of systems in several domains, such as surveillance, control, and analysis. In addition, there are some recent research fields where the automatic tracking of humans in video sequences is rising up, such as human-computer interaction and augmented reality [8], [36], [42], [43], [44], [45], [46].
Regardless of the kind of object to be tracked, the identification of Regions Of Interest (ROIs) is the first and most important step in the most of computer vision applications, including object tracking. This step requires the application of some image processing techniques in order to make easier the identification and selection of ROIs; the difficulty of this approach mostly depends on both the acquisition system (e.g., camera resolution, field of view and technology) and the environmental conditions (e.g., lighting conditions). Although it seems a trivial process, in some approaches the previous sequence of steps could be sufficient to track one or more objects into a video sequence under certain conditions [47], [48], [49].
In more complex applications, some features need to be extracted in order to describe the identified regions. The extracted features, whose kind is related to the acquired signal, are then used as input in the subsequent step for the discrimination of the identified objects; finally a tracker is necessary to follow the considered object (or class of objects) during the video flow [3], [8], [12], [13], [18], [19], [21], [22], [23], [25], [26], [32], [36], [43], [44], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96], [97], [98], [99].
To simplify and strengthen the step of ROIs identification, and consequently the overall tracking system, some authors introduced active and passive markers (or optical references) to be applied to the object to track. In literature, several kinds of marker could be found; their nature is strictly related to the technology of the acquisition system, allowing an accurate tracking in several conditions [9], [90], [100], [101], [102], [103], [104], [105], [106], [107], [108], [109].
In recent years, the spread of innovative techniques based on Deep Learning has prompted many research groups to apply these techniques for the segmentation of objects in images and tracking in videos with different aims [110], [111], [112], [113], [114], [115], [116], [117], [118], [119]. This kind of approach seems to be very interesting and powerful since the steps needed for the features extraction from the segmented ROIs is overcame thanks to DL architectures that make use of deep classifiers, such as Convolutional Neural Networks (CNNs).
In the sections that follow, we present the application fields of pedestrian detection and tracking systems, first. We then describe the different configurations of the vision systems in the Section 3. Subsequently, we present the different methods for video processing and features extraction in the Section 4 focusing on pedestrian subjects in the Section 4.1. Then, we introduce the approaches pedestrian classification using Machine Learning and Deep Learning techniques in the Section 5, while we present a final discussion in the Section 6. Finally, we present conclusions.
