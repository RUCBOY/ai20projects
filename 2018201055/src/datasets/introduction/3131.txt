Visualization through immersive virtual reality is successfully used in the analyses of complex data and their interpretation in the form of visual perception for users. The first CAVE was developed in 1992 as a specialized hardware for the visualization of virtual worlds (Cruz-Neira et al., 1993a). It was applied in a number of various tasks, such as architectonic walks, space browser, and visualization of molecular dynamics of cancer. The usage reflected technological possibilities of that time and showed the importance of sophisticated visualization for science. The success of the first CAVE device stimulated other researchers to develop similar equipment. The majority of the CAVE systems are prototypes that meet specific requirements. With regard to visualization purposes, they are built in various configurations of projection walls (DeFanti et al., 2011). They can either consist of one front, two sidewalls and a floor, as in the case of the first CAVE system (Cruz-Neira et al., 1993b), or the user can be completely surrounded by the projection, as in the 5-wall StarCAVE (DeFanti et al., 2009) or the 6-wall CAVE systems such as the Cornea (Cornea 2017) C-6 in Iowa (VRAC, 2008). Many CAVE systems are based on pointing the projector at the back wall, although more modern devices employing screens instead of projection walls are also built. Such a system was constructed by a team of EVL scientists and is known as CAVE2 (Febretti et al., 2013), which indirectly indicates the second generation of the systems. The systems also often exist in the form of mobile display panels consisting only of several screens, such as NextCAVE (Merrill, 2009). The number of projection walls is an important parameter for application opportunities of the device in different scientific areas. Also other types of sophisticated visualization devices can be used for the purposes of visualization. Those systems are often HMD- (Head-Mounted Display) based which can depend on external sensors (e.g., Oculus Rift (Oculus, 2017)) or devices that use internal sensors of the display device such as mobile phone (Samsung, 2017), accelerometers (LG, 2017), etc. Those technologies can work optionally in combination with specialized movement devices such as the Virtuix Omni (Virtuix, 2017) or the Cyberith Virtualizer (Cyberith, 2017), both of which address the possible uses of natural forms of movement. Other complex solutions are Virtusphere, (2017) or Cybersphere (Fernandes et al., 2003). Each solution provides a different level of immersivity experience, affordability, space-demands and possibilities of cooperation in a virtual environment.
Many applications of immersive forms of virtual reality in different areas have been registered recently. For example, in medicine, virtual reality is intensively exploited for visualization of human organs during the training of young surgeons (Kral et al., 2004) or for 3-D “trips” through a human body (Crees, 2012). In biology, these systems have been used for the visualization of ontogenesis of microorganisms (Karr and Brady, 2000) and in micro-biology for the visualization of biological macro-molecules (Virtalis, 2012). In geoscience, immersive visualization was applied in the search for deposits of mineral resources (Maes and Hunter, 2006). Devices using immersive virtual reality are also suitable for design and architecture purposes (Palmer, 2011). They can also be used to visualize data obtained from terrestrial or aerial laser scanning (Kreylos et al., 2008). Data are visualized directly as point clouds, or models are created by post-processing of point clouds (Fabio, 2003). Methods of immersive visualization are also successfully used in the design and testing of device prototypes to be produced in the future. In such a way, costs can be saved and high efficiency can be achieved even before starting mass production; one such example is the automotive industry (Bell, 2013). There are numerous possibilities for the use of immersive visualization systems, as evidenced by other examples produced by scientific institutions (EVL, 2017) dealing with applications development within the framework of applied research.
A specific usage of visualization techniques and systems of virtual reality is in the area of creating and developing trainers. In conjunction with appropriate simulation tools, these applications create complex devices intended for training different fields of human activity (aviation, transport, astronautics, medicine, etc.). Development of technologies has also affected the development of forestry, e.g., trainers in harvesting and transport technologies (Ovaskainen, 2005). The use of trainers is still a rare phenomenon in this field; however, they could be used to solve many more tasks. One of them is training in thinning methods. This is a practical activity based on the knowledge gained in the educational process and the experience acquired in the field. Moreover, its impact becomes distinct only after a few years or decades. Therefore, training in thinning methods in the field is incomplete. It lacks the immediate feedback that would provide the information about the thinning impact on the forest's state, structure and stability. These effects can be examined using simulators that model forest development (Pretzsch, 2009; Weiskittel et al., 2011, Burkhart and Tomé, 2012, Fabrika and Pretzsch, 2013). Different modeling concepts (process-based, structural, or empirical) can be applied. Spatially explicit (distance-dependent) models, e.g., eco-physiological tree models (Grote and Pretzsch, 2002, Parrott and Lange, 2004), functional-structural plant models (Prusinkiewicz et al., 2007), or empirical tree models (Hasenauer, 1994, Nagel, 1999, Pretzsch et al., 2002, Fabrika, 2007) are suitable for these purposes. It is also important to ensure the performance efficiency of the final system, because the simulation after the performed thinning must be finished in a short time period (in a few seconds to a few minutes).
These tools are not fully fledged thinning trainers. They lack the dimension of practical performance, i.e., manual selection of trees. Some approaches used simple procedures for the selection of trees directly from the list in a database or a text table (Pretzsch et al., 2002, Sterba et al., 1995). Hasenauer (1994) included the selection of trees in the MOSES growth model from the horizontal projections of tree crowns. However, neither approach reproduces selection procedures used in a real forest environment. This is because they focus only on the horizontal distribution of trees, while the vertical structure is in the background. Thus, some authors have attempted to use three-dimensional projections of a forest. From multiple products we can mention BWINPro software (Nagel, 1999), TRAGIC++ (Parrott and Lange, 2004) or Sylvan Stand Structure with the Sylview visualization extension (Larsen and Scott, 2010). A similar approach is used in SVS, the Stand Visualization System (McGaughey, 1997), a specialized tool for forest visualization. These products move the interaction closer to reality, because they are oriented toward a more complex idea about the structure of the original and remaining populations. Nevertheless, they still do not copy the performance of thinning in a real forest stand. This feature was achieved by implementing virtual reality procedures. A successful attempt was SmartForest (Orland, 1994) with the forest manager interface extension (Uusitalo et al., 1997) and the TreeView product from Seifert (1998). This product was successfully linked to the SILVA (Pretzsch et al., 2002) and BALANCE (Grote and Pretzsch, 2002) models. A more versatile solution was suggested by authors who used VRML language for modeling virtual worlds as for example in Virtual Forester (Lanwert, 2007) or in the visualization extension of the SIBYLA model (Fabrika, 2003). Described approaches do not imitate interventions to the forest realistically.
The Marteloscope method (Poore, 2013) is one field-thinning training-based method. Its concept uses thinning research plots fixed in the field focused on individual trees and their parameters. Plots are often reproduced in many forms suitable for use by computer programs, even growth simulators. This connection is useful according to the forest's virtual reality and possibility for evaluating interventions, optionally to simulate the growth, but it is fixed only to particular plots that are expensive to establish. A better way to ensure the flexibility and versatility of a thinning trainer is to replace such plots fixed in the field with their representations in immersive forms of virtual reality (CAVE, HMD-based, etc.). This process allows the use of any initial forest stand structure.
A thinning trainer can be defined as a system composed of a mathematical model of a forest, computer software and hardware used for training tree selection and simulation of immediate impact of thinning on forest condition (production, ecological and economic). The difference between a simulator and a trainer is in the thinning realization phase. Simulators usually use algorithms to select trees for thinning, but in a trainer the thinning is done manually by the user—preferably interactively in the immersive virtual reality experience. A trainer attempts to mimic reality as well as possible, i.e., it contains elements of advanced virtual reality with a high degree of immersivity and interactivity. Due to this requirement, its development requires that the integration of three inevitable components must be solved: a mathematical forest-growth model, a software solution for forest visualization, and a hardware tool for forest visualization and interaction. The objective of this paper is to present a thinning trainer developed at the Technical University in Zvolen that uses the SIBYLA spatially explicit (distance-dependent) empirical tree model as a technological platform and the CAVE system as a platform for computer-aided virtual reality. We demonstrate the representativeness of virtual reality in the thinning trainer via comparison of a real research plot with its virtual model in the CAVE. This experiment serves to prove the hypothesis of how reliably a thinning trainer we developed can represent reality. At the same time, we also managed to perform a practical example—a defined type of thinning conducted by two independent persons and the SIBYLA model. The experiment proves the hypothesis, that our thinning trainer can substitute for field-thinning training methods (e.g., the Marteloscope method), thus serving as a fully functional system to realize thinning training.
