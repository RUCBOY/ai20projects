The importance of computer network security is growing with the pervasive involvement of computers in people’s daily lives and in business processes within most organizations. As an important technique in the defense-in-depth network security framework, intrusion detection has become a widely studied topic in computer networks in recent years.
In general, the techniques for intrusion detection can be categorized as signature-based detection and anomaly detection. Signature-based detection (e.g., Snort [31]) relies on a database of signatures from known malicious threats. Anomaly detection, on the other hand, defines a profile of a subject’s normal activities and attempts to identify any unacceptable deviation as a potential attack. Typically, machine learning techniques are used to build normal profiles of a subject. Any observable behavior of a system, such as a network’s traffic [13], [19], a computer host’s operating system [11], [36] or a mobile application [2], [39], can be used as the subject information.
Anomaly detection has a potential to detect unforeseen attacks. As new attacks appear very frequently and signature-based detection methods may be overwhelmed by an abundance of polymorphic attacks, using anomaly detection sensors to discover zero-day attacks has become a necessity rather than an option [8]. We are entering the era of “big data” [23]. The increasing volume of information generated by enterprises, the rise of social media and the Internet are fueling an exponential growth of data. Anomaly intrusion detection techniques are therefore challenged by the demand to process more massive data in higher dimensions at high speeds. A practical and efficient Intrusion Detection System (IDS) capable of detecting potential attacks is required so that resolutions can be implemented as quickly as possible.
In general, as shown in Fig. 1, there are four steps in anomaly intrusion detection: data collection, attribute construction, model building and anomaly detection. Prior to building the models, attributes are typically normalized [42]. Many methods [3], [4], [7], [12], [16], [17], [24], [32], [36], [44], [45] have been employed for anomaly intrusion detection. However, most of them mainly focus on attribute construction [12], [16], [17], [32], [44] or on detection algorithms [3], [4], [7], [24], [35], [36], [45]. In this paper, we aim at building a lightweight IDS with enhanced capability to process big data. Intuitively, the approach to high-speed processing of massive audit data in intrusion detection is to reduce the amount of data without losing the valuable information in the data before the detection model is built. We call this process data abstraction. In this work, we introduce a “data abstraction” step between the “attribute construction” and the“model building” steps, as shown in Fig. 1. This step yields a dataset we call abstracted audit data.Download : Download high-res image (254KB)Download : Download full-size imageFig. 1. Steps for anomaly intrusion detection.
We propose three strategies to perform the data abstraction. The first strategy is to perform attribute abstraction after the attributes have been constructed. In this paper, we use Principal Component Analysis (PCA) to transform audit data in a high-dimensional space onto a space of fewer dimensions. The transformed attributes in the low-dimensional space are not part of the original attributes. The second strategy is attribute selection, which locates a subset of original attributes to represent the whole data. In this work, we employ Information Gain (IG) to select a small subset of key attributes from the originals. Different from attribute abstraction or attribute selection where we analyze the attributes, we propose a third strategy called exemplar extraction which focuses on the data samples. The process of exemplar extraction is also based on the training data. The strategy is to extract a smaller set of representative exemplars from the large amount of training data, so that the training is based on a smaller set and the test is based on a compressed detection model. An exemplar refers to a factual data item (e.g., a http request, a network connection) that represents a number of similar data items. Compared to randomly sampling data items (e.g., Netflow based network intrusion detection [5]), exemplars summarize massive audit data and thus better represent the audit data for anomaly detection.
For exemplar extraction, we employed two clustering methods, a newly developed Affinity Propagation (AP) [10] as well as traditional k-means [21] to cluster the original training data before the detection model is built. After the clustering process is finished, each cluster can be represented by an exemplar for AP, and by a mean center for k-means. We then use the exemplars or the cluster centers as the data input for building the detection models. In this way, the data is largely reduced while the valuable information is preserved to build a lightweight detection model with fewer exemplars for processing. This paper extends our previous work [40], [43] by conducting more extensive experiments and comparing the three strategies of data abstraction in terms of the accuracy and efficiency of the detection. In addition, we comprehensively discuss the advantages and the disadvantages of these three strategies of data abstraction during the detection.
Two http traffic data sets collected in a real computing environment as well as the KDD’99 benchmark data are used to validate the three strategies of data abstraction. The extensive test results show that the AP-based exemplar extraction significantly improves the detection efficiency and achieves a more robust detection performance than the information-gain-based attribute selection or the PCA-based attribute abstraction.
In this paper, we make three contributions:

•We propose three strategies of data abstraction to accelerate the process of intrusion detection in massive data using lightweight models: exemplar extraction, attribute selection and attribute abstraction. We compare the three strategies in terms of detection accuracy and efficiency. The comprehensive study provides a valuable reference for the processing of big data in intrusion detection.•We employ Affinity Propagation (AP) to extract exemplars from the massive training data. We thus build a lightweight IDS based on a smaller data set extracted from original training data such that the detection is based on a compressed model. We prove this process of extracting exemplars to be effective for anomaly intrusion detection. In most cases, the AP-based exemplar extraction outperforms attribute abstraction and attribute selection in terms of detection efficiency. To the best of our knowledge, this is the first work to extract exemplars from audit data for intrusion detection with AP.•We use two types of data, real http traffic data and synthetic KDD’99 benchmark data, to validate the three strategies of data abstraction for intrusion detection. We provide extensive test results that demonstrate the effectiveness and high-speed performance of our methods for lightweight anomaly intrusion detection.
The remainder of this paper is organized as follows. Section 2 briefly introduces the related work. Section 3 describes the three strategies of data abstraction for anomaly intrusion detection. Extensive experiments and comparative results are reported in Sections 4 and 5. Concluding remarks follow in Section 6.
