The 2016 Global Games Market Report 1 presented the economic potential of digital games, which traded more than 99.6 billions of dollars, an increment of 8% when compared to the previous year. The growth in this market always pushes forward the quality and development of associated industries and technologies as, for example, computer graphics methods. These methods are essential to make games more realistic through high quality graphics.
Another entertainment field that takes advantage of advanced computer graphics methods is the movies industry. Thinking about realism, in the last years we haveexperienced huge steps towards a complete deceiving of our visual senses. Productions as Rogue One: A Star Wars Story showed the potential of Computer Graphics (CG) characters construction, introducing in a live action movie characters entirely based on real actors.
The search for a perfect generation of digital scenarios, objects and even people is endless and recently reached an astonishing point, mostly helped with the latest advances of computing processing, in special the modern GPU cards (Graphics Processing Units). One current example of such an achievement was the digital reproduction of the actress Carrie Fisher in the last Star Wars movie,2 with the same appearance of the beginning of her career in the 70’s.
In spite of the safe and benign results of these advances, once the goal of perfect CG image generation is accomplished, some threats come along and introduce new challenges to other science areas as pointed out by Holmes et al. [1]. One example of such a challenge is the identification if an image was a photo generated (PG — the one generated by a digital camera) or generated by CG methods. Fig. 1, shows an example of how difficult is to discern between PG and CG images.
Recent studies showed how easy is to deceive people using images [2]. In special, several examples of undesired situations can be described involving the CG images. Imagine, for example, a CG image depicting a terrorist execution of a kidnapped report spreading across the globe. Or another CG image of a rising politician, posted in social networks putting him in an embarrassing or criminal situation days before an election. We are living in what some are calling the Fake News/Post-Truth Era [[3], [4]], where mass communication platforms (as social media networks) can be used to influence and deceive people [[5], [6]]. If a well-crafted invented text can have a great impact on public opinion, imagine the effects of a CG image produced by a very (probably well-paid) skilled professional posted on social networks.Download : Download high-res image (262KB)Download : Download full-size imageFig. 1(a). (a) PG.Download : Download high-res image (290KB)Download : Download full-size imageFig. 1(b). (b) CG.Fig. 1. Example of how challenging is to recognize PG and CG images by simple visual analysis.
The distinction between PG and CG has even more complex legal implications when related to child pornography. In Brazil, any person who produces, reproduces, directs, takes pictures or records, in any way, scenes involving explicit sexual or pornographic act involving children or teenagers, can be sued according to Brazilian Law No 11,829 published on November 25th, 2008. This legal process can result in 4 to 8 years in jail. This situation raises a fundamental legal and ethical question created by technology: What happens if the material is proved to be CG generated? Are the legal consequences the same?
The task of CG image and video detection was already studied and several Digital Forensics methods were proposed [[7], [8], [9], [10]]. However, the results are far from considering the problem as completely solved. Very often these methods are based on the discovery of inconsistencies in very specific situations, hindering their wide application. For example, Conotter et al. [11] developed a method based on blood flow information of CG constructed people in videos. In contrast, Tokuda et al. [7] proposed a more generic method that applies machine learning techniques to solve the CG image identification task and is more similar with the one presented by this work.
The rise of Deep Neural Networks (DNN) in the past few years, presented a shift in classification process, specially in the feature engineering step of this process. Algorithms based on DNN have outperformed other approaches in image classification, becoming the standard approach for these tasks. They consist of learning algorithms with multiple stages, acting over the raw input (image pixels, for example) transforming the representation at one level into another at a higher, slightly-more-abstract level [[12], [13], [14]]. As this stack of layers gets bigger, more complex functions can be learned from data. Besides this power of representing more complicated mappings, a great advantage of DNN is that there is no need for human engineered features, with a general purpose algorithm learning direct from raw data.
In spite of the basic concepts of DNN being around for some decades, only now, with the plenty availability of data and the recent developments of GPU cards DNN showed its full potential, specially in image classification challenges such as the ILSVRC (ImageNet Large Scale Visual Recognition Challenge) [15]. This highlighted the transition from hand-crafted features combined with shallow classifiers to deep classifiers acting directly on raw data as is the case of DNN.
Since then, there is been a trend of, as deeper the model is, the better is its performance and more difficult is the training process. This can be demonstrated by ImageNet challenge results. In 2012 the 8-layers AlexNet network [16] astonished the machine learning community winning the challenge with a top-5 classification error rate of 16.4% and a huge leap from the second place (this one using usually hand-crafted features and shallow classifiers). In 2014, two VGG DNN models (one with 16 layers and the other with 19 layers) got a top-5 classification error rate of 7.3% [17] while GoogleNet with its 22 layers won the challenge with 6.7% error rate [18]. Finally, in 2015, the Residual Network (ResNet) model, a DNN with 152 layers, achieved a top-5 classification error of 3.57% [19]. Also, in the same year, for the first time was presented a DNN technique capable of performing better than humans in image classification tests [20].
This paper presents a novel approach for dealing with the task of detecting CG image generation. Two different models are developed, starting from the DNN ResNet with 50 layers (ResNet-50) [19] and adapting it to the binary problem of CG image detection. Applying concepts of transfer learning [21], we were able to transfer the weights of ResNet-50 layers pre-trained on ImageNet dataset to our model, avoiding overfitting and achieving 97% of accuracy without the burden of designing complex hand-craft features. To our best knowledge, this is the first work to propose applying DNN techniques to this problem, not requiring human experts to design features.
Regarding the actual state-of-the-art method for detection of CG image generation [7], the main contributions of this paper are: (i) the proposal of a new approach based on DNN and transfer learning techniques that achieve the same accuracy of 0.97 as state-of-the-art methods without the need for human level feature extraction; (ii) the use of an extended dataset (more difficult for the task); (iii) a method robust against image processing operations as noise addition, filtering and JPEG compression; (iv) a faster method when compared against state-of-the-art methods3 ; (v) evaluation of different kinds of classifiers in association with a DNN in order to find the best combination (features + classifier); (vi) and a qualitative analysis of bottleneck features produced by ResNet-50 in CG image detection problem.
The text is structured in the following way: Section 2 briefly presents the main works in the Digital Forensics literature that deal with the problem of detecting CG image generation. Section 3 explains with details the proposed methodology while Section 4 describes the main experiments conducted to validate the methodology and presents the achieved results, comparing with the state-of-the-art found on the literature. Lastly, Section 5 presents the main conclusions and some future research directions.
