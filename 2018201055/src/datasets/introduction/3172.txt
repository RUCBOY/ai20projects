Among the many computational systems available for scientific analyses, in silico experiments offer advanced results and demand higher computational capacity. Non-specialized users have shown difficulty in using complex computational solutions, due to their particularities. Therefore, simplicity of use must be one of the fundamental characteristics of such systems, once transactions and computations must be transparent for facilitating access and manipulation of the available resources.
Science Gateways consist of a set of tools, applications, and data integrated via a user-friendly portal and their main objective is to enable a larger group of users to conduct experiments, even if they are not skilled for dealing with the details of a computational resource configuration. Typically, they use tools as workflow management systems, e.g., Galaxy [1], Taverna [2], gUse [3] among others [4], [5], [6], [7], [8], for reproducibility and simplification of execution processes [9]. Such systems are integrated with databases for the acquisition of workflow steps and input data or storage of the processing results [10]. On the other hand, Science Gateways may suffer from performance traps. As they offer a high-level solution, users do not have information about servers location or installed capacity. Systems for sophisticated computations are expected to offer enough capacity, regardless of the complexity of the processing parameters, which is not always true. Hardware limitations can hamper the experiments performance, slowing the progress or delivering poor results. Protein Structure Prediction (PSP) tools, designed for discovering the native structure of a protein based on its amino acid chain [11], are an example of such complex experiments, once they demand strict controls of computer performance and generate intensive data.
Among the Science Gateways challenges are (i) selection of a gateway that is actively maintained, (ii) discovery of new services, (iii) real-time service monitoring and management, (iv) identification of sufficient computing resources for the problem complexity, and (v) support from the user's community [12]. Science Gateways must deal with deadline constraints and paid resources for processing experiments in constant growth, therefore, the allocation of more computational resources from cloud computing is a reasonable solution. Limitations on the allocation of heterogeneous systems include different cloud providers that are not inter-operable [13] and nonexistence of a module, framework or strategy that guides the user towards the definition of an optimized computational resources configuration for running experiments.
This paper proposes a strategy based on data mining techniques for the understanding of the relationship between users input data and the behavior of the system over the execution time. The results showed Scientific Gateways require a module to help the decision on the type of resources allocation for the execution of scientific experiments. The contributions of the approach can be summarized into:
•an extensive evaluation of Galaxy capacities and shortcomings;•a comparison of processing PSP in a varied set of machines; and•a base module for any Science Gateway to support the computational resources identification for running experiments.
The remainder of the paper is organized as follows: Sections 2.1 and 2.2 briefly review the Service Oriented Architecture and the concepts of protein prediction structures, respectively, Section 3 introduces Galaxy framework and its mechanisms; the main proposal, materials and algorithms are presented in Section 4; Section 5 addresses the benchmark setup and the performance evaluation of executions in Galaxy environment; Section 6 reports the main works related to Science Gateways; finally, Section 7 provides the concluding remarks and suggests some future work.
