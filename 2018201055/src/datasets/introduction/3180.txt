Prostate Cancer (PCa) is one of the most common types of cancer among men. It accounts for almost one in five new diagnoses of cancer (Siegel et al., 2016). Initial screening of PCa is done using Digital Rectal Exam (DRE) and estimation of Prostate Specific Antigen (PSA) (Penzkofer and Tempany-Afdhal, 2014), following which possible candidates are subjected to Transrectal Ultrasound (TRUS) biopsy. The current method of determining the aggressiveness of prostate cancer is through TRUS biopsy. TRUS biopsy often has low specificity and causes over-diagnosis (Harvey et al., 2012, Ahmed et al., 2017). Moreover, it can lead to bleeding, pain and life-threatening sepsis (Ahmed et al., 2017). Only a small portion of the gland is sampled for biopsies, and hence the result cannot be considered as representative of the whole organ. MRI is a proven modality which can be used for earlier detection and staging of prostate cancer (Turkbey and Choyke, 2012). However manual reading and analysis of MRI images by radiologists are time-consuming due to the large volume of multi-modality MRI data. Moreover, diagnosis depends on experience and expertise of the radiologist. The Gleason grading system (Gleason et al., 1974, Epstein et al., 2005) was considered as the standard for assessing the aggressiveness of cancer. In November 2014, International Society of Urologic Pathology (ISUP) Consensus Conference on Gleason Grading of Prostatic Carcinoma proposed a new grading system for prostate cancer (Epstein et al., 2016). The number of grading classes was reduced from Gleason Scores (GS) 2 to 10, to Grade Groups (GG) 1 to 5. The World Health Organization (WHO) has accepted the revamped grading system and the nomenclature Grade Groups 1 to 5 for 2016 edition of “Pathology and Genetics: Tumours of the Urinary System and Male Genital Organs” (Epstein et al., 2016). Table 1 describes the revised grading system (Epstein et al., 2016). PCa belonging to GG 1 (GS ⩽ 6) are low-grade or indolent tumours which does not require treatment, whereas PCa belonging to GG 2 to GG 5 are high-grade cancers which require immediate medical attention (Irshad et al., 2013).Table 1. Revised grading system (Epstein et al., 2016).Grade groupComparable Gleason scoreDescription1≤6Individual disjunct well formed glands only23 + 4 =7Mainly well-formed glands with fewer component of poorly-formed/fused/cribriform glands34 + 3 =7Mainly poorly formed/fused/cribriform glands with fewer component of well-formed glands44 + 4 =8(i) Poorly-formed/fused/cribriform glands only or3 + 5 =8(ii) Mainly well-formed glands and fewer component lacking glands or5 + 3 =8(iii) Mainly lacking glands and fewer component of well-formed glands59–10Lacks gland formation with or without poorly formed/fused/cribriform glands
Even though there are proven methods for automatically detecting and locating cancerous tissues using mpMRI, their use in detecting the aggressiveness of cancer has only a little been explored. Nketiah et al. (2017) used point-biserial correlation coefficients and Spearman correlation coefficients to analyze the correlation between prostate cancer with Gleason scores (3 + 4 =7) and (4 + 3 =7) using texture features derived from transaxial T2 weighted (T2W) MRI (Nketiah et al., 2017). Based on statistical analysis using t-test, Nezzo et al. (2016) observed that the use of Mean Diffusivity (MD) of DTI MRI images acquired at high B values could be used for distinguishing GG < 3 from GG ≥ 3 (Nezzo et al., 2016).
Citak-Er et al. (2014) evaluated LDA and Support Vector Machine (SVM) classifiers for classifying low-grade (GG = 1) vs. high-grade (GG ≥ 2) PCa. They used patient's age, level of PSA, presence or absence of a prostate anomalousness based on DRE, tumor size and Likert scales of T2W, Diffusion-Weighted (DW) and DCE MRI and achieved a higher sensitivity, but a lower specificity using SVM compared to LDA. Wibmer et al. (2015) performed Haralick texture analysis and Linear Regression (LR) to examine the correlation among texture features and Gleason score. Fehr et al. (2015) used Gray-level Co-occurrence Matrix (GLCM) texture features and SVM to classify GG = 1 vs. GG ≥ 2 and also (3 + 4 =7) vs. (4 + 3 =7) Gleason scores. Le et al. (2017) classified PCa with GG = 1 from GG ≥ 2 using high-level features extracted through Convolutional Neural Network (CNN) and SVM classifier. Few methods (Citak-Er et al., 2014, Fehr et al., 2015) used classifiers like SVM to classify PCa with GG = 1 vs. GG ≥ 2 whereas the other methods performed statistical analysis to find out the correlation between features and aggressiveness of PCa. The aforementioned techniques just distinguish between high-grade (GG ≥ 2) and low-grade (GG = 1) cancers and not among all the 5 grade groups. None of these methods has been tested on a public dataset. Table 2 displays the existing techniques for the grading of PCa.Table 2. Comparison of works.Sl. no.AuthorNo. of patientsFeaturesTest/classifierClassification of GG/GSModality1Nketiah et al. (2017)23Texture, ADC, Ktrans, VeU testGS = 7(3 + 4) vs. GS = 7(4 + 3)T2W, DW, DCE2Nezzo et al. (2016)38Mean Diffusivity (MD)t-testGG < 3 vs. GG ≥ 3BVAL DTI3Citak-Er et al. (2014)33Age, abnormality in DRE PSA level, Likert scalesLDA, SVMGS = 6 + GS = 7(3 + 4) vs. GS = 7(4 + 3) + GS > 7T2W, DW, DCE4Fehr et al. (2015)217first-order, 2D GLCM TextureRFE-SVMGS = 7(3 + 4) vs. GS = 7(4 + 3)GG = 1 vs. GG ≥ 2T2W, ADC5Le et al. (2017)364High-level featuresSVMGG = 1 vs. GG ≥ 2T2W, ADC6Proposed method162High-level featuresSoftmaxGG 1, 2, 3, 4, 5T2W, ADC, BVALThe details regarding proposed method is indicated in bold.
The techniques mentioned above except that of Le et al. (2017) have used hand-crafted texture features for distinguishing between various Gleason grades. Hand-crafted features are incapable of transforming to different datasets, limiting their potential clinical use (Liao et al., 2013). The representation power and effectiveness of these features may vary depending on data (Liao et al., 2013). To handle this constraint, deep learning based feature representation techniques are developed to derive hidden information, which can be transformed into available data. Deep learning (DL) is a learning method which hierarchically learns high-level features that are useful for distinguishing structures from raw input data (Bengio et al., 2013). Recent studies show that deep networks can be more efficient than shallow architectures in multi-class classification by extracting hidden features in the input data (Pathak et al., 2014, Liu et al., 2015). In applications like medical image analysis where it is difficult to find a large number of labelled data, deep learning can find a noteworthy application.
The stacked sparse autoencoder (SSAE) is a deep learning architecture in which low-level features are encoded into a hidden representation, and input are decoded from the hidden representation at the output layer (Xu et al., 2016). SSAE is trained, bottom up, in an unsupervised fashion, in order to extract more efficient hidden features from raw input. The hidden features can provide more accurate, supervised classification in the top layer. The capability of SSAE to understand and exploit large number of unlabelled instances make them useful for MRI image analysis. Shin et al. (2013) have successfully applied the stacked autoencoders to organ identification in DCE MRI, which shows their potential for application to MRI images. Recently, Dalmış (2017) used deep learning for segmentation of breast in MRI volume. Yuan and Meng (2017) developed stacked sparse autoencoder with image manifold constraint, to detect polyps in wireless capsule endoscopy images.
Hand-crafted texture features, given as input to stacked sparse autoencoder is also proven to provide promising results. Yang et al. (2016) have used LBP features as input to stacked sparse autoencoder for face spoofing detection. GLCM and Gabor features enhanced using stacked sparse autoencoder have been successfully applied for SAR image classification (Geng et al., 2015). In this paper, we present a deep learning method, based on stacked sparse autoencoder to classify PCa to different grade groups. Our main contributions can be summarized as follows.
1.We have introduced a method which uses stacked sparse autoencoders to transform low-level features into high-level features for grouping prostate cancer lesions into grade groups.2.This method is one of the pioneer approaches which attempted to classify 3D volumetric prostate cancer lesions into 5 grade groups from MRI images using multi-class classification. Aforementioned existing techniques of PCa grading use binary classification for grouping of low-grade PCa (GG = 1) vs. high-grade PCa (GG ≥ 2).
