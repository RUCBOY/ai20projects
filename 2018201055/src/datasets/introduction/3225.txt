Mobile robots have been widely used in industry for civilian and military tasks. For example, Urrea and Muoz [1] evaluated the performance of position control for a mobile robot in crops; Kim and Hong [2] proposed a distributed and autonomous routing algorithm for distributed mobile surveillance robotics platforms.
According to Bailey and Durrant-Whyte [3], mobile robot mapping and localization methods can be geometric, topological, or hybrid. Geometric maps represent the absolute position of the robot and landmarks. On the other hand, topological methods use graphs to estimate the environment topology. Cheng, Chen and Liu [4] stated that topological maps are simpler than geometric ones, requiring less computer memory, and, therefore, speeding up computational navigation processes. Hybrid methods are a blend of both topological and geometric techniques.
In an indoor environment, navigation systems such as Global Positioning System (GPS) can not provide accurate positioning information. In this way, several types of positioning systems have been developed to determine the absolute position of a mobile robot in this kind of environments, such as Bluetooth, Radio Frequency Identification (RFID), and image-based technologies. The last has become an important research topic in the development of mobile robots [5]. The advantages and disadvantages of these technologies are presented in Section 2.
In recent years, machine learning methods, such as artificial neural networks [6] and Support Vector Machine (SVM) [7] have been widely used for mobile robots navigation using images due to their capabilities of learning complex patterns and make intelligent decisions based on data [8]. Jodas et al. [9] presented a system to control the navigation of an autonomous mobile robot through tracks in plantations using SVM and an artificial neural network.
The aim of the paper is to propose a novel approach for mobile robot localization via classifiers with rejection option. For that, we adopt topological map information. In this context, the navigable area recognition is achieved by processing the input image and classifying them into states which represent the current robot context. Thus, the robot is able to determine its location into a topological map and also to navigate autonomously through the environment, reaching the desired destination.
In addition, we present a comparative study of several feature extraction methods and machine learning techniques in an indoor environment, resulting on two novel image datasets. The navigation and localization system is, initially, assessed with images generated from a virtual environment. After that, we use a GoPro camera to evaluate the system in a real environment. Also, we compare our results with a navigation system using an omnidirectional camera proposed by Marinho et al. [10]. Based on the results, combining Spatial Moments with the Bayes classifier has provided the best performing model with regards to both accuracy and computational time. Moreover, the results show that using the conventional vision camera is the best choice for the navigation task considering the accuracy and computational cost among the evaluated settings.
The next sections of this paper are organized as follows. Related works are presented in Section 2. Section 3 briefly introduces the feature extraction techniques and Section 4 describes the machine learning methods. Section 5 presents the methodology emphasized the proposed method, robot, topological map of the environment and datasets. Results and discussions of our experiments are explained in Section 6. Finally, Section 7 presents our conclusions.
