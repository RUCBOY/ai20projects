This paper aims to investigate the differences between the level of abstraction achieved by deep convolutional neural networks as compared to the human performance in the context of painting analysis. To synthesize the motivation, let us recall Pablo Picasso’s words: “There is no abstract art. You must always start with something. Afterward you can remove all traces of reality”. Art historians and enthusiasts are able to note, while recalling major artistic works through the history, that the level of abstraction steadily increased.
In parallel, in the last period, works that use computer vision techniques to analyze visual art increased with respect to both the quantity and the quality of reported results. Two trends favored these developments. First, there were consistent efforts to digitize more and more paintings, such that modern systems may learn from large databases. Two of such popular efforts are Your Paintings (now Art UK1) which contains more than 200,000 paintings tightly connected with historical British culture and WikiArt2 which contains around 100,000 paintings gathered from multiple national cultures. The databases come with multiple annotations. For this work, we are particulary interested in annotations dealing with the painting's subject or scene type. From this point of view, a more complete database is the WikiArt collection, where the labelling category is named genre. The second trend is purely technical and it deals with the development of the Deep Neural Networks, that allowed classification performances that were not imagined before. In this work, we will use the more popular Convolutional Neural Networks (CNN) to recognize the painting genre.
Let us now establish the meaning of "genre", its relation with the scene and with the image subject. A list of definitions for various paintings genres is presented in Table 1. To label a painting into a specific genre, in most of the cases, a user has to identify the subject of that painting. The exceptions are “Abstract Art”, “Design”, “Illustration” and “Sketch and Study”, where the main characteristic is related to the depiction mode. In this majority of cases, the subject is related to the scene represented in the work of art. The term “genre” is typical for art domain, and is a more general, including, concept than mere “subject” or “scene type”. In this work, while referring to paintings, we will use all three with the same meaning of “genre”. In comparison, for a non-artistic photograph, as there is no artistic intervention in the depiction mode, the subject is more related to the scene, while the genre is hard to be defined. For artistic photos, the “genre” gets meaning again.Table 1. Overview of the genre organization of the WikiArt database and the explanation of the label meaning. We have marked only genres with more than 200 images.GenreNo. imgs.Description1Abstract Art7201Uses shapes, forms etc. to replace accurate representations2Allegorical Painting809Expression of complex ideas using another subject3Animal Painting1233Paintings which depict animals4Battle Painting273The main subjects are battles and wars5Cityscape4089Works which contain cities or other large communities6Design1577Conceptual schemes of objects and structures7Figurative1782Forms inspired by objective sources, but altered8Flower Painting1270Paintings of flowers9Genre Painting10,984Scenes of everyday life10History Painting656Depictions of historical events11Illustration2493Visual representations usually meant for books, magazines, etc.12Interior511Paintings depicting interiors of structures13Landscape11,548Contains representations of land or other natural scenes14Literary Painting418Subject taken from literary work15Marina1385These paintings show scenes from docks or ports16Mythological Painting1493Inspired by mythology17Nude Painting1758Paintings which contain nudes18Portrait12,926Images of real individuals19Poster229Works which are usually intended for advertising20Religious Painting5703Inspiration is drawn from religious scenes21Self-Portrait1199The subject of the painting is the artist22Sketch and Study2778Drawings done for personal study or practice23Still Life2464Images which depict inanimate objects24Symbolic Painting1959Content suggested by symbols in the forms, lines, shapes and colors25Wildlife Painting259Paintings of natural scenes, including animals in their habitats
Starting from the idea that Deep Neural Networks share similarities with the human vision [1] and the fact that such networks are already proven to be efficient in other perception-inspired areas, like object recognition or even in creating artistic images, we ask ourselves if they can pass the abstraction limit of artistic paintings and correctly recognize the scene type of such a work.
In this paper, we will first work with Residual Network (ResNet) on the standard WikiArt database so to obtain state of the art results. Afterwards, we will test different domain transfer augmentations to see if they can increase the recognition rate; also we will study if the network is capable to pass the abstraction limit and learn from different types of images that contain the same type of scenes. Furthermore, we introduce several alternatives for domain transfer to achieve a dual-task: improve the scene recognition performance and understand the abstraction capabilities of machine learning systems.
Regarding deep networks, multiple improvements have been proposed. In many situations, if the given task database is small, better performance is reachable if the network parameters are previously trained for a different task on a large database, such as ImageNet. Next, these values are updated to the given task. This is called fine-tuning and it is a case of transfer learning. As our investigation is related to a different domain transfer, we will avoid to use both of them simultaneously, in order to establish clearer conclusions. To compensate, we are relying on the recent architecture of Residual Networks (Resnet [2]) that was shown to be able to overcome the problem of vanishing gradients, reaching better accuracy for the same number of parameters, when compared to previous architectures.
1.1. Contribution and paper organizationThis paper extends our previous works [3, 4], being mostly developed from Ref. [3], where we had initiated the discussion about the efficiency of various methods to transfer information from the photographic domain to the paintings domain, such that the recognition by CNNs of paintings genre is improved. In this paper we significantly extend the discussion, by including other transfer methods and by adding more significant results that allow crisper conclusions. In the second work ([4]), we showed that the artistic style transfer remains as efficient even if a reduced number of iterations are performed while over–imposing the style of an artistic painting and the content from a photograph onto a new image, according to the neural style transfer introduced by Gatys et al. [5].Overall, this paper claims several contributions along a number of directions. On one direction, we investigate which aspects, comprehensible by humans, hinder the CNNs while understanding a painting genre; subsequently by means of domain transfer, we retrieve information about the internal description and the organization of the painting clusters. In order to accomplish such a task, we annotate artistic photographic images with respect to the scene type related to genres and we stylize a large corpus of photographs using different style transfer methods. All this data will be made publicly available to be used in other research works.On a second direction, this paper is the first to objectively evaluate the efficiency of the currently popular neural style transfer methods. Currently existing solutions [[5], [6], [7], [8]] compare themselves by speed, stability within video sequences or number of transferable styles. By quantifying the improvement while adapting photographs to the painting domain, we reach a surprising conclusion, namely that they are less or at most as efficient as non-neural style transfers solutions. Evermore, a CNN finds as informative the original photographs without any style transfer applied.The remainder of the paper is organized as follows: Section 2 presents previous relevant works, Section 3 summarizes the CNN choices made and Section 4 will discuss different aspects of painting understanding. Section 5 presents the used databases, while implementation details and results are presented in Section 6. The paper ends with discussions about the impact of the results.
