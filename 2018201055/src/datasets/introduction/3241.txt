The goal of the present study is develop a prosody model that integrates discourse association and information structure to simulate continuous L1 English speech prosody towards more comprehensible L2 communication. The model is intended as CALL baseline for advanced L2 learners who need to produce more intelligible and expressive continuous speech by improving overall global prosody. Our motivation stems from that fact that though quite a number of individual prosodic features have been identified to contribute to L2 accent, intelligibility and comprehensibility, little is known as to how these features are interactively related to more expressive speech, and where L2 speakers’ learning attention could be directed. However, we noted that most of existing CALL systems tended to use prosodic features derived from data of read isolated sentences instead of more realistic continuous speech, and inadvertently by design left issues specific to continuous speech prosody unaddressed. Our group has long been investigating speech prosody with data of continuous speech, and adopted a top-down hierarchical perspective from the start. We consider this departure of perspective from the mainstream is particularly significant when dealing with fluent continuous speech consisting large size multi-phrase speech unit whose output generation involves both linear and hierarchical derivation, and by default would bring to light prosodic issues of global nature. The following presentation reports our current attempt to CALL application that was encouragingly supported by recent works (Domínguez et al., 2014, 2016) that not only accounted for the close relationship between discourse prosody and information structure, but also predicted discourse prosody in continuous speech. We believe works devoted to analyzing and simulating more realistic sentences of continuous speech, whether well planned or spontaneous, merit more research attention.
In the physical sense, prosody is generally referred to the melodic and rhythmic aspects of speech that involves modulations of fundamental frequency, duration, and amplitude in the speech signal (Munro, 1995, Scruton, 1996, Derwing and Munro, 1997; Anderson-Hsieh et al., 1992; Benrabah, 1997, Coniam, 1999, Witt and Young, 2000, Trofimovich and Baker, 2006, Moustroufas and Digalakis, 2007). By examining the acoustic aspects of speech output at face value it is no surprise that some reported studies concluded that the range of prosodic variation is non-systematic and unpredictable (James and Atkinson, 1976, Peppé et al., 2000; Jacewicz et al., 2010). However, we believe this is largely due to examining output acoustic data at face value instead of understanding its composition that involves both linear association as well as hierarchical governing. Note that three parallel layers contribute to prosody formation, namely, linguistic, para-linguistic, and nonlinguistic. The linguistic layer encodes phonetic representation, lexical (semantic), syntactic (phrase and sentence), discourse information and some pragmatic information that can be predicted from content. The paralinguistic layer conveys speaker's attitudes, emotions, dialect, sociolect, idiolect, etc. The non-linguistic layer delivers the speaker's gender, age and physical state. In other words, the majority of output prosodic variations from linguistic contributions should be largely predictable, and therefore could be modeled. For instance, the procedures of how the syllables are combined to form prosodic words and how prosodic words form prosodic phrases and sentences are already well known (Selkirk, 1984; Nespor and Vogel, 1986). Furthermore, various prosodic hierarchy supported by other L1 studies also verified how acoustic correlates at each prosodic level contribute collectively to surface prosody, as well as identifying a range of communicative functions such as marking stress, focus, and boundaries etc. (Bailly and Holm, 2005, Fujisaki et al., 2005, Xu, 2005, Mixdorff, 2002a). The fact is acoustic models that successfully separate contributions from words and sentences (Laver, 1991, Fujisaki, 2004) are available; these models could easily be extended to accommodate additional higher level contributions from larger size speech units. For instance, instead of examining single spoken phrases or simple sentences at one time, Tseng et al., 2005, Tseng and Su, 2008), as an alternative, extended a perceived prosodic hierarchy to include discourse-level multi-phrase association patterns in order to account for the formation and generation of cross-phrase global prosody of continuous speech from multiple levels of contributions. Through corpus studies of Mandarin L1 speech data, the perception based discourse hierarchy, supra-segmental acoustic correlates F0, duration, intensity and pause duration were analyzed with a regression procedure that teased apart each prosodic correlate from surface prosody into particular discourse levels as well as their cumulative contribution to output prosody. It turned out that the hierarchical alternative not only accounted for contributions from the syllable, prosodic word, and prosodic phrase, but also successfully took into account physiological constraint change of breath when speaking continuously and multi-phrase units, thereby substantiating contributions above words and sentences in order to form coherent multi-phrase speech paragraphs. Thus a working model capable of predicting the interaction and modulation among involved discourse layers and ultimate prosody output prosody of multiple-phrase units is already in existence to account for how underlying prosodic patterns systematically correspond to various discourse levels and derivationally contribute to output prosody.
In comparison to the relatively little corpus linguistic investigation of output prosody that accounts for phrase/discourse association, even less attention has been paid to prosodic modulation conditioned by arrangement of information structure beyond the sentence level. While information structure (IS) coded in words (lexical) as well as larger structure (sentence) generally refers to the organization that reflects the important content of utterances (Halliday, 1967; Chafe 1974; Lambrecht, 1994), utterance in these studies remained at the sentence level and corpus based results scarce. Among the two best accepted definitions of IS from L1 studies, the more generally assumed one is the given/new dichotomy of information status (Prince, 1981) while the less assumed other is focus structure (König, 2002). We note here that as working definition for corpus analysis, the sentence-based definition of given/new status soon became inadequate when used to analyze data of continuous speech, for example, narratives because the same nouns and noun phrases would appear over and over. Graphic display of acoustic data of continuous speech also showed how the intonation contours of individual phrases varied highly on the one hand, and almost always contained more than one peak on the other. Instead, reported works showed how prosodic features in English, Bulgarian, Italian and Dutch are attributed to focus types (Hoskins, 1997, Sityaev and House, 2003, Avesani and Vayra, 2003, Hanssen et al., 2008, Andreeva et al., 2016), hence focus specified status appeared to be a more possible and plausible working definition to analyze information structure of continuous speech data. We therefore tested perception of focus types as a separate level of manual annotation for data preprocessing, and were able to retain consistent tagging across transcribers. Consequently, we adopted focus type as our working definition of Information Structure.
We noted that similar to L1 studies, the majority of L2 studies have also been limited to single specification by isolated single tokens at a time, at individual levels and without mention of cross-level and cross sentence interactions. For example, at the phonetic level, studies of L2 English consonants and vowels produced by Javanese and Swedish speakers showed how their temporal patterns differ from L1 English due to influences from their respective mother tongue (Thorén, 2007, Perwitasari et al., 2015). At the lexical level, when L2 English of Japanese and Mandarin speakers was compared with L1 English, it was found the L2 speakers produced weaker acoustic contrasts between stressed and unstressed syllables (Nakamura, 2010, Tseng et al., 2013). But there has been little to no report on the phonetic-lexical interaction in perceived L2 accent, let alone discourse features that must be taken into account to produce continuous speech of multiple phrase units.
Similar to reported works on L1 prosodic features, information structure related L2 prosodic features has also received less attention, and attention has also been paid to sentence and discourse prosody separately. At the sentence level, most reported results showed that expressing information structure via prosody turned out to be more challenging than expected for L2 speakers. For example, given/new information related pitch accent placement of L2 English speech by German, Spanish, Japanese, Malay and Thai speakers showed that L2 speakers would often emphasize given information instead (Wennerstrom, 1994, Grosser, 1997, Ramirez Verdugo, 2002, Gut, 2009, 2013). Focus structure related pitch accent placement, i.e., broad vs. narrow focus, by L1 Taiwan Mandarin and Beijing Putonghua speakers showed insufficient differentiation of on-focus/post-focus contrasts (Visceglia et al., 2012). Vietnamese and Hong Kong L2 English exhibited similar weakened realization of pitch accent contrast (Nguyễn et al., 2008) and post-focus compression (Gananathan et al., 2015). L2 focus realization distinct from L1 was also found in Atterer and Ladd (2004) and O'Brien and Gut (2010) at the sentence level. At the discourse level, patterns of chunking and phrase association that may attribute to L2 comprehensibility/accent have also been studied, though not as extensively as sentence level issues. Both L1 Taiwan Mandarin (Tseng et al., 2010) and Bengali (Saha and Mandal, 2017) speakers exhibited similar chunking features: (1) Inconsistency of realizing discourse-level chunking, continuation or termination among speech paragraphs and among speakers. (2) More units of intermediate chunking than L1 English speakers. In short, these studies collectively demonstrated that though some distinct features related to individual prosodic units and/or levels have been widely studied, the interaction among them was hardly addressed, especially with respect to discourse/paragraph association and information structure. The lack of understanding of how individual features interact is also evidenced by a recent comprehensive review of CALL systems applying TTS (Text To Speech) that concluded by recommending existing CALL systems to pay more attention to the development of natural prosody and expressiveness (Handley, 2009).
Motivated by the common lack of interactive studies to help determine the prosodic constitution of multi-phrase speech units with appropriate information placement, especially Computer-Aided Language Learning (CALL) systems for more advanced L2 learners, we set our goal to construct a prosody training system for CALL applications that would incorporate interaction of involved factors and trained with data of continuous speech. We hope the linguistic information-based model of English prosody could bring more implications for advanced computer-assisted language learning. In the following sections, we will present our proposed model based on models summarized in Bailly et al. (2005), Fujisaki et al. (2005), Xu (2005), and Tseng et al. (2005) using refined methods from earlier research (Zellner and Keller, 2001, Tseng et al., 2005, 2008). We will use a hierarchically inclusive perspective integrating linguistic-layer categories from both discourse and information structure to analyze L2 prosody. Specifically, prosodic modules/patterns were extracted from surface prosody at particular linguistic levels in order to provide a finer-grained, hierarchical analysis of the individual and collective contributions made by each prosodic level, as well as to investigate the possibility of interaction among those levels. Based on data-driven approaches, a bottom-up, additive model of L1 prosody was built, starting with phonetic and phonological specifications at the lexical level; then superimposing higher-level syntactic/semantic specifications at the phrase and sentence levels. After which patterned prosodic projections of paragraph associations and information structure were added to produce fluent continuous speech. The same model was also used to compare L1 and L2 Taiwan English prosody from a hierarchical perspective, which allowed us to identify differences in production of prosodic modules/patterns at each level of linguistic specification, as well as the interactions among these levels. We also developed a L1 prosodic model to provide corrective norm for L2 learners by simulating L1 prosodic features using the proposed predictors and optimized model trained from L1 speech corpus. Simulated L1 prosodic features were compared with a baseline model by objective evaluation (RMS error and correlation). The simulated L1 prosodic features were further superimposed onto L2 speech tokens, resynthesized and compared with original L2 tokens in terms of perceived accented using subjective evaluation (native-listener perception test). We will show that the increased prediction accuracy and reduced L2 accent makes the model a good candidate for CALL implementation, in particular how it could be used as corrective feedback toward prosody training.
