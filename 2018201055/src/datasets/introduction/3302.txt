Parkinson's disease (PD) is a neurological disorder caused by the progressive loss of dopaminergic neurons in the mid-brain, leading to clinical symptoms like bradykinesia, rigidity, tremor, postural instability, and others. Non-motor symptoms like sleep disorders and problems in cognition and emotions have also been observed [1]. Most of Parkinson's patients develop hypokinetic dysarthria, which is a multidimensional impairment that affects different aspects or dimensions of speech including phonation, articulation, prosody, and intelligibility [2]. The neurological state of PD patients is evaluated subjectively by clinicians who are, in most of the cases, mainly focused on the evaluation of motor deficits rather than the speech impairments; however, the patients claim that the reduced ability to communicate is one of the most difficult aspects of the disease. The Royal College of Physicians in the NICE guidelines [3] recommends that every PD patient should have access to speech and language therapy among other kinds of non-pharmacological treatments [4].
The research community has shown interest in developing computational tools to help patients and clinicians to assess Parkinson's speech. There have been several initiatives towards the development of computer-aided tools to support or assist the speech therapy and the diagnosis of different disorders. In [5] the authors present VOCALIZA, a software application for computer-aided therapy in Spanish language with three levels: phonological, semantic, and syntactic. The system is mainly based on a speech recognizer and it is used to train the language skills of speakers with different pathologies. Several characteristics of using automatic speech recognition (ASR) systems for the assessment of voice, speech, and language disorders are presented in [6]. Additionally, the use of such systems to support the speech and language therapy of patients who had their larynx removed due to cancer and for children with cleft lip and palate was evaluated in [7]. In that work the authors introduced the system PEAKS, which is mainly based on prosodic features (at word and turn level) and showed to be suitable to support several applications (diagnosis and monitoring) in the clinic. Another work based on ASR systems to assist speech and language therapy is presented in [8]. In that work the authors introduce the system to evaluate the speech of children with neuromuscular disorders, e.g., dysarthria. Further to the use of an ASR system, the authors use a pronunciation verification (PV) approach to evaluate the improvement in the communication skills of the user at both phoneme and word levels. Further to the aforementioned studies, several works have been published summarizing the technology that has been developed to support the speech and language therapy. In [9] the authors present a brief description of several systems that were developed to assist the speech therapy of Romanian patients with different disorders, e.g., stammering, logoneurosis, dyslexia-dysgraphia, and others. Recently, in [10] the authors present a systematic review of the literature about computer-aided systems developed to support speech and language therapy mainly focused on articulation and phonological impairments. According to their review, “all the studies introduced their own developed tools and used them for intervention except one study, in which a previously developed software was used”. Additionally, the authors mention that the intervention of each study varies based on the technical abilities of the system, the disorder targeted, and the intervention framework. The types of interventions covered on the review include phonation, articulation, phonological awareness, and general intervention.
According to the reviewed literature and the evidence collected in [10], the research community, patients, medical doctors, and therapists lack of computational tools with different characteristics including: user-friendly, easy to use, open source, able to perform several interventions/analyses, and able to be personalized or adapted according to the necessities of the users. In this paper we introduce NeuroSpeech, a new system for the semi-automatic analysis of speech signals. It includes measurements to model four speech dimensions: phonation, articulation, prosody, and intelligibility. NeuroSpeech has been designed and tested upon Parkinson's speech signals; however, its methods and techniques can be easily adapted to perform analyses of other speech disorders. Further to the computation of several speech dimensions, the system is able to perform a regression analysis based on a support vector regressor (SVR) to estimate the neurological state of the patient (according to the Unified Parkinson's Disease Rating Scale – UPDRS [11]) and the dysarthria level according to a modified version of the Frenchay Dysarthria Assessment (FDA-2) score [12]. This software and its associated documentation, i.e., source code, user and technical manuals, can be downloaded for free from the link https://github.com/jcvasquezc/NeuroSpeech. Further details of the characteristics of NeuroSpeech and several case study examples will be provided in the next sections.
