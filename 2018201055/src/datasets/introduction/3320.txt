With the tremendous use of computers in various field, data in large quantity is required to be accumulated to solve our numerous problems. In order to enhance the efficiency of mechanism, the researchers have designed certain algorithms over the years to overcome the emerging problems. Basically, an algorithm is a step-wise procedure to efficiently solve a problem with pencil and paper in a finite number of steps [1]. Algorithms have a crucial role in solving problems of mathematics and computer science. Data search is the basic problem almost in every field where computers are being used [2]. Traversing each element of a list from beginning to end in order to find the desired element is a complete wastage of time and computation cycles. To avoid this wastage, techniques of indexing and sorting came into light, but sorting proved to be more beneficial.
Sorting is one of the fundamental operations in computer science that re-arranges elements of a list into an ascending or descending order. Elements can be numeric, alphabetic or any object having specific key value [3]. There are a large number of sorting algorithms being used in industry and academia [4]. Factors affecting the selection of suitable sorting algorithm for an application can be divided into two groups; direct factors and indirect factors [5]. The size of a list, distribution scenario of the elements, percentage of already ordered elements in the list [6], time and space complexity of an algorithm come under direct factors [7]. Indirect factors include programming effort, data type of elements, processor speed, size of primary and secondary memory [8].
The performance of an algorithm can be computed on the basis of time and space complexity, which is usually represented by asymptotic notations [4]. The time complexity of a sorting algorithm is, generally, calculated in terms of number of comparisons or shifting operations made. Total working storage required by an algorithm in worst case scenario will amount to space complexity. On the basis of worst case time complexity, sorting algorithm can be divided into two categories. First category is O(n2); and second is O(nlogn) which is faster than the first. Selection sort, Insertion sort, Bubble sort, etc. come under O(n2) category and Binary insertion sort, Heap sort, Merge sort, etc. appear under O(nlogn) category. Due to stability, performance, simplicity, in-place, online nature; insertion sort is considered from the first category [7] and binary insertion sort from second as the best among peers.
Sorting is often used as a building block in designing of many important algorithms as once a list gets sorted, various other problems are reduced. A reduction is a process of transforming complex computational problems into easier ones. Some of the major applications where sorting is a prerequisite process are searching, element uniqueness, closest pair determination, selection, frequency distribution, convex hulls, etc. Usage of sorting in a large number of applications has increased the demand for developing more efficient, scalable and shorter running time sorting algorithms whose performance does not deteriorate with an increase in dataset size. This research paper proposes Brownian Motus Insertion Sort (BMIS) and Clustered Binary Insertion Sort (CBIS) sorting algorithms to decrease the time complexity of traditional Insertion Sort (IS) and Binary Insertion Sort(BIS) respectively. Time complexity has been measured in terms of a number of comparisons required by sorting algorithm. The time complexity has been decreased by eliminating many useless comparison operations through a novel approach for location identification. BMIS is a variant of IS; and CBIS is a variant of BIS. Both BMIS and CBIS belong to the comparison, in-place, stable and online sort class of sorting algorithms. Performance and scalability of BMIS and CBIS is much better than their traditional counterparts.
Further, the paper has been organized into various sections. Section 2 describes the application of Insertion Sort; and also highlights major improvements in the field. Section 3 presents the data used for the experimental work. Section 4 explains the proposed algorithms and pseudo-code, while Section 5 shows the execution illustration of BMIS and CBIS. Proposed algorithms have been theoretically analyzed; and complexity is computed in Section 6. The results of this research work have been discussed in Section 7. A comparison of proposed algorithm with traditional IS and BIS has been also made in the section. Section 8 summarizes and concludes the research.
