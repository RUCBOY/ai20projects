Due to its richness and versatility for representing and dealing with knowledge, First Order Logic (FOL) is regarded as one of the preferred knowledge representation languages for automated reasoning and inference systems. However, an exploding amount of typically uncertain data, information sources, and conflicting evidence keeps demanding improvements to FOL representations to enhance its capabilities, robustness, and efficiency.
In an effort to enrich FOL for reasoning in the presence of uncertainty, several approaches have focused on extending it using probabilistic measures. Examples of these approaches span from the already mature probabilistic logic [1] and fuzzy logic [2] theories, to the more contemporary Markov Logic Networks (MLNs) [3] and Probabilistic Soft Logic (PSL) [4] frameworks. By relying on graphical model structures, the latter approaches (i.e., MLNs and PSL) are perhaps better equipped for reasoning with large amounts of data. These approaches, however, may be hampered by scarce training data, conflicting evidence, or when the uncertainty is characterized as intervals. Our goal is to provide a framework that overcomes these issues, and complements probability-based logic reasoning systems with the ability of representing uncertainty using intervals. We call this framework Uncertain Logic Processing (ULP).
At its core, ULP extends the scope of FOL by adding uncertainty management via Dempster–Shafer (DS) models. By relying on DS theory, ULP inherits the robustness for dealing with conflicting evidence [5] and provides a more flexible alternative for representing uncertainty through intervals. With a solid theoretical foundation, ULP is flexible enough to support reasoning systems that follow a variety of logic-based inference techniques (e.g., logic inference and satisfiability for both classical logic and paraconsistent logic models), and provides a substrate for creating efficient automated reasoning frameworks through optimization formulations or graphical model approaches.
1.1. Related researchWhen addressing quantification and propagation of uncertainty in logic reasoning systems, one of the earliest approaches is probabilistic logic [1]. Probabilistic logic provides a generalization of logic in which the truth values of sentences are probability values (between 0 and 1). A related approach, possibilistic logic [6], defines mechanisms (based on possibility theory) to associate logic formulas with weights. To efficiently address the computational complexity of larger problems, two new probability-enhanced methods have been recently introduced, namely, MLNs [3] and PSL [4]. MLNs combine FOL and Markov networks as undirected graphical models and assign weights to FOL formulas whose truth values are represented through probability values. PSL also uses undirected graphical models to represent templates for FOL formulas, and represents truth values as a number in the interval [0,1]. PSL relies on the Lukasiewicz t-norm and its corresponding co-norm to model AND and OR operations. Both MLN and PSL are statistical methods that attempt to find uncertainty parameters that ensure satisfiability of the logical models specified by the users. Their definition, however, does not insist on being consistent with classical logic, as is our goal with ULP, and their accuracy may be compromised when the amount of training data is small.Other approaches that extend logic reasoning to address uncertain scenarios are many-valued logics and fuzzy logic. Many-valued logics [7] do not restrict the number of truth values of propositions to two. Fuzzy logic is based on the theory of fuzzy sets [2]. In fuzzy logic, the imprecision in probabilities is modeled through membership functions defined on the sets of possible probabilities and utilities. Although useful in some applications, these logic reasoning systems introduce new design problems: What is the appropriate number of truth levels to be used in an application? How should we define the membership functions? As an alternative, in ULP we extend logic reasoning systems with the capability of modeling uncertainties based on intervals, without attaching new design requirements such as the definition of membership functions.Regarding the use of intervals as a means of representing uncertainty, it appears in several methods, such as possibility theory [8] and DS theory. The latter, incorporates a rigorous methodology for assigning probabilistic measures based on available evidence [9]. Given the direct relation that exists between DS theory and probability (DS belief and plausibility measures are closely related to lower and upper probabilities [9]), it is possible to simplify DS models to probabilistic models. Considering these advantages, a number of researchers have studied the relation of DS theory and logic. The work in [10] is similar to the probabilistic logic in [1], but uses epistemic logics and interval-based extensions of probability functions (e.g., lower and upper probabilities, DS belief and plausibility bounds) instead of probabilities of possible worlds. In [11], DS theory is formulated in terms of propositional logic, enabling certain logic reasoning operations in the DS framework. Further work in [12] integrates this logic formulation of DS theory in a system for visual recognition. Motivated by the need for enhancing expressiveness in DS models, [13] proposes a more general formulation of DS models as propositional logic operations than [11]. A belief-function logic that uses DS models and operations to quantify and estimate uncertainty of logic formulas is introduced in [14]. This logic system allows non-zero belief assignments to the empty set and relies on Dempster's combination rule as the method for quantifying the propagation of uncertainty. It is also used in deduction systems where the logic formulas are in Skolemized normal conjunctive form. An application of this system for inference is described in [15]. Another application of DS-based extensions of logic systems is in [16], where information coming from sensors is modeled in DS theory, and then input into AgentSpeak [17], a logic-based inference system. Further analysis on DS-based logic is presented in [18]. A detailed study on uncertain implication rules is in [19]. This latter work, however, is focused on modeling causal probabilistic relations, and does not provide consistency with classical logic, as ULP does. In general, existing work on combining DS theory and logic does not necessarily aim to attain consistency with classical logic, as is our goal with the ULP, and are still limited to propositional logic models.
1.2. ContributionsIn this paper we formalize the fundamental theory of ULP. ULP is an extension of FOL into the DS theoretic framework. In ULP, the uncertainty of logic expressions such as φ(x) is quantified using an uncertainty interval [α,β],0≤α≤β≤1. The ULP framework allows us to model the uncertainty of this expression, and to combine it with similar expressions in order to solve various inference and reasoning problems. When α=β, ULP renders probabilistic results. When α=β∈{0,1}, ULP converges to FOL. ULP can be used as an adaptive many-valued logic, with the quantization of the truth space varying according to the granularity defined by the input data. ULP can preserve consistency with classical logic. By preserving this consistency, it is possible to seamlessly move between the classical logic and DS domains, and to incorporate both the strength of FOL for information representation and inference, and the strength of DS for representing and manipulating uncertainty.This paper extends original preliminary work that was outlined in [20], [21]. In particular, this paper includes revised ULP definitions and notation, a more thorough description of the satisfiability problem in ULP, and a new example that addresses a bigger testing scenario.The remainder of the paper is as follows:•Sections 2 and 3 provide basic definitions of the DS theoretical framework and the logic models used in ULP, respectively;•Section 4 provides definitions of basic ULP operators (e.g., NOT, AND, OR), based on generic DS fusion operators;•Section 5 provides guidelines for the selection of appropriate DS fusion operators, as needed for enforcing particular properties of ULP operators; moreover, it defines a DS fusion operator for classically-consistent ULP;•Section 6 introduces quantifiers for ULP;•Section 7 provides guidelines for inference using ULP, and illustrates the process with an example;•Section 8 introduces a method for scalable reasoning in ULP based on satisfiability formulations, and illustrates the method with examples;•Finally, Section 9 concludes the paper.
