We are living in a computer-based world full of objects driven by software [1]. In this scenario, where computing has become ubiquitous and underpins every life dimension, to handle the language of computers is emerging as indispensable to fully participate and thrive in our digital societies [2]. Therefore, computer programming is becoming considered as a new literacy (‘code literacy’) [[3], [4]]. If code literacy refers ultimately to an emerging read–write practice, computational thinking (CT) refers to the underlying problem-solving process that allows it [5]. In other words, computer programming is the fundamental way that enables CT to come alive [6], a key tool for supporting the cognitive tasks involved in CT, and a demonstration of computational competencies [7]. However, CT can be projected on different kinds of problems that may not involve directly programming tasks [[8], [9]].
Given this current reality, it is not surprising that CT is arising as a key set of problem-solving skills that must be acquired by the new generations of digital learners, and many countries around the world have decided to incorporate computer programming and CT in their curricula [[10], [11]]. Nevertheless, from a psychometric approach, we find several reasons to affirm that we are still at an early stage in regards to the definition and assessment of CT as a psychological construct (i.e., as a psychological variable):

1.There is still a lack of consensus about a definition of CT [[12], [13], [14]].2.There is still a worrying vacuum of standardized tests aimed to measure CT that have undergone a full validation process [15]. As it has been pointed out by [16], there is an urgent need for having standardized tools in the Computer Science (CS) Education community.3.Related to the previous point, since there is a lack of CT validated tests, the nomological network of CT (i.e., the correlations between CT and other key psychological constructs) has not been fully defined by the researchers yet [17].4.Finally, resulting from the above, we are missing out the benefits of having validated tools for assessing CT. For example, one benefit could be to evaluate confidently if a CS curriculum has been effective to improve the CT of the students (e.g., through a pre-post quasi-experimental research design) [6]. Another one could be to early detect students with special needs in CT ability, even before they start to learn computer programming, in order to implement proper and personalized educational interventions.
Since there is still no consensus on a CT definition, it is necessary to make explicit that we have assumed for our work the one given by Aho, who conceptualizes CT as the thought processes involved in formulating problems so “their solutions can be represented as computational steps and algorithms” [18]. It could be argued that this definition over-identifies CT with algorithmic thinking, and gives a narrow and reductionist view of CT. However, we selected Aho’s general definition because it is useful to subsequently derivate specific operational ones from where CT assessment tools can be designed, which is essential for our psychometric research approach. In other words, algorithmic thinking seems to be a central part of CT, and specifically the most susceptible part for being measured. Furthermore, relevant authors have recently synthesized CT as “the conceptual foundation required to solve problems effectively and efficiently (i.e., algorithmically, with or without the assistance of computers)” [14]. We assume this statement too, and remind that, although CT ability can be mainly demonstrated by means of computer programming, it can also be expressed within unplugged contexts [[19], [20]].
In any case, if the aforementioned issues are not addressed soon, CT is at risk of not being seriously considered in the context of educational psychology, and even more important, CT might have an unsuccessful way into the K-12 curricula [[7], [12]]. In response, one of the major recent attempts to design and validate a CT assessment tool is the Computational Thinking Test (CTt) [21], which has demonstrated to be valid and reliable (internal consistency α=.80; test–retest stability rxx=.70) in Spanish middle school subjects [17]. The administration of the CTt to over one thousand middle school students without prior formal programming experience showed a quasi-normal distribution with large variability [17]. Consequently, in order to design adequate and personalized educational actions, the individual differences in computational ability that seem to exist should be deeply described. In this paper, we will focus on the right tail of the distribution, that is, on students with high computational ability.
Furthermore, the criterion validity of the CTt with respect to other cognitive and non-cognitive psychological variables has been already reported. Regarding the former [17], statistically significant correlations at least moderately intense between CT and problem-solving ability (r = .67), spatial ability (r = .44), and reasoning ability (r = .44) have been found. Regarding the latter [[22], [23]], published results show statistically significant correlations between CT and three of the dimensions from the ‘Big Five’ model of human personality: Openness to Experience (r = .41), Extraversion (r = .30), and Conscientiousness (r = .27). In summary, these results have contributed to start the definition of the nomological network of CT, and to empirically corroborate the conceptualization of CT as a problem-solving ability linked with general mental ability (‘g’). Further description about the CTt will be given in paragraph 3.2.1.
However, the predictive validity of the CTt has not been studied yet. Then, our research questions are:

•RQ1: What is the predictive validity of the CTt regarding academic performance?•RQ2: What is the predictive validity of the CTt regarding coding achievement?•RQ3: What is the predictive validity of the CTt to early detect ‘computationally talented’ students?
