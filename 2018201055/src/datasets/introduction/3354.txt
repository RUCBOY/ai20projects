The TSP is a well-known, popular, and an extensively studied problem in the field of combinatorial optimization. It has immense applications in the field of engineering science like designing hardware devices and radio electronic devices in communications, in the architecture of computational networks, designing of microchips, DNA sequencing [1], data association, vehicle routing [[2], [3]], data transmission in computer networks [4], image processing and pattern recognition [5], to quote a few. The concept of the TSP is very simple but yet it remains one of the most challenging problems in operations research. More succinctly, it is an optimization problem to find the shortest connectivity among all the nodes in a closed network by touching all the nodes exactly once. Although seems simple, the computer running time for an extensive search approach lies within a polynomial factor of O(n!), where n is the number of nodes, thus making the problem most difficult, even for n = 20. In theoretical computer science, such kind of problem is known as the classical NP-complete problem [6], which means, for the worst-case, the running time for any algorithm for the TSP increases super-polynomially (or, perhaps exponentially) with the number of nodes [7]. The graph-theoretic method identifies the problem as finding the Hamiltonian cycle with the least weight for a given complete weighted graph [8].
Since 1950s, researchers are trying to develop various computer intensive algorithms to reach an optimal or near-optimal solution. Among these algorithms, branch and bound [9] has been adopted for solving the TSP with smaller scale. Apart from TSP with one salesman, one may consider the problem with multiple salesmen, departing from several starting cities and returning back to their respective starting cities. Such TSP is known as fixed destination multi-depot multiple traveling salesmen problem (MmTSP). Dynamic programming is one of the conventional methods for solving the TSP, both symmetric and asymmetric and also MmTSP, which starts with a minimum sub-tour and the optimal tour is reached by augmenting the city not yet in the sub-tour [[10], [11]]. Particle swarm optimization [[12], [13]] has been invoked to solve the TSP with a larger scale say, for n = 51–76. Such solution has been successfully applied for vehicle routing problems [[2], [14], [15]]. Another metaheuristic, known as ant colony optimization has been applied to solve such MmTSP [[16], [17]]. This algorithm mimics the behavior of the real ants in search of food, where every ant leaves an amount of pheromone on the path it passes and chooses the path with more pheromone left on it from the previous ants. Since more ants pass the shorter roots, gradually, more and more ants choose the shorter root and as a result, the colony finds the best way to get to the food. Genetic algorithms are an alternative metaheuristic optimization algorithm which encode a potential solution to a specific problem on a simple chromosome-like data structure, and apply recombination operators to these structures in such a way as to preserve critical information [[18], [19], [20]]. Simulated annealing [[21], [22]] is one of the widely used algorithms to achieve a global optimal solution for computation intensive combinatorial optimization problems in recent days. Simulated annealing is a method for improving local optimization, and it needs less memory space. However, to find a better solution, simulated annealing algorithm generally requires longer computational time compared to other heuristics of discrete optimization, a brief review of which is discussed in the next few paragraphs.
The simplest of its kind is the nearest neighbor algorithm (NNA) [23]. This algorithm starts with a sub-tour, or path, containing a subset of randomly chosen cities from the list of n cities and then adds the nearest city that is yet to visit. The algorithm stops when all cities are included in the tour. An extension to this algorithm is to repeat it with each city as the starting point and then return the best tour found, which is called the repetitive nearest neighbor algorithm (RNNA) [23]. Another approach is known as Insertion Algorithm (IA) [23], where it starts with a sub-tour consisting of two arbitrary cities (say, i and j) and then chooses in each step a city k not yet in the sub-tour. This city is inserted between the two cities i and j, such that the insertion cost (i.e., the net increase in the cost of the tour) given by d(i, k) + d(k, j) − d(i, j) is minimum. This insertion process is repeated with the current sub-tour i → k → j and a fourth city is inserted between either i and k, or k and j, with the objective of minimizing the net increase in the cost of the next sub-tour. As before, the algorithm stops when all the cities are included in the tour. According to Hahsler and Hornik [24], four variants of IA are available, depending upon the way the city is to be inserted next is chosen, which are (1) Nearest Insertion (NI), (2) Farthest Insertion (FI), (3) Cheapest Insertion (CI) and (4) Arbitrary Insertion (AI), among which the first two are most popular. For the comparative analysis of the proposed algorithm, we have considered only the first two.
Some algorithms based on local improvements of the existing tour through simple tour modifications are also available in the literature. Such algorithms are specified in terms of a class of operations (exchanges or moves) that can be used to convert one tour into another by reducing the tour length until a tour is reached for which no such operation yields an improvement (i.e., a locally optimal tour). Among such simple local search algorithms, the most famous are 2-Opt and 3-Opt algorithms. The 2-Opt algorithm was developed by Croes [25], although it was earlier proposed by Flood [26]. The procedure deletes two edges of the tour, thus breaking it into two paths, and then reconnects those paths in the other possible way. A modified 2-Opt algorithm named as the Quicker 2-Opt was introduced in [27], by reducing search space for a selected pair of links, instead of deleting and reconnecting all possible pairs of links in the 2-Opt algorithm. In the 3-Opt algorithm [28], the exchange replaces up to three edges of the current tour. The idea of 2-Opt and 3-Opt algorithms may be extended to k-Opt algorithms where the exchange replaces up to k edges of the current tour. This extension by Lin and Kernighan [29] does not use a fixed value for k for its k-Opt moves but tries to find the best choice of k for each move.
To obtain a locally optimal solution, the search operation is confined among the neighbors of an initial solution, called neighborhood, where the neighbors are iteratively obtained through a systematic change of the nodes of the initial tour. Through this change, and by means of local search, an algorithm has been developed that leads to one kind of metaheuristic algorithm, known as variable neighborhood search (VNS) algorithm [[27], [30]]. The VNS-1 and the VNS-2 algorithms are recognized as such neighborhood search approaches, where the local searches (i.e., improvements over the present solution) are carried out through 2-Opt and quicker 2-Opt algorithms, respectively.
The objective of the present work is to suggest some modifications over the variable neighborhood search (VNS) algorithm, suggested by Hansen and Mladenović [[27], [30]] to solve TSP, with regard to the following three aspects:
•a reasonably good and computationally efficient choice of the initial tour,•a clever choice of neighborhood construction,•an incorporation of a stochastic approach, close to the more popular annealing schedule, to avoid ending at a local optimum and achieving the global optimal solution.
Through the above three aspects, the present hybrid VNS algorithm aims to deal with some imprecision and uncertainty in order to achieve near-optimal, robust and low-cost solution. These contributions have been attempted and highlighted by demonstrating the distributional properties of the final tour lengths obtained by the proposed algorithm and various other algorithms. The application aspect of the proposed algorithm is discussed through its ability to handle moderately large TSP with little computational complexity and at the same time its flexibility to take care of other areas of discrete optimization with equal competence. Such an algorithm has been suggested by Hore et al. [[31], [32]] to find a near-optimal or optimal allocation design with different treatments to several experimental units with the known covariate(s). The proposed algorithm is similar to the algorithm suggested in the context of the design issue addressed there, with the necessary modifications of enlargement of the search space.
The paper has been structured as follows. In Section 2, a brief review of the VNS algorithm has been done. In order to obtain a near-optimal tour, a moderately acceptable initial solution is needed. A procedure to obtain such initial solution is discussed in Section 3. Section 4 describes the proposed algorithm, based on the initial tour. A detailed analysis of two TSPs, one each for the symmetric and asymmetric case, from the TSPLIB dataset of R, along with two more asymmetric TSPs generated through simulation experiments, are considered in Section 5. These examples establish the efficacy of the proposed algorithm in comparison to existing algorithms, as available and implemented in R and other VNS algorithms. The performance of the present algorithm is also judged in light of 60 benchmark symmetric TSPs from the TSPLIB dataset. The datasets and corresponding optimum solutions are available at [35]. To demonstrate the flexibility of the proposed hybrid VNS algorithm for solving combinatorial optimization problems, some applications other than the TSP are described in Section 6. The paper ends with some concluding remarks and scopes for further research.
