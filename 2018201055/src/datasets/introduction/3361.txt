Scientific analysis in experiments such as high-energy physics or climate modeling, usually involve extremely complex workflows to ensure successful and reliable results. These workflows include a number of tasks, involve multiple actors, software and infrastructures, that work together as a workflow from data generation to delivery. For example, in the Advanced Light source (ALS) data is generated from multiple detectors which is then collected on an NERSC supercomputing data center via high-speed network connections. It is imperative that the data is delivered in a timely manner, with minimum loss, such that further computations can be performed using supercomputing resources that have to be a priori reserved. In order that the supercomputing resources are maximally utilized, this requires the network service to allow deadlines for large data transfers.
There are two approaches to ensure that the data transfers can be made with predictable performance and within requested deadlines. One approach is to use advanced reservations of links, such as OSCARS or open NSA [1], that allow setting up circuits of specified capacities between routers. Advanced reservation schemes require additional time to setup circuits, are only associated with WAN border routers and are difficult to automate due to required user knowledge, network topology and request details. Furthermore, applications do not generate traffic all the time which leads to wasted reserved capacity.
The second approach is to run the network at low utilization and use standard TCP. New TCP protocols, such as TCP Hamilton [2] and BBR-TCP [3], can efficiently adapt to the bottleneck capacity and where multiple competing flows are involved, they equally split the bottleneck capacity. However, even with the new TCP algorithms, sustained bottlenecks lead to unpredictable throughput performance and difficulties in arbitrarily splitting bottlenecked bandwidths among competing flows. Finally, as the growth in data transfer volume out-paces the increase in the data link rates, running the network at low utilization is not cost effective [4].
To help accelerate the effort to run the network at high utilization and enable deadline aware data transfers, network automation through Software-Defined Networks (SDN) is being advanced to control network traffic depending on data demand. In principle, SDN allow individual switches to be managed and controlled following centralized traffic engineering principles [5]. Furthermore, SDN switches provide the ability to shape traffic at ingress of the network rapidly and in an on-demand fashion. These features in addition to TCP protocol, or the pacing algorithm at the source nodes [6], together provide the necessary tools to dynamically allocate bandwidth to flows for meeting deadlines while ensuring the network operates at high utilization. There has been network-utilization-focused work along these lines presented in [[7], [8]]. Simulation-based work on deadline-aware networking has also been carried out in [[9], [10]]. However, Calibers is not only capable of simulating the performance of these tools, it actually deploys a fully-functional, trans-continental deadline-aware SDN in a quasi-production network testbed, with some non-participating end-systems, to maximize deadline performance while also attempting to maximize link utilization.
This paper aims to implement a centralized traffic engineering approach and control distributed agents at the edge (ingress point of the network) to dynamically pace flow for meeting transfer deadlines, while achieving high network utilization. The dynamic pacing algorithm is able to analyze traffic patterns and follow a rolling horizon model to pace flows at appropriate rates to optimize network performance and meet deadlines. As a result, Calibers not only calenders flow, but also lays the foundation for future work where these capabilities can be coupled with advanced tools to control networks dynamically. Calibers aims to solve the problem of maximizing deadline performance and network utilization while minimizing flow rejection, given some set of network bottlenecks on a link-state routed network. Calibers is protocol-agnostic, and with the use of edge-pacing, is able to function on a network core, regardless of the presence of non-participating end-systems, whose traffic can be shaped at the network edge to relinquish bandwidth for deadline-critical flows.
Following are the main contributions of this work:
 
1.We describe an architecture that implements bandwidth calendaring for scientific workflows. The architectures leverage SDN switches that can pace flows at the ingress point. The architecture implements a central controller with distributed agents at the edge of the network that monitor flow performance and implement dynamic flow pacing set by the controller.2.We present experimental results using Globus and GridFTP that show the importance of pacing in achieving deadline aware data transfer service. We compare our results with TCP Hamilton results.3.We propose different heuristic algorithms based on combining two orthogonal principles - 1) local vs global optimization and 2) Shortest Job First vs Longest Job First (LJF). We perform a preliminary performance comparison of these algorithms with respect to a performance metric efficacy that is defined as the difference between reject rate and network utilization. Our results show that simple heuristics, that optimize locally on the most bottlenecked link can perform almost as well as heuristics that attempt to optimize globally.
