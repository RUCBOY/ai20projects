In optimal conditions, vision is the main source of information from the environment, therefore, it is the most studied sensory system and crucial to understanding human perception.
Visual processing involves mechanisms to generate internal abstract representations, by applying multiple transformations to the light of environmental objects that reaches photoreceptors in the eye. Recognition refers to giving a meaning to such representations (Albright, 2015, chap. 28), regardless of simplicity, and it is shaped by the current sensory activations, past sensory experiences and associations between these experiences.
Effective and efficient visual recognition is critical in various scenarios, like detecting dangerous predators hidden in the woods or interpreting a red traffic light while driving. Visual recognition plays an important role in setting basic information required to generate plans to interact with the environment, and then be able to make decisions over possible actions to satisfy goals.
Russell and Norvig (2009) state some commonly required properties that a general artificial intelligence should include, such as being capable of sensing, perceiving, learning, representing knowledge, and making decisions. The issue is often how all these capabilities coexist in the same schema. Cognitive Architectures (CA) are useful approaches to construct this type of systems, because they aim to describe the structure and interactions of the human mind’s functions, and how to integrate them.
The main motivation of this work is to build a model of visual processing for virtual entities that resemble the way humans do and contribute to a better comprehension of the mechanisms and functions involved in the process of visual object recognition tasks. The emphasis is on bottom-up and top-down, as well as the process importance when encompassed in a larger a cognitive system, such as a cognitive architecture.
In this paper, we present a cognitive model for visual processing and object recognition that can be integrated with a broader cognitive architecture, by setting the basis of the different processes and brain areas involved. This model has modules associated with brain areas that perform operations of one or various Cognitive Functions (CF). The CF provide specific human-like capabilities to the overall CA in which these are integrated.
We distinguish between two main cognitive functions that compound visual processing: sensory system and perception. The first, sensory system, is linked to the pure sensory aspects of the stimulus, that encompasses neural activations of visual features elicited by stimuli. Those characteristics could be as simple as the orientation of bars, or more complex as contour integration (Gilbert, 2015, chap. 25). We propose operations to extract those features in a similar way to the visual cortex. On the other hand, perception is related to the integration of features into a particular entity, it concerns the representation and discrimination of visual objects which leads to visual recognition (Miyashita, 1993). In that aspect, the model introduces a function to associate visual representations to previously presented visual objects.
Memory participates in the retrieval and maintenance of visual representations generated by perception. We divide memory into two functions: working memory, in the model it keeps the task information and visual representation; and semantic memory, that has information about known objects, but it is beyond the scope of the present study.
This paper is organized as follows: In Section ‘Related models of visual processing with recognition’ we describe some other bioinspired models for visual recognition. Section ‘Neuroscientific evidence’ explains the neuroscientific basis of the proposal. Section ‘Biomodel of visual recognition’ presents the proposed model and describes in detail the different processes considered. The study case used to evaluate the model and the obtained results are described in Section ‘Experimentation and results’. Section ‘Discussion and conclusions’ presents a discussion about the limitations of the model and future work.
