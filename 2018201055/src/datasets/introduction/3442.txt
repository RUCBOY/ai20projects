In this article, we describe a project in which we developed and evaluated a program to help students gain proficiency in scientific discourse leading to improved science achievement. Helping students learn how to engage in scientific discourse and argumentation has become a major focus of science education in the U.S. An influential report, Taking Science to School: Learning and Teaching Science in grades K–8 (National Research Council, 2007), used evidence on child development and learning to advocate for four strands of scientific proficiency for all students. Specifically: “Students who understand science (1) know, use, and interpret scientific explanations of the natural world; (2) generate and evaluate scientific evidence and explanations; (3) understand the nature and development of scientific knowledge; and (4) participate productively in scientific practices and discourse” (p. 2).
Our study was designed to (a) engage students in one-on-one conversations with a virtual science tutor, and (b) engage students in small groups in conversations stimulated by questions posed by a virtual tutor. In both groups, students were presented with a set of narrated multimedia science presentations, and engaged in conversations about the science. We hypothesized that students who received either one-on-one or small group tutoring sessions with a virtual tutor would demonstrate greater science learning gains than students who received similar classroom instruction, but did not engage in one-on-one or small group tutoring sessions.
The article is organized as follows. Section 1 provides an overview of, and scientific rationale for, the study.
Section 2 describes the two experimental conditions used in the 3rd, 4th and 5th grade classrooms, then presents and briefly summarizes the results. Section 3 discusses these results; Section 4 identifies and describes the main conclusions from the investigation, and describes implications for future work.
1.1. Overview of the studyStudents participated in this study in one of two conditions. Students in one condition engaged in a series of one-on-one tutoring sessions with a virtual science tutor, Marni. In these sessions, Marni asked each student questions about science presented in narrated multimedia presentations, including follow-on questions designed to stimulate students’ reasoning about the science and construct accurate explanations. Students in a second condition interacted with Marni in small groups, of 3 students. Students in small groups received the same multimedia presentations individually, but were asked to discuss the questions with the other students in their group before the student in control of the microphone during the session provided Marni with a spoken response to her question. We asked students in each condition about their learning experiences, and compared learning gains of students in each condition to students in business-as-usual (control) classrooms. These control classrooms received similar classroom instruction to treatment students, but did not receive supplemental tutoring with Marni. Our main research questions were:
1.Would students in both one-on-one and group conditions achieve significant and equivalent learning gains relative to students in control classrooms who did not receive tutoring?2.Would students in small groups engage in meaningful discourse and argumentation, and report that those discussions were beneficial?
1.2. Scientific foundations1.2.1. Theory and research on scientific discourse and argumentationHistorically, research in argumentation and collaborative discourse has acknowledged the strong influences of the theories of Vygotsky 1978, Vygotsky 1987 and Bakhtin, 1975, Bakhtin, 1986, who argued that all learning occurs in and is shaped by the social, cultural, and linguistic contexts in which they occur. Roth (2013, 2014) provided an excellent integration of Vygotsky's and Bakhtin's theories and their relevance to research on collaborative discourse. He argued that, when considered in the context of these theories, “currently available analyses of science classroom talk do not appear to exhibit sufficient appreciation of the fact that words, statements, and language are living phenomena, that is, they inherently change in speaking” (Roth, 2014, in online Abstract). The seminal writings of Vygotsky and Bakhtin have had a profound influence on subsequent research in discourse and argumentation, including (Wells, 1997, Wells 2000, Wells, 2008) research on dialogic inquiry. We embrace this emphasis as a main focus of the current study: to learn whether children in small groups will become comfortable using their words to express, support, defend, reflect on, and modify their ideas during scientific discourse.The past 25 years have witnessed remarkable growth in research on discourse and argumentation in education. Kuhn (1993, 2000) argued that “a conception of science as argument has become to be widely advocated as a frame for science education” (p. 1). Support for argumentation has codified into both a reform movement and framework for science education. It is supported by growing evidence of substantial benefits of explicit instruction and practice on the quality of students’ argumentation and learning (Chin and Osborne, 2010, Harris et al., 2006, Kulatunga and Lewis, 2013, Kulatunga et al., 2013, McNeill, 2011, Nussbaum et al., 2008, Sampson et al., 2009, Schworm and Renkl, 2007, Simon et al., 2006, Voss and Means, 1991). Evidence from these studies indicated that argumentation can be improved by providing professional development to teachers or knowledgeable students (Berland and Reiser, 2009, Bricker and Bell, 2008, Bricker and Bell, 2014, de Jong et al., 2013).Metanalyses of programs designed to foster discourse and argumentation in US elementary and middle school classrooms identified several interventions that improved student achievement in language arts and literacy over the course of a school year (Murphy and Edwards, 2005, Murphy et al., 2009; Soter et al., 2008). One of these programs, Questioning the Author (Beck and McKeown, 2006), described below, motivated the dialog moves produced by the virtual tutor in the present study.A classic study by Hake (1998) compared pretest vs. posttest performance of a diverse sample of over 6500 high school and college students on a standardized test of conceptual knowledge of physics in two conditions: traditional classes that involved lectures and little or no interaction among students, and interactive classes where teachers stopped their lectures to ask students to discuss questions. Students in interactive classes demonstrated 48% learning gains relative to 24% learning gains in classrooms where teachers lectured but did not ask questions.Moreover, a synthesis of over 250 research studies by Black and Wiliam (2009) indicated that administering formative assessments to students, and providing teachers and students with feedback on their performance, produced effect sizes 0.40–0.70 on standardized tests, relative to students in classrooms who were not administered formative assessments. Therefore, students benefited from feedback on their understandings of the science they were learning, and teachers benefited from feedback that informed their instruction.Finally, a meta-analysis by Chi (2009) indicated that students whose instruction involves interactive tasks that included collaborative discourse and argumentation learned more than students whose learning involved constructive tasks, (e.g., classroom investigations and written reports), or active tasks (e.g., classroom science investigations). Menekse et al., (2013) obtained strong evidence that interactive instruction led to higher scores on deep reasoning questions relative to constructive, active, or passive instructional methods.In sum, over three decades of scientific research indicate the importance of integrating discourse and argumentation into classroom instruction to improve student motivation and learning. There is strong evidence that when teachers are trained to initiate and manage classroom conversations in which students share, compare, and modify their ideas, those students and their teachers become more engaged and excited about learning, and overall student achievement improves.1.2.2. Discourse in US classroomsLarge-scale studies of discourse in U.S. classrooms indicate that extended conversations, in which students do most of the talking, are rare (Nystrand and Gamoran, 1991). Over a period of 2 years, trained observers paid 4 visits to 58 8th grade and 54 9th grade English classes in US parochial and public schools in rural, suburban and urban settings. The observers recorded the amount of time spent on different instructional activities, and recorded and coded over 23,000 teacher and student questions to form a set of variables contrasting monologic and dialogic dialogs. Questions were coded for authenticity (a question was authentic if the answer was not known in advance by the asker) and uptake (previous answers were incorporated into new questions). The study found that “in virtually all classes, the teacher asked nearly all the questions; few about literature were authentic, and equally few followed up on student responses” (Nystrand, 1997, p. 44). Specifically, on average, there was less than 50 s of discussion per 8th grade class period and 20 s per 9th grade class period. Approximately 60% of all classes had no discussions; the single classroom with the most discussion averaged 2 min of it. Interestingly, there was a significant positive correlation between the amount of discourse in individual classrooms and student achievement in language arts. These results were replicated in a second, large-scale study (Nystrand et al., 1997). Extended conversations about science are also rare in science classrooms; as Osborne (2010) noted, “argument and debate are common in science, yet they are virtually absent in science education” (online abstract). The lack of discourse in U.S. classrooms is especially puzzling given the compelling evidence that effective programs have been developed, as discussed above, in which teachers engage students in discourse leading to significant gains in student motivation and learning (Murphy et al., 2009, Soter et al., 2008).1.2.3. Benefits of individualized instruction: human tutoringOver three decades of research have indicated that learning is most effective when students receive individualized instruction, either one-on-one, or in small groups. Bloom (1984) summarized studies that reported 2 Sigma learning gains for students who received one-on-one or small group tutoring, relative to students who received regular classroom instruction. Evidence that tutoring works has been similarly obtained from dozens of well-designed research studies and meta-analyses (Cohen et al., 1982) and positive outcomes were obtained in large-scale evaluations of specific tutoring programs (Slavin and Madden, 1989, Topping and Whiteley, 1990).Factors that contributed to the effectiveness of individualized instruction, measured by gains in student achievement were associated with tutoring aligned with classroom instruction, asking students authentic questions, scaffolding learning with hints after questions, follow-on questions, and media designed to stimulate reasoning and help students’ build on prior knowledge. These factors helped students continually generate explanations in response to deep reasoning questions (Butcher, 2006, Chi et al., 1989, Craig et al., 2000, Driscoll et al., 2003, King, 1989, King et al., 1998, Palinscar and Brown, 1984, Pine and Messer, 2000, Soter et al., 2008). Hausmann and VanLehn (2007) noted that: “explaining has consistently been shown to be effective in producing robust learning gains in the laboratory and in the classroom” (p. 418).1.2.4. Benefits of individualized instruction: intelligent tutoring systemsResearch in intelligent tutoring systems addresses a current, critical need to provide teachers and students with accessible, inexpensive, and reliably effective tools for improving young learners’ interest and achievement. They enhance learning by providing students with individualized and adaptive instruction like that provided by an effective human tutor. Most Intelligent Tutoring Systems (ITS) rely on typed input to support dialogs with high school and college students. Intelligent tutoring systems that support spoken dialogs with users include D’Mello et al., 2010, Johnson et al., 2009, Johnson et al., 2000, Litman et al., 2002, FOSS, 2007, Ward et al., 2011.Advances in research and development of Intelligent Tutoring Systems (ITS) have informed the design of systems that produce learning experiences and outcomes equivalent to human tutoring (e.g., Graesser et al., 2005, VanLehn et al., 2005. A recent review by Van Lehn (2011) compared learning gains in studies in which students received human tutoring or interacted with an ITS. Students in these studies participated in tasks that required problem solving and constructing explanations. When compared to students who did not receive tutoring, the effect size of human tutoring across studies was d=0.79 whereas the effect size of ITSs was d = 0.76 (Cohen’s d. Cohen, 1992). Van Lehn (2011) concluded that “intelligent tutoring systems are nearly as effective as human tutoring systems” (pg. 197). A meta-analysis of ITS by Ma, Adesope, Nesbit & Liu (2014) that incorporated 107 effect sizes involving 14,321 participants indicated that use of intelligent tutoring systems was associated with greater achievement, with moderate to large effect sizes, in comparison with teacher-led, large-group instruction (g = .42), non-ITS computer-based instruction (g = .57) and textbooks or workbooks (g = .35; Hedges’g, Hedges, 1981). The analysis revealed there was no significant difference between learning from ITS and learning from individualized human tutoring.The large majority of intelligent tutoring systems described in the scientific literature support typed input with high school students, college students, and adults. Intelligent tutoring systems that support spoken dialogs with users include D’Mello et al., 2010, Johnson et al., 2009, Johnson et al., 2000, Litman et al., 2002, Ward et al., 2011, Ward et al., 2013, Litman et al., 2002.1.2.5. Benefits of peer collaboration in intelligent tutoring systemsThe development of technologies and systems to assess and facilitate collaborative problem solving is a vital and growing area of research (Hao et al., 2015, Liu et al., 2015, Zapata-Rivera et al., 2016, Von Davier et al., 2017). The evidence indicates that collaborative problem solving is typically superior to the performance of individuals working independently. For example, Hoa et al. (2015) compared the performance of 486 individuals and 278 teams (dyads) who collaborated on a volcano science task using a web-based simulation; performance of the teams was significantly higher than performance of individuals.Recent studies of collaborative learning in intelligent tutoring systems have reported statistically equivalent learning gains when students engaged in one-on-one tutoring or worked with other students to solve problems. Studies have compared student learning in the two conditions for secondary or college students in physics (Hausmann et al., 2008); engineering design (Kumar et al., 2010); computer science (Harsley et al., 2016) mathematics (Diziol et al., 2010), and language learning (Toussas et al, 2014). Few studies have compared children's learning during one-on-one or peer tutoring using an intelligent tutoring system. Olsen et al. (2016) found equivalent learning gains by 4th and 5th grade students who used a tutoring system to learn fractions, either individually or in small groups. A subsequent study (Olsen et al., 2017) compared students who (a) received one-on-one tutoring, (b) participated in peer tutoring, or (c) received a combination of both one-on-one and peer tutoring. The group that participated in both one-on-one and collaborative tutoring sessions produced significantly greater learning gains than students in either of the one-on-one or collaborative tutoring conditions.1.2.6. Benefits of spoken dialogs between children and a virtual science tutorMy Science Tutor (MyST) is an intelligent tutoring system that engages students in conversations with a virtual science tutor, leading to learning gains comparable to those obtained with expert human tutors. To our knowledge, MyST is the only system developed to date that supports spoken tutorial dialogs with children (aged 7–10). MyST dialogs are aligned with science concepts encountered in small-group, classroom science investigations, using the Full Option Science System (FOSS) program. FOSS is a kit- and inquiry-based program, used by over 1 million students in 100,000 classrooms in the U.S. (FOSS, 2007). A typical FOSS science module includes 4 major Investigations over an 8–10-week period. For example, the in the FOSS Magnetism and Electricity (M&E) module, the 4 Investigations are Magnetism, Serial Circuits, Parallel Circuits, and Electromagnetism. Within each Investigation, students in small groups (3–5 students) conduct 4 different classroom science investigations. Thus, in a typical FOSS science module, students participate in a total of 16 classroom science investigations. Each MyST tutorial dialog session was aligned to the vocabulary and concepts students encountered in a specific classroom science investigation. Soon after completing a classroom science investigation, consented students left their classroom, and engaged in a tutorial dialog session with the virtual tutor Marni about the science being taught in the classroom.Questioning the author: A defining feature of tutorial dialogs in MyST was that Marni asked students open-ended questions about science presented with media. The media included static illustrations, silent animations, or interactive simulations. Marni asked questions, like “What's going on here?” or “What would happen if…?”). MyST's spoken dialog system analyzed students’ spoken answers to the question to identify which points were expressed by the student. When students did not express each of the points required for a complete explanation, Marni asked follow-on questions, and optionally presented new media, to stimulate reasoning and scaffold learning.Marni's “dialog moves” are based on Questioning the Author (QtA), an effective approach to classroom discourse used by hundreds of teachers in US classrooms. In a metanalysis of programs designed to foster classroom discourse, Murphy and Edwards (2005) and Murphy et al. (2009), QtA was identified as one of two approaches to classroom conversations, out of nine examined, that promote high-level thinking and comprehension of texts. QtA produced effect sizes of 0.63 on text comprehension measures, and 2.5 SD's on researcher-developed measures of critical thinking and reasoning.A key point in QtA is that student-to-student interactions are valuable only if they involve students truly listening to each other and building on each other's ideas. QtA dialog moves are designed to do exactly this. The role of the teacher (or virtual tutor) is to model this process, so students listen to each other, reflect on what other students have said, and self-assess and revise their ideas. The teacher or tutor models the process of listening carefully, extracting meaning and making connections between students’ ideas using established dialog moves which paraphrase or elaborate student's ideas. Questions are substantial and meaningful. The teacher does not ask questions like “How many centimeters are in a meter?” Instead they ask for connections among student contributions: “How does that fit in with what Wayne said?” Or, “So are you disagreeing with what Jennifer said?”During development of My Science Tutor, we worked closely with Margaret McKeown, co-developer of QtA, to incorporate key principles of QtA into tutorial dialogs between Marni and individual students, and to train human tutors to use QtA dialog moves when tutoring students. The QtA dialog moves used most often in MyST tutorials were marking and rejoicing (Beck and McKeown, 2006). These two techniques required the system identify the student's dialog content (marking it) followed by repeating (revoicing) a paraphrase of the information back to the student as a part of the next question: “Cindy, you mentioned that electricity flows in a closed path. What else can you tell me about how electricity flows?”Detailed descriptions of how knowledge is represented in MyST dialogs, how the system interprets students’ answers to open-ended questions, and the selection of prompts that Marni produces in response to students’ answers, are described in Ward et al. (2011, 2013) and Ward and Cole (2016). A 3-min video of a student conversing with Marni about the flow of electricity in a serial circuit can be found at NSF-STEMforAll (2016).MyST summative evaluation results: A summative evaluation of MyST, in five different science topics, was conducted during the 2010–2011 school year in 3rd, 4th and 5th grades. Students were randomly assigned to one of three conditions: (a) business as usual classroom instruction using the FOSS program, (b) supplemental tutoring by human tutors (using QtA dialog moves), or (c) tutorial dialog sessions with Marni. Over the course of an 8-week science module, taught in fall, winter or spring trimesters, students engaged in 16 dialog sessions lasting about 20 min—about 5 h of spoken dialogs with Marni. In an average dialog session, both Marni and the student produced approximately 7 min of speech. Analysis of transcriptions of over 1000 dialog sessions revealed that the MyST spoken dialog system recognized approximately 90% of all correct answers produced by students. Results of the evaluation indicated that Students tutored by Marni demonstrated learning gains of about one-half of one grade, which were statistically equivalent to learning gains of students who received human tutoring, relative to students in control classrooms who did not receive tutoring as a supplement to classroom instruction.
1.3. Novel features of the proposed workOur review of the literature indicates that the present study is the first to compare children's learning, individually and in small groups, during spoken conversations with a virtual science tutor. A key distinction between our previous studies using the MyST spoken dialog system (Ward et al., 2011, Ward et al., 2013), and the present study, is that students in our previous studies engaged in spoken dialogs with the virtual tutor throughout an entire 15–20-min session. The tutor asked open-ended questions about science presented in media, and students produced spoken answers to the questions. Each session concluded with Marni presenting a brief (30–60-s) summary of the key science concepts discussed.In the present study, individual students, or students in small groups, received narrated multimedia science presentations before engaging in spoken dialogs with the virtual tutor about the content of the presentations. In each session, students were presented with two narrated multimedia presentations. The first presentation introduced a science question or problem. Following the problem scenario, Marni asked students to explain the problem in their own words, with a question like “What was the problem Jack and Jill were trying to solve?” The second narrated presentation provided a solution to problem, followed by Marni asking students to explain the solution in their own words, e.g., So, how did Jack and Jill solve the problem?” Students in the small group condition were instructed to discuss their answers before the group leader (for the current session) presented a spoken answer to the tutor. Each ∼20-min session concluded with a 5–6-min spoken dialog with the virtual tutor. These dialogs were truncated versions of MyST spoken dialogs, with Marni asking questions about science presented in media about the key science concepts discussed in the session. Hereafter, we refer to spoken dialogs in our previous MyST studies (Ward et al., 2011, 2013) as MyST-SLS (Spoken Language System). We refer to the current study as MyST-MP&D (Multimedia Presentations and Dialogs).
