The ubiquitousness of digital cameras, for example in smartphones, in CCTV-systems, and integrated in devices such as cars and drones, results in a rapidly growing number of images. As a result, images play a large role in forensic investigation and become increasingly more important to solve cases. Examples are child pornography and homicide cases where images can help to find links between suspects and victims.
In forensic investigations the following two related questions are often asked: whether images were made with a specific camera (Qu et al., 2013), for example owned by a suspect, and whether different images were made with the same camera (Gisolf et al., 2014). For the first investigation, called source identification, the camera has to be available, for example seized by the police, and the goal is to match the sensor of the camera to images. For the second investigation, called common source identification, the camera is not available and the goal is to find images that are made with the same camera. This entails comparing a set of images amongst each other and group the images so that images with a common source form a cluster. In contrast to source identification, common source identification is much more computationally intensive as O(N2) comparisons have to be made for N images, whereas source identification only needs N comparisons.
To answer these types of questions, the method that is used in forensic practice and casework worldwide is Photo Response Non Uniformity (PRNU) (Fridrich, 2013). Within ENFSI (the European Network of Forensic Institutes) (Ho and Li, 2015) in the past two years, proficiency tests have been organized to compare the results of the different laboratories. Several publications (Bertini et al., 2015; Karaküçük et al., 2015) apply the technology on images from social networks.
PRNU is a measure of imperfection of an image sensor, which is caused by the manufacturing process of the CCD or CMOS sensors in the camera. Many papers (Singh and Malik) have been published on methods for extracting and comparing PRNU patterns. The first approaches were based on pixel defects (Geradts et al., 2001), whereas later ones used the pattern caused by variation of sensitivity of the pixels.
Since common source identification (no camera available) is computationally expensive, it is common practice to trade off accuracy for performance. Examples are reducing the number of images to compare, using only a crop of the image for the noise pattern, noise patterns with loss of information, comparison methods with reduced accuracy, and clustering with approximations (Gisolf et al., 2014; Chuang et al., 2011; Fridrich, 2013; Bayram et al., 2012; Li, 2010).
However, the reduced accuracy can lead to more false positives and negatives with reduced confidence in the results. By using the PRNU with the accuracy maximized, we minimize the number of false positives. In this article, since digital images are prevalent and of high importance in a growing number of cases, we aim to advance the state-of-the-art in common source identification. Our goal is to obtain high performance and high accuracy by using the full noise patterns, offering high-quality comparisons and clustering while supporting large data sets. Our approach is to use modern compute infrastructure effectively.
Many-core hardware, such as Graphics Processing Units (GPUs), is increasingly becoming the computing platform of choice, because of the high performance against low costs and power consumption. In fact, 7 out of top 10 fastest supercomputers (P500 Supercomputer Site, 2018) (as of November 2017) use many-core accelerators.
Since the field of many-core processors witnesses a high development rate, with each year faster processors, high-performance computing systems have become more heterogeneous, often containing a variety of many-core devices, each with different performance characteristics. Table 1 shows several heterogeneous supercomputers with more than one type of many-core devices in the TOP500 Supercomputer list (P500 Supercomputer Site, 2018). The increased diversity in the computing infrastructure leads to a true computing jungle (Seinstra et al., 2011), in which the programming complexity is vastly increased. For example, our own DAS-5 (Bal et al., 2016) cluster contains four different types of GPUs, each type with a different performance characteristic.Table 1. TOP500 Supercomputers with more than one type of many-core devices.nameinstituterankingconfigurationJurecaFZJ29Xeon Phi 7250, K40, K80self-madeFacebook35P100, Quadro GP100ThunderAir Force Research Laboratory40Xeon Phi 7120, K40RaijinNCI-NF76Xeon Phi, P100QuartettoKyushu University169Xeon Phi 5110P, K20, K20XLomonosovMoscow State University2272070, PowerXCell 8iPalmetto2Clemson University244K20m, K20, K40, P100ZenithDell HPC Innovation lab292Xeon Phi 7290, Xeon Phi 7230, Xeon Phi 7210HPCCUniversity of South Carolina435K20m, K40mHC2000Internet Company462K40, K80
While presenting challenges for application developers, the increased performance also offers new opportunities for application design. For example, many algorithms and applications have been developed including trade-offs between performance and accuracy. The introduction of many-cores presents not only the opportunity to improve application performance, but also to implement different algorithms that provide higher accuracy.
Our main contributions are:
1.detailed explanation of our approach to use modern hardware2.two applications for common source identification3.detailed discussion of the accuracy of our results4.high performance, supporting large databases of images5.highly reproducible results
Our first application (Software repository of tha; van Werkhoven and Hijma, 2018) makes use of optimized compute kernels designed for use on GPU-equipped Desktop computers for fast processing of small to medium sized collections of images. The typical use-case for this application is an investigator, for example a forensic technician, using a GPU-equipped Desktop computer. The application is implemented using CUDA (Nvidia, 2018), optimized using Kernel Tuner (van Werkhoven, 2018), and runs on a single computer equipped with an NVIDIA GPU.
The second application (Software repitory of the; Hijma and Jacobs, 2018a) is designed for scalability and intended for processing huge collections of images on heterogeneous computing infrastructures. The typical use-case for this application is an institution that has the resources for a many-core enabled cluster computer. It is implemented using Cashmere (Hijma et al., 2015a; Software repository of thb; Hijma and Jacobs, 2018c), a programming system for heterogeneous many-core cluster applications. In Cashmere, the computational kernels are implemented and optimized in using Many-Core Levels (MCL), which supports a methodology that we call stepwise-refinement for performance (Hijma et al., 2015b; Software repository of thc; Hijma and Jacobs, 2018b). Cashmere is capable of leveraging the fine-grained parallelism that many-core hardware offers on a large scale, typically clusters with compute nodes that contain a variety of many-core hardware such as GPUs.
Before we discuss our implementations, we provide a brief introduction to GPU Computing in Sec. 2. We then provide a detailed discussion of our implementation of the PRNU pattern extraction (Sec. 3), of the PRNU pattern comparison (Sec. 4), of the clustering algorithm we used for identifying common image sources (Sec. 5), and of our heterogeneous cluster application implemented using the Cashmere programming system (Sec. 6). We then evaluate the accuracy of the clustering, the performance of the Desktop application and scalability of the Cashmere application in Sec. 7 which leads us to the conclusions in Sec. 8.
In this section, we give a brief introduction to GPU Computing and explain some of the terminology used in this article. Throughout this article we will use the terminology from the CUDA programming model (Nvidia, 2018) to refer to GPU programming concepts. Although we also use other programming models in this article, CUDA is the most used programming model for GPUs.
In GPU Computing, a system consists of a host (the CPU), and one or more devices (the GPUs). The host is responsible for the memory management of the device and can move application data between host and device memory. This means that the host must allocate and free the device memory when needed. To increase the performance, data transfers between CPU memory and GPU memory may be overlapped with computation on both the GPU and the CPU.
The device is responsible for executing computational functions that are referred to as kernels. The kernels are designed to exhibit a large amount of data parallelism, allowing the same arithmetic operations to be performed simultaneously on many data elements. Kernels are executed concurrently on the device by extremely large numbers of threads. As GPU threads are much more lightweight than traditional CPU threads, kernels can be executed by millions of threads in parallel.
Threads executing the same kernel are organized in a two-level hierarchy: threads are grouped into thread blocks that are subsequently grouped into a grid. Thread blocks typically contain hundreds of threads depending on the device. Built-in variables provide threads and thread blocks with indices that direct the threads to different parts of the data. Threads in the same thread block are able to synchronize with each other, whereas there is no synchronization possible between thread blocks.
The GPU programming model supports different memory types. Global memory is a large (several GBs) high-latency off-chip memory that is typically used to store large input and output data structures. Although global memory bandwidth can be very high (up to 300 GB/s), it generally limits the performance of kernels if no other memory types are utilized. Due to the design of modern DRAMs, the peak global memory bandwidth can only be achieved if memory accesses are coalesced, that is, all threads with consecutive indices access aligned and consecutive global memory locations. Global memory is not coherent, that is, the result of a write operation is not guaranteed to be read by other threads until additional synchronization is used or the kernel finishes execution.
Shared memory is an on-chip memory that can be allocated to thread blocks and accessed at very high speed in a highly parallel manner. As all threads in a thread block can read and write to shared memory, it is an efficient way for threads to share input data and intermediate results. However, like global memory, shared memory is not coherent and as such, thread block wide synchronization is required before written values become visible to other threads.
Registers are used to store variables that are private to each thread. The number of registers used by each thread differs per kernel and is determined by the compiler. The register usage per thread block thus also depends on the number of threads in each thread block.
The performance of GPU execution often depends on how well its vast parallel resources can be utilized. The number of thread blocks that can execute in parallel on each multiprocessor within the device is bound by the dynamic partitioning of resources. Each multiprocessor has a maximum number of thread blocks and threads that it can support simultaneously. In addition, the register file and shared memory are partitioned among the concurrently executing thread blocks. The occupancy is defined as the number of threadblocks that can execute in parallel on each multiprocessor. The partitioning of multiprocessor resources often results in subtle interactions between resource limits, as a slight increase in resource usage could reduce the occupancy and result in a dramatic reduction in the achieved performance.
