Several computer vision and Artificial Intelligence applications require classification of segmented objects in digital images and videos. The use of object descriptors is a conventional approach for object recognition though a variety of classifiers. Recently, many reports have been published supporting the ability of automatic feature extraction by convolutional neural networks (CNNs) that achieve high classification accuracy in many generic cases, without the need for user-defined features. This approach is often referred to as deep learning. More specifically, CNNs have been suggested as state of the art methodology for pattern recognition [1], object localization [2], object classification in large-scale databases containing real world images [3], and malignancy detection on medical images [4], [5], [6]. The success of the CNNs on the aforementioned fields relies on their inner ability to exploit the local translational invariance of signal classes over their domain [7], allowing the transformation of long range interaction in terms of shorter localized interactions.
CNNs are trainable multistage architectures [8]. Each stage may be one of three types of layers, or an arbitrary combination of them: convolution, pooling or classic neural network layer. The last is commonly refereed as fully connected layer. The trainable components of a convolutional layer are mapped as a batch of kernels and perform the convolution operator on the previous layer's output. The pooling layer performs a subsampling to its input. The most common pooling function is the max pooling, which takes the maximum value of the local neighbourhoods. Finally, the fully connected layer can be treated as a special case of kernel with size 1 × 1. To train this network, the Stochastic Gradient Descent is usually utilized with the usage of mini-batches [9]. A drawback of the CNNs is the requirement of long training times, due to the amount of trainable parameters. However, the inherent parallelism of their structure, allows the utilization of Graphics Processing Units (GPUs) for performing the training phase [3].
The trained CNNs construct proper local features to discriminate between different image classes. This is a convenient property that removes the burden of extracting user-defined image features, while also often outperforms traditional classifiers based on the user provided features. However, in certain problems the statistical properties of local stationarity and multi-scale compositional structure may not hold. Consequently, the performance of CNNs may deteriorate when compared to global image descriptors. This was observed in our previous work [10], where the Zernike image descriptors, custom designed using the calibration of the acquiring fisheye camera, outperformed CNNs in human poses recognition (in a limited number of real videos), while GZMI exhibited slightly inferior performance when applied to the synthetic data.
A limited number of the previously described works utilize CNNs with binary images, while, the combination of CNN features and other explicitly defined external features (at the feed-forward neural network (FNN) layer) is not extensively explored in literature. In this work, we present an enhancement of the well-established CNNs’ architecture with the utilization of geodetically corrected Zernike moments (GZMI) [11] for human pose recognition in binary images. Synthetic human silhouettes were used to produce the extensive dataset required for the training of the CNN. The silhouettes were generated by rendering 3D human models through a calibrated omni-directional (fisheye) camera. The testing of CNNs is performed on a subset of the synthetically generated silhouettes, as well as on automatically segmented, manually labelled real videos of humans performing similar poses. Furthermore, transfer learning from training with synthetic to real data has been implemented by continuing the training of the CNNs with few frames of real human silhouettes, using the weights of synthetically trained CNNs as initial weights. Comparisons between CNNs, GZMI, CNNs enhanced with GZMI, with and without transfer learning are provided for synthetic and real data.
The rest of the paper is structured as follows: in Section 2 related work and background information are provided, while in Section 3 the proposed methodology is described. The corresponding experimental results are reported in Section 4 and the conclusions in Section 5.
