The abstract concept of game has proved to be a fruitful metaphor in theoretical computer science [2]. Several decision problems can, indeed, be encoded as path-forming games on graphs, where a player willing to achieve a certain goal, usually the verification of some property on the plays derived from the original problem, has to face an opponent whose aim is to pursue the exact opposite task. One of the most prominent instances of this connection is represented by the notion of parity game [3], a simple two-player turn-based perfect-information game played on directed graphs, whose nodes are labeled with natural numbers called priorities. The goal of the first (resp., second) player, a.k.a., even (resp., odd) player, is to force a play π, whose maximal priority occurring infinitely often along π is of even (resp., odd) parity. The importance of these games is due to the numerous applications in the area of system specification, verification, and synthesis, where it is used as algorithmic back-end of satisfiability and model-checking procedures for temporal logics [4], [5], [6], logics for games [7], [8], [9], [10], [11], [12], [13], [14], and as a core for several techniques employed in automata theory [15], [16], [17], [18]. In particular, it has been proved to be linear-time interreducible with the model-checking problem for the modal μCalculus [5] and it is closely related to other games of infinite duration, such as mean payoff [19], [20], discounted payoff [21], simple stochastic [22], energy [23] games, and prompt games [24], [25], [26], [27]. Besides the practical importance, parity games are also interesting from a computational complexity point of view, since their solution problem is one of the few inhabitants of the UPTime ∩ CoUPTime class [28]. That result improves the NPTime ∩ CoNPTime membership [5], which easily follows from the property of memoryless determinacy [16], [3]. Still open is the question about the membership in PTime.
The literature on the topic is reach of algorithms for solving parity games, which can be mainly classified into two families. The first one contains the algorithms that, by employing a divide et impera approach, recursively decompose the problem into subproblems, whose solutions are then suitably assembled to obtain the desired result. In this category fall, for example, Zielonka's recursive algorithm [29] and its dominion decomposition [30] and big step [31] improvements. The second family, instead, groups together those algorithms that try to compute a winning strategy for the two players on the entire game. The principal members of this category are represented by Jurdziński's progress measure algorithm [32] and the strategy improvement approaches [33], [8], [34].
A recent breakthrough [35] by Calude et al. proposes a succinct reduction from parity to reachability games based on a clever encoding of the sequences of priorities that a player finds along a play. This allows for a mere quasi-polynomial blow up in the size of the underlying graph and sets the basis of the fixed-parameter tractability w.r.t. the number of priorities. The approach has been then considerably refined in [36], where these encodings are modeled as progress measures. A similar technique is also used in [37]. Despite the theoretical relevance of this new idea, preliminary experiments seem to suggest that the practical impact of the result does not match the theoretical one, as all exponential algorithms outperform, often by orders of magnitude, the current implementations of the quasi-polynomial ones, which do not scale beyond few hundred vertexes. This evaluation is consistent with the fact that the new techniques essentially amount to clever and succinct encodings embedded within a brute force search, which makes matching quasi-polynomial worst cases quite easy to find.
Recently, a new divide et impera solution algorithm, called priority promotion (PP, for short), has been proposed in [38] and further developed in [39], which is fully based on the decomposition of the winning regions into dominions. The idea is to find a dominion for some of the two players and then remove it from the game, thereby allowing for a recursive solution. The important difference w.r.t. the other two approaches [30], [31] based on the same notion is that these procedures only look for dominions of a certain size in order to speed up classic Zielonka's algorithm in the worst case. Consequently, they strongly rely on this algorithm for their completeness. On the contrary, the PP procedure autonomously computes dominions of any size, by suitably composing quasi dominions, a weaker notion of dominion. Intuitively, a quasi dominion Q for player α∈{0,1} is a set of vertices from each of which player α can enforce a winning play that never leaves the region, unless one of the following two conditions holds: (i) the opponent α‾ can escape from Q (i.e., there is an edge from a vertex of α‾ exiting from Q) or (ii) the only choice for player α itself is to exit from Q (i.e., no edge from a vertex of α remains in Q). A crucial feature of quasi dominion is that they can be ordered by assigning to each of them a measure corresponding to an under-approximation of the best priority for α the opponent α‾ can be forced to visit along any play exiting from it. Indeed, under suitable and easy to check assumptions, a higher priority quasi α-dominion Q1 and a lower priority one Q2, can be merged into a single quasi α-dominion of the higher priority, thus improving the approximation for Q2. This merging operation is called a priority promotion of Q2 to Q1. A refinement of this approach, where the attention is restricted to strongly connected quasi-dominions called tangles, has also been recently proposed in [40].
The PP solution procedure has been shown to be very effective in practice and to often significantly outperform all other solvers. Moreover, it also improves on the space complexity of the best known algorithm with an exponential gain w.r.t. the number of priorities and by a logarithmic factor w.r.t. the number of vertexes. Indeed, it only needs O(n⋅log⁡k) space against the O(k⋅n⋅log⁡n) required by Jurdziński's approach [32], where n and k are, respectively, the numbers of vertexes and priorities of the game. It also improves w.r.t. the recently introduced quasi-linear space algorithms [36], [37]. Unfortunately, the PP algorithm also exhibits exponential behaviors on a simple family of games. This is due to the fact that, in general, promotions to higher priorities requires resetting promotions previously performed at lower ones.
In this article, we continue the study of the priority promotion approaches trying to find a remedy to this problem. We propose a new algorithm, called DP, built on top of a slight variation of PP, called PP+. The PP+ algorithm simply avoids resetting previous promotions to quasi dominions of the same parity. In this case, indeed, the relevant properties of those quasi dominions are still preserved. This variation enables the new DP promotion policy, that delays promotions that require a reset and only performs those leading to the highest quasi dominions among the available ones. Experiments on randomly generated games show that the new approach performs much better than PP in practice, while still preserving the same space complexity.
