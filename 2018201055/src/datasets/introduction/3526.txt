Visual attention mechanism has prompted many researchers to stimulate such ability of human vision system in computer vision. Saliency detection aims at finding the most attractive objects in a scene in order to simulate the functionality of biological vision system. The ultimate goal of saliency detection is modeling the visual attention mechanism of human perceptrons. Salient object detection methods usually offer a saliency map to measure the saliency value for each pixel. This map can provide more useful evidence in pre-processing stage for numerous computer visions tasks, including object detection, image categorization, and video compression, to just name a few [1].
Bottom-up methods largely depend on a series of low-level saliency priors, e.g., center surround prior, boundary connectivity prior, local contrast prior, etc., which can guide the design of such hand-crafted models. However, bottom-up methods can hardly model human attention mechanism by capturing both high-level semantic information and spatial relationship between salient object and its surroundings when dealing with complex images. Top-down approaches, which are also called as learning-based methods, put more efforts on capturing high-level information by feature extraction, feature learning and model structure design [2]. Recent years have witnessed the rapid development of deep learning, especially the convolutional neural networks (CNNs). Models based on CNN structures have been proposed and achieved superior performance on various challenging computer vision tasks [3], [4], [5]. Many works on developing CNNs for saliency detection have also been proposed [6], [7], [8]. Different models with complex network structures and post-processing steps were introduced to improve the performance with respect to saliency segmentation accuracy.
Motivated by the recent success of conditional generative adversarial network (cGAN) on image-to-image translation tasks [9], [10], in this paper we formulate the saliency mask prediction as a saliency object segmentation task, and propose to solve this task using conditional adversarial network under a popular image-to-image translation framework, PixelGAN [9]. To the best of our knowledge, this is the first work to handle salient object detection by using conditional adversarial network. Moreover, to further investigate the ability of GAN for capturing the relationship between a salient object to its surroundings, we perform translating saliency mask to real image. The contributions of this work are two-fold: (1) A new formulation of saliency detection is introduced by transferring the saliency map prediction to an image-to-image translation task under the cGAN framework; (2) The Wasserstein-1 distance(i.e., Earth-Mover(EM) distance) is integrated into the cGAN model to improve the detection performance and training stability. Extensive experiments were performed on validating the ability and effectiveness of our framework by comparing with both bottom-up and top-down methods.
The rest of the paper is organized as follows. In Section 2, we briefly overview related works. Section 3 provides an overview of our proposed method. Experimental results on validating our proposed method are illustrated in Section 4. In Section 5, we conclude the paper with future work propositions.
