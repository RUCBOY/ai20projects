The notion of the computer as a blind symbol-processing engine is under-prepared to describe the complexity of modern computational systems and tasks. The idea that any communication with a computer must be symbolic (thus limiting the tool-set used to investigate it) by virtue of the computer's processor operating, on the lowest level, upon zeros and ones is philosophically naive and denies the flexibility of modern input and output methods (both physical and abstract) and their suitability for particular interfaces. One particularly interesting instance is medical image processing systems which lie at the confluence of two vastly disparate fields: computer vision and artificial intelligence in which ill-defined problems are structured, solved, and thus addressed; and personalized medicine in which the medical course of action is determined patient-by-patient preceded by diagnostic testing, often genetics or imaging based.
Although medical image processing is an umbrella term encompassing many distinct applications, this article focuses on the problem of medical image segmentation, defined as the partitioning of an image into a series of regions each corresponding to a organ or other anatomy of interest. As volumetric imaging such as magnetic resonance imaging and computed tomography to digital histology has become invaluable to modern medicine, segmentation, fundamental for personalized medicine, has become more complex. The identification and delineation of anatomical structures or regions of interest is often seen as a fundamental step in processes as diverse as quantification of anatomical features (Bagci et al., 2013, Moonis et al., 2002), physiological and anatomical modelling (Huang et al., 2013, Juneja et al., 2012), computer-assisted diagnosis (Wiemker et al., 2014, Armato and Sensakovic, 2004), the detection and localization of pathology (Prastawa et al., 2004, Zheng et al., 1995), determination of margins in cancer resection and other treatment planning (Peters and Cleary, 2008), and visualization of surgical scenes in image-guided interventions (Peters and Cleary, 2008). Additionally, medical image segmentation has served a vital role in medical imaging research from anatomical atlas generation and registration (Park et al., 2003), to finding correlations between imaging modalities (Turkbey et al., 2012) (Goubran et al., 2014). Thus, medical image processing (segmentation in particular) has become the meeting ground of clinicians of various stripes, basic science researchers in a variety of fields, and applied scientists in computer vision, biomedical engineering and medical technology. The techniques and algorithms in medical image segmentation vary widely from application to application. This diversity is dependent on the multiplicity of factors which govern the selection of segmentation frameworks, including the imaging modalities available, computational memory and efficiency constraints (Scholl et al., 2011), financial and hardware considerations (Smistad et al., 2015), the structure of the anatomical regions of interest and any associated normal or pathological variability.
A common concept in computer programming is the separation of interface and implementation, which isolates the underlying computational processes from those which interact directly with the user. In that vein, a segmentation algorithm is the underlying computational processes that perform segmentation, whereas a segmentation interface is the front-end components through which the user communicates with the computer as well as the general or abstract, rather than specific, behaviour of the algorithm. Both of these, as well as the user's reasoning, are a part of the larger segmentation process which encompasses how the segmentation is performed as a whole. The diversity of segmentation algorithms and interfaces currently available is both large and growing. The purpose of this article is not to contend with literature reviews of medical image segmentation research, nor to enumerate the different computational processes and properties thereof. (Many such literature reviews are available, an all-too-brief list includes (Smistad et al., 2015, Clarke et al., 1995, Pham et al., 2000, Peng et al., 2013). One distinctly different literature review is that of Olabarriaga and Smeulders (2001) which proposes a three-pronged approach to understanding segmentation processes, rather than algorithms or interfaces, at an abstract level, focusing on the interaction between the clinical user and the computer. The first prong involves determining the type of input from the user during the segmentation process, the second the interpretation of user input as feedback to some computational mechanism, and the last the determination of the overall purpose of user intervention in this process. Although each individual category may display its age, having being published more than 15 years ago in a fast-paced research environment, the approach is fairly comprehensive and certainly motivates the concept of understanding human-computer interaction in medical image segmentation at an abstract level. Unfortunately, this paper is presented primarily as a survey of the state-of-the-art at the time and thus did not search for an underlying theory or rigorous conceptual framework to support its insights. In addition, since it was published in 2001, several advances have been made in medical image segmentation. The popularization of ITKSnap as a standard tool for manual segmentation and the development of frameworks such as MeVisLab (Ritter et al., 2011) and 3D Slicer (Pieper, 2004), for designing medical image computing tasks, have provided a more common and repeatable basis for creating segmentation processes, giving an avenue for new interaction mechanisms to thrive. New algorithmic paradigms such as graph-cuts (Boykov and Jolly, 2001) and deep learning (Hinton, 2006) have also created new challenges in structuring complex segmentation problems. In this new environment, a unified approach to understanding segmentation can help elicit the fundamental commonalities between disparate approaches and the contrasts between similar ones, ultimately guiding conceptual development.
The purpose of this article is to develop that systematic program for conceptually analyzing segmentation processes by specifically updating and expanding upon the approach made by Olabarriaga and Smeulders (2001). The intent is to encourage readers regardless of field to critically examine all currently used and state-of-the-art segmentation algorithms and interfaces, both in research and in the clinic, in terms of their roles in the overall segmentation process and to do so from a rigorous philosophical point-of-view. Peircean semiotics, as well as more recent thought in cognitive science, can motivate that larger perspective. Section 2 motivates viewing the segmentation process as a dialogue involving a series of exchanged signs, which fundamentally necessitates a framework for semiotic analysis. Section 3 describes a conceptual framework for the design of segmentation processes from the view of information that must be communicated via a sign exchange. Section 4 describes a framework for understanding the input to, and output from, segmentation interfaces in terms of Peircean semiotics, which supports our conceptual framework. In Section 5, a series of quality metrics based on the cognitive science of analogical reasoning are proposed to assist in evaluating the efficacy and usability of individual signs. Section 6 uses the ITKSnap and MeVisLab interfaces as case studies in semiotic design and analysis. The final section discusses how this overall framework reflects the state-of-the-art in segmentation interfaces and provides a program for moving the state-of-the-art forward.
