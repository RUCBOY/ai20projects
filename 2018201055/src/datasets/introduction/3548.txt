It has become more and more critical to build large training datasets for many computer vision tasks. Retrieving images from the Internet is one of the most useful methods [1], [2], [3]. However, the retrieved results often contain many irrelevant images. For example, when we input ‘Flower’ query in a search engine, it may return a few plant images, which introduce outliers to the ‘Flower’ category. Therefore, outlier detection and removal are essential to help us construct pure training dataset.
In order to detect outliers efficiently, many outlier detection mechanisms have been proposed. There exists a category of methods that utilizes the reconstruction error to detect outliers [4], [5], [6], [7]. They are all based on the assumption that there are strong statistical correlations among the features of normal data. By minimizing the reconstruction errors of normal training data, these reconstruction-based methods are able to capture these correlations. Therefore, normal data should have relatively smaller reconstruction errors than the outliers. Those data having large reconstruction errors are determined as outliers. In [4], [5], the authors adopted PCA to learn the feature correlations from normal data. The methods in [6], [7] learn the non-linear correlations from data by using autoencoder. However, for high-dimensional image data, it is very difficult for one single autoencoder to fully learn the feature correlations of normal data.
In this paper, we combine autoencoder with Adaboost (ADAE) to detect image outliers. By repeatedly training on the weighted normal dataset, ADAE is able to obtain a sequence of weak autoencoders. The final prediction model of ADAE is a weighted summation of all the weak autoencoders. As each successive autoencoder attempts to capture the correlations that the previous one has failed to capture, ADAE can better capture the image feature correlations than the single autoencoder. In addition, we introduce the Sparse Group Lasso (SGL) constraint to the learning objective of the autoencoder in order to eliminate unnecessary parameters.
The main contributions of our work are threefold. Firstly, we propose a novel image outlier detection model which combines autoencoder with Adaboost. By evaluating on several popular image datasets, this model has been shown to have better detection performance than the other detection methods. Secondly, we further introduce the Sparse Group Lasso constraint into ADAE (ADAE-SGL) to obtain a compact detection model. In order to optimize this additional objective of ADAE-SGL, we combine Adagrad with Proximal Gradient Descent (Ada-PGD). Thirdly, in order to determine the best penalty factors of SGL, we reformulate the objective of ADAE-SGL into a bi-objective optimization problem. Therefore, by utilizing evolutionary multi-objective optimization method, we find the best penalty factors successfully. The evaluation results show that ADAE-SGL achieves similar detection performance while obtaining a compact detection model.
The rest of this paper is structured as follows. Section 2 presents a general discussion about the existing outlier detection approaches. In Section 3, we propose the novel image outlier detection algorithm. In Section 4, we first introduce the Sparse Group Lasso constraint into ADAE. Ada-PGD optimization algorithm is proposed here to optimize the new learning objective. In addition, by reformulating the learning objective into a bi-objective optimization problem, we utilize evolutionary multi-objective optimization method to determine the best penalty factors for SGL. In Section 5, we compare the detection performance of ADAE with other outlier detection algorithms by evaluating them on several famous image datasets. We also evaluate the effectiveness of ADAE-SGL. Session 6 concludes the paper.
