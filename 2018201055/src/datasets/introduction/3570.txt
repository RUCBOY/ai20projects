Blur detection, aiming to measure and extract blurred regions from an input image, is an important and challenging task that can be widely used in many computer vision applications, e.g., spatially variant deblurring [1], [2], camera stabilization [3], image quality assessment [4], and saliency detection [5], [6]. There are several feasible methods for this problem [7], [8], [9], [10]. Most of them employ a two-step strategy. First, some low-level blur-related features are handcrafted based on various empirical image statistics in gradient, frequency and data-driven filters domain. Then, a binary classifier is used to distinguish blurred and non-blurred regions. Hence, an essential problem in blur detection is to extract effective blur features. Despite being simple and low-dimensional, handcrafted features generally lack expressive, discriminative and generalization capability compared to properly learnt deep features, which has been validated by latest advances in deep learning and generic object recognition [11], [12], [13].
Despite the great success of deep CNN model in solving challenging object recognition tasks [13], it has not been used in blur detection. Unlike object recognition, blur detection is to “recognize” blur from input images. Since blur is a kind of degradation to image quality, a reliable blur detector should be robust enough to tolerate the huge intra-class variance caused by different image content. This is fundamentally different to object recognition, where degradation factors, like noise or blur, should be robustly ignored.
In this paper, we propose a simple 6-layer CNN model to learn discriminative deep blur features for blur detection and measurement. We show that high-quality blur detection can be achieved by this simple yet effective model. Based on real-world data, we empirically analyze the role of each layer of our model. Specifically, our first 5 layers, respectively, serve as low-, middle- and high-level blur features extraction (layers 1–3), dimensionality regulation (layer 4) and discriminative feature transformation (layer 5); the last layer is a binary classifier. We also classify the filters into positive, negative, image-like and null by the similarity of the appearance between the ground truth with the feature maps. To capture rich structural information of local blur, we apply our model at three coarse-to-fine patch scales, 21 × 21, 35 × 35 and 49 × 49. As shown in Fig. 1 and Table 3, all single scale blur detections using the proposed CNN model clearly outperform state-of-the-art methods. In the 3rd row of the Fig. 1, we show some learned features i.e., Feature-S1,2,3, corresponding to our BDNet-1,2,3. We can find that our model learns discriminative blur features from image, which is unlike traditional feature learning methods [15], [16] that use feature transform methods to learn a representative coding from the handcrafted features. Although feature transformation can select important features, it cannot change the distinguishing ability of the original handcrafted features. To conquer scale ambiguity, we further present a closed-form approach to optimally fusing multiscale blur likelihoods. Extensive experiments on benchmark dataset validate the superior performance of the proposed model on challenging blur detection of natural images.Download : Download high-res image (570KB)Download : Download full-size imageFig. 1. An example of blur detection. We compared our blur results of single scale (i.e. BDNet-1,2,3) and fused (i.e. BDNet-F) with the results of Chakrabarti et al. [8], Shi et al. [10] and JND [14]. F denotes F1-measure, and M denotes mean absolute error. We also show examples of the effective and idle features of each single scale CNN.
Specifically, our major contributions are three-fold:

•We design a simple and effective 6-layer CNN model for reliable blur detection. The increasing discriminative power of blur features, generated by deeper network layers, has been empirically validated.•We present null filters removal and effective feature sampling to significantly reduce the size of the proposed CNN model.•We find that our blur likelihood map can be used as an effective background prior, thus to further boost the performance of state-of-the-art saliency detectors.
