Visual tracking [1], [2], [3], [4], [5], [6] is an important task in computer vision field, containing single object tracking [7], [8], [9] and multiple object tracking [10], [11]. Multiple object tracking aims to estimate the trajectories of all the targets for the given video or image sequences. Thanks to the advancement of the object detection methods in recent years [12], [13] , the tracking-by-detection framework is adopted. The advantage of this framework is that the number of the targets can be self-adaptive. With the detection results, the position of the targets can be much more accurate avoiding the target drift. The tracking-by-detection methods could be broadly categorized into two groups: the global (batch) tracking methods like [14], [15], [16] and the online tracking methods like [17], [18], [19]. The global tracking methods can utilize the frames information from the past, current and the future. Therefore they can represent the targets and detections with more information and cues. In contrast, the online tracking methods infer the positions of objects with just the past frames and the current frame. On the other hand, the online tracking methods correspond with many reality applications such as the unmanned aerial vehicle and the self-driving cars. In this paper, we focus on the online tracking methods.
Under the tracking-by-detection framework, the multiple object tracking problem is formulated as finding the most reasonable association between detections and trajectories. To this end, are two aspects should be considered: the way to represent the proposal detection and the metric to measure the affinity between the detections and targets. Because of the lack of the positions and appearance changes in the future, the online tracking methods are more challenging which need more robust description for targets and more capable affinity measure between detections and targets.
Object detections are usually represented as bounding boxes around objets. Bounding boxes contain not only pixels of objects but also background pixels around objects. Most methods focus on the object in the bounding box with treating all the content in the bounding box as the foreground. However, we observe that the context information in the bounding box also contributes to distinguishing the objects, as shown in Fig. 1. The two people in Fig. 1 have similar appearances, and in this case the context around the target could be a better cue to distinguish the targets from each other because of their distinctive context. Based on these observations, we propose an Exchanging Objects Context (EOC) model in this paper. In this model, the background cue is introduced into describing the target, which utilizes the background information to measure the similarity between detections and targets. The main idea of EOC model is that there is a correlation of the context of a target between adjacent frames. So we exchange the context of a detection bounding box at the current frame with the target context at the last frame. We utilize the changes between the original context and the constructed virtual context as the affinity measure.Download : Download high-res image (263KB)Download : Download full-size imageFig. 1. The targets locate in the scene with different context. Most methods focus on the objects in the bounding box. However when the appearances of the targets are similar, the context information could also make a contribution to distinguishing or locating the targets in the scene.
The cues of object description mainly contain the appearance cue, the motion cue, the position cue, the structure cue and so on. For the appearance cue, only a few methods take enough attentions on the appearance feature design, even some methods adapt no appearance cue (such as [20]). Most tracking methods deal the appearance cue with the traditional and simple features, such as [21] uses the color histogram [22], [23] uses the color histogram and histogram of gradient (HoG) [24]. So a robust description of the target appearance is worth to research on.
In this paper, we design a new histogram feature to effectively describe the target area and its context considering both color information and the gradient information. Inspired by the conception of the HoG feature, our feature takes account of image local gradient information to get the statistics of color, called Color Histogram by Gradient (CHG).
The main contributions of our work are summarized below. We propose an EOC model which takes advantage of the context information for an efficient affinity measure to associate detections. Meanwhile, a detection refining method using EOC model is proposed. For a effective description of targets and contexts, a novel feature CHG is proposed. The framework of our proposed method is shown in Fig. 2. We demonstrate the effect of the proposed method by carrying out extensive experiments on challenging datasets.Download : Download high-res image (731KB)Download : Download full-size imageFig. 2. The framework of the proposed method for online multiple object tracking with EOC. There are three components in our proposed method: detection representation, data association and detection
refining. In detection representation, the features of each detection would be extracted by different cues. In data association, the affinity between the detection and the target would be measured using the features and the EOC model. The association scheme would be determined with the affinity metric. In detection refining, the position and shape size of the associated detection would be refined using the EOC model for the final tracking results. Colorful arrows and circles with IDs stand for the trajectories of different targets. Red blank circles and bounding boxes stand for the detections in current frame.
