Despite the breakthrough in gaming technologies, the game industry still seeks to reflect the real world in a better way. One relevant subject, in particular, is the role of the Non-Playable Characters (NPCs), where most of them have their behavior and motion manually defined by game designers, normally using decision trees in a limited way. As Warpefelt [29] comments in his work, “Many of the problems with NPCs stem from the fact that they do not achieve a sufficient level of believability, particularly in the social arena. This is primarily related to the fact that the NPCs do not behave in ways that align with the expectations of the player. This can lead to the player misunderstanding the role and purpose of the NPCs, which damages the believability of the game. By extension, this lessens the enjoyment the player can derive from the game”. Since it restricts the possibilities, it can generate unrealistic motion or behavior, which in turn can make the players bored or uneasy. Also, game designers spend a significant amount of time and resources on this task, which could be used to work in more important matters.
The main goal of this paper is to propose a way to generate NPCs and groups of NPCs behaviors based on learning trajectories from real video sequences. While the process to generate trajectories use tracked motion from video sequences at each frame, groups are also identified in the videos, as well some of their characteristics. Examples of computed features are speeds, orientations and distances among people. Then, captured and computed data are used to simulate crowds based on video sequences, having both individuals and groups. It is not the first time computer vision and games are related. As presented by Freeman et al. [9], “the appeal of computer games may be enhanced by vision-based user inputs”.
Fink et al. [8] also explore the use of computer vision in games. In their work, authors make use of computer vision techniques to extract information from a played game. In other words, they use the graphical output of a given game (during the game play) to learn the behavior of NPCs and other entities, using the method presented.
Although some works were found in the area, the use of computer vision to create NPCs motion is still incipient. Section 2 discusses some related work. The main contribution of this paper is to use captured data from video sequences, using computer vision, to generate individual and grouped trajectories of NPCs for games, in an automatic way. Computer vision methods are used to detect and track individuals and groups of people. Indeed, we propose two different ways of control: the Continuous Based Control (CC) which aims to continue a specific video sequence keeping NPCs and groups behaving exactly like in the video, and the User Based Control (UC), which allows the user to inform the number of groups and agents to be created in the simulation/application.
The remaining of this paper is organized as follows: Section 3 presents the method we adopt to detect and track people in video sequences and describes our proposal to learn and estimate new trajectories for NPCs, as well our proposal to identify groups of people and compute groups parameters. Then, we developed an Unity application that allows to read a short video and provides simulation using the two possible controls: CC or UC, based on the learning trajectories. This application allows to visualize the whole film, partially from real life, partially computer-generated. Such aspects are discussed in Section 4. Lastly, Section 5 presents our final considerations and future work.
