With overwhelming increase of computers in society and their ubiquitous influence in our daily activities, facilitating human computer interactions has become one of the main challenges in recent years. Hence, there has been a growing interest among the researchers to develop new approaches and better technologies to overcome this problem. The ultimate aim in this process is to achieve more sensor accuracy and efficiency of methods to bridge human-computer interaction gap and make it as natural as human-human interactions. Such methods will have a broad range of applicability in all aspects of life in a modern society from gaming and robotics to medical diagnosis and rehabilitation tasks. Considering recent progress of computer vision field, there has been an increasing urge upon medical domain. Computer-aided rehabilitation technologies are therefore gaining popularity among medical fraternity and are targeting more health-care applications (Zariffa & Steeves, 2011). Employing Gesture recognition where human-computer interaction is indispensable, becomes one of the most favorable applications owing to its natural and intuitive quality.
Cognitive disorders such as Alzheimer’s disease (AD) are prevalent among older adults. Studies show a maximum correlation between AD and limb apraxia in all phases of the disease (Chandra, Issac, & Abbas, 2015). One of the effective tests which has been developed to diagnose these disorders is the Praxis test. Praxis is defined as the ability to plan and perform skilled movements in a non-paralytic limb based on the previously learned complex representations. Accordingly, limb apraxia is inability to carry out a learned motor act on command while there is no motor or sensory deficit in the subject (Chandra, Issac, Abbas, 2015, Heilman KM, 2003). According to Geshwind’s “disconnection model”, apraxia is considered as failure (spatial or temporal error or failing to respond) of a subject to respond correctly with the limbs to a verbal command or having difficulty to imitate an action after being performed by an examiner (Catani & ffytche, 2005). Based on the American Psychiatric Association’s report, Praxis test is accepted as diagnostically indicative sign of cortical pathologies such as AD (Association, 2000). However, the test is frequently neglected by clinicians despite being uncomplicated, straightforward and reliable estimate of the AD (Peigneux, Van der Linden, & Le Gall, 2003). The clinicians skip the test mainly because: The whole process of the classical test takes longer time to conduct and even the developed countries face an acute shortage of well-trained specialists capable of performing and evaluating the test. Moreover, instruction of the test is not standardized and accordingly, not objective enough. Clinical practice reveals that, even when the test is performed, two kinds of problems can occasionally be observed: first one is the error in demonstrating the gestures to the subjects by an examiner and second, the errors in assessing subject’s performance. In addition, most of the clinicians rely on memory and attention assessments in cognitive assessment process because memory and attention are the most frequent impairments in neuro-degenerative disorders. However, some of these disorders, in addition to memory impairments, have specific gesture impairments that distinguish them from the others. In order to diagnose those disorders, it is very important to systematically perform the praxis assessment. Therefore, automatic solutions to address these problems by providing a standardized test can be considered as a significant contribution in the field.
To capture changes in elderlies’ behavioral pattern and to classify their cognitive status (Alzheimerâ;;s disease - AD, mild cognitive impairment - MCI, healthy control - HC), there has been a lot of studies on patient monitoring and surveillance (Banerjee, Keller, Popescu, Skubic, 2015, Brulin, Benezeth, Courtial, 2012, Negin, Cogar, Bremond, Koperski, 2015, Pirsiavash, Ramanan, 2012) with a main focus on recognition of activities of daily living (ADLs) (Avgerinakis, Briassouli, Kompatsiaris, 2013, König, Crispim-Junior, Uria, Covella, Derreumaux, Bensadoun, et al., 2016). The main goal of such frameworks is mostly to provide cost-efficient solutions for in-home or nursing homes monitoring. These systems try to alert the healthcare providers about a significant change in the ADL behavior pattern which may lead to cognitive impairment, falling of the patient or other health related changes. However, ADLs usually have a complex and highly-variable structure and need to be evaluated for a long period of time so as to be useful for clinicians to timely detect health deterioration in subjects.
Meanwhile, contact-based and various sensors for rehabilitation tasks (Sucar, Luis, Leder, Hernández, Sánchez, 2010, Tan, Chin, Lim, 2013) have been developed and found practical applications such as post stroke recovery (Khademi et al., 2014) and limb rehabilitation (Vamsikrishna, Dogra, & Desarkar, 2016). Having their own advantages and disadvantages, they have been mostly utilized in rehabilitation and not for assessment and diagnosis. The most prevailed field which has been applied for computer-assisted diagnosis is image processing. Machine learning algorithms fed with X-Ray, CT scan, MRI, retina images, etc., which are de-noised, segmented, and represented, assist the clinicians with diagnosis or surgical planning through finding meaningful patterns (Pereira et al., 2016). While these methods provide valuable diagnostic information for surgical purposes, their need to use advanced hardware and to process huge datasets, which result in high cost for image interpretation, is a big drawback compared to cost-effective gesture recognition tasks. However, using gesture recognition to obtain an objective classification of a person’s performance, particularly for medical diagnosis, still remains as a novel and largely unaddressed challenge for the research community. Regarding the above-mentioned discussions, we have proposed a gesture recognition method by paying special attention to the Praxis test. The aim is to develop a robust and efficient computer-vision-assisted method to automatize the test procedure and to carry out assessments that help clinicians to have a more reliable diagnosis by providing a standardized method of performing the evaluations and a detailed analysis of subjects performances. Consequently, we have collected a challenging dataset1 composed of dynamic and static gestures provided by clinicians for the Praxis test (Fig. 1). We also adopt a gesture recognition framework, using a deep convolutional neural network (CNN) (LeCun, Bottou, Bengio, & Haffner, 1998) coupled with a Long short-term-memory (LSTM) (Hochreiter & Schmidhuber, 1997), that jointly performs gesture classification and fine grained gesture correctness evaluation. As a result, we report performance of the proposed method and comparisons with developed baselines. With the evaluations we provide strong evidence about superiority of our representation learning method over traditional approaches, ensuring that robust and reliable assessments are feasible. The remainder of this paper is organized as follows. In Section 2, we review the related studies on gesture recognition and computer-assisted rehabilitation and diagnosis. Section 3 introduces the formulation of our baseline methods and suggested CNN+LSTM model followed by Section 4 that presents the experimental analysis, results and discussions. Finally, Section 5 concludes the study and discusses about future work.Download : Download high-res image (425KB)Download : Download full-size imageFig. 1. The collected dataset consists of selected gestures for Praxis test. There are two types of gestures in the dataset: dynamic (14 gestures) and static (15 gestures) gestures. The dynamics are the ones including movement during the time that gestures are performed. The dynamic gestures are indicated with red arrows indicating their motion direction. On the other hand, the static gestures include body part orientation and position configuration without any movement during an amount of time. In another taxonomy the gestures are divided to: Abstract, Symbolic and Pantomimes (starting with “A”, “S” and “P” respectively). (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)
