The constant evolution of technology has grown in tandem with the quantity of data generated from scientific experiments and research. But in the last few years, due to the increase in popularity of social media applications and the rise of smart devices, such as smartphones, smartwatches and health monitor gadgets, smart city solutions, like intelligent semaphores, and the Internet of Things trend, the amount of data generated has grown exponentially. Proper analysis of that information, combined with the insight offered by data gathered by organizations and institutions, could prove useful in taking right decisions or in the prevention of catastrophes. In order to store, access, analyze and process large volumes of information, that is produced at a fast rate, new paradigms needed to be explored [14], paradigms that make use of parallel and distributed architectures and suitable algorithms. Computer clusters, computer grids and modern supercomputers have become the most popular systems when dealing with the challenges of big data or with intensive parallel applications.
Supercomputers are formed of dedicated machines, that are connected with each other throughout a well organized and fast network, and have high performances, but usually have high costs and are specialized in solving certain problems [26]. Computer clusters or grid systems made of commodity hardware are the favorite solution both in the industry and in the academia, because of its low costs and highly configurable characteristic, given by the frameworks and platforms that run on the systems. One such framework is the Apache Hadoop Ecosystem [30] that implemented the successful data processing model MapReduce [8], published by Google. The framework has grown over the years integrating components that assure data replication and consistency, fault-tolerance, security, safe execution of scalable parallel applications. One of the most important enhancements to the Hadoop environment was the separation of the resource negotiator, known as YARN [19], the advantage being the ease of customization. This intended versatility of YARN confirms the importance of the scheduling process in the efficiency of the system and of the applications. Other important aspects are related to throughput optimization [25], [5], [6] and energy- aware resource allocation [9], [18].
Scheduling in distributed systems represents a broad subject, given the complexity of modern computer clusters and the nature of applications that run in them. Scheduling may refer to job or task scheduling or resource allocation. The scheduling can be dynamic, deciding for current running jobs and tasks, or it could schedule in advance the assignment of tasks from a given workflow [3], [1], [4]. Modern systems allocate virtual machines or containers, that have reduced resource capabilities, and form clusters of heterogeneous nodes in which applications can run. The general scheduling problem is a NP-hard [27] problem and it is difficult to find a general heuristic method to solve it. In this paper it is discussed the problem of assigning tasks, that can be represented as a directed acyclic graph of dependencies, on a given set of machines in order to obtain better performances.
Machine learning is a vast domain of artificial intelligence, that has grown in popularity because of its simple recipes or algorithms that give programs the capability to learn patterns, behavior, models and functions, and use that information to make better decisions or actions in the future. Machine learning can be classified as: supervised learning, where a training data set is given and the agent learns how to predict output values of certain input targets; unsupervised learning, where an agent learns a certain structural organization of the input data or the relationship of the elements of the data set; and reinforcement learning, where an agent is given certain rewards corresponding to the utility of an action or decision relative to the world model, with which the agent interacts. Neural networks and deep learning are the most prominent concepts that roam in artificial intelligence, as a result of their capacity to find more efficient solutions than heuristic approaches. These are used in many classification problems [13], [15], [29], [31]. Regarding the problem of task scheduling in distributed systems, the machine learning box will use reinforcement learning algorithms to schedule the tasks in the given cluster of computers.
The intent of this paper is to explore the scheduling problem in distributed systems, through the perspective of reinforcement learning algorithms. In order to be able to integrate machine learning methods in systems that use task schedulers, this paper proposes the implementation of a Machine Learning Box (MBox). The MBox application uses the BURLAP library [12], [16], [17] for the implementation of the reinforcement learning agents, the domains and the world models of the scheduling problem. BURLAP offers a simple and configurable interface for the implementation of various planning and learning algorithms, and it has a collection of machine learning algorithms ready for use. It also offers a suite of analysis tools for the visualization of domains and agent performance. The Machine Learning Box offers scheduling services, through the Java RMI API, to distant or local clients. The clients use remote allocated schedulers, in order to register different world models, that characterize the number of machines for which the scheduling will take place, and send schedule request, receiving a response with the scheduling solution. As an example, the WorkflowSim [7] toolkit was used for the testing and performance evaluation of the scheduling solution. In our previous research we proposed a machine learning toolbox, named as MLBox, to find what scheduling algorithm should be used for a certain request (for BoTs and DAGs) [28].
The rest of the content is organized as follows. Related work is presented in Section 2, along with the most known and most used reinforcement learning algorithms. In Section 3 the scheduling problem in distributed systems is defined and the proposed reinforcement learning model is discussed. In Section 4 the Machine Learning box architecture and design is detailed with the result being analyzed in Section 5. Section 6 draws conclusions and discusses future work.
