Human action recognition, a hot research topic in computer vision [1], [2], [3], [4], can be applied to many scenarios, such as abnormal human behavior recognition [5], user identification [6], semantic scene model [7], etc. The main task of human action recognition is to identify actions with high accuracy and low computational complexity. Over decades of development efforts, great progress has been made in the human action recognition technology based on RGB videos [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20]. Recently, researchers discovered that depth information provided by RGBD sensors, such as Kinect, improves the efficiency of the action recognition results. In RGBD video, the depth information is mainly considered. In addition, the human skeleton can be well estimated based on the depth information [21], [22]. Therefore, the main approaches of action recognition in RGB and RGBD videos are quiet different. In this work, we focus on the study of human action recognition in RGBD videos.
Most researchers focus on designing highly discriminative features in RGBD videos [23], [24], [25], [26]. Pose is a good way to recognize actions. According to early research in 1973 [27], human can recognize simple actions only based on the movements of major joints. For RGBD data, human body joints are precisely extracted in the case of frontal view and little occlusion [21], [22]. Most RGBD datasets provide the positions of the joints. Some features are based on the positions of the joints; other features are based on depth appearance around the joints; still other features are based on both position and depth appearance. And some of recent studies are based on deep learning, which are data-driven. However, we found most approaches have some common drawbacks: A large image area is always required to extract feature descriptors (typically the whole image or body), leading to high computational complexity and high dimensionality. Compared with image-based features, joint-based features are compact, but suffer from the noise of joint position. Moreover, it’s very difficult to judge which parts of feature distinguish one action from another.
Some researchers learn discriminative regions and achieve good result in recognition accuracy [25], [28], [29]. Wang et al. [28] defined actionlet as a conjunction of the features for a subset of the joint. Discriminative actionlets are mined and linearly combined to represent an action. Rahmani et al. [25] selected discriminative regions mostly around human body joints. However, their method requires many initial positions within the whole body, resulting in a large computational burden. Other studies used joint positions, rather than the whole body. Ofli et al. [29] ordered joints by the displacement variation only and used the Sequence of the Most Informative Joints (SMIJs) to model action. However, accuracy on MSR Action 3D dataset [30] is somewhat low. These joint-based approaches of learning discriminative regions involve less regions to extract features, but still suffer from joint estimation noise.
Learning Discriminative Part (DP) is an efficient solution to solve the above drawbacks. Not all the joints are important to recognize actions. For each action, there are some discriminative parts to perform an action (e.g. hand and head for ‘drinking’), while other parts are unimportant for recognize action (e.g. leg for ‘drinking’). Moreover, some joint positions are very noisy in the provided data. Using the noisy joints may reduce recognition accuracy but increase feature dimension. Furthermore, DPs well reflect the degree of inter-variance. The DPs among different actions may be totally different, partially different, or identical. For example, Fig. 1 shows four actions in MSR Action 3D dataset: high arm wave (a1), draw circle (a2), two hand wave (a3), and side kick (a4). The DP of a1, a2, a3, and a4 are right arm, right arm, left and right arm, and right leg, respectively. The degree of inter-variance is different among those actions. First, a1 and a2 have exactly the same DPs – right arm. These two actions are similar and have little inter-class variation. Second, the DPs of a1 and a3 include the same joints (right arm) in part. Therefore, their inter-class variation is somewhat larger than that of a1 and a2. Third, the DPs are totally different for a1 and a4. The degree of inter-class variation is largest compared with the above two action pairs. The degree of intra-variance can be used to well characterize different actions. In summary, DP based feature is interpretable, which meanwhile reduce joint noise and feature dimension.Download : Download high-res image (168KB)Download : Download full-size imageFig. 1. The Depth map of Four Actions with DPs in MSR Action. (a) high arm wave, b) draw circle, (c) two hand wave, (d) side kick.
Therefore, the purpose of this work is to learn and apply DPs, especially in respect to efficient reduction of dimension and noise. The Out-of-Bag (OB) of Random Forest (RF) classifier is applied in this work. OB estimates appear almost unbiased, i.e. the average of the OB error estimates is almost equal to the average of the test set error estimate, especially in the case of small datasets. Furthermore, the OB estimate outperforms cross-validation by not using complicated computations. Because most datasets in RGBD video are small, the unbiased OB estimates can be applied to learn DPs. In detail, we propose a novel approach to measure the discrimination of joints based on OB errors and uniformly learn DPs (Fig. 2). The main procedures are as follows:
 a) Feed separately all the features of the several single-joints and the several joint-pairs into a RF classifier to (1) determine OB error estimates separately for each individual action in the data set and (2) determine an OB error estimate for the data set as a whole. Then we determine the discrimination ranking of joints based on the error rates of single-joints and joint-pairs. b) Learn DPs for each action and the entire dataset. c) Concatenate the features of DP for the entire dataset and train an SVM model on the reduced features. Our proposed model is evaluated using MSR Action 3D dataset [30] and MSR Daily Activity3D Dataset [28]. Results show that the accuracy of our proposed method is comparable with that of the basic feature. But our method reduces feature dimension and noise.Download : Download high-res image (387KB)Download : Download full-size imageFig. 2. The framework of our proposed discriminative parts learning for action recognition.
The main contributions of this paper are as follows: (1) A novel approach based on OB error estimates of RF is proposed to evaluate the discrimination of joints. The evaluation is robust to the estimation noise of joints, fair to reflect the discrimination of joints. 2) A simple, but effective, DPs learning technique, with a few parameters, is proposed. 3) The framework of feature dimension reduction and classification is universal, which efficiently reduces noise and the dimensions of features without loss of accuracy.
The rest of the paper is organized as follows: Section 2 introduces related work. Section 3 describes the learning of DPs. Section 4 presents the experimental results. Finally, Section 5 concludes the paper.
