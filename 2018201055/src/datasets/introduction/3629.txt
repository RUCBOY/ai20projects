Over the last few decades, developed countries in Europe, Asia, and North America have experienced a significant change in the age profile of their demographic structure, with a steady increase in the number of adults aged 65 years or older. Although longer lifespan is a clear sign of progress and improved quality of life, the considerable growth of the elderly population poses far-reaching social and economic challenges regarding the fiscal sustainability of the welfare state. As such, health-care system and related services have to be rethought to treat aging as a manipulable long-term biological process whose detrimental effects can be limited or procrastinated rather than passively accepted as inevitable.
Key research challenges need to be effectively and efficiently addressed to cope with the ever-growing amount of epigenetics data that is being exponentially produced. Traditional techniques and tools for data analytics and autonomous learning are no longer suitable and even unusable to extract human-interpretable knowledge and information from the enormous complex amount of data. Therefore, new revolutionary approaches and tools are more than required, among these tools we highlight clustering.
Almost 60 years beyond have passed from the first proposed clustering algorithm [1]. Cluster analysis aims at grouping data points into separate groups called clusters. It plays a versatile role in knowledge discovery, and it is used in a myriad of fields to extract hidden relationships among data. An up-to-date review of the application of clustering analysis can be found in [2]. A plethora of clustering algorithms has been designed to deal with different types and distributions of data. The exponential increase of data makes cluster analysis even more challenging than before. Two broad approaches have emerged to alleviate the issue, either by reducing the dimensionality of data (dimensionality reduction) [3] or by reducing the number of samples within a dataset (sampling) [4]. However both approaches have been proved to be ineffective when a single machine is used as the prohibitively large amount of data cannot be kept on a single computer. Therefore, multiple machines are needed, and parallel processing of data is undeniably necessary.
Hardware accelerators such as field programmable gate array (FPGA) and graphics processing unit (GPU) have emerged recently as promising technology drivers [5]. On the other hand, application programming interfaces (APIs) such as message passing interface (MPI) and OpenMP have traditionally provided a software-oriented approach. However while dealing with parallel programming languages, additional concerns have to be considered, such as the load balancing, the communication flow, the topology choice, the split of data, etc. This makes designing a parallel algorithm a very tedious task. To deal with these concerns, a new open source framework called Apache Hadoop consisting of a storage part namely Hadoop distributed file system (HDFS) and a processing part namely MapReduce (MR) has emerged lately. HDFS is a distributed file system that provides high-performance access to data across Hadoop clusters by managing pools of big data and handling big data analytics applications. MapReduce, designed by Google [6], provides a new methodology of thinking and developing a parallel algorithm suitable for large scale systems without being concerned about scalability as MapReduce is auto-scalable. The idea was inspired by the “map” and “reduce” primitives characterizing the functional programming LISP. Hadoop encapsulates the details of parallelization, fault-tolerance, data distribution and load balancing. It demonstrates a great performance in big data scenarios, especially for challenging tasks such as clustering.
Nevertheless, data clustering is an NP-hard problem. If the number of clusters exceeds three, the alternative ways to group the data is knk!, where k is the number of groups, and n is the number of data points to be clustered.
However, data clustering can be easily cast as a global optimization problem of finding the partition that maximizes/minimizes an objective function. This can be appropriately tackled using metaheuristics, such as ant colony optimization (ACO), artificial bee colony (ABC), particle swarm optimization (PSO) and so forth. These metaheuristics exhibit different dynamics leading to distinct strategies that can be effectively combined to handle hard optimization problems such as Clustering large datasets.
In this paper, we present a novel scalable and elastic framework for clustering large datasets. The framework is a generalized island model (GIM) that includes three swarm intelligence algorithms, cooperating with each other through a migration operator. The main motivation behind the use of such a GIM is to combine the search capabilities of the three algorithms for more efficiency of the search space exploration. The GIM is designed in a parallel and distributed manner in a way to help the three cooperating algorithms to converge to high-quality solutions in a short time while. The developed parallel and distributed architecture are designed using MapReduce programming model to deal with the huge data volume. First, a MapReduce model is derived for each of the cooperating algorithms separately and then merged lately to achieve the overall framework which we refer to as MapReduce Clustering-GIM (MRC-GIM). The framework is validated on many computers (192 computers) connected with each other and large real datasets (more than 30 GB). The comparative study reveals that MRC-GIM outperforms novel developed clustering algorithms dedicated to big data clustering in terms of convergence time and solution quality.
Subsequently, we use MRC-GIM to investigate the correlation between epigenetics and aging. As a result of this application, we found that epigenetics changes slightly and not aberrantly with aging, this latter confirms previous evidence shown in [52], [53].
The remainder of the paper is organized as follows: in Section 2 a brief description of the background material is given. In Section 2.1 a review of clustering large data sets algorithms is provided. Section 3 is devoted to the presentation of the proposed frameworks. In Section 4, the performance of MRC-GIM is evaluated using large datasets and parallel metrics. In Section 4.4 we study the correlation between epigenetics and aging and finally in Section 5 conclusions are drawn.
