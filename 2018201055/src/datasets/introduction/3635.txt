Despite the fact that the ocean plays a very foundational role of human life, we have a limited ability to explore the underwater world for a long time in history. Today's technologies and materials allow us to explore the ocean in deep and observe the undersea environment continuously. Undersea exploration can help us to better understand marine ecosystems and environmental changes. Autonomous underwater vehicles (AUV) and video monitoring systems give us opportunities to make detailed observations and collect samples of unexplored ecosystems. Specially underwater video techniques play an important role in observing macrofauna and habitat in marine ecosystems [1], [2], which provide abundant information for oceanography and fisheries science research. Underwater video based applications are increasingly developed in marine ecology studies and fisheries management. The most popular and widely reported cases in literatures are counting and measuring fish [3], investigating coastal biodiversity [1], observing species behavior [4], and exploring the undersea terrain [5].
Object detection and recognition techniques have been commonly used on videos analysis for the assessment of animal populations. With the underwater cameras, in recent years, a few research studies have been investigated for fish detection, recognition [6], tracking [7] and counting. In contrast to the conventional fishery monitoring approaches including mark-recapture techniques and gill netting [8], the underwater video based methods have advantages such as accurate species counting due to long term observation and environmental sustainability without disturbing their habitat. However, the low-light and high-noise scenarios pose several great challenges for the underwater video analysis. (1) Firstly, low illumination environments cause relatively low contrast background, which can confuse the traditional interest point detectors and produce weak descriptors. (2) Secondly, the object may appear to be of significantly different shapes over various camera angles due to the freely swimming environment. (3) Thirdly, most of underwater videos are of low resolution and low saturation, thus discriminative information is limited to recognize objects from the videos. Above all, most state-of-the-art image and video analysis methods suffer seriously from these drawbacks.
All the above issues motivate us to design a novel solution for underwater object recognition from low-contrast and low-resolution underwater videos. Fig. 1 shows the proposed framework for object recognition tasks on underwater videos. It can be seen from the illustration that an offline deep Convolutional Neural Network (CNN) model is firstly learned by proposing a transfer approach in order to overcome the insufficient training data problem. Then, with the pre-trained underwater CNN model (UW-CNN), a real time object recognition system is designed for underwater videos. The advantages of this work is that: (1) As the interesting points are difficult to be detected from the low-contrast and low-resolution images, the state of the art CNN method gives us a chance to produce abstract discriminative features from the object. Fig. 2 illustrates a comparison between the SIFT and CNN results. We can see that only a few interest points are detected on the object using the SIFT method. Most of them are tedious and do not contain powerful discriminative information. So it is better to identify the object from its shapes rather than local features. Fig. 2 also visualizes part of the middle layers of the CNN output. It can be observed that the global shape information is well captured. (2) To overcome the predicament of “data-hungry” of CNNs with limited underwater training data, we introduce the transfer learning to learn a special CNN model for underwater object recognition together with the help of data augmentation tricks. The data augmentation simulates various possible shapes of the object from normal ones to improve the robustness of the CNN model. (3) To identify the object from videos, we consider the importance of the objects presented in the successive frames. For the final decision of object recognition, the object closer to the camera should have a higher weight than the others. So in the real time object recognition system, a weighted probabilities decision mechanism is used.Download : Download high-res image (809KB)Download : Download full-size imageFig. 1. Illustration of the proposed framework by taking AlexNet as an example.Download : Download high-res image (297KB)Download : Download full-size imageFig. 2. An comparison illustration between the SIFT and CNN.
The main contributions of this work include:

-We use the deep CNN model [9] for underwater objects recognition from low-contrast and low-resolution underwater videos, which can better achieve illumination invariant and overcome the challenges caused by low quality videos.-We overcome the difficulties imposed by small size underwater training data by proposing a transfer learning framework, which takes a fully-trained model from the ImageNet challenge as prior knowledge. Moreover we enlarge the training dataset by horizontal mirroring, rotating, subsampling and affine transformation in order to enrich the varieties of the image dataset. To the best of our knowledge, it is the first to use deep knowledge transferring method in the special field of underwater object recognition-A weighted probabilities decision mechanism based on trajectory is applied to identifying objects. Then we propose a practical deep based application for underwater video analysis.
