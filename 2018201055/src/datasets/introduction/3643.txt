Training a DNN for a new image recognition task is expensive. It requires a large amount of labeled training images that are not easy to obtain. One common practice is to use labeled data from other related source such as a different public dataset, or harvesting images by keywords from a search engine. Because (1) the distributions of the source domains (third party datasets or Internet images) are often different from the target domain (testing images); and (2) DNN is particularly good at capturing dataset bias in its internal representation [2], which eventually leads to overfitting, imperfectly paired training and testing sets usually leads to inferior performance.
Known as domain adaptation, the effort to bridge the gap between training and testing data distributions has been discussed several times under the context of deep learning [3], [4], [5], [6]. To make the connection between the domain of training and the domain of testing, most of these methods require additional optimization steps and extra parameters. Such additional computational burden could greatly complicate the training of a DNN which is already intimidating enough for most people.
In this paper, we propose a simple yet effective approach called AdaBN for batch normalized DNN domain adaptation. We hypothesize that the label related knowledge is stored in the weight matrix of each layer, whereas domain related knowledge is represented by the statistics of the Batch Normalization (BN) [7] layer. Therefore, we can easily transfer the trained model to a new domain by modulating the statistics in the BN layer. This approach is straightforward to implement, has zero parameter to tune, and requires minimal computational resources. Moreover, our AdaBN is ready to be extended to more sophisticated scenarios such as multi-source domain adaptation and semi-supervised settings. To summarize, our contributions are as follows:

•We propose a novel domain adaptation technique called Adaptive Batch Normalization (AdaBN). We show that AdaBN can naturally dissociate bias and variance of a dataset, which is ideal for domain adaptation tasks.•We validate the effectiveness of our approach on standard benchmarks for both single source and multi-source domain adaptation. Our method achieves state-of-the-art results.•We conduct experiments on the cloud detection for remote sensing images to further demonstrate the effectiveness of our approach in practical use.
The rest of the paper is organized as follows. Related works are briefly reviewed in Section 2. In Section 3, we introduce a pilot experiment to analyze the domain shift in deep neural networks, and then present the details of the proposed AdaBN algorithm. Section 4 shows the experimental results of our proposed method and we also evaluate a practical application with remote sensing images. Finally, concluding remarks are given in Section 5.
