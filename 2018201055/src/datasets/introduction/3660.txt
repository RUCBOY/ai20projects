The detection of malicious software that “deliberately fulfills the harmful intent of an attacker” (Bayer et al., 2006) (malware) is a persistently difficult challenge for network security analysts. Attackers are developing increasingly sophisticated methods to avoid detection based on vulnerabilities in software and weak configuration of technical security countermeasures. Typical network security countermeasures include Network Intrusion Detection Systems (NIDS) capable of performing fine-grained network data and protocol-level analysis to identify anomalous and malicious traffic; and anti-virus tools that scan incoming software and attempt to match code signatures to a list of known malicious code bases.
Examples of such malware at the extreme end of the sophistication scale are known as Advanced Persistent Threats (APTs). An in-depth study of the “Big 4” APTs – Stuxnet, Flame, Duqu and Red October – highlighted the factors that enabled malware to evade detection from security solutions (Virvilis and Gritzalis, 2013). The factors include (i) encrypted and/or obfuscated network traffic, limiting the effectiveness of network traffic analysis. Command and control servers received traffic on ports 22/TCP, 80/TCP and 443/TCP, so egress traffic was merged with other http packets (80/TCP) or encrypted in transit (22/TCP and 443/TCP). For http traffic, Duqu transformed data into JPEG image files before transmission avoiding packet-level analysis; (ii) Stuxnet, Flame and Duqu scanned the target for endpoint security products and customised the payload accordingly to evade detection, limiting the effectiveness of signature based static analysis of executables; (iii) Red October made use of in-memory execution to remain undetected (Virvilis and Gritzalis, 2013). conclude that Anti-virus and Network Intrusion Detection products face serious shortcomings in the detection of APT and propose the analysis of “low severity events” that malware will inevitably generate during the attack's life cycle' as a future research direction. As such this work generates a range of system-level activity metrics by executing samples of malicious and trusted executables in a Sandbox environment, and uses these metrics to train a machine classifier to distinguish malicious from trusted executables using “low severity events” that are inevitably generated while the executable is running – namely CPU User Use (percentage), CPU System Use (percentage), RAM use (count), SWAP use (count), received packets (count), received bytes (count), sent packets (count), sent bytes (count), number of processes running (count) – just 9 metrics in total.
An additional consideration for malware classification with so many new instances appearing daily is the ability to detect malware that exhibits previously unseen behaviour. McAfee suggests tens of thousands of distinct samples that are seen daily1, and VirusTotal provides statistics that show that 1.37 million distinct new samples were submitted on Feb 12 20172. This is a non-trivial task but an important test is whether a classification model can generalise from previously seen features – those used to train the model – to unseen features. One way to partially test this is to use a different set of samples to test the classification. Not all previous work does this – several existing research papers use k-fold cross validation which does split the dataset into iterative train/test subsets but does not use an unseen dataset. Thus, this paper also investigates the performance limitations of using cross validation versus an unseen dataset when using various machine learning methods.
Our main contributions are (i) using continuous machine activity data (e.g. CPU use, RAM/SWAP use, Network I/O) to classify malware – thus not depending on network traffic or API calls that can presently be encrypted or obfuscated by the malware itself. Malware can detect and avoid virtual machines but it cannot avoid leaving a behavioural footprint, so we use these data to classify malware. The introduction of continuous data offers the opportunity to identify fuzzy activity boundaries in unseen attacks; (ii) the identification of over-fitting in some machine learning algorithms when using cross validation, leading to a drop in performance on unseen data (representing zero-day attacks), while other algorithms that are outperformed on cross validation show less evidence of overfitting when tested on unseen data; and (iii) using Self Organising Feature Maps (SOFM) to process machine activity data to capture fuzzy boundaries between machine activity and classes (malicious or trusted). This approach overcomes overfitting issues presented by other machine learning methods such as decision trees and support vector machines (for which we present performance results as a baseline for the SOFM improvement). An additional benefit of the SOFM data processing is the intuitive visual representation of machine activity data. We present the node activation frequencies of two competing SOFMs to develop behavioural visualizations for malicious and benign behaviour that have implications for use in Security Operation Centres (SOCs) for human analysis and visual detection of malicious behaviour.
