Recent years have seen major changes in children’s reading practices, with more reading now taking place in a digital environment, often in online, multimodal contexts involving the integration of text with images, videos, and audio files (Ng & Bartlett, 2017). Rideout, Foehr, and Roberts, (2010) reported that American students (8–18 year olds) spent three times as much time reading on a digital device as they spent reading traditional, printed materials, a gap that is unlikely to have reduced in the intervening years.
There are many similarities between the processes involved in print and digital reading, and the mode in which a test is presented has been shown to have a comparatively small effect on reading test performance. A meta-analysis examining the effect of test mode (pencil-and-paper or computer-based) showed no statistically significant effect on reading achievement scores (Wang, Jiao, Young, Brooks, & Olson, 2007), although it has been argued that for tests involving extensive reading passages, performance is lower on computer-based tests (CBT) compared to paper tests (Paek, 2005).
However, until recently, most comparisons of digital- versus paper-based reading have tended to focus on digital texts in a general sense (i.e., including pdfs, Word documents, etc.), rather than specifically analysing differences associated with reading in an online, internet environment. Yet, as Mullis, Martin, and Sainsbury (2015) note, internet reading is gradually becoming one of the main ways in which pupils acquire information, so educators are particularly interested in how children read in an online environment, and how “transferable” reading comprehension skills are from paper to online. There is increasing evidence that while reading successfully in an online environment requires many of the same general comprehension skills and strategies as reading on paper, they may be used somewhat differently to how they would be used in a traditional text environment.
Coiro and Dobler (2007) found that compared to a print environment, students reading online used both similar and more complex applications of strategies for inferential reading and for self-regulation. Students also used more complex applications of prior knowledge from four sources: the topic; printed informational text structures; informational website structures; and, web-based search engines. Research suggests that successful internet reading requires making strategic decisions about what texts to read and a sequence for reading them (Cho & Afflerbach, 2015), and that some online reading skills do not have a paper equivalent, particularly in relation to evaluating reliability of information (Afflerbach & Cho, 2010). As such, as Leu (2017) noted “By gathering information about the online reading ability of fourth grade students, we generate greater awareness and understanding of these differences and that allows us to introduce classroom experiences to develop proficiency in the additional areas required for online reading”.
This paper draws on data from the 2016 Progress in International Reading Literacy Study (PIRLS, (Mullis, Martin, Foy, & Hooper, 2017; Mullis, Martin, Foy, & Hooper, 2017) to explore the extent to which there is variation between paper-based and online reading in terms of the characteristics associated with reading achievement. As this is the first multivariate analysis of the PIRLS 2016 dataset in Ireland, an exploratory approach is adopted whereby numerous explanatory variables are considered and used in the modelling process. The main research questions addressed in this study are:
What are the predictors of reading achievement as measured in paper-based format (PIRLS)? What are the predictors of reading achievement as measured in online format (ePIRLS)? What, if any, are the differences between the predictors of achievement for each mode of assessment?
More specifically, we examine if 1) similar associations are found between characteristics of the child’s home background and home climate and achievement in paper and online reading, 2) use of a computer at home or school is differentially associated with paper and digital reading, and 3) reading attitudes and engagement are differentially associated with paper and digital reading, and 4) if school or class characteristics are differentially associated with paper and digital reading.
The remainder of this paper is structured as follows. Section 1.1 briefly reviews research on associations between pupil and home background characteristics and academic achievement. Section 1.2 considers the association between computer usage and academic achievement. Section 1.3 outlines how reading is assessed in PIRLS, and in a related, but separate, digital assessment called ePIRLS. Section 1.4 describes Ireland’s performance on PIRLS and ePIRLS. Section 2 presents the data and method used in the current study. Section 3 describes the results of the analysis. Section 4 provides a more detailed discussion of the results.
1.1. Pupil and home background factors associated with achievementAcross different age groups and assessments, gender differences in favour of girls have been found for both print and online reading (e.g., Mullis et al., 2017a, 2017b; OECD, 2016b). Using data from over 30 countries, Gustaffson, Hansen, and Rosén (2013) suggest that one explanation for the achievement advantage of girls in reading is a stronger emphasis placed on literacy skills in the homes of girls compared to boys prior to starting school. In almost all the countries they examined, parents reported a stronger emphasis on early literacy activities than early numeracy activities when their child was a girl compared to when their child was a boy. Also, in some countries, including Ireland, parents reported a higher frequency of books at home for girls than boys (although this could be attributable to the child rather than the parents). An analysis of gender differences in performance on international reading assessments across age groups in Nordic countries (Solheim & Lundetræ, 2018) found that the magnitude of gender differences may be associated with features of the assessment, including text type (e.g., fiction/non-fiction, continuous/discontinuous), item format (multiple choice or constructed response), aspects of reading assessed (e.g., reflecting on text, interpreting text or retrieving information), and study implementation (e.g., approach to sampling, assessment duration).Characteristics of pupils’ home environments have been consistently shown to be associated with academic achievement. For example, across international contexts and studies, and using different outcome domains, positive associations are almost always found between parental education, parental income, access to books in the home, and academic achievement at both primary (e.g., Kavanagh, Shiel, Gilleece, & Kiniry, 2015; Mullis, Martin, Foy, & Drucker, 2012; Mullis, Martin, Foy, & Hooper, 2016; Mullis, Martin, Foy, & Hooper, 2016; Mullis et al., 2017a) and secondary level (e.g., OECD, 2016b). Numerous theories have been used to attempt to explain the relationship between socioeconomic status and achievement, including Bourdieu (1977) concepts of economic, cultural and social capital. Cultural capital incorporates the skills, attitudes, and use of language, as valued in the education system. Higher levels of parental education and higher status occupations are associated with higher levels of cultural capital. Children who start school with higher levels of cultural capital are better positioned to benefit from the education system as there is a better match between their home and school environments. Educational studies operationalise measures of the various types of capital in different ways but typically employ measures of parental occupation, home educational resources and indicators of material wealth, and the number of books in pupils’ homes (e.g., Hooper, Mullis, & Martin, 2015; OECD, 2016b).Turning to attitudinal factors, Ng and Graham (2017) review the role of motivation, self-efficacy, and reading engagement in predicting reading achievement and note that reading motivation accounts for unique variance in reading comprehension over and above the variance explained by other variables. They also note that reading motivation is a multidimensional construct, incorporating competence beliefs, extrinsic reasons, and social purposes for reading. Motivation constructs have been shown to be semi-independent, with motivation for reading narrative texts somewhat distinct from motivation for informational texts (Guthrie et al., 2007).
1.2. Computer use and academic achievementNot surprisingly, given the myriad of potential uses for computers in the classroom, there is not a simple association between computer usage at school and academic achievement. For example, a cross-national analysis of the reading achievement of fifteen year olds found that students who made below-average use of computers at school had the highest performance in digital reading (OECD, 2016a). Compared to those who had no computer use at all, limited use of computers at schools was associated with higher achievement but levels of computer use above the OECD average were associated with significantly poorer results. Findings were similar for digital reading and print reading.However, Wenglinsky (2006) argues that quality of work is more important than amount of time spent using a computer, particularly for younger students (fourth and eighth graders), with positive effects on achievement associated with using computers to solve the types of complex problems that tap into higher-order thinking skills. This suggests that teacher competence in ICT usage is important. Also important are pupil characteristics - for example, pupils with Special Educational Needs (SEN) may find particular benefits from assistive technologies, including spell checkers and speech recognition systems (e.g., Maor, Currie, & Drewry, 2011).Data from PIRLS 2016 indicate that, relative to the PIRLS international average, Irish pupils have below average access to computers for reading lessons. For example, fewer than 3% of Irish pupils had their own device compared to an international average of 10%, while 18% had access to shared computers in their classroom, compared to an international average of 24%. Similarly, Irish pupils were below the PIRLS international average in frequency of use of computers or tablets for a variety of school-related work. For example, 46% indicated that they never or almost never used a computer at home for schoolwork, compared to an international average of 23%. Similar poor levels of access were reported in a census of technology in Irish schools, in which some primary teachers also reported that their ICT resources were so poor that use was often limited to specific purposes, or for specific pupils (e.g., additional support for pupils with SEN) (Cosgrove et al., 2014). An evaluation of ICT in Irish schools conducted about a decade ago similarly found that special education teachers made greater use of ICT resources than mainstream class teachers (Department of Education and Science (DES) (2008)).An examination of how increased broadband provision in Ireland was linked to classroom internet usage and educational performance showed that teachers’ use of internet in the classroom doubled in the two-year period following the provision of broadband to schools. Furthermore, use of the internet in class was associated with significantly higher average achievement in mathematics and to a much lesser extent, in reading (Hyland, Layte, Lyons, McCoy, & Silles, 2015). The models of Hyland et al. controlled for school disadvantaged status, as it has been shown that schools serving larger numbers of pupils from disadvantaged backgrounds (where achievement is typically lower) make greater use of technology in the classroom (McCoy, Quail, & Smyth, 2012; McCoy, Smyth, & Banks, 2012). It is important to note however that the study by Hyland et al. was not designed as an experiment but rather made use of coincidental timing of the rollout of broadband to some schools and data collection for another study. It is therefore quite possible that unmeasured variables (in particular, the more or less contemporaneous introduction of a national literacy and numeracy strategy (Department of Education and Skills (DES) (2011))) have a confounding effect on the findings.Turning to access to, and use of, technology at home, research in Ireland has mainly shown positive associations with performance in reading and mathematics at primary level (Casey, Layte, Lyons, & Silles, 2012; Kavanagh et al., 2015). Kavanagh et al. found that access to a computer at home was associated with higher achievement on reading and mathematics, but that ownership of a mobile or smartphone, while positively associated with achievement at sixth grade, was negatively associated with achievement at second grade. Casey et al. (2012) reported that, relative to children who reported having a computer at home but not using it, children who used the home computer either ‘a little’ or ‘a lot’ had significantly higher performance in reading and mathematics. Although children who reported ‘a little’ computer use had significantly higher reading (but not mathematics) scores than children who reported ‘a lot’ of use, this difference was not statistically significant once social class variables were included as controls in the models. Thus, any computer usage was associated with higher achievement compared to no computer usage. Further, only some types of activities (i.e., surfing the internet for fun, doing projects for school, and emailing) were associated with higher achievement, whereas others (instant messaging, downloading music, and watching movies) were negatively associated with achievement. Again, this links to the argument that the nature of computer activity is of at least as much importance as the amount of computer activity.
1.3. How PIRLS and ePIRLS measure reading achievementPIRLS is the largest international comparative assessment of reading achievement at primary level, assessing pupils in their fourth year of formal schooling (2017b, Mullis et al., 2017a). First run in 2001, it takes place every five years. Fifty countries and 11 benchmarking regions participated in the 2016 cycle of PIRLS, which included a new element called ePIRLS, an assessment of online reading skills. Ireland was one of 14 countries and 2 benchmarking regions that also participated in ePIRLS. As they use different modes of assessment and are designed to assess related, but different, skills, there is no overlap in test content between PIRLS and ePIRLS.The PIRLS assessment is designed to assess two purposes for which children read – for literary experience, and, to acquire and use information (Mullis et al., 2015). It is in paper format, and uses a matrix sampling technique, in which 12 texts are systematically presented across 16 different test booklets (Martin, Mullis, & Foy, 2015). Each booklet contains one “Literary” and one “Informational” text. Total testing time is a maximum of 80 min, with a break between texts.The digital ePIRLS assessment comprises Informational texts only. Pupils complete two of five randomly assigned “ePIRLS projects”. Projects require navigation through webpages in a closed, fake internet environment, containing features such as tabs, pop-ups, and hyperlinks. Pupils are guided through the project by a teacher avatar, who prompts with questions about the online content. Total testing time is a maximum of 80 min, with a break between projects.Both PIRLS and ePIRLS assess four comprehension processes: focus on and retrieve explicitly stated information; make straightforward inferences; interpret and integrate ideas and information; and, evaluate and critique content and textual elements. These processes are represented by two scale scores (Retrieving and straightforward inferencing, and, Interpreting, integrating and evaluating), both of which are available for PIRLS and ePIRLS.In addition to achievement data, PIRLS gathers a large amount of contextual data through questionnaires distributed to participating pupils, parents, teachers, and school principals.
1.4. Summary of Ireland’s performanceIrish pupils performed very well on PIRLS and ePIRLS (Eivers, Gilleece, & Delaney, 2017; Mullis et al., 2017a,b,). On PIRLS, just two countries – the Russian Federation and Singapore – had significantly higher mean scores than Ireland. On ePIRLS, only Singapore had a statistically significant higher mean score. Ireland was one of only two countries (along with Canada) where there was no significant difference between performance on PIRLS and ePIRLS. In Ireland, there was a strong correlation (r = 0.8) between scores on the two assessments. In seven participating countries, the average ePIRLS score was significantly higher than PIRLS, while in five countries, achievement in PIRLS was significantly higher than in ePIRLS.As 2016 was the first time that ePIRLS was conducted, there is (to the authors’ knowledge) no substantive research examining reasons behind relative national and/or individual strengths and weaknesses on the two assessments. However, Mullis et al. (2017b) note that an informal discussion among PIRLS National Research Coordinators suggested that, at national level, stronger ePIRLS performance is associated with higher levels of computer use in school. They also note that countries with a relative strength on ePIRLS tended to have had higher access to digital devices in the home. As noted earlier, Ireland was below the PIRLS average for access to digital devices in school. However, Ireland is also slightly above the PIRLS average for home access to devices, and on the frequency with which pupils use devices for non-schoolwork activities. The combination of these factors may have contributed to Ireland’s balanced performance on PIRLS and ePIRLS.On PIRLS, gender differences in Ireland were somewhat smaller than the corresponding international average: a 12-point gap in Ireland in favour of girls, compared to 19 points on average internationally. Looking only at the fourteen countries that participated in both PIRLS and ePIRLS, the average gender gap on paper-based PIRLS was 14 points. Turning to ePIRLS, the gender gap in Ireland (11 points) was about the same as the international average (12 points). In Ireland, girls showed a slight relative strength (5 points) on ePIRLS versus PIRLS Informational reading, while boys’ performance was almost identical on both measures.
