1.1. MotivationEnergy efficiency is critical to performance improvement of computer systems at all levels, ranging from devices and transistors to large information processing systems, and from small sensors at the edge of the Internet of things to large-scale data centers for cloud computing and high-performance computing. Performance improvement is limited by energy inefficiency that results in computing systems overheating and experiencing thermal management problems. The electronic circuits in computer chips still operate far from any fundamental limit to energy efficiency. Future performance improvement is now severely limited by the amount of energy taken to manipulate, store, and transport data. The performance-energy crisis requires revolutionary (not evolutionary) approaches to addressing this challenge. Such investigation aligns with the recently (2015/10/15) announced Nanotechnology-Inspired Grand Challenge for Future Computing, which aims at creating a new type of computer that can proactively interpret and learn from data, solve unfamiliar problems using what has been learned, and operate with the energy efficiency of the human brain. This also aligns with the Executive Order of Creating a National Strategic Computing Initiative (signed by the US President on 2015/7/29), whose primary objective is to accelerate the delivery of a capable exascale computing system.
1.2. Related researchIt has long been recognized that power consumption in high-performance computer systems is a cost metric which increases according to the well known Moore's law. It has been reported that power density will soon reach that of a nuclear reactor [66]. If not properly handled, such increased energy consumption will cause serious problems economically, ecologically, and technically [16], [19], [23], [62]. Reducing processor energy consumption has been a fundamental research issue which is theoretically challenging and practically useful. Developing energy-efficient computing systems has attracted extensive research efforts in recent years [15], [17], [18]. Refs. [1], [8], [9], [64], [65], [66], [77] provide several comprehensive surveys of an explosive body of literature on existing research on power-aware computing and communication.Many thermal-aware hardware and software design techniques have been developed to reduce power consumption in computing systems at various levels. In particular, software techniques for power reduction can be implemented by a mechanism called dynamic voltage scaling (equivalently, dynamic frequency scaling, dynamic speed scaling, dynamic power scaling). The underlying idea is that based on the fact that many existing technologies and commercial processors support dynamic voltage (frequency, speed, power) scaling, a power-aware algorithm changes supply voltage and clock frequency appropriately at run time to optimize a combined consideration of power and performance tradeoff.In a seminal work [67], [69], Weiser et al. introduced the technique of dynamic power management at the operating system level, which refers to supply voltage and clock frequency adjustment schemes implemented while tasks are running. These energy conservation techniques attempt to explore various opportunities for fine tuning the energy-delay tradeoff [63]. Since then, power-aware task scheduling has been extensively studied by numerous researchers. These investigations were conducted (1) to schedule tasks with arrival times and deadlines on a uniprocessor computer with minimum energy consumption [4], [5], [6], [12], [29], [32], [46], [47], [48], [70]; (2) to schedule independent or precedence constrained tasks on uniprocessor or multiprocessor computers in real-time applications [3], [21], [24], [25], [27], [31], [35], [49], [51], [54], [57], [58], [60], [61], [68], [73], [74], [75], [76]; (3) to deal with the energy-delay tradeoff [7], [11], [13], [20], [30], [34], [45], [59], [71], [78]; (4) to develop high-performance and energy-efficient computing systems [10], [15], [17], [18]; (5) to improve system level power management [14], [26], [33], [50], [55]; (6) and to conduct other studies [2], [53], [72]. In a series of papers [36], [37], [38], [39], [40], [41], [42], [44], power allocation and task scheduling with energy and time constraints were considered as combinatorial optimization problems on multiprocessors with dynamically variable voltage and frequency and speed and power.It has been assumed by much existing research that several important variables, e.g., clock frequency and supply voltage and execution speed and power supply, can be changed continuously in any range. However, such an ideal and simplistic assumption does not apply to the currently and commercially available processors, which can only provide a few discrete and even irregular adjustment levels [28], [56]. A number of researchers have investigated task scheduling on processors with discrete and irregular speed levels. On a uniprocessor computer, a polynomial time algorithm was developed to find an optimal preemptive schedule with minimum energy consumption [32], [47], [48]. On multiprocessor computers with discrete speed levels, an analytical study has been performed for nonpreemptive task scheduling with energy and time constraints [43]. Furthermore, in real-time multiprocessor systems, such realistic processors were also considered [52], [74].
1.3. Our contributionsIn reviewing the current studies of energy-efficient task scheduling, we find that there are two different approaches. On the one hand, there are investigations based on ideal power consumption models. The advantage of this approach is that algorithms that take advantage of these models can be developed, so that the performance of these algorithms can be analyzed and their solutions can be compared with optimal solutions. The disadvantage of this approach is that these ideal power consumption models may not be available in the current technologies. On the other hand, there are investigations based on more realistic power consumption models. The advantage of this approach is that algorithms developed for these models can be directly applied in real applications. However, the disadvantage is that it is very difficult to find useful information about the optimal solutions which are critical in evaluating the performance of heuristic algorithms.In this paper, we consider energy and time constrained scheduling of independent sequential tasks on a multiprocessor computer with bounded and discrete and irregular clock frequency and supply voltage and execution speed and power consumption levels. This is a very realistic power consumption model. Unfortunately, for processors with bounded and discrete and irregular clock frequency and supply voltage and execution speed and power consumption levels, previous lower bounds do not apply, since these lower bounds are derived for processors with unbounded and continuous and regular clock frequency and supply voltage and execution speed and power consumption levels.Our approach in this paper has two unique features. First, we develop algorithms that are applicable to all multiprocessor computers with bounded and discrete and irregular clock frequency and supply voltage and execution speed and power consumption levels. Second, we evaluate the performance of these algorithms on multiprocessors with a regular or close-to-regular power consumption model, for which, we have lower bounds for the optimal solutions. By using these lower bounds, we can perform both analytical study and experimental evaluation of the performance of our algorithms. Thus, we have algorithms which are practically useful and whose performance compared to optimal solutions is also known. Our approach has successfully overcome the shortcomings of all existing investigations in power-aware and energy-efficient task scheduling.We find that for both energy and time constrained scheduling, there are two subproblems, i.e., power allocation and task scheduling. Each heuristic algorithm for energy or time constrained scheduling must include methods for these two subproblems. Our algorithms are classified into two categories, i.e., pre-power-determination algorithms (i.e., allocating power first and then scheduling tasks) and post-power-determination algorithms (i.e., scheduling tasks first and then allocating power). All our algorithms are based on two fundamental techniques. First, tasks should be distributed to the processors with balanced workloads. Second, tasks on the same processor should be allocated roughly the same power. We propose the following algorithms:•Nine pre-power-determination algorithms for energy constrained scheduling;•Nine post-power-determination algorithms for energy constrained scheduling;•Nine pre-power-determination algorithms for time constrained scheduling;•Nine post-power-determination algorithms for time constrained scheduling.The performance of these algorithms are evaluated analytically and also experimentally by comparing their solutions with optimal solutions, where the optimal solutions are obtained for regular or approximately regular power consumption models. We find that the combination of the largest execution requirement first method for task selection and the longest time first method for list scheduling yields the best performance.The rest of the paper is organized as follows. In Section 2, we present our power consumption model and a processor model with bounded and discrete and irregular clock frequency and supply voltage and execution speed and power consumption levels. In Section 3, we describe our pre-power-determination and post-power-determination algorithms for energy constrained scheduling. In Section 4, we describe our pre-power-determination and post-power-determination algorithms for time constrained scheduling. In Section 5, we define our performance measures. We also derive lower bounds for the optimal solutions and analyze the performance of our algorithms when a processor has a regular or close-to-regular power consumption model. In Section 6, we demonstrate and discuss our experimental results. We conclude the paper in Section 7.
