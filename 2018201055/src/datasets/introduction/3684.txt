In real-life, emotion plays an important role in the human–human interaction. Considering the evolving nature of the machine, we look forward human–machine interaction through BCI nowadays. Brain-Computer Interface (BCI) is an interface between brain and outside world without the direct intervention of any muscular activity. BCI technology has mainly consisted of four sections, such as Signal acquisition, Signal processing, Feature extraction and classifications, Application Interface. BCI has several applications like P300 speller, wheelchair control, robotic arm movement, and cursor movement. In our previous paper (Chakladar & Chakraborty, 2017), we had proposed an efficient algorithm of cursor movement to reach the desired target in minimum time. For building an effective human–machine interaction system like Brain-computer interfacing, the most prerequisite is to develop an efficient emotion recognition system (Wang, Nie, & Lu, 2014). According to the two-dimensional model of emotion described by Davidson, Schwartz, Saron, Bennett, and Goleman, 1979, emotion is represented in two-dimensional space (arousal and valence) as shown in Fig. 1. Valence represents the quality of emotions from negative to positive due to higher frontal activity in alpha power, whereas arousal represents quantitative excitation from passive to the active emotional state of higher beta power in the parietal lobe. The recognizability of emotions depends on how well the EEG features are mapped to the arousal-valence 2D model (Bos, 2006). Emotion can be explained in many ways (1) visual (images/pictures), (2) audio-visual (clips/video clips) and (3) audio (songs/sounds) (Murugappan, Ramachandran, & Sazali, 2010) etc. Various studies show that peripheral physiological signals like Electrocardiogram (ECG), Skin Conductive Resistance (SCR), and Blood Volume Pressure (BVP) can also change the emotions (Picard, 2000). Davidson and Fox, 1982 suggested that frontal brain activity is related to positive and negative emotions. A probabilistic classifier and “perceptron convergence” algorithm are used for emotion classification (Yoon & Chung, 2013). Previously, several works have been done on dimension reduction of the input features, but this paper focuses on a new dimension reduction technique (Correlation-based subset selection) of input channels and classifies those input based on four different types of emotions (positive, negative, depressed and harmony). For the sake of simplicity, here we choose four important emotions from the arousal-valence model. We select the positive, negative, angry and harmony emotion from high arousal-high valence (HAHV), low arousal-low valence (LALV), high arousal-low valence (HALV) and low arousal-high valence (LAHV) region of the arousal-valence model (Fig. 1) respectively. After performing dimension reduction process, we select emotion-specific channels for each class which gives a true prediction rate over the test data that leads to a good classification accuracy. The rest of the paper is organized as follows. In Section 2, we have described the overall flowchart of our proposed work and the algorithm of dimension reduction technique. In Section 3, we analyze the proposed algorithm and perform emotion classification of thirty-two healthy subjects. Section 4 illustrates the discussion of the entire work and list out all the observations of our work. In Section 5, we have compared our proposed work with some previous studies related to different parameters of classification. Finally, Section 6 gives the conclusion of this paper.Download : Download high-res image (75KB)Download : Download full-size imageFig. 1. Two dimensional emotional model (Davidson et al., 1979).
