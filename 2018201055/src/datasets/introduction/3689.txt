With the rapid development of Web 2.0 and the rise of online social networks, social networks have become an important tool for people to communicate with each other. Compared with traditional networks, social networks are more complex and have some special features. For example, the scale of social networks is enormous; the data of social networks are heterogeneous and from different data sources, etc. Since the most prominent property in a network is its community structure, the exploring the community structure of the large-scale social networks has become a hot aspect in social network analysis. There is no uniform definition of community structure, intuitively, a social network is typically modeled as a graph whose vertices and edges represent entities and relationships between entities respectively. Community structure in a network is always represented as a group of entities with dense connections within groups and sparse connections with other groups [1]. The community structure can be divided into two types, non-overlapping and overlapping. In real life, overlapping communities are more common than non-overlapping ones, such as a person is a student as well as a member of some clubs. Our algorithm is proposed to handle the discovery of overlapping communities.
A great deal of community discovery algorithm have been proposed to mine reasonable community structure from complex social networks in the last decades. The Kernighan–Lin algorithm [2] discovers communities by minimizing the difference between intra-edges and inter-edges. Spectral methods determine the minimum cut to separate a graph and recursively divide a network into sections where communities emerge naturally [3]. The two methods mentioned above are two typical methods to discover community structure. Grivan and Newman first propose the concept of modularity, which was utilized to discover community structure [4]. After that, modularity is becoming a measure of community quality, based on the concept of modularity, a variety of methods are derived [1]. As the sharp increase in the amount of social network data, most of the existing community discovery algorithms are not applicable to handle such large-scale data. To uncover community structure in a near linear time, Raghavan et al. proposed a distinguished algorithm named label propagation algorithm (LPA) by employing a simple label propagation during each iteration [5]. LPA is practical and simple, due to the lower time consumption of LPA, it can be easily applied to large-scale data.
However, some drawbacks, such as the formation of a monster community, weak robustness and high randomness, remain in traditional LPA [5]. When community labels in a large community stop to propagate, labels in a small neighborhood nearby have not yet spread, and the label of the big community may affect the label of the small community as well, and the small communities will be devoured. After several such phenomena, a monster community may be formed. As a result, the quality of community discovery becomes very low. In addition, during the iterative process of the algorithm, nodes are updated randomly, so there may be some less influential nodes first updated and in turn affect the influential nodes, which leads to the phenomenon of countercurrent label. Furthermore, nodes randomly select tags when the neighbor nodes have the same labels. Thus, the result exhibits high randomness, which greatly affects the stability.
In order to solve the problem mentioned above, we propose a new LPA algorithm, at the same time, we must find a way to evaluate the significance of nodes in networks. Plenty of nodes ranking measures have been proposed such as local metrics, global metrics, and random-walk-based metrics [6]. Degree centrality is a typical type of local metric [7]. Local metrics are simple but ignoring the global structure. Global metrics contain betweenness centrality [8], closeness centrality [9], etc. Global metrics are suitable to uncover the important nodes but the computation cost is high. Random-walk-based metrics, composed by eigenvector centrality [10], PageRank [11], LeaderRank [12], etc., evaluate the significance of nodes using multiple iterative operations. All the methods above are not suitable to handle large-scale networks. K-shell decomposition algorithm is a fast node ranking method for large-scale networks, which is first put forward by Kitsak et al. [6]. Traditional K-shell use the location information of nodes to calculate node influence. The most influential nodes are those located in the core of the network, which can be identified by the K-shell decomposition method. In our paper, we proposed a novel K-shell decomposition algorithm to rank nodes effectively.
Spark [13] is a fast and general open-source framework with the advantages of MapReduce for large-scale data processing, it stores the intermediate results in the memory. Spark use Resilient Distributed Dataset (RDD) [14] for sharing data in cluster applications. GraphX is a new component based on Spark for graphs and graph-parallel computation. At a high level, GraphX extends the Spark RDD by introducing a new Graph abstraction: a directed multigraph with properties attached to each vertex and edge. To support graph computation, GraphX exposes a set of fundamental operators (e.g., subgraph, joinVertices, and aggregateMessages) as well as an optimized variant of the Pregel API. In addition, GraphX includes a growing collection of graph algorithms and builders to simplify graph analytics tasks.
This paper proposed a new label updating strategy to solve the above-mentioned problems. The contributions of this paper are summarized as follows:

•A method is proposed to calculate the propagation probability and similarity between each pair of nodes with a low computational complexity which utilized the iteration information in the improved K-shell decomposition.•This paper proposed a new label updating strategy using the propagation probability and similarity between each pair of nodes, each node owns a label probability which stands for the probability of belonging to a community.•The proposed algorithm is implemented on Spark and can handle the large-scale datasets efficiently.
The remainder of the paper is organized as follows. Section 2 mainly introduces the research background of community detection algorithms in networks. Section 3 provides a comprehensive discussion of the proposed parallel label propagation algorithm based on probability and similarity and its detailed implementation. The results of the experiments conducted on artificial and real social networks are presented in Section 4. Section 5 concludes the study and presents an outline for future research.
