Breast cancer is the most common cancer among women across the globe. However, early detection and intervention substantially improve the chance of successful treatment. Screen-film mammography and full-field digital mammography are typical imaging modalities used widely by radiologists to screen for breast cancer. These imaging modalities have reduced breast cancer mortality rates over the course of 30 years [1]. Despite the ability of methods to successfully detect the early signs of breast cancer, such as irregular shape masses, a cluster of micro-calcifications, architectural distortions, and bilateral asymmetry, they suffer from some issues. High breast compression hides a lot of angular breast information, especially for dense breasts [2]; for example, overlapping breast tissues keep some suspicious lesions out of sight.
Digital breast tomosynthesis (DBT) is an imaging modality that can be used to perform high-resolution limited-angle tomography, which is able to see through layers of breast tissues. DBT produces multiple two-dimensional (2D), low-dose X-ray images (angular projections) of the entire breast by a single screening [3]. These images are subsequently processed to detect cancer or breast diseases in their early stages. In DBT, multiple projection scans are acquired by rotating the X-ray tube around the breast at a limited angular range. A quasi-three-dimensional (3D) DBT volume is generated by a reconstruction algorithm, whereby a 3D DBT is reconstructed from a small number of projection views acquired over limited angles around the breast. A reconstruction algorithm which has been used to prepare 3D DBT, is the most important post-acquisition aspect that can impact clinical DBT performance [4]. Abundant slice images from the breast provide vast information about hidden abnormalities in mammography modalities.
In DBT, radiologists have to review many more image slices per breast when compared with mammography exams. As such, computer-aided detection (CAD) systems have been developed to aid radiologists in the detection of abnormalities in DBTs. Based on the nature of DBT images, a CAD framework for detecting breast cancers in DBT images can be developed either based on 2D data [5,6] or on volume [4, 7]. The synthetically reconstructed 3D DBT cannot precisely address DBT projection view information given the limited acquisition rate of the 2D DBT scan range (an average of 24 images per scan). This drawback introduces an inherent imprecision into the CAD framework based on quasi-3D volumes. In this study, we designed a CAD framework based on 2D slices of DBT data to avoid the drawback stated above while taking advantage of a wide range of analysis techniques on digital mammograms to analyze DBT images.
In spite of the fact that traditional CAD studies have focused on adopting a variety of hand-crafted features in supervised manners [5, 8], some CAD approaches that utilize deep learning models have been proposed [[9], [10], [11], [12]]. They have resulted in several breakthroughs when analyzing and learning image patterns through deep learning methods [13, 14]. Deep learning models build high-level image features from low-level ones to represent observed data inside a hierarchical structure. Due to the difficulty and low reliability of finding proper features manually, we used deep learning approaches in our CAD architecture to extract features of 2D slices automatically.
After extracting information from DBT slices, the major task of the CAD through slice-based DBT analysis relies on choosing a learning method to combine the information derived from slices while labeling DBTs. Multiple-instance learning (MIL), as a weakly supervised learning algorithm, achieves the best performance when annotating data (bag) consisting of unlabeled instances [15]. An MIL model assumes that a positive bag (cancerous DBT) includes at least one positive instance. This assumption is similar to the approach used by radiologists to analyze DBT images. Even if one corresponding slice is cancerous, the entire DBT image is deemed cancerous. When DBT is denoted as a bag and its slices as its corresponding instances, then the task of DBT annotation is based on information extracted from 2D slices; this is a well-suited task for MIL approaches.
In this study, our work focuses on exploring a novel CAD framework for DBT imaging, in which the 2D image slices are analyzed. We present a CAD architecture for the detection of masses in DBTs. This comprises of deep convolutional neural network (CNN) architecture, which automatically extracts the appropriate features of 2D slices, as well as MIL with randomized trees, which is used to classify DBT samples based on the extracted information from 2D slices. The framework has been developed and evaluated using a DBT dataset, which was prepared by radiologists at Massachusetts General Hospital. Experimental results on the DBT dataset show that the proposed CAD model achieves the highest level of classification when compared to two other approaches, hand-crafted, feature-based MIL and deep cardinality-restricted, Boltzamnn machines-based CAD models. To our knowledge, this is the first DBT study to employ deep CNN and MIL to automatically classify DBT images.
