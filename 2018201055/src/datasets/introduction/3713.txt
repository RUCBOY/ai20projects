Fine-grained object classification is a well know challenge in computer vision, and there has been some previous work on bird species recognition using individual images (Gavves et al., 2015; Berg et al., 2014; Berg and Belhumeur, 2013; Huang et al., 2013; Branson et al., 2014; Duan et al., 2012). Robust automated classification would be of potential benefit to ecologists studying bird populations; however, there are significant limitations with existing works, which are trained and tested on high quality images. Such images are difficult to capture in real-world settings. In addition, most existing methods are not fully automated, limiting the data which can be processed. For useful deployment, such systems need to classify birds in flight, and this has also not yet been fully studied. In-flight classification introduces challenges around image quality, shape, and image noise, but also presents some opportunities: the flight patterns of birds are known to vary across different species (Bruderer et al., 2010; Duberstein et al., 2012) and are used by human observers to assist recognition. Very few existing studies (Cullinan et al., 2015; Matzner et al., 2015) have made use of motion features in this way, and these have only differentiated small numbers of species. None has previously combined appearance and motion features to facilitate improved classification.
We focus on this challenge, and present our system which can reliably classify thirteen bird classes in flight. In our previous work (Atanbori et al., 2016), we presented separate sets of appearance and motion features, and showed that our appearance features out-performed the state-of-the-art (Marini et al., 2013). We further showed in Atanbori et al. (2015) that motion features can be used for real-time classification. In this paper we present the following new contributions:
1.We combine appearance and motion features to classify bird species in flight.2.We introduce an extended dataset, which contains video data of thirteen bird classes. This presents a significant challenge, and is representative of real-world monitoring contexts.3.We compare feature selection methods, with four standard classifiers, Random Forest (RF), Random Tree (RT), Naive Bayes (NB), and Support Vector Machines (SVM), and compare performance.4.We compare our method with two state-of-the-art deep learning models (VGG19 and MobileNet), which are used to classify individual images from our dataset.5.We have demonstrated that the most significant motion features improve correct classification rate compared to using appearance features only.
The remainder of this paper is structured as follows. In Section 2, we review existing work, including applications to other species. In Section 3, we introduce our dataset and processing architecture, then proceed to Section 4 which describes our motion and appearance features. In 4 Feature extraction, 5 Feature selection, 6 Experiments we describe our feature selection, classifiers, and experimental setup, and conclude in 7 Results, 8 Conclusion, by presenting our evaluation and results.
