Beyond object recognition in images, action recognition in videos is a more complex and semantic task which is required to understand not only what are in videos but also the movements and relations between them. As video is a temporal sequences rather than a set of order-less images, methods processing each frame independently is insufficient for action recognition. One of effective methods dealing with sequence data is the Long Short Term Memory networks (LSTMs) [1]. The output of LSTMs is depending on the current input and previous state, which makes it very suitable to model sequence dependency. Many efforts that use LSTMs to model the temporal sequence of video frames have been made, such as [2], [3], [4]. Most of those models apply Convolutional Neural Networks (CNNs) to extract the feature from each frame, and then feed the feature sequence into LSTMs.
However, video data is very enormous and has a large variation. As Fig. 1 depicts, the backgrounds are varied not only in different videos but also in the same video. As a result, feature extracted from the whole frame contains much useless information which will harm the action recognition performance. Inspired by the human visual system that can focus on different parts of a scene as needed to get the most relevant information rather than attending all parts with no differences [5], [6], attention models have been attracting researchers’ interests in many applications, such as machine translation [7], [8], image and video captioning [9], [10], [11]. As attention models can dynamically focus on the most relevant parts, we can achieve a better performance.Download : Download high-res image (204KB)Download : Download full-size imageFig. 1. Examples for action riding bike. The picture under each frame is the visualization of attention map learned by our model for the corresponding frame and the brightness indicates the strength of attention.
Generally speaking, attention models can be divided into soft attention and hard attention. Soft attention weights each part and adds them up to form the last representation, while hard attention only selects one part from all candidates exclusively. However, those attention models just compute attention weights for all parts independently and discard the spatial-temporal relations between them which are helpful for attention weights computation. There exists a common observation that in the video columns, if a region area is a crucial part for recognition task, its neighbour regions in spatial and temporal dimensions have high possibility of being crucial parts. Therefore, it is better to build attention models using this spatial-temporal relations.
Enlightened by the input gate function of LSTMs that can dynamically determine how much information should be imported into the network and its ability of modeling sequential correlations, we propose a novel attention mechanism that leverages the gate system of LSTM to compute the attention weights for action recognition. The proposed attention mechanism is embedded in a 3D recurrent attention network to focus on important regions for action recognition. Our model realizes a more accurate attention by exploring spatial-temporal relations between regions from intra and inter frames. For better attention computation, we also derive a new attention unit from the standard LSTM unit. The newly designed attention unit simplifies and improves the gates system and information computation to let our model learn attention weights from its input gate. We evaluate our proposed recurrent attention network on the UCF101, HMDB51 and Hollywood2 datasets, and experiment results demonstrate our model outperforms other attention models, especially with 3.0, 3.1 and 3.4 percentages of improvement respectively in three datasets compared with the soft attention model.
The contributions of our model can be summarized as following:

•We propose a new attention mechanism that leverages a novel attention unit derived from the standard LSTM unit for better attention. Our new attention unit is inspired by the gate system of LSTM and how important the local part is only depends on the value of its input gate.•We apply our proposed attention mechanism for action recognition in videos. Our attention mechanism can explore the relations between different local parts within the same and neighbouring frames to compute the attention weights.•We conduct many experiments in three datasets. The experiment and visualization results show that our method achieves significant improvements compared with other attention models.
