An expression is a realistic and mighty between human beings for the approach of communication. Human beings convey their expressions through the body and facial signals, reaction changes and tone of voice. In a control system, transform the reaction changes, human being expressions into valuable guidelines using the scheme is namely consistent expression observation. The human being doesnâ€™t express themselves at all times via reactions and languages so expression recognition is a braving task. Human FER is a multidisciplinary region together with speech analysis, machine learning, psychology and computer vision. Face expressions act as a fundamental role in Human-Computer Interaction (HCI) and measured as dominant of one to one communication subsequent to speech signals (Qayyum et al., 2017).
Facial nerve gives the motions to legion muscles which are affixed to the facial skin are facial expressions. Clearly adept to produce different facial expressions such as angry, sadness, happy, fear, disgust, surprise by human beings (De la Torre and Cohn, 2011). Currently, FER systems are broadly used in various research fields, for example, laptop games, detection of mental disorder, driver exhaustion detection human-computer interface, e-Learning, and other emerging applications (Chang, 2017).
In general Facial Expression Recognition holds three steps. The first step is face acquisition and it holds face region detection and localization. The second step is the facial data extraction, here appearance based and geometric features are extracted. The third step is the expression recognition and it classifies the expression. Classification is the important role in FER and the large number of classifiers are used likely neural network classifiers, fuzzy classifiers, etc., (Tian et al., 2011). The face tracking and face recognition area achieves a lot of enhancement and expansion in modern days. The common approach of facial feature description is divided into two groups. The first group follows the holistic manner in which the features are getting from the entire face image. The second group follows local manner, here the features are getting from the parts of the face image (Jameel et al., 2016, Yang and Bhanu, 2012).
Uddin et al. proposes an FER system which uses the novel feature extraction method called Local Directional Position Pattern (LDPP). The texture features are extracted by using LDPP, Principal Component Analysis (PCA) and Generalized Discriminant Analysis (GDA). Next, the expressions are characterized by using Deep Belief Networks (DBN) (Uddin et al., 2017). Sajjad et al introduces the mixture of Histogram of Oriented Gradients (HOG) and Uniform - Local Ternary Operator (U-LTP) to extract the appearance, shape and textural features of the entire face image. The features are combined into the single feature vector and classified using the Multiclass SVM classifier (Sajjad et al., 2017).
Kamarol et al. proposes the FER and intensity estimation based on weighted voting scheme. The feature extraction is achieved through the Active Appearance Model (AAM) and extracts the geometric features. The classification is performed by using the Hidden Markov Model (HMM) (Kamarol et al., 2017). Mistry et al. proposes the facial emotion recognition system that contains three major stages such as feature extraction, feature optimization, and emotion recognition. The modified Local Binary Pattern (LBP) descriptor is used for feature extraction which produces the primary specific facial representation. The feature optimization is achieved through the Particle Swarm Optimization (PSO) algorithm and classification are performed by diverse classifiers (Mistry et al., 2017).
Baddar et al. suggests the Siamese networks with two objective functions for FER with the consistent illumination. The first objective function is conscientious for expression class classification error. The second objective function is conscientious to variation among Convolutional Neural Networks (CNN) for feature minimization (Baddar et al., 2017). Nazir et al. propounds the FER using HOG based transformed features. The HOG features are extracted from the face image and they are transformed using Discrete Cosine Transform (DCT) which stores the high variance features. The RF (Random Forest), KNN (K-Nearest Neighbor) and Sequential Minimal Optimization (SMO) classifiers are used to classify these features (Nazir et al., 2017).
Muqeet et al. introduces the combination of LBP and Directional Wavelet Transform (DIWT) for facial feature extraction. The multi-resolution analysis based descriptor is formed from LBP histogram features in which these are extracted from the DIWT subbands (Abdul and Holambe, 2017). Meena et al. proposes the improved FER which can be performed with Graphical Signal Processing (GSP). Here the mixture of Discrete Wavelet Transform (DWT) and HOG features are extracted which can be reduced with the help of GSP and the KNN classifier is used for classification of these reduced features (Meena et al., 2017). Arshid suggests the Multi-Stage Binary Pattern (MSBP) for FER which generates 16-bit code. Two scenarios of experiments are performed such as holistic and zone based. The holistic gives the better performance for expression recognition than the zone based scenario (Arshid et al., 2017) (Multistage binary).
In this paper a novel work is proposed which exploits the existing descriptor LDN with the new descriptor DGLTP which extracts the texture features for effective FER. The major contribution of this paper is EMDBUTMF method is used for noise reduction, LDN and DGLTP descriptor is used for extracting texture features from noise-free facial image, SVM is used for recognition of expressions.
The rest of the paper is structured as follows. Section 2 gives the brief description and working of the proposed methodology. Section 3 illustrates the experimental results and discussion of the proposed method. Section 4 explains the conclusion of the proposed method.
