The computation of solutions maximizing the social welfare, i.e., maximizing the total “happiness” of the advertisers, in sponsored search auctions (SSAs) strongly depends on how such happiness is defined. Clearly, the more clicks their ads receive, the more content advertisers are. The number of clicks received by an ad is usually modeled by means of a suitably defined click-through rate (CTR) function. A naive CTR would, for instance, only consider the quality of the ad itself (e.g., “better” ads receive more clicks). However, one cannot overlook the importance of externalities in this context: specifically, slot-dependent externalities (i.e., ads positioned higher in the list have a higher chance to get a click) and ad-dependent externalities (e.g., the ad of a strong competitor – e.g., BMW – shown in the first slot can only decrease the number of clicks that the ad – e.g., of Mercedes – in the second slot gets).
Related Work. Much research focused on modeling externalities in SSAs and providing algorithms for the resulting optimization problem. On one hand of the scale, there is the simple, yet neat, cascade model [1], [6], [8], [12]. In the cascade model, users are assumed to scan the ads sequentially from top to bottom and to click on ad ai shown in slot sm with a probability that is proportional to the product of the intrinsic quality qi of the ad, the relevance λm of slot sm (slot-dependent externality) and the continuation probability (i.e. the probability that the user, having looked at an ad, continues to the next ad) of all the ads allocated to slots s1 through sm−1. A host of results is proved in this model as the input parameters vary (e.g., λm∈{0,1} rather than λm∈[0,1]). In its more general version, the optimization problem of social welfare maximization is conjectured to be NP-hard, shown to be in APX (i.e., a 1/4-approximation algorithm is given) and shown to admit a QPTAS (a quasi-polynomial time approximation scheme) [12]. In addition to its unknown computational complexity, the cascade model has two main limitations to be considered a satisfactory model of externalities in SSAs. First, it assumes that users have unlimited “memory” and that, consequently, an ad in slot s1 exerts externalities on an ad many slots below. This is experimentally disproved in [10] wherein it is observed how the distance between ads is important. Second, it assumes that the externality of an ad is the same no matter what ad is exerted on. Nevertheless, while BMW can have a strong externality on Mercedes since both makers attract the high end of the market, the externality on makers in a different price bracket, e.g., KIA, is arguably much less strong.
On the other hand of the scale, we can find models that try to address these limitations. In [7] Fotakis et al. propose a model whereby users have limited memory, i.e., externalities occur only within a window of c consecutive slots, and consider the possibility that externalities boost CTRs (positive externalities) as well as reduce CTRs (negative externalities). In particular, the externalities of an ad apply to ads displayed c slots below (forward externalities) and ads displayed c slots above (backward externalities). Moreover, in order to model the fact that externalities might have ad-dependent effect, they introduce the concept of contextual graph, whereby vertices represent ads and edge weights represent the externality between the endpoints. Their model turned out to be too rich to allow tight and significant algorithmic results (their main complexity results apply to the arguably less interesting case of forward positive externalities).
Our contribution. The present work can be placed in the middle of this imaginary spectrum of models for externalities in SSAs. Our main aim is to enrich the literature by means of more general ways to model slot- and ad-dependent externalities, while giving a (nearly) complete picture of the computational complexity of the problem. We do not attempt to explicitly model the user's behavior but bridge the aforementioned models in order to overcome the respective weaknesses. In detail, we enrich the naive model of SSAs by adding the concepts of window and contextual externalities, while keeping ad- and slot-dependent externalities factorized as in the cascade model. We also complement much of the known literature by studying a model wherein the externalities coming from ads and slots cannot be expressed as a product. Our study gives rise to a number of novel and rich models for which we can provide (often tight) approximability results. Since the case of selfish advertisers is of particular relevance in this context, we also initiate the study of mechanism design for the optimization problems introduced and consider the incentive-compatibility of our algorithms, i.e., whether they can be augmented with payment functions so to work also with selfish advertisers.
As regards externalities, we analyze two families of models: one in which slot- and ad-dependent externalities cannot be factorized, which we name FNEaa, and another one in which we assume that externalities can be factorized, which we name FNEsa. Furthermore, we discriminate our models along two other dimensions that are orthogonal to the factorization of externalities. The first dimension has to do with the size c of the user memory with respect to the number of slots K. Specifically, we consider the case when users have “limited” memory, i.e., c<K, and “large” memory, i.e. c=K. The second dimension regards the effect empty slots have on users' attention. In a sort of whole page optimization fashion [13], we think of those slots as occupied by a special fictitious ad (e.g., an image) that either raises users' attention (reset model), or does nothing (non-reset model). The combination of these orthogonal dimensions give rise to the models listed in the first row of Table 1, which gives an overview of our results (formal definitions of these models are given in Section 2).Table 1. Summary of our results: LB (UB, resp.) stands for lower (upper, resp.) bound on the approximation of the problem; the row SP, instead, contains the approximation guarantees we obtain with truthful mechanisms. Results marked by ‘⋆’ require c = O(1). APX-completeness of a subclass of FNEaa(c)-nr is also given. (See the model for details on the notation.)FNEaa(c)FNEaa(K)FNEsa(c)nrrnrrLBAPX-hardAPX-completepoly-APX-completeAPX-completeP ⋆UBlog⁡(N)2min⁡{N,K}⋆SPlog⁡(N)2min⁡{N,K}⋆1/21/K1/21⋆
For FNEsa(c) (i.e. the version in which slot- and ad-dependent externalities cannot be factorized and externalities occur in a window of size c) we prove that the optimization problem is in P, if c is a constant. We consider the LP relaxation of the ILP describing the problem and prove that the integrality gap is 1.
For FNEaa(c) (i.e. the variant of the problem with factorized externalities, contextual ad-dependent externalities and window of c slots) the aforementioned distinction on the effects that empty slots have on users' behavior is useful. For FNEaa(c)-nr (i.e. the variant of FNEaa(c) where the special ad cannot be used, or, equivalently, the user's attention cannot be reset) we prove that the allocation problem is poly-APX-complete whenever c=K. Specifically, we give an approximation preserving reduction from the Longest Path problem and design an approximation algorithm using several different ideas and sources of approximation; interestingly, its approximation guarantee matches the best known approximation guarantee for Longest Path. However, we prove that this algorithm cannot be used in any truthful mechanism and note that a simple single-item second price auction gives a weaker, yet close, truthful approximation. We complement the results for this model with the identification of tractable instances for which we provide an exact polynomial-time algorithm. For c<K instead, we are unable to determine the exact hardness of approximating the problem in general. To the APX-hardness proof, we pair a number of approximation algorithms that assume constant c. The first, based on color coding [2], returns a non-constant approximation on any instance of SSA. The second assumes that the contextual graph is complete and returns a solution which (roughly) guarantees a γminc fraction of the optimum social welfare, γmin being the minimum edge weight in the graph. Interestingly, this algorithm shows the APX-completeness of the subclass of instances having constant γmin (we indeed further provide a hardness result for instances with complete contextual graphs). We believe the tight result for this subclass of instances to be quite relevant. In fact, complete contextual graphs are quite likely to happen in real-life: the results returned by a keyword search are highly related to one another, and, as such, each pair of ads has a non-null externality, however small.
For FNEaa(c)-r (i.e., the variant of FNEaa(c) where the special ad can be used to refresh users' memory) the problem becomes easier and turns out to be APX-complete, for any c. We first prove the problem with c=K to be APX-hard, via a reduction from (a subclass of) ATSP (i.e., asymmetric version of TSP) and then surprisingly connect instances with c<K to instances with c=K by reducing the case with c=1 to the case with c=K and binary externalities (i.e., the weights of the edges of the contextual graph can be either 0 or 1). We also observe how a simple greedy algorithm cleverly uses the special ad to return 1/2-approximate solutions and leads to a truthful mechanism.
Three final observations on our set of results are needed. Firstly, as common in the literature on SSAs, the number of slots is an input parameter of the problem, rather than a fixed constant. This is consistent with common practice of SSA in real life in some scenarios: for instance, the number of ads displayed by major search engines like Google and Bing is not constant, but rather varies with respect to the keyword being used. However, in the scenarios where K can be assumed to be constant, the allocation problem in our models becomes computationally tractable (by, e.g., running the color coding algorithm [2]) and truthfulness can be achieved by imposing VCG payments. Secondly, more research is needed to complete the picture concerning truthful SSAs with externalities. The fact that we principally address computational complexity issues is nevertheless a needed step in this direction. Indeed, recall that in our (single-parameter) setting, truthfulness reduces to designing a (computationally efficient) monotone algorithm (see below for details). Therefore, settling the computational complexity serves as a benchmark for the approximation guarantee of the monotone algorithms we design. Thirdly, our analysis is worst case and then does not rule out the possibility that on real-life instances the approximation ratio obtained is smaller: e.g., the best known algorithm for the cascade model performs better than its theoretical approximation guarantee.
The remainder of this paper is organized as follows. In Section 2 we introduce our models of SSA with externalities and give some preliminary definitions. In Section 3 we give our results about FNEsa. In Section 4 we turn our attention to FNEaa(K)-nr, and prove it is Poly-APX-hard. In Section 5 we prove that FNEaa(K)-r is APX-complete. In Section 6 we prove that FNEaa(c) is APX-hard, irrespective of the reset model. In Section 7 we focus on the complexity of FNEaa(c)-nr and establish the APX-completeness of the subclass of instances having constant γmin, whereas in Section 8 we give an approximation algorithm for FNEaa(c)-nr. Finally, in Section 9 we draw some conclusions and highlight some open problems and directions for future research [9].
