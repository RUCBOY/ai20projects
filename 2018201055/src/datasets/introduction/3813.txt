Given two structures for knowledge and awareness, when do they contain the same information? When does an agent whose knowledge or beliefs are modeled in these structures know exactly the same in both? Can an agent have knowledge about things that it is unaware of? In this paper, we provide answers to all three questions. We propose a notion of awareness bisimulation to answer the first question: structures contain the same information if they are awareness bisimilar. The answer to the second question is a corollary of that: they should be the same (awareness bisimilar) for anything that the agent is aware of. And by employing awareness bisimilarity we propose a notion of speculative knowledge with which we can reason about unawareness. This we can do while preserving the expressivity of explicit knowledge. We provide an exhaustive comparison of explicit, implicit, and speculative knowledge in terms of bisimulation characterizations, expressivity, and axiomatizations.
Our work is rooted in the tradition of epistemic logic [21] and in particular multi-agent epistemic logic [26], [7]. An early paper extending knowledge with awareness is Levesque's A Logic of Implicit and Explicit Belief [24]. In [24], what would later be coined ‘unawareness’ in [6] is modeled as the value ‘unknown’ for a proposition, which means ‘neither true nor false’, such that apart from true and false a fourth value is ‘both true and false’. Levesque's analysis of implicit and explicit belief then only uses three values, not the value ‘true and false’. Such fourth-valued logics are suitable for reasoning about inconsistency in communicating databases. They have since then followed a different line of development [2], [10], [30], which we will recall when reviewing dynamics of awareness, later. Levesque permits belief (and thus some form of awareness) of tautologies containing unaware variables. This is not taken along in the subsequent [6], but remained a contested topic in the awareness literature, e.g., in [28, p. 269], where it is discussed whether one should always be aware of 1=1.
In Belief, Awareness, and Limited Reasoning [6], Fagin and Halpern propose a framework for awareness and knowledge that can be seen as a further development of [24], and that obtained foundational status in the knowledge and awareness corpus of literature that since then evolved, also incorporating independent lines of research in economics, including [6], [27], [28], [13], [19], [15]; see also the survey [33]. We then have a modality for implicit knowledge, interpreted as modal accessibility, a modality for awareness of formulas, and a modality for explicit knowledge, interpreted as implicit knowledge plus awareness of a formula.
Roughly, one can distinguish a more syntactically flavored approach, wherein an agent is aware of the formulas in a given set, and where this set is a parameter in a given state of information [6], [13], [35], from a more semantically flavored approach, wherein the agent is aware of all formulas only containing a subset (the aware variables) of the set of all propositional variables [6], [27], [28], [19].
The reason to call the former ‘syntactic’ is that it allows, for example, an agent to be aware of p∧q but not of q∧p, namely when the former is in the set of aware formulas but the latter is not. In particular, we can then have that the agent is aware of p and p→q but not of q, so that, even if the agent knows that p and knows that p→q, she still does not know q because she is not aware of q. Thus, the rationality of the agent is bounded or limited. Other principally syntactic approaches include [20], [12], [16].
The ‘semantic’ approaches include those wherein the agent is aware of all formulas only using a subset of all propositional variables. The reason to call this ‘semantic’ might be its popularity among economists using partitional information structures to define awareness. These are logic-free, and thus syntax-free, approaches, so to speak: we can also identify a propositional variable with its denotation in a model, a semantic proposition. Within the restriction of the aware variables, agents may be fully rational. This should rather be called lack of conception than lack of awareness. The partitional information structures of [27], [28] can be seen as the single-agent case of the complete lattice of spaces of [19], and are equivalent to the (single-agent) class of epistemic awareness models in which each agent knows what she is aware of [13]; the complete lattices of spaces are equivalent to the same (multi-agent) class of epistemic awareness models in [15]. Our proposal falls straight into the semantic corner.
In such multi-agent logics with implicit and explicit knowledge, implicit knowledge is a primitive notion needed to define explicit knowledge, and one should be careful when mixing the two notions. Consider the following example. ‘Knowledge’ means ‘explicit knowledge’.
Example 1We are both quite interested in the outcome of the presidential elections. A candidate has illegally employed immigrants (proposition p). We both know this.(X) A scenario wherein you are uncertain whether I know p (i), is different from a scenario wherein you know that I know p (ii). And my knowledge about what you know about me may then also be different. This is standard multi-agent epistemic logic.(Y) Let us now assume that you are uncertain whether I am aware of p. It may then be that I know that you are uncertain whether I am aware of p. It is not problematic for me to reason about what you think of me in such a case.(Z) Let us instead assume that you are unaware of p. So now, it is no longer the case that we both know that p. You don't know p, as you are unaware of p. You then cannot distinguish the scenario wherein I know p from a scenario wherein I don't know p, or the scenario wherein I am aware of p from a scenario wherein I am unaware of p. (If I am unaware of p, it is irrelevant whether I implicitly know p (i), or not (ii). Explicit knowledge is all the agents have.) Such scenarios are indistinguishable given your current level of awareness. Consequently, what I know about your knowledge should also be the same in both scenarios, and in particular my knowledge about your knowledge about me.1 We will see that we can distinguish the scenarios under Z in a logic with implicit and explicit knowledge and awareness, but not in a logic with only explicit knowledge and awareness. These logics have been well investigated, but not what their distinguishing power is on a class of structures. In modal logics, determining the difference between structures requires a notion of bisimilarity. We propose different notions including one called awareness bisimilarity.
With awareness bisimilarity at our disposal, we can also consider other epistemic notions. We define an epistemic operator called speculative knowledge, which not only varies over all the propositions the agent is aware of in the accessible states, but also over all the propositions that agent is unaware of in the accessible states, by way of considering all models that are the same as the actual one with respect to the aware variables, i.e., models that are awareness bisimilar for that agent to the actual model. In other words, it quantifies over bisimilar states. Propositional quantifiers were proposed by Fine in [9], which was followed up by work on bisimulation quantifiers in [44], [22], [11]. Speculative knowledge incorporates bisimulation quantification over unaware variables. Therefore, the speculative knowledge semantics permits knowledge of unawareness. Speculative knowledge will be reviewed in Section 3. It has been proposed in [37], [38] in a setting also considering awareness of agents, becoming unaware, and explicit quantification (see Footnote 3, later). It is as expressive as explicit knowledge, a main result in this paper. Thus, we get the benefits of resolving an issue deemed problematic by the community for a long time (see the concerns voiced in [24], [28], above) without having to pay a price. The following is an example of knowledge of unawareness.2
Example 2My grandmother drives a car. She is aware that the engine can be broken. Moreover, if the engine is broken she knows it and if the engine is not broken she knows it too. But it happens that in modern cars there are sensitive control units, essentially computers that control the functioning of the engine, that can be broken too. In particular, if the engine is broken, the control unit will break as well. The control unit can also break without the engine going broken. This can be easily known from the repair shop. My grandmother, being of an older generation, is clearly unaware of the control unit. But she certainly considers it possible that the car mechanic in the repair shop would know about any device that is causally linked to the engine. Based on this speculation, she regularly has her car checked up, even when the engine is not broken. (See Example 16 in Section 3.)
Proposals to model awareness of unawareness include [16], [17], [45], [1]. Our knowledge of unawareness compares to such awareness of unawareness. Halpern and Rêgo [16] use quantification over variables to formalize propositions such as “the agent knows that there is some fact that she is unaware of but that another agent is aware of.” These ‘quantifier variables’ are different from the propositional variables. Their setting is for ‘syntactic’ awareness, of a set of formulas, and also applies to (‘semantic’) awareness of all formulas containing aware propositional variables. They assume awareness introspection. In their setting, the proposition that an agent does not know whether she is aware of all formulas is not satisfiable. As this seems desirable, [17] introduced a variant of the logic wherein to each state is associated a (possibly different) set of propositional variables of which agents can be aware or unaware. This amounts to having two levels of unawareness: in the first place, there are the unaware versus aware propositional variables in a state, and in the second place there are the variables not in the language for that state. Quantifying is allowed over variables of the first kind but not over variables of the second kind, of which the agent is therefore, so to speak, even more unaware. Although operating on different modeling principles, [45], [1] also allow for awareness of unawareness, and for levels of unawareness; [1] has operators for “agent i has full awareness” and for “agent j is aware of more than agent i”. We can thus say that the agent has explicit knowledge of her lack of full awareness, and also that she is unaware of some fact of which another agent is aware. A probability-based framework modeling different levels of (un)awareness is given in [23]. For yet other work, see [33, Section 3.5]. Section 7 will give a more technical comparison between [17] and our proposal.
We now survey the dynamics of awareness. Although not the focus of this investigation, it demonstrates the relevance of our results for artificial intelligence, decision theory, and economics. Our results on the dynamics of awareness and knowledge have been reported in [37], [39], [40], [38]: all agents simultaneously becoming aware of a propositional variable in [37], agents differently becoming aware in [39] (i.e., action models for awareness; awareness of an action means awareness of its preconditions and postconditions); the axiomatization of the dynamic logic of explicit knowledge and awareness in [40]; becoming aware and becoming unaware of agents, and becoming unaware of propositional variables, in [38]. Becoming unaware should rather be seen as ‘conscious’ abstraction than as things ‘subconsciously’ gradually slipping out of one's mind. Other recent studies on awareness dynamics are [20] and [12], [35], [41]. The works by Velazquez-Quesada and collaborators typically consider syntactic awareness (instead of the ‘semantic’ awareness of all formulas containing the aware propositional variables), for example, making the reasoning agent aware of a formula that is a conclusion in a chain of reasoning (it is dynamics of access). Schipper gives many other pointers to dynamics of awareness in [33, page 140]. Dynamics of awareness is important in game theoretical settings, where awareness of actions may determine strategies and equilibria, so that making agents aware of more actions may change their behavior. Works include [18], [31], [8], [25]. From game theory and economics it is only a short way to consider unawareness in epistemic planning. Recalling our description above of ‘becoming unaware’ as ‘abstraction’, the dynamics of knowledge and awareness are relevant for planning with abstraction [29], and in particular for epistemic planning [4]. Finally recalling the original view of an unaware variable as the unknown value for that variable in a four-valued setting [24], also known as reasoning about impossible possible worlds, recent studies refresh this comparison of three-valued and four-valued approaches [14] or introduce dynamics, for example on top of epistemic bilattices [32].
Example of the interaction of knowledge and awareness  To explain our treatment of knowledge, awareness, and change of knowledge and awareness, we first give an abstract single-agent example, that is technically simple, and we then give an intuitively more compelling multi-agent example, that is technically more complex.
Let us define ‘agent i knows φ explicitly’, notation KiEφ, as □iφ∧Aiφ, where □i stands for ‘agent i implicitly knows φ’, interpreted with modal accessibility and where Aiφ stands for ‘agent i is aware of φ’, interpreted as a domain function A such that Aiφ is true at state s iff φ∈Ai(s). We only consider awareness generated by propositional variables.
In the presence of implicit knowledge, this definition of explicit knowledge can lead to counterintuitive situations. Consider the models M and M′ in Fig. 1. It suits the purpose of the exposition that the accessibility relation here corresponds to a standard modality, not to knowledge (which is interpreted on models with equivalence relations). As said, in a given state an agent explicitly knows a proposition if it is aware of the proposition and if the proposition is true in all accessible states. Consider state t and agent i. The agent i is unaware of p at (M,t), and therefore of the value of p in the single accessible state u: from her perspective, (M,t) and (M′,t′) are the same. But if that is so, then, because t is the single accessible state from s (and t′ from s′), the pointed models (M,s) and (M′,s′) should also be the same for her. We will propose a notion of bisimilarity for which (M,s) and (M′,s′) are indeed bisimilar.Download : Download high-res image (10KB)Download : Download full-size imageFig. 1. Two single-agent models for knowledge and awareness. Model M has a domain {s,t,u}, and a single agent i with accessibility relation R = {(s,t),(t,u)}. As we have a single agent only, the arrows in the figure are not labeled with the name i of the agent. Propositional variable p is true in all states (indicated by white/open dots), and the agent is aware of p only in state s (indicated by {p}). Model M′ is like M, except that p is false in u′ (indicated by a black dot).
Now here is the surprise: in the language with awareness and modal box, states (M,s) and (M′,s′) are not modally equivalent. Recalling that explicit knowledge KiEφ is □iφ∧Aiφ, consider KiE□ip. This formula is true in (M,s) but false in (M′,s′). It seems undesirable that bisimilar models are not modally equivalent.
We now replay this example in a multi-agent setting, interpreted on an S5 model (wherein all accessibility relations are equivalence relations). This appeals to our intuitions about knowledge. It is elementary to duplicate properties observed in a single-agent model with directed (asymmetric) accessibility to a multi-agent setting wherein intersecting equivalence classes for different agents force such asymmetry. Consider Fig. 2.Download : Download high-res image (19KB)Download : Download full-size imageFig. 2. Two multi-agent models for knowledge and awareness. Models T and T′ have equivalence accessibility relations for agents i and j (a line represents a two-directional arrow, and reflexive arrows are omitted). Agent i is aware of p in the states w,w′ and s,s′, and unaware of p in every other state; agent j is unaware of p in every state. The only difference between T and T′ is that p is true at (T,u) and false in (T′,u′).
As agent i is unaware of p in the equivalence class {t,u}, she should be indifferent to the fact that in model T the propositional variable p is true in state u, but that in model T′ p is false in u′. Therefore, in state s, what the other agent j considers possible for i to know, should be indistinguishable as well in T and T′. And therefore, in state w, what i considers possible for j to consider possible about i, should also be indistinguishable. So again, intuitively, these models are the same from agent i's perspective. But KiE□j□ip is true in (T,w) and false in (T′,w′).
The problem in both examples is the presence of the □ modality. If the KE operator is not defined by abbreviation but a primitive in the language, then the models cannot be distinguished, as we will prove. For example, unlike KiE□p, the formula KiEKiEp is false in both (M,s) and (M′,s′). In fact, if we only have the KiE modality for agent i, then (M,s) and (M′,s′) are modally equivalent. So that the logic with KiE and □i must necessarily be more expressive than the logic with merely KiE.
As explicit knowledge is implicit knowledge plus awareness, instead of saying that the logic with KiE and □i is more expressive than the logic with KiE, we can say that the logic with □i and Ai is more expressive than the logic with KiE and Ai. This makes our story one of comparing different epistemic notions, namely comparing explicit knowledge and implicit knowledge in the presence of awareness. Alternative epistemic notions then also come to the fore, wherein we wish to focus in particular on the recently proposed notion of speculative knowledge KiS [36], [37]. A third contestant in this comparative study is then the logic with KiS and Ai as primitive operators.
In a state s an agent i speculatively knows φ, KiSφ, if in any i-accessible state t, in any state u indistinguishable from t as far as awareness of i is concerned, φ is true. This is exactly the sense in which (M,s) and (M′,s′), or (T,w) and (T′,w′), are similar for i. Technically, (M,s) and (M′,s′), and (T,w) and (T′,w′), are p awareness bisimilar. On the one hand, explicit and speculative knowledge are really different. For example, in (M,t) it is false that KiE(p∨¬p), for the obvious reason that the agent is not aware of p in state t. But in (M,t) it is true that KiS(p∨¬p), because any way in which agent i can envisage becoming aware of p will make the tautology p∨¬p true. On the other hand (and this is main result), explicit and speculative knowledge are not really different, because the logic with KiE and Ai is as expressive as the logic with KiS and Ai.
Here is another peculiarity of this epistemic notion. Assume that the accessibility relation is serial, transitive, and euclidean, i.e. KD45. These frame properties are associated with belief. You do not consider it possible that p is false but that you believe that it is true: ◇i(¬p∧□ip) is inconsistent in KD45. Now let α be an informative event (such as a public announcement) with associated modality 〈α〉, which stands for ‘there is an execution of the action α after which’. Then even ◇i〈α〉(¬p∧□ip) is inconsistent, because this would entail 〈α〉◇i(¬p∧□ip), and again we end up with an inconsistency. The presence of awareness, as in explicit knowledge, does not matter: LiE〈α〉(¬p∧KEip) is also inconsistent — where LE means ‘explicitly considering possible’. However, given the action 〈A+p〉 of becoming aware of p, the formula LiS〈A+p〉(¬p∧KiSp) is consistent: you speculatively consider it possible that you become aware of p such that p happens to be false but you (firmly) believe that it is true. We will define and motivate speculative knowledge at length and explain this particular example in detail.
The action A+p, where [A+p]φ (the necessity form of the modality) stands for ‘after all agents become aware of the propositional variable p, φ is true’, is interpreted as a Kripke model transformer, e.g., on the models M and M′, the result would be as in Fig. 3. (Proceeding likewise on the models T and T′ of Fig. 2 is also depicted.) Recalling the previous example, one can now easily calculate that KiEKiEp is true in (M+p,s), whereas it is false in (M+p′,s′). Therefore, [A+p]KiEKiEp is true in (M,s), whereas it is false in (M′,s′): the logic with KiE and with modalities for awareness change is more expressive than the logic with only the KiE modality, wherein we cannot distinguish (M,s) and (M′,s′).Download : Download high-res image (37KB)Download : Download full-size imageFig. 3. Above, the result of i becoming aware of p in Fig. 1. Below, the result of i and j becoming aware of p in Fig. 2.
Overview  In Section 2 we present the well-known epistemic awareness structures of [6], [28], [19], [15]; we present two notions of bisimulation for these structures, standard bisimulation and awareness bisimulation; and we present three logics for knowledge and awareness, that all contain operators Aiφ for awareness of variables occurring in φ, but contain different epistemic operators: the logic of implicit knowledge (with □i, so that KiE is definable), the logic of explicit knowledge (with KiE), and the logic of speculative knowledge (with KiS). Speculative knowledge is knowledge modulo speculation over unaware variables [36], [37]. Section 3 motivates this novel notion of speculative knowledge. In Section 4 we then show that, on image-finite models, standard bisimilarity corresponds to modal equivalence in the logic of implicit knowledge, but that awareness bisimilarity corresponds to modal equivalence in the logic of explicit knowledge, and also to modal equivalence in the logic of speculative knowledge. Section 4.4, ‘Having the same knowledge’, applies the results on modal equivalence and bisimulation to determine when structures are the same from the perspective of an agent, or of all agents. Section 5 lists various expressivity results, including that the logic of implicit knowledge is (strictly) more expressive than the logic of explicit knowledge, and that the logic of speculative knowledge and the logic of explicit knowledge are equally expressive. Section 5 also gives the expressivity hierarchy for fragments below the three logics of implicit, explicit, and speculative knowledge, e.g., what happens if one also removes the awareness operator from them. In Section 6, we give axiomatizations for our three logics. We present an axiomatization for the logic of implicit knowledge [6], one for the logic of explicit knowledge [28], [13], [19], and an axiomatization for the logic of speculative knowledge. We distinguish axiomatizations with respect to the class of all models (K) from those with respect to the class of models with equivalence relations and awareness introspection (S5AI). (Axiomatizations for KD45 models with awareness introspection, interpreting belief, are typically not greatly different from those for S5AI, and have therefore been omitted.) For the logic with speculative knowledge, wherein the modality is a quantifier over a class of models, this is not trivial, as the axiomatization over S5AI is not a conservative extension of the axiomatization over K. In Section 7 we give a more detailed comparison of our results: with [6], [13] for the axiomatizations, with the lattices of spaces [19] for our notion of awareness bisimulation (the lattice of spaces corresponds to a partially ordered tree for restricted awareness bisimilarity in the model with commonly known uncertainty over all valuations), and with awareness of unawareness [16], [17] for speculative knowledge.3
