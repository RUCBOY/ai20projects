In the recent years, with advances in ℓ0-norm and ℓ1-norm techniques, sparse representation [5], [12] has been widely applied in computer vision. However, most of sparse representation based classification (SRC) algorithms [27], [29], [33] are mainly designed for problems associated with vector-valued data. The higher-dimensional signals like images (2D, 3D or higher) have to be dealt with primarily by vectorizing them and applying any of the available vectorial techniques [11], [32]. As a result, much information such as spatial information has got lost, thus less efficient in characterizing the high-dimensional data in community of computer vision and machine learning. Concretely, in the traditional sparse representation based classification, the sparsity representation for each query image is attained by a dictionary composed of all gallery data across all classes in a linear combination way. Recent advance [21] suggests that encoding images through symmetric positive definite (SPD) matrices and then interpreting such matrices as points on Riemannian manifolds can lead to promising classification performance. For instance, the human facial images are regarded as samples from a nonlinear sub-manifold [24]. Unfortunately, the linear combination is not applicable to this case where data may be better modeled by nonlinear manifolds [10].
To address this problem, a few solutions have been recently proposed to generalize sparse coding problems to Riemannian manifolds, such as [4], [9], [19]. While for low-rank representation(LRR), a series of nonlinear model has been proposed to extend the traditional LRR from Euclidean space to Stiefel manifold [30], SPD manifold [6] and abstract Grassmann manifold [22], respectively. The most common approach is to calculate the tangent space to the manifold at the mean of the data points so as to obtain a Euclidean approximation of the manifold. Locally flattening Riemannian manifolds via tangent spaces can handle their non-linearity, nevertheless it inevitably leads to very demanding computation due to switching back and forth between tangent spaces and the manifold [7]. Furthermore, linear reconstruction of SPD matrices is not as natural as that in Euclidean space and this may incur errors [14]. To this end, by mapping SPD matrices into Reproducing Kernel Hilbert Space (RKHS) [31], the linear combination can make sense. Based on this observation, sparse representation methods on SPD matrices can be shown to be effective to classification [7], [14].
However, there still remains problems with classification in the multiple sub-manifolds setting [25] with sparse representation in non-Euclidean spaces. In real world, some data are often from multi-manifold, which has been regarded as several different clusters each of which corresponds to a separate, simple low-dimensional manifold [26]. In nonlinear settings, SPD matrices are often low-dimensional data embedded in the high-dimensional Euclidean space, whose underlying sub-manifolds are geodesic, and referred to Riemannian multi-manifolds [25]. As for this issue, in the existing methods the locality of SPD matrices has not been sufficiently explored yet. As the mechanism of ℓ1-minimization, the sparse coding coefficients may be significantly non-zero even when the samples are outside a class of interest [16]. That is, it is not guaranteed that the neighbors (i.e., non-zeros coefficients) to the test sample in the ℓ1-graph [3], [23] are also near to itself under some metric. Specifically, letting X be a SPD matrix and hence a point on Sd+, it can be assumed residing on the tubular neighborhood of some unknown geodesic sub-manifold Mk(1≤k≤K), of a Riemannian manifold. As well known, in classification, the importance of locality constraint often accounts for high efficiency and local smoothness of the codes [13]. Another reason is, may not trivial, the sparse coding coefficients may vary a lot even for similar query samples in classification task due to ℓ1-minimization. As a result, an unsatisfied recognition rate may be achieved. Motivated by these observations, in this paper, we propose a novel method for robustly classifying SPD matrices by solving a local weighted ℓ1-minimization problem. Specifically, to thoroughly exploit the intrinsic geometry among data on Riemannian manifold, a neighborhood preserved prior induced from the geodesic distance, besides the sparsity, is imposed on the sparse coefficients so that the similar query data can produce similar sparse codes. Although the recent work [8] has considered the locality of data and proposed the kernel locality-constrained coding (LLC), it requires to determine the set of training samples closest to the input in advance, as a dictionary, which is not easy to handle at all.
The main contribution of our work, putting it simple, is two-fold. One is to integrate the intrinsic local Riemannian geometry into the sparse classification framework which is a much finer model than existing ones and therefore equipped with more power to capture the hidden patterns of the data. The other is to explore the nonlinear subspace structure of SPD matrices, which are highly nonlinear representation of the original data, and to realize the model by employing an appropriate kernel so that the optimization complexity is under control.
The remainder of this paper is organized as follows. In Section 2, we give a brief review on the related works. Section 3 is dedicated to introducing our novel neighborhood preserved kernel SRC, termed as NPKSRC. Section 4 presents experimental results on image classification tasks. Finally, Section 5 concludes our paper and provides the directions for future improvements.
