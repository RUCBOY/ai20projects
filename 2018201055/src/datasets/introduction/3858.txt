At least five factors [1] contribute to intelligence: (1) genome (or the developmental program), (2) the sensors, (3) the effectors, (4) the computational resources, and (5) the environment (body, teachers, and other physical facts) that each individual lives through. All these 5 factors are important to the development of agent. The goal of this work mainly corresponds to (3) the effectors and (5) the environment that facilitates the development of agent’s simple-to-complex skills. In particular, we study how the information in the effectors facilitates the development of the agent’s behaviors under the environment. By doing so, we do not mean that other factors are totally irrelevant.
There are two types of skills [2], declarative skills (e.g., verbal) that can be expressed using a certain language, and non-declarative skills (e.g., bike riding) since such skills are typically not demonstrated using a language. For classification tasks, the actions often correspond to declarative skills. For robotic navigation tasks, the actions often correspond to non-declarative skills. Although we used the term “action” in this paper, the term “action” is for both declarative and non-declarative skills, not just an action that an arm carries out.
Symbolic labels are commonly used in speech recognition. They have been handcrafted by human programmers, as labels for phonemes, words, and sentences.
Compared to symbolic labels, actions are information-dense in time and provide much information for temporal processing tasks.
1.1. Symbolic vs. non-symbolic methodsMuch effort has been spent to overcome temporal processing problems in recent years. Many existing methods are task-specific because they involve handcrafted symbols. These methods cannot learn new concepts after symbol design for the symbols need to be fully handcrafted in advance. Instead of symbols, DN uses a framework of autonomous development that with patterns as representations. Such representations automatically emerge from experience, and can be learned incrementally.
1.2. Time warping and time durationTime warping means that two sequences are treated equally if they are similar but the duration of some segments in a sequence is different. Time warping is a common objective for temporal processing which needs to be treated carefully.Dynamic time warping (DTW) is an algorithm widely used in the analysis of video, audio, and graphics sequence. It measures the similarity between two sequences with some variances in time duration. For example, both the voice recognition in [3] and the spoken word recognition in [4] used DTW. DTW itself does not use probabilities.Hidden Markov Models (HMMs) use probabilities which implicitly deal with time warping instead of explicitly modeling time warping. HMMs are often used hierarchically. For example, phonemes, letters, words, are three levels in a hierarchy. In each level, each state in HMMs corresponds to a stage. For example, in [5], HMMs were used to model two-handed tracking from videos. In [6], Vogler and Metaxas used HMMs to recognize American Sign Language (ASL) sentences. HMMs were utilized to recognize Arabic handwriting in [7].Both DTW and HMMs use symbolic representations, because their states, often formed by a clustering technique, are handcrafted.Time duration is opposite to time warping. Time duration means the duration of two different sequences is the key factor to distinguish them. In English, phone duration helps in distinguishing several words from each other, such as “pitch” and “peach” or “ship” and “sheep”. In some other languages like Finnish, phone durations can be the only clue in discriminating between certain words [8]. Good time duration modeling can be a major issue in temporal processing. Hidden semi-Markov model (HSMM) in [9] and expanded state HMM (ESHMM) in [10] are extended by explicitly approximating state duration distributions in HMMs framework. The work in [11] compares and evaluates the performances of these extended HMMs methods with duration modeling techniques.Neural networks use connections to reach a certain type of flexibility in temporal trajectories. They at least partially use emergent representations (i.e., patterns of neuronal firing instead of a series of symbols), but the emergent representations have often been mixed with symbolic representations, e.g., handcrafted internal representations (states like those in Kalman filters).Neural networks use natural and discriminative training to estimate the probabilities of frames in the temporal stream. Many successful neural networks based methods are adept in handling short-time units such as individual phonemes in speech recognition and isolated words in language processing. The work in [12] utilized the neural network for phoneme classification. A sliding-mode neural network was presented for the tracking control of the robot manipulator in [13]. Collobert and Weston proposed a convolutional neural network model for sentence analysis (e.g., chunks, semantic roles) in [14]. Recently Long Short-Term Memory (LSTM) and Recurrent Neural Networks (RNN) have been used in this field [15]. They can detect latent temporal dependencies. To make the neural networks more efficient, some methods are proposed for intermittent measurement and dynamic analysis of the neural network (e.g., [16], [17]).These systems require a sophisticated design by a human programmer who typically focuses on one specific task. Without a general-purpose framework and fully emergent representations, they do not fully use temporal contexts during processing, and do not directly take actions from output side as contexts.
1.3. Developmental methodsA developmental method is task-nonspecific. This is because the developmental method never involves symbols in any of the internal representations and is never restricted in the representations of one specific task. If a teacher uses symbols, they only use emergent patterns (in sensors or effectors). Unlike symbols, which are either the same or different, patterns of the same sensors or effectors have distances in the neuronal inner product spaces, so new patterns never observed can be dealt with based on their similarities with observed patterns.DN is skull-closed, different from symbolic methods, which means it does not need human designers to manually adjust internal representations after birth and can learn incrementally during interaction with natural environments. According to Weng [18], the networks, which can generate emergent representations, can easily deal with natural inputs and motor actions, and incrementally learn. DN can deal with information-dense natural sensory patterns and has motor areas representing information-dense actions. DN performs well in pattern recognition tasks. It is used as an object recognition network for a navigation mobile application in [19]. Its implementation of visual parking assistance system is present in [20].Our goal is to use DN to process temporal streams in real-time. DN can demonstrably learn any TM immediately one transition at a time and free of any errors [18]. The TM was assumed to be handcrafted upfront. Although the human common sense knowledge base can be considered as a grand TM at a coarse language level, the states at a fine-grained time level (e.g., 20 ms–100 ms) are typically unavailable.This work investigates how actions at a fine-grained time level are useful as states, where we regard states and actions are the same: both declarative skills and non-declarative skills can be expressed as fine-grained actions.In this work, we use automatically generable and temporally information-dense patterns as temporally information-dense actions. Natural robotic actions are better since no tangible restrictions are imposed on such action patterns. But natural robotic actions are difficult to come by without the method here first being sufficiently investigated. we plan to use natural action patterns from the robot body to replace current temporally information-dense patterns when the DN-equipped autonomous robot body is completed.Our original work has been accepted by 2017 International Joint Conference on Neural Networks (IJCNN) [21]. Based on that, we extend the work more than 40% to this archival journal version. The main additional novel parts of this journal version are:
1.The information entropy of temporal sequence has been used to mathematically define the density of actions in the conference version. The entropy values have been computed for all experimental settings to contrast their different values in terms of mathematically defined information-dense concept.2.The patterns of concept 2 motor neurons (dense) are much more now, and they are automatically generated but before they were much fewer and were handcrafted. In other words, the concept 2 actions automatically emerge as patterns but before they are handcrafted labels. This greatly reduced the cost of system development, because the programmer does not need to care which patterns correspond to a label — the vector representation and the inner product space automatically take care of such similarity among patterns.3.Volume information representation is added to replace original adding “energy-component” element method — a batch method — when processing the waveform. This mechanism corresponds to a hypothesized “genes prepositioned” but “partially emergent” feature in the sensory input of every neuron that might be present in many “purely emergent” features. The experimental results show that this volume-feature performs better than the “energy-component” in the conference version.4.We refine the definition of “hair cells” so that each covers shorter frames and with certain overlap between the consecutive frames. This refinement provides more information-dense contexts and improved the performance.5.The hidden neurons now have locations inside “skull’. Before, all hidden neurons are location-free, which is common in many artificial neural networks. This new mechanism encourages the smoothness of hidden representations — nearby neurons detect similar features. It allows the recruitment of neurons during the life-long learning implemented by Hebbian learning. This process of recruitment gradually adapts a “hierarchically” smooth representations to better fit the changing distribution.The remainder of the paper is organized as follows: we first discuss the theory part in Section 2. The DN algorithm and some key details are listed in Section 3. In Section 4 we present the implementation details and analysis of experimental results. Concluding remarks are offered in Section 5.
