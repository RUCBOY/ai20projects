User engagement is a quality of user experience characterized by the depth of an actor’s investment when interacting with a digital system (O’Brien, 2016a). Engagement is more than user satisfaction: it is believed that the ability to engage and sustain engagement in digital environments can result in positive outcomes for citizen inquiry and participation, e-health, web search, e-learning, and so on. Yet user engagement (UE) is an abstract construct that manifests differently within different computer-mediated contexts, and this has made it challenging to define, design for, and evaluate.
This research is fundamentally focused on the challenge of measuring engagement so that it can be used in design and evaluation. A range of methodological approaches have been utilized to measure engagement, including (Lalmas, O’Brien, Yom-Tov, 2014, O’Brien, Cairns, 2016):

•behavioural metrics such as web page visits and dwell time;•neurophysiological techniques such as eye tracking and electrodermal activity (EDA);•self-reports such as questionnaires, interviews, diary entries and verbal elicitation.
All methodological approaches have their advantages and limitations with respect to use with specific populations, settings, and time scales, from a single user-computer interaction to longitudinal observations. In addition, measures may capture interactions formatively or summatively, and subjectively or objectively (Lalmas et al., 2014). In general, there has been advocacy for multiple measures and mixed methods to reliably and validly capture constructs such as user engagement. This requires attention to the robustness of individual measures, as well as to triangulating multiple measures.
Our work is concerned with the User Engagement Scale (UES), a 31-item experiential questionnaire. The UES (or items derived from it) has been used to evaluate engagement in a range of settings: information search, online news, online video, education, and consumer applications, haptic technologies, social networking systems, and video games (see (O’Brien, 2016b) for an overview of this work). Although there is evidence to suggest that the UES is a reliable and valid means of capturing subjective user engagement, some findings have questioned its effectiveness, which are reported in O’Brien (2016b). Such findings may point to flaws in the UES, the ways it has been administered and analyzed in practice, or some combination of these. For instance, few researchers have used the UES in its entirety, which makes it difficult to assess its factor structure and robustness over time and across different digital applications. On the other hand, the decision to not use all 31 items raises pragmatic issues of using the UES in a study (i.e., length), or poor documentation regarding how to adapt, implement, and make meaning from the measurement tool.
In the current research, we applied state-of-the-art statistical techniques to re-analyze the data originally collected to develop the UES. Based on our findings, we proposed a revised long-form and short-form (SF) of the questionnaire, which we then evaluated with a new data set collected over a three-year period as part of a large digital library project. In the remainder of this paper, we provide background information on the UES and our approach to data analysis; present the revised UES and UES-SF with an explanation of our findings, and conclude with recommendations for the administration and analysis of the UES and UES-SF in future studies.
Our contribution is three-fold:

•firstly, we offer a robust measurement tool to measure user engagement in HCI settings; this tool can be used to guide the design of digital media or to evaluate user experience with computer-mediated systems;•secondly, the validated UES can be confidently used as a benchmarking and corroborating tool for emerging methodological approaches or process-based metrics; and•finally, we hope to improve the administration of the UES and other self-report questionnaires by providing guidance on how to adapt and interpret the UES in different research contexts.
