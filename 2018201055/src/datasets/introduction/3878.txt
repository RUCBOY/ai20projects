The development of human–machine interaction, computer science, cognitive science, psychology, neuroscience and other fields enable the artificial intelligence technology to become the research hotspot again within a few years. The ultimate goal of artificial intelligence is to research and develop the theory, method, technology and applications, in order to make machine intelligence close to human intelligence [1]. Thus, for artificial intelligence researchers, recognize emotion of users is an important basis to correct feedback of an intelligent system, as well as the direct manifestation of machine intelligence [2]. Therefore, understanding and managing the emotion interactive experience of users become one of the important challenges for intelligent applications at present. The quality of user experience (QoE) is generally influenced by whether an application or local/background processing of a machine is sufficiently intelligent [[3], [4]], especially for the smart healthcare systems [[5], [6]] and emotion interaction applications. If a system fails to correctly reflect the operation of users, the customer will feel depressed. Thus, we prefer the operator to solve the problems by formulating intelligent strategies directly, rather than the user taking remedial measures passively.
In order to quantify and manage the user experience, CEM (Customer Experience Management) emerges to understand the comprehensive the behavior of humans and system. What is Customer Experience Management (CEM)? In an universal meaning, CEM aims to enhance the quality of user experience and pays attention to contacting with users at each time by transmitting the request information for the user purposefully and seamlessly in overall process of productions [7]. The so-called “experience” is the activity of product with the platform as services that is memorable to the consumers. The user experience is directly generated from interaction between users and products. An ideal user experience is surely composed of a series of psychological processes, such as comfort, appreciation, praise, and aftertaste, which brings the strong psychological feelings of gaining the values to the user. Good customer experience management will bring a benign feedback and increase the better use feeling for the user, which is the result of implementing CEM.
Moreover, combining with the artificial intelligence and cognitive science [8], CEM becomes a popular topic in human–machine interaction application [9]. Our research focuses on improving user experience by blending AI and CEM in emotion recognition and interactive intelligence application. However, many current researches only investigate the emotion recognition and interaction roughly or call the matured interface on the market directly without improvement, rather than conducting the experience management in practical applications [10]. Thus, AIEM method proposed in this paper makes the following contributions.



•
Intelligent management of emotion acquisition:In the emotion interaction application, the emotion data is the important basis for machine intelligence. The data type usually includes text, video, audio, image, physiological data, and etc. [[11], [12]]. Generally, the emotion data will be used for systems to make the comprehensive learning and judgment based on previous behaviors of the user and the historic records interaction. Thus, the emotion acquisition becomes the first step to conduct emotion interaction management. AIEM method considers acquiring the massive emotion data intelligently (i.e. multimodal data collection, and concurrent user management and control) and transmitting the emotion data to background efficiently.
•
Accuracy management of emotion recognition: For emotion interaction QoE, the accuracy of emotion recognition can reflect the application intelligence directly. If a machine fails to recognize the user’s emotion, the feedback result or subsequent interactive information will wrong. This is detrimental to CEM. Thus, we introduce AIWAC emotion recognition system to analyze the emotion of the user mainly by facial expression and speech recognition. This multidimensional emotion recognition can enhance the accuracy and lead to better user experience.
•
Real-time management of emotion interaction: Nowadays, emotion recognition users mostly are the mobile users, which has very high real-time requirements for interaction result feedback. However, heterogeneous network devices with user mobility result in unstable communication latency [[13], [14]] of different computing requirements [[15], [16]]. Thus, it is necessary to use a more elastic computing mode. We naturally think that different computing tasks and corresponding computing modes need computing in different places. Hence we introduce smart clouds architecture. Some researches propose introducing AI (such as deep learning) in the cloud, but they do not consider deploying different computing strategies in the places with different computing capabilities and communication latencies such as local, fog, and cloud. Multilayer computing offloading strategy included in AIEM method can manage and balance the contradiction among computation intensive task, latency sensitive task, and user experience better.
