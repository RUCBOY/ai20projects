Cloud computing is facilitating an impressive shift in how organizations meet their computing needs. Through massive integration of powerful computing servers and enormous data storage units, cloud systems deliver three deployment models: IaaS (Infrastructure as a Service), PaaS (Platform as a Service) and SaaS (Software as a Service). Cloud-powered applications (i.e. applications using cloud deployment models as a platform) are globally used, causing a dramatic growth of cloud resource usage. Scheduling this extraordinary number of computing tasks and distributing the data files they require are critical concerns for cloud providers.
The scientific community is providing ever-growing problems to the information technology community, demanding overwhelming computing power to fulfill their needs [1]. As an example, nucleotide sequencing machines in genomics are producing more data each year than non-dedicated computing machines are able to process; as a reference, nucleotide sequencer capacity reported a growth of three to five times per year while computer processor speed only doubles every two years (following Moore’s Law benchmark) [2], [3]. Big-data analytics to process extraordinarily large amounts of data, in the order of terabytes and beyond, are another type of scientific application that requires and demands efficient storage systems [4], [5]. For instance, the Large Hadron Collider [6] produced ∼13 petabytes of data in 2010 and the Large Synoptic Survey Telescope [7] coming online in 2016 is projected to produce 10 petabytes of data a year [3]. Similarly, it is calculated that labs and hospitals around the globe are able to provide around 15 quadrillion nucleotides per year, i.e. 15 petabytes of compressed genetic data.
As well as their storage requirements, scientists aim to obtain analytical results from collected data. To accomplish this task, researchers automate their experiments as scientific workflows, i.e. scripts to call in data and computer programs to analyze and obtain insights from retrieved data. Cloud computing presents the best environment to execute workflows due to 1) large computing power and extraordinary volume data storage, 2) unlikely grids, any public user can access resources at a cost established by a cloud provider, 3) it doesn’t require an initial investment in supercomputers or specialized clusters, 4) in contrast to clusters, resources can scale up and down adjusting to workflow demands and 5) users can access necessary resources immediately in contrast to supercomputing where a waiting period of weeks may be common.
Cloud systems are linked to scientific workflows through a scheduling platform. This platform, commonly referred to as the scheduler, receives an application from the user, analyzes it and assigns it to a computing resource. It is expected that scheduling analysis has a relatively small duration in comparison with the total workflow execution time. However, cloud schedulers often require complex analysis since they manage a large number of variables such as network bandwidth, instance types, tasks’ computing demands, data file sizes, and dependencies among others. Given the extraordinary number of possible solutions this scenario provokes, the scheduling of workflows falls into the type of an NP-complete problem [8], i.e. a problem that cannot be solved within polynomial time using current computing systems.
After deep analysis of a large number of scheduler proposals, we observe that there is not an accurate investigation of cloud schedulers that manages both computing and data intensive applications with task interdependencies considering a number of resources as a variable within its process [9], [10], [11], [12], [13], [14], [15], [16]. The investigation also discovered that a lack of a proper cost model [9], [12], [15] prevents current algorithms from analyzing a realistic scenario. Every public cloud provider offers its resources at a price per quantum of time, usually hours. Whether the user has an unlimited budget or not, idle resources stop cloud providers from assigning those resources to a different user, affecting the complete system efficiency.
Additionally, we noticed schedulers do not create realistic scenarios, most of them realize experimentation over a fixed pool of resources; few of them dually optimize execution time and monetary cost using a public cloud pricing model. Runtime and monetary cost objectives have great importance to the execution of workflows: on one hand, execution time has a direct impact on variables such as reliability, security and energy consumption; on the other hand, monetary cost represents the pay-as-you-go model of public cloud providers. GA-ETI is an approach we developed to address this problem, it is able to (1) evaluate configurations with a different number of resources, (2) employ the Amazon EC2 cloud pricing model [17] and (3) converge to an optimal, minimizing makespan and monetary cost.
For the reasons outlined above, this paper addresses the problem of scheduling scientific workflows in cloud environments employing a genetic algorithm. The contributions are: (1) a cloud scheduler for the optimization of execution time and monetary cost; (2) modification of mutation operator to scale up/down the number of resources to provide the exact number of required VMs to a user; additionally provide estimation of (i) makespan and (ii) monetary cost; and (3) a scheduler orientated for computational and data-intensive scientific workflows contemplating (i) time to transfer data files, (ii) time to execute each workflow task and (iii) dependencies among tasks. Results demonstrate that GA-ETI successfully balances the conflicting objectives and outperforms up-to-date cloud schedulers in scheduling current scientific applications.
This work is divided into eight sections organized as follows: Section 2 presents related work; Section 3 outlines the system model; Section 4 discusses the problem statement; Section 5 provides a detailed analysis of the GA-ETI; Section 6 analyzes experiments; Section 7 provides a discussion of results; finishing with Section 8, the conclusion.
