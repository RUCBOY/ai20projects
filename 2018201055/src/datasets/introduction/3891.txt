In recent years, 3D reconstruction based on structure from motion (SFM) has received much attention from the computer vision and graphics communities. It is well known that SFM plays an important role in 3D reconstruction because of its many potential applications, including augmented reality, multiview stereo, image-based localization, 3D face modeling, 3D head modeling, image-based navigation, place recognition, hand-eye calibration, autonomous driving and camera localization. In essence, SFM is a collection of techniques that can reconstruct 3D point-cloud models from image sequences. A typical SFM system consists of camera calibration, feature tracking, camera pose estimation, triangulation and bundle adjustment [1]. One of the most important components of 3D reconstruction in SFM is local feature extraction, whose goal is to locate correspondences between different images. Thus, in the SFM framework, the quality of the resulting 3D model is heavily dependent on the method used for local feature extraction.
Over the past decade, many SFM-based 3D reconstruction systems have been proposed for various applications. However, these systems carry significant computational burdens, especially for large-scale reconstructions involving thousands of images, because they utilize scale-invariant feature transform (SIFT) [2] and brute force matching (BFM). To save on computation time, Zach et al. [3] exploited speeded up robust features (SURF) to detect keypoints and compute feature descriptors at the stage of feature tracking, which resulted in a fast SFM system named ETH-3D. Wu et al. [4] developed a Visual SFM (VSFM) system to produce sparse point clouds; it saves on computation time by using GPU-accelerated SIFT in feature tracking to locate keypoints. In addition to its speed, the VSFM system has an excellent graphical user interface (GUI) that allows it to be operated easily. Moreover, the VSFM can be integrated with a patch-based multiview stereo system (PMVS) [5] to produce dense 3D geometric models. Recently, Ni et al. [6] proposed a novel algorithm that solves the SFM problem in a divide-and-conquer manner by exploiting bipartite graph structure to split the large-scale SFM problem into many simpler nonlinear subproblems.
After a detailed investigation into the problem of SFM-based 3D reconstruction [7], we found that the existing local feature extraction method requires too much computation time, especially in large-scale settings. To speed up the SFM and improve the quality of the resulting 3D models, in this paper, we propose a fast and robust local feature extraction method for SFM-based 3D reconstruction. For convenience, we use the abbreviation OOD to refer to the combination of OAGAST and ODGs. To detect an OOD feature, we first use the Adaptive and Generic Accelerated Segment Test (AGAST) [8] detector to detect keypoints and then use the image moment [9] to define an orientation for the detected keypoints. This new local feature detector is called oriented AGAST (OAGAST). Second, the oriented difference of Gaussian descriptor (ODG) is employed to describe the detected keypoints, which can be computed directly from the difference of Gaussian (DOG) image. Third, the OAGAST detector and ODG descriptor are combined into a single local feature extraction method for convenience.
The main contributions of this work are summarized as follows:
•A novel local feature detector called oriented AGAST (OAGAST) is proposed to locate keypoints. The OAGAST detector has both low computational cost and high repeatability. Thus, OAGAST can significantly accelerate the process of SFM-based 3D reconstruction and may also improve the quality of the 3D models.•A robust local binary descriptor, called the oriented difference of Gaussian (ODG) descriptor, is proposed to describe the detected keypoints. The proposed ODG descriptor is highly discriminating with regard to rotation and lighting changes.•A comprehensive experiment is conducted on several different datasets to assess the proposed OOD method on computational cost, matching precision and practical applicability to SFM-based 3D reconstruction. The experimental results indicate that the proposed OOD method outperforms several state-of-the-art methods on both efficiency and effectiveness.
The rest of this paper is organized as follows. Related work is presented in Section 2. The proposed method is described in Section 3. In Section 4, a prototype 3D reconstruction system is presented. Experimental results are given in Section 5. The conclusion and final remarks are given in Section 6.
