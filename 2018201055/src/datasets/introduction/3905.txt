Helping robots understand basic three-dimensional structures of indoor scenes is a considerable challenge, which may seem strange in light of how humans do so easily. It has been proposed that binocular parallax may be used to recover 3D structures, but experiments [1] indicated that the human ability to estimate the depth of isolated points is very weak and that we are more likely to infer relative depth of different surfaces from their jointed points. This indicates that binocular features are not that important, and it is possible to understand scenes using only monocular images. In the human visual system, it was reported that there are some low-level structures that identify objects on the same surface and that we are sensitive to surfaces of different orientations, which allows us to extract surfaces and orientation information and so understand the scene [2]. It was described what they called a “visual cliff”, and showed that this kind of ability is inborn and does not require additional knowledge [3]. So we can assume that there are some simple rules that can be used to infer the 3D structure over a short period of time.
There are lots of rectangles in 3D indoor scene(e.g. walls, tables, windows, doors, shelves, screens). These spatial rectangles are projected into two-dimensional projections in 2D images. These projections would enable us to estimate the original position in a 3D scene. In this paper, an approach to understand the 3D indoor scene from a single image is presented. First, edges and straight lines were found. Second the number of quadrangles was determined. Third, projection of spatial rectangles, which can be used to estimate the current vanishing point (VP) of depth orientation, were extracted. Then, since a number of projected rectangles has been extracted here, it is pretty easier to efficiently estimate the VP. Finally, through the projection of spatial rectangles, our method not only can estimate room layout of scene, but also can reconstruct excellent details of scene.
Due to simple geometric inferences, our method can cope with clutter without prior training, making it practical and efficient for a navigating robot. The method searches the projection of spatial rectangles, and reconstructs their estimated locations and positions in 3D scenes, without the knowledge of camera’s intrinsic parameters, nor of the relation between the camera and world. The current approach takes less time than existing 3D scene understanding work. Also, it is robust to the changes in illumination, color, and features of realistic scenes, such as clutter with incomplete surfaces and coverage. We compare the room layout estimated by our algorithm against room box ground truth, measuring the percentage of pixels that were classified correctly. Furthermore, we evaluate our ability to fit the indoor scene by comparing against the details that were reconstructed correctly in scene. Moreover, due to the rapidity and stability, the current approach supports understanding the rough 3D indoor scene from video frame, which can be applied to the real-time robot navigation. The experimental results show that the proposed method is capable of reconstructing various structures of indoor environments and that the above innovations make a considerable contribution to its success.
