Urban flooding is a global problem that costs lives and money. In 2010 alone, 178 million people suffered from floods. The total economic losses in 1998 and 2010 both exceeded $40 billion (Jha et al., 2012). Urban floods can be caused by a variety of reasons, including natural hazards of river overflow, coastal storm surge, sea-level rise, flash floods, groundwater seepage, sewer overflow, lack of permeability, and lack of city management. As urbanization proceeds and climate change intensifies, urban planners and city managers are facing the challenge of preparing for and mitigating flood damage. They need tools to monitor and predict the event for emergency response and development planning.
Monitoring and predicting urban floods needs high-resolution data with good coverage. High-resolution data can capture the variation of flood flows among streets or parcels, so that the heterogeneity of flood flows caused by heterogenous urban landscape can be captured. In this study, we define data that can reflect the variation on the parcel and street scale as “hyper-resolution” data. In addition to resolution, it is important to have a good coverage of flood data to obtain complete information.
The traditional method of obtaining flood related data lack both resolution and coverage. Remote sensing is a commonly used data source. Aerial photography, for instance, is being conducted by many research teams, engineering companies, emergency response services as well as governmental departments, and has demonstrated its value (Marcus and Fonstad, 2008). However, the systematic application of aerial photography is limited by vegetation canopies and cloud cover during floods (Hess et al., 1995, Hess et al., 2003). The limitation also exists in radar and satellite imagery that is based on optical sensors (Wilson et al., 2007). The most realistic and feasible approach is considered to be microwave remote sensing, which penetrates cloud cover. However, because of the corner reflection principle (Rees, 2001) along with coarse ground resolution, this technology is currently unable to extract flood data from urban areas. Another commonly used data source is distributed sensors. In the U.S., sensors have been installed in coastal areas by National Oceanic and Atmospheric Administration (NOAA) and in rivers and canals by United States Geological Survey (USGS), but almost no sensors are distributed on streets that are dedicated for urban flood monitoring purpose.
There are very few existing urban flooding datasets that can be used for detailed model validation and urban planning. A dataset about a flood event on January 10, 2005, in the City of Newport Beach, California, was built by a collection of 85 digital photographs and eyewitness reports from city employees who were dispatched to manage and photo-document the flood. The data collection involved interviews and email communications (Gallien et al., 2011). Another example in UK showed that contemporary newspaper reports can enrich the evidence of the witness reports and photos taken on the day following the storm (Smith et al., 2012). In addition, insurance reports can provide some additional information of flooding events such as damage evaluation. However, recording of such information is not a priority for civil defense agencies during a major coastal disaster, and data collected using this method could be expensive to access, incomplete in coverage, and substantially delayed.
Since urban area usually has a dense population, a big data approach, which relies on volunteered data reports from citizens, could be a potential solution to provide primary or complementary urban flooding data. The history of using social media data to study natural hazards can be traced back to Muralidharan et al. (2011), who compared the difference between non-profit organizations and media in the use of Twitter and Facebook during the Haiti earthquake in 2010. Since then, a series of studies based on social media data have emerged with a focus on floods. Sun et al. (2016) mentioned their effort to use Flickr images to support remote sensing based flood maps. Jongman et al. (2015) explored the potential to use Twitter data for early detection of flood events in Philippines and Pakistan. Fohringer et al. (2015) was the first to use flooding water depth information, which was manually extracted from the photos posted in Twitter. Eilander et al. (2016) studied the floods of Jarkata in Indonesia with Twitter data. They introduced a probability map to quantify the data uncertainty and found the general accuracy of location is around 69% but rises to over 90% if the specific location was mentioned in the content of the posts.
These studies clearly showed the value of data mining in flooding research, but their application is still limited due to the poor resolution of data collected. For example, the resolution of Jongman et al. (2015) is at city level. To achieve sub-city resolution, researchers heavily relied on manual reading as used in Sun et al. (2016) and Fohringer et al. (2015). The best resolution based on automatic algorithms was probably obtained by Eilander et al. (2016). Based on a group of independent tweets reporting flood depth, they constructed a probability map on the scale of urban community with an average size of a few square kilometers. To obtain the location information, the authors used manually defined location names and gazetteers to match location mentions in tweets. To support disaster monitoring, relief responses, model validation, and decision making, we still need higher data quality and accuracy to fully understand the details of flooding events.
The present paper is aimed at demonstrating a new approach to collect and process data for urban flooding research using Natural Language Processing and Computer Vision (CV) techniques. These techniques are shown promising to extract hyper-resolution data with a wide coverage to support urban flooding issues.
