Object recognition aims at automatically assigning labels of object categories from a finite label collection to a given image. It is a fundamental problem in the field of computer vision and also a core technique for many applications [1], [2], [3]. Various algorithms for object recognition have been developed in the past decades which can be roughly summarized into the following standard pipeline: first a variety of handcrafted features are extracted [4], [5]; then the features are fed into some sophisticated feature encoding or transformation (e.g. dimension reduction [6], feature pooling [7]) procedures; finally those high-level features are classified with trained sophisticated classifiers. Though many works (e.g. SIFT [4], LBP [8], HOG [9], Gabor [5]) focus on developing better handcrafted features, the feature is still undoubtedly the major bottleneck for improving the performance of object recognition.
In recent years, great progress has been achieved in object recognition which is arguably attributed to the availability of larger datasets for training more sophisticated models and greater computation resources, and more importantly the application of deep learning algorithms.
The convolution neural network (CNN) – a popular example of deep learning algorithms – adopts a deep architecture that consists of many stacked convolutional and fully-connected layers. Such an architecture is specifically designed for solving computer vision related problems [10], [11], [12], [13], [14], [15], [16] and has also seen many other successful applications. The designed architecture of CNN is end-to-end trainable and is able to automatically learn features performing well for specific targets at different abstraction levels. With these high-level features, it is possible to classify images accurately with a simple classifier. Nowadays, CNN-based algorithms have achieved the state-of-the-art results on many challenging tasks [1], [3], [17], [18], [19], [20].
However, the simple feedforward architecture cannot well handle some challenging cases of object recognition. For instance, it has been observed that the powerful GoogLeNet [21] often fails in recognizing small objects in an image. Another challenging case for the feedforward deep architecture is the fine-grained object recognition [22] where the differences among different fine-grained categories are quite subtle. Distinguishing fine-grained categories requires the CNN based models to extract features from the most discriminative regions. Therefore, part annotations are usually utilized to assist fine-grained image classification [23]. Through empirical statistics on the classification errors, we find that the network is able to predict several candidate categories that include the correct one with high confidence. However, making the correct final decision on the single category is difficult for the network based models, due to the distraction from other candidate categories. Motivated by the above observations, we propose a novel Learning by Rethinking (LR) algorithm in this paper: instead of making the final decision based on one-pass of the data through the network, we introduce feedback connections and allow the network based models to “re-think” the decision and take the high-level feedback information into feature extraction. Benefiting from the feedback, the model is able to extract more discriminative low-level features with the guidance from the high-level information.
We propose two new types of layers – the “feedback” layer and the “emphasis” layer – to serve as the channel for transferring the feedback information. The feedback layer connects one top layer to one specific bottom layer in the network. The emphasis layer produces different weights based on such top-down information for the feature maps in the connected bottom layer. The proposed Learning with Rethinking algorithm exploits the fed back posterior probability of candidate object categories in the feedback layer, and endows the network model with the ability to “re-think” the decision during training. A new prediction will be made with consideration of previous prediction.
Fig. 1 provides the overall pipeline of the Learning with Rethinking algorithm in a time-unfolded manner for illustration purpose. Here we take the network-in-network (NIN) network as a basic CNN structure and illustrate how we build the proposed “Learning with Rethinking” network through augmenting the existing neural network architecture. The small “ibex” in the image is misclassified as “parachute” by a classic feedforward CNN (as shown in the left part where the probability of “parachute” is larger than “ibex”). In contrast, by further exploiting the posterior probabilities in the top layer before making final decision, the Learning with Rethinking algorithm recurrently adjusts the feature maps in hidden layers through feedback connection and identifies the correct category from other distracting categories. We will detailedly describe this pipeline in Section 3.Download : Download high-res image (451KB)Download : Download full-size imageFig. 1. Illustration of the time-unfolded overall pipeline. With a pre-trained model, several emphasis layers are inserted. Initial emphasis vectors in T=1 are fixed for all 1, and other emphasis vectors are calculated from feedback layers in the following iterations. The emphasis layers then alter the response of corresponding feature maps through the inserted emphasis layers. The total loss during training is the sum of all lt with equal weights. The blue solid and red dash arrows refer to the forward pass and the backward pass respectively. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)
The remaining content is organized as follows. In Section 2, we review some related works. Section 3 describes the architecture and other details of our Learning with Rethinking algorithm. Section 4 presents the experimental results. Finally, Section 5 concludes the paper.
