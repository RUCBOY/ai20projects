It is common practice to bring together groups to collaboratively decide upon solutions for complex problems. These groups and their facilitators have a challenging task. It is human nature to simplify complex problems to cope with difficult decision-making tasks (Sterman, 1994). If simplifications are biased or do not accurately account for complexity, solutions are often ineffective or can even worsen the problem (Sterman, 2006). Furthermore, individuals often have different tacit, unspecified perceptions about complex problems that create disagreement about solutions and paralyze decision-making (Vennix, 1999; Vennix, 1996). Thus, facilitators of collaborative groups must help participants conceptualize and appreciate the complexity of the issue, and use that understanding as the foundation for making decisions. Yet, facilitators typically have little information about how participants conceptualize an issue or the extent that their conceptualization incorporates and organizes complexity over time.
Conceptualization involves forming an internal representation of something by mentally combining its characteristics and parts (Craik, 1943; Johnson-Laird, 1995). Internal representations are the basic building blocks for learning and retention and believed to guide how individuals make decisions (Ifentaler, Masduki, & Seel, 2011; Shavelson, 1974; Snow & Lohman, 1989). For complex problems, a simple representation is not likely a complete depiction of the situation and can lead to ineffective solutions (Sterman, 2006). Conversely, a complex but disorganized representation can also hinder learning or paralyze decision-making (Ausubel, 1963). At the collective level, groups with more complex representations have also been shown to be more successful and perform better (e.g., producing higher quality products) (Carley, 1997; Curseu, Schalk, & Schruijer, 2010), and groups who have similar internal representations are more likely to have a shared view of the problem and solutions (Cannon-Bowers, Salas, & Converse, 1993; Rouwette, Vennix, & Mullekom, 2002; Scott, Cavana, & Cameron, 2013). Evaluation of participants’ conceptualizations can offer facilitators information about specific characteristics or parts of an issue that are becoming more or less clear to participants or becoming more or less agreed upon among a group. This information is useful to guide learning and improve shared decision-making.
Evaluating conceptualization involves two main steps: elicitation and characterization. First, one must elicit individuals’ internal representations (Jones, Ross, Lynam, Perez, & Leitch, 2011). Indirect elicitation approaches ask participants to write or provide verbal responses to prompts (e.g., “what do you think caused the rise in obesity?”). Direct elicitation approaches guide participants to represent their internal representations as a diagram or concept map. Both direct and indirect elicitation can either ask for open-ended responses (ideographic) or constrain responses to pre-determined concepts (nomothetic) (Curseu et al., 2010). Second, one must characterize conceptualization by looking for patterns or regularities in the characteristics and parts of the elicited responses.
A wide range of methodologies have been developed and used to evaluate individual or group conceptualization (Al-Diban & Ifenthaler, 2011; Fokkinga, Bleijenbergh, & Vennix, 2009; Johnson, O’Connor, Spector, Ifenthaler, & Pirnay-Dummer, 2006; Kane & Trochim, 2007; Kim, 2013; Novak & Cañas, 2006; Pirnay-Dummer, Ifenthaler, & Spector, 2010), and each have varying strengths and limitations. All elicitation methods distort one’s internal representation to varying degrees (Doyle & Ford, 1998; Scott et al., 2013). Elicitation asks individuals to create a representation of an internal representation (whether in verbal or written descriptions), which in itself changes conceptualization and even simple prompts introduce confounding effects. Many direct elicitation approaches that were originally designed as tools to help individuals or groups organize information and learn new concepts (Kane & Trochim, 2007; Novak & Cañas, 2006) likely distort representations more than indirect elicitation methods such as interview techniques that were designed specifically to reduce such confounding influences (Bougon, Baird, Komocar, & Ross, 1990; Nicolini, 1999). Ideographic elicitation with open-ended responses also distorts representations less than nomothetic because it does not constrain participants to certain concepts. By constraining choices, nomothetic methods make assumptions about the need to include and exclude different concepts, and may fail to capture stakeholders’ perceptions that are important for group discussion about the nature of the problem and solutions.
There are also numerous methods to characterize conceptualization and each method answers different questions. The methods generally focus on one or a combination of characterizations including: (1) assessment of accuracy (e.g., comparisons of concept maps with an expert map (Koszalka & Epling, 2010)), (2) assessment of the similarity of concept maps across a group (Johnson et al., 2006; Pirnay-Dummer et al., 2010), and (3) assessment of patterns of structure in the concepts and their connectivity (Ifenthaler, Pirnay-Dummer, & Seel, 2007). Each characterization method requires a coding process to track the presence (or absence) or concepts and structures in the participants’ elicited representations (e.g., counting the frequency of specific concepts). Choices about how closely to code to participant’s exact ‘words’ (e.g., apple = apple, orange = orange) or to generalize (e.g., apple = fruit, orange = fruit) create tradeoffs between capturing similarity across maps and masking differences (Carley, 1997).
Ultimately, different elicitation and characterization methods have different strengths and answer different questions. Researchers recommend the choice of methods should be consistent with the research questions of interest (Daniels & Johnson, 2002). However, evaluation in real-world practice is qualitatively different than in research settings. First, time and technological resources for data collection are more limited in practice than research settings, and a method that is fast and easy to implement is often a top priority that eclipses other considerations. Also a resource consideration, indirect elicitation methods such as interviews are intensive, especially when collaborative groups involve participants with less-developed or discordant language skills (e.g., youth, individuals with limited formal education or limited English proficiency) making them less acceptable or feasible. Second, evaluation in practice is ongoing and the specific research questions shift over time. Thus, a flexible approach that allows for different methods of characterization over time is needed.
Using established methods as a foundation, we designed an elicitation and characterization method with practice-based considerations in mind. We designed the elicitation method with the aim to prioritize feasibility in practice while limiting distortion of participants’ representations. We designed the characterization method with the goal to prioritize flexibility while allowing measurement of complex thinking. The purpose of this paper is to document and share the method. We first briefly review major existing methods that informed our research. Second, we will use a case example to illustrate the data collection and analysis methods we developed to evaluate how conceptualization of obesity changed among a small group of African American youth participating in a series of systems thinking workshops. Specifically, we will describe how we collected and used mind maps to evaluate changes in the breadth, depth and structural complexity of the youths’ conceptual understanding of obesity and assess their collective conceptualization of obesity. Finally, drawing on this case study, we will describe our evaluation strengths and weaknesses.
