Patients who suffer from amyotrophic lateral sclerosis (ALS), Parkinson’s disease or other motor disabilities usually require a direct and easily accessible communication approach. A brain–computer interface (BCI) bridges one’s brain signals directly to the external world without needing any muscular activities from the subject [1]. Among different brain signals, EEG has relatively higher temporal resolution and properties like non-invasiveness, inexpensiveness and safety. The P300 event-related potential (ERP) is one of the EEG signals that is commonly used in building speller systems. Due to the non-invasive signal acquisition method, the collected P300 ERPs often have very low signal-to-noise ratios (SNRs). Thus, stimuli must be repeated to improve the robustness of the spelling process. However, increasing the number of repetitions also lowers the typing speed. Such issues can be mitigated by adaptively choosing the flashing times [2], but more fundamentally, correct classification of P300 responses under a small repetition number is critical for building faster speller systems [3].
Previous works on P300 classification mainly utilized traditional machine learning techniques such as support vector machine (SVM) and linear discriminant analysis (LDA). Rakotomamonjy and Guigue [4] ensembled 17 SVM classifiers, reaching an average accuracy of 96.5% in character predictions, ranking the top in the BCI competition 2004 Data Set II [5]. The proposed method filtered the signal into 0.1–10 Hz and down-sampled and averaged them to reduce noise and variability. Then, it used a recursive channel elimination algorithm to select the best number of channels for different subjects. Li et al. [6] implemented ICA for ocular artifact correction before the SVM classification. Bostanov [7] used bagging linear discriminant analysis (LDA) to achieve a comparable result to SVMs in BCI competition II [8].
Over the past decade, deep learning, as a sub-field of machine learning, has made impressive advances in solving real-world problems such as computer vision and natural language processing. Novel deep architectures such as VGG net [9] and ResNet [10] have been proposed, empowered with the ability to capture sophisticated and hierarchical features of high-dimensional data. However, applications of deep neural nets in EEG signal detection are still at the beginning stage [11]. Cecotti and Graser [12] developed a 4-layer convolutional neural network (CNN) to achieve comparable results to the ensembled SVMs. The spatial and temporal features of the input P300 signals were extracted respectively by the first and second layer of the CNN and then were sent to a fully connected layer for classification. More recently, Langkvist et al. [13] used deep belief networks (DBN) to perform automatic feature extractions on raw sleep data. Wulsin et al. [14] modeled single channel EEG waveforms with DBNs for classification and anomaly detection in a semi-supervised paradigm. Stober et al. [15] combined CNN with DLSVM output layers to achieve rhythm classification among individuals. However, there is a lack of efficient methods proposed for fast P300 classification in real-world speller systems.
In this paper, we propose a novel deep neural network to achieve state-of-the-art P300 signal classification and character recognition. EEG signals often have a low SNR and high subject variability, for which hand-designed features perform suboptimally. Deep convolutional neural networks, as proved in the field of computer vision, may be capable of capturing the intrinsic features of EEG signals. We introduce Batch Normalization and Dropout to improve the generalization of our model and use ReLU activations in convolutional layers to accelerate training. Our model combines the feature extraction and classification steps into one process, requiring less signal preprocessing work. The paper is organized as follows: in Section 2, we describe the P300 speller paradigm. In Section 3, we provide information regarding our experimental data, model architecture and training details. Experimental results are presented in Section 4 and discussions are provided in Section 5.
