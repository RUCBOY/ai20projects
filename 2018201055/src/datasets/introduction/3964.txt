With the development of information technology and social media networks, digital images are found everywhere in our daily life and nearly become the most pervasive information carrier. Besides playing an important role in information spreading, digital images, as a kind of visual data, are usually regarded as a certification of truth or evidences in front of a court of law since we traditionally believe in the integrity of what we see. However, people can acquire images easily with the popularity of inexpensive cameras and cell phone devices, and more importantly, can also manipulate them from the source information to contents and even create ones as they want with the development of image manipulation softwares and social networks over the years. Therefore, the situation highlights the necessity to verify the source and authenticity of digital images. It is a key work in the field of digital image forensics [1].
As one main field of image forensics, source camera identification has two branches. One is to match an image with one individual camera, and the other is to match it with a specific camera model. For these tasks, the researchers have been devoted to studying the pipeline of image acquisition process and exploiting traces or artifacts introduced to the images to capture source information. As shown in Fig. 1, image acquisition process involves several stages each of which can be implemented differently in different cameras. Consequently, some unique traces or artifacts are introduced in the final images. According to those traces from given cameras, a variety of camera identification approaches have been proposed and they can be categorized into two groups.Download : Download high-res image (282KB)Download : Download full-size imageFig. 1. A common digital image acquisition process. When a digital camera captures an image, the light reflected by the real scene firstly pass through the optical lens and the filter. Before hitting the imaging sensor which is usually only one and can only record on color value at each pixel, a color filter array(CFA) is used to allow only one color component of light to pass through it at each position. Then the other two color channels are interpolated by specific CFA interpolation algorithm which is known as demosaicing algorithm. After demosaicing, a set of post-processing operations including software processing and in-camera JPEG compression are performed to obtain a digital image. Finally, the image experiences some out-camera processing such as data transmission and computer processing to generate the final digital image.
The first group of methods managed to compute a hypothesized analytical model on certain stages of image acquisition and then evaluates the correlation between the model and the tested image. Lucas et al. [2] used a sensor pattern noise model to identify the source camera sensors. Choi et al. [3] chose a lens radial distortion pattern as a fingerprint. Dirik et al. [4] utilized dust-spot characteristics to identify the source digital single lens reflex camera. In order to extract reliable photo-response non-uniformity (PRNU), Amerini et al. [5] introduced a minimum mean square error (MMSE) filter in the un-decimated wavelet domain to estimate the PRNU noise. Li [6] suggested that an enhanced fingerprint can be obtained by assigning weighting factors according to the magnitude of scene details to eliminate the influence of image content. Furthermore, Tomioka et al. [7] proposed a method based on the pairwise relationships of pixel clusters to suppress the effects of noise contamination. Recently, Li et al. [8] proposed the use of principal component analysis (PCA) to formulate a compact SPN representation. Besides, a training set construction procedure was also proposed to enhance the de-noising effect in [8].
The other group of methods relied on well-designed feature vector extraction and machine learning classifiers. Swaminathan et al. [9] constructed an efficient camera identifier through estimating interpolation coefficients of color filter array (CFA). Xu et al. [10] extracted 354-dimensional features based on local binary patterns (LBP) to distinguish camera models. Hu et al. [11] developed an improved algorithm using inter-channel demosaicing traces for camera model identification. Tuama et al. [12] proposed a method to extract high order statistics consisted of co-occurrences matrix, traces of color dependencies features related to CFA interpolation arrangement, and conditional probability statistics. A better identification result compared with the correlation based method was reported in their paper. Different from [10], the recent work [13] also investigated the discriminative ability of local phase quantization (LPQ), a LBP like texture descriptor, to distinguish imaging devices. The combined texture features of LBP and LPQ resulted in higher identification accuracy compared with [10]. Chen etal [14] built a rich model of 1372-dimensional features to identify the model of an image’s source camera. They utilized two co-occurrence matrixes to capture the reconstructed error between the original image and the reconstructed version. The average identification accuracy of 99.2% over 12 camera models was reported in their paper.
On the other hand, the convolutional neural networks (CNNs) ,which are strong in feature learning, have made great success in computer vision tasks and developed rapidly since 2012 [[15], [16], [17], [18]]. These achievements arouse attention from the community of digital image forensics and several works have been done to exploit suitable approaches to apply CNNs to solve forensic problems. Baroffio et al. firstly applied CNNs to identify source cameras, but the poor performance indicated that the CNNs designed for computer vision (CV) cannot be suited to camera identification directly. On the basis, they proposed a new approach to dealing with camera identification in [19]. They simply regarded CNNs as a feature extractor and combined the networks with SVM classifiers to complete the classification tasks. Chen et al. [20] noticed that the difference among classes of image forensics problems is subtle and added a preprocessing layer before CNNs for median filtering forensics. This preprocessing process achieved a significant boost in performance. Bayer et al. [21] proposed a new convolutional layer which is similar to a preprocessing layer as a part of the CNNs to detect image manipulation. Tuama et al. [22] presented a CNNs structure similar to AlexNet and equipped it with a high-pass filter (HPF) layer [23] to cope with camera model identification. Their experimental results showed the important role that preprocessing part plays in classification accuracy and indicated that trying the bigger networks such as GoogleNet or ResNet might be promising. The experimental results in [24] also confirmed the points mentioned above. Recently, Yang et al. [25] proposed content-adaptive fusion residual networks to detect image origin and achieved satisfactory performances in the case of query images with small size in camera brand identification. But for camera model identification, the detection accuracy is only 87.55%, so there is still much room for improvement.
The CNNs method is promising but not efficient enough for camera model identification. Firstly, the database available is not as large as ImageNet. Therefore, the CNNs cannot be very deep, or rather the effectiveness of training may be affected. Secondly, the CNNs tailored for CV are sensitive to the primary visual information of an image rather than the intrinsic source information which is invisible for the naked eyes. From the view of the current situation of the related research, the intrinsic source information is mostly hidden in the noise of images or other statistical features. It might be not realistic to let CNNs capture such low signal-to-noise signals. However, we can make “glasses” for CNNs so that the effective source information can be enlarged in the “eye” of CNNs or exists in a way that is easier to be recognized by CNNs. That is to say, we can give some hints or guidance to CNNs. Therefore, we propose that CNNs can capture the information that human’s eyes cannot perceive and accomplish the camera model identification tasks with the help of research results from the experts of related fields. Particularly, we modify a shallow CNNs architecture like AlextNet and use the simplest LBP operator to help the CNNs to extract source camera information of images. Experimental studies illustrate that our method achieves better classification accuracy results compared with the state-of-art classical and CNN-based methods.
The rest of the paper is organized as follows. Section 2 explains the details of our proposed method. In Section 3, extensive experiments are carried out and comparisons of state-of-art are presented to show the superiority of proposed method. And, conclusions of the paper are drawn and some perspectives are proposed in Section 4.
