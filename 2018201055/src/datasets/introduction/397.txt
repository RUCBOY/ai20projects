Technology of accurate depth estimation has been widely used in industrial applications, such as human-robot interaction, ultrasound image diagnosis, autonomous driving and 3D reconstruction [1]. Binocular Stereo Matching algorithm belongs to passive depth estimation, which consists of two cameras placed horizontally [2]. A stereo image pairs can be captured simultaneously by these cameras. Our researches focus on calculating the disparity d of each pixel between corrected stereo image pairs. Algorithm acquires disparity d by finding the shifts between one pixel and its corresponding pixel in the other image so that the two pixels are the homologous points in real space.
A typical stereo matching algorithm can be decomposed into four steps: feature extraction, matching cost computation, matching cost aggregation and disparity estimation [3]. According to [3], each stage of stereo matching is set up with corresponding optimization objectives, and the optimization criteria of each stage is all designed by manual. Most previous methods [4], [5], [6], [7] used hand-crafted reliable features to represent image patches and then selected matching pairs. However, using the method of manual design to calculate the matching cost of pixel intensity directly will lead to the poor robustness of the system [8], [9]. Lately, due to the breakthrough progress of deep learning, methods based on convolution neural networks (CNNs) have achieved the best scores on many visual tasks such as image classification [10], object detection [11], and semantic segmentation [12], [13]. CNNs show a strong feature extraction and model expression ability [14]. CNNs-based disparity estimation method transforms stereo matching into a learning problem, which can automatically learn optimal expression from labeled image data. Recently, with the development of deep neural networks, the performance of disparity estimation is signficantly improved [15].
In the light of [15], CNNs are used to extract the deep semantic features of image patches and compute matching cost. Although the performance on several benchmarks is significantly promoted, there remains some difficulties, including the limited receptive fields and complicated regularized functions. Up to date, end-to-end models [16], [17], [18], [19], [20], [21] are designed to obtain disparity map directly from stereo images, which achieve outstanding results. However, the above methods still have drawbacks, the problem of local ambiguities in textureless areas, reflective surfaces, thin structures and repetitive patterns are very limited.
Human can perform binocular alignment well at ambiguous areas by exploiting more cues such as global perception of foreground and background, scaling relative to the known size of familiar objects, and semantic consistency for individuals [21]. Sudden changes and constant disparity values are difficult to deal with for machines. This kind of situation mostly appears in the foreground, background and edge of the object. And it can be solved in the semantic classification task. We can introduce semantic classification task to improve the cognitive ability of system. Both semantic classification and disparity estimation tasks usually use deep convolution networks as feature extractor, such as ResNet-50 [22] or VGG-16 [23]. However, the construction of depth neural network also brings difficulties to the optimization of disparity estimation [24], [25], because with the stacking of convolutions, we will gradually blur low-level feature information and highly integrate high-level feature information, which is exactly the rich and accurate low-level feature information plays an important role in stereo matching. From [26], it has been demonstrated that subpixel shifts contained in stereo images can be used to improve super-resolution and disparity estimation performance.
In this work, we propose a network named MASNet to exploit semantic clues and richer multi-level feature information in stereo matching. More precisely, dilated convolution [16], [17] and segmentation attention mechanisms are used during feature extraction to learn more about segmentation maps so that disparity can be better regression. A multiple cost volume is proposed to provide multiple clues for disparity regression. The shallow merging network is deployed behind the 3D network to integrate with deep semantic features and compensate for the negative impact of network depth. Therefore, we can use the characteristics of our network architecture to fuse the deep disparity prior and low-level feature for disparity estimation. Through our method, we can bypass the negative influence of network depth and overcome the difficulty of matching in some inherent ill posed areas, and even deal with more complex structures.
Based on the discussion above, our main contributions are listed below: 1) we construct a multiple cost volume (MCV) to provide better similarity measures for disparity estimation; 2) we develop and deploy a segmentation attention head module (SAH) in this work, which can be leveraged to capture contextual information from long-range dependencies more effectively, so as to provide perfect evidence for disparity prediction; 3) we integrate a novel shallow merging network, which can obtain richer multi-level feature information from aligned RGB-LRS image pairs. And it is embedded in the high-level feature information obtained from the Top-k pooling layer; 4) we adjust the 3D module to avoid the computational cost and optimization difficulty caused by the 3D structure.
