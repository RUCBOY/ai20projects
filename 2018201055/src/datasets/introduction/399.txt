Object recognition has gained immense popularity in the last decade with the creation of sufficiently large datasets, and improvements in processing resources [1]. After the revolutionary work AlexNet [2] which achieved state-of-the-art recognition accuracy on ImageNet [3], there has been enormous amount of work [4], [5] that came through with even deeper networks and better accuracy results. Later, the idea of object localization with bounding boxes is also studied in plenty of research [6], [7] and exposed more network parameters to deal with. Furthermore, most of these systems with enormous number of parameters are deployed in mobile applications such as face recognition, product differentiation, pedestrian detection etc. Integrating such frameworks into devices with limited amount of resources such as memory, power storage and computational units is crucial. Fortunately, notable amount of redundant parameters [8] in a deep neural network (DNN) makes it possible to uncover a smaller network whose test accuracy is comparable to that of original network [9].
In addition to the complexity that arises in DNNs due to the increasing network sizes, broadly speaking, deep learning is applied as a black box on the observed or simulated data. Therefore, this black boxness reveals artificial intelligence (AI) frameworks which are not interpretable in terms of either model, design or algorithm [10]. This lack of transparency causes AI frameworks not to be reproducible, verifiable and reliable. Intrinsically, systems without interpretable domains suffer from being explainable as well. As the integration of machine controlled systems deploying AI to make critical decisions into human life grows, the importance of an AI framework to be explainable understood much better since concerns such as safety, robustness, accountability, etc. raise. Assume an autonomous vehicle assisted by an AI framework detects objects on the lane and prevents crash without interacting with human. If we only know the performance of the trained model but not the reason that it is obtained that high, then we wouldn’t be able to explain the reason of an unexpected crash or how to prevent it for the next time. In the future, this problem will turn into a larger intractable mechanism when we consider classification tasks that is trained on much larger datasets in terms of both volume and category. Furthermore, human-like multitask AI frameworks trained on such datasets and that are capable of categorizing many sub-domains such as text, image, speech in a single network will have more black boxness due to larger and complex optimization and hyperparameter spaces. Human brain, which is highly capable on a diverse set of tasks has the ability to focus on a sub-task, e.g., searching an object, checking condition of a machine etc., which enhances perception of task related objects; while suppressing irrelevant stimuli. Research on explaining brain mechanisms to focus on a specific task can indeed be useful for investigating deep neural networks too.
Our source of inspiration, Human Visual System (HVS), is optimized for quick detection and recognition of objects within the visual field [11]. Visual attention mechanism of the HVS is divided into two components: bottom-up and top-down. Bottom-up mechanism is a non-attentional process observes a scene in general and gathers high-level information, which, when associated with other thinking processes, helps us to control the attention processes and navigate to a certain part of the scene. On the other hand, top-down visual attention mechanism is goal oriented and it is driven by the intention of the observer. This phase of attention includes constraining the recognized scene, based on scene understanding and object recognition [12]. Therefore, when we look for a specific kind of object, our visual sensitivity is biased in favor of identifying the features belonging to that specific target, while other objects become outliers or less perceivable which is known as inattentional blindness [13]. On the other hand, attention based research in deep learning mostly focuses on revealing salient features of a scene when model is being trained [14]. In each iteration of learning process, this information is exploited to update model in a way where irrelevant pixels which are obtained through heat maps of activation features are weakened (soft-attention) or not considered (hard-attention) in the final decision. Moreover, this saliency based feature extraction is performed regardless of a specific category search. These attention mechanisms also help to interpret how network learns input-output mapping and selects a target class as an output. It can be argued that the stimuli driven, bottom-up part of the visual attention mechanism is inherently included in a well-trained neural network, due to assigning higher weights for the salient visual features during optimization. Besides, network pruning and attention based network update methods have similar impacts as they remove or weaken redundant neurons which probably belong to non-salient regions. Furthermore, the impact of saliency based feature extraction on the performance of object detection is explored in various studies [15], [16]. However, goal oriented top-down part have not been employed in neural networks based object recognition methods yet.
Network pruning approaches are subsequent to a preliminary training of the originally designated network and followed by fine-tuning to compensate accuracy drop. In contrast, proposed method first trains a network until all weights converge well. Afterwards, we prune this well-trained network to make it competent on a specified task among all tasks the network is learned. Once network is converged, fine-tuning is never performed in the proposed method. This is because pruning a well-trained network in favour of a specified task and then fine-tuning demolishes already learned weights that contribute other classes. Our policy is ’train once and prune as desired’. Hence, when network is converged, we store weights in the system memory and utilize them either to specialize network on a specific task by pruning or to generalize it over all target classes without pruning. Moreover, fine-tuning an already pruned (not goal-driven) network to compensate accuracy drop and uncover a smaller network differs from our objective and it is another research idea whose examples are summarized in Section 2. Proposed method mimics top-down mechanism in HVS in which when a certain task is confronted, human doesn’t utilize every representation he has learned but the ones that evoke the given task. By doing so, it is possible to understand how much of the representations learned in optimization are utilized in recognition of a specified target. More specifically, this process reveals units or kernels which activates specified class. It also enables to extract neuron activation patterns and hence to measure the similarity between categories. The ability of proposed method to distinguish salient and non-salient features for specified targets, providing similarities between categories and making decisions based on these understandings is the contribution to the explainable deep learning research field. Moreover, we demonstrate that without harming overall performance it is possible to reduce the computational units, memory footprint and processing time in the inference phase. Finally, our method can be more effective on multitask networks trained on very multi-class datasets.
To exemplify goal-driven object recognition, assume a DNN integrated into an unmanned aerial vehicle looking for any of the target classes the network is learned to recognize. Then the network plausibly considers all of the neurons in a forward pass as seen in Fig. 1(a). On the other hand, consider the case the network is assigned to recognize a specific class out of all targets. Do we still need to use all network parameters to identify this specific object or is there any subset of parameters (Fig. 1(b)) that can obtain same performance with less time and storage? Later we will show that it is possible to accelerate inference and reduce memory footprint by removing those parameters which do not activate the features of that specific target in a similar fashion with top-down mechanism.Download : Download high-res image (700KB)Download : Download full-size imageFig. 1. (a) All of the network parameters are utilized to recognize any possible target class the network is trained on. (b) Goal-driven network pruning in which only relevant network parameters are utilized for recognition.
To our best knowledge, none of the network pruning frameworks published before performs pruning for a specific search task. Nonetheless, in Section 2, we briefly present most important and recent pruning studies to hold an opinion on different pruning criteria. Our approach removing task irrespective weights is introduced in Section 3. While we discuss and illustrate the results we obtained in Section 4, a brief summary with possible directions to guide future work is provided in Section 5.
