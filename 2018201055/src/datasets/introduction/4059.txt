Assessment procedures have been recognized as an important stage in understanding students’ learning achievement by providing feedback to teachers and students (Boud, 2007). However, static and simple standardized tests are insufficient to represent learning outcomes (Marzano, 2000, Tzuriel, 2000), as this type of assessment focuses too much on learners’ overall performance. The results of such tests show the learners’ present achievement (Marriott, 2009, Wang, 2010); lack feedback (Resing, Tunteler, de Jong, & Bosma, 2009) or adequate information for remedial instruction (Shih, Ku, & Hung, 2013); make no attempt to change, guide, or improve students’ learning performance (Tzuriel, 2000), and fail to reflect the learning potential of students and learning processes (Resing et al., 2009, Wang, 2010).
To overcome the criticisms of static assessment, researchers have proposed dynamic assessment (DA), emphasizing that the DA procedure is closely related to learning processes (Tzuriel, 2000). Instead of focusing on a specific moment, DA integrates an overall plan to enhance students’ learning potential and change their cognitive functions and structures, resulting in more flexibility and applicability in problem-solving situations (Davidovitch, Parush, & Shtub, 2006). DA has been found to be more effective than standard web-based tests or traditional paper-and-pencil tests in facilitating students’ learning and performing remedial teaching (Wang, 2011). Moreover, web-based DA can also collect data on students’ learning effectiveness through specific web characteristics (Wang, 2010, Wang, 2011).
The technology-mediated learning (TML) perspective seeks to motivate researchers to learn about how technology enhances learning (Alavi & Leidner, 2001). The effectiveness of web-based DA in facilitating learning has been previously demonstrated (Wang, 2010, Wang, 2014). The conditions of the DA system do not allow interaction with other learners or instructors; the system is designed to encourage learners to acquire prompts and instruct them on how to apply the prompts in their learning processes to enhance their learning performance. Thus, based on the TML perspective, we focused on developing and using the graduated prompting assessment in an effective TML environment.
Additionally, despite computer-based assessment’s increasing acceptance in engineering graphing courses to train students in graphing skills, empirical research that sheds light on the efficacy of the assessment in engineering graphing courses is still being undertaken. Engineering graphing is an important part of the process of manufacturing industrial products. Poor product designs have a direct influence on the quality of the products (Selvaraj, Radhakrishnan, & Adithan, 2009). Nirmalakhandan, Daniel, and White (2004) noted that the application of computer-based DA improved problem-solving skills and enhanced academic performance in basic engineering.
Thus, the aim of the present study was to contribute to our understanding of how the computer-based graduated prompting assessment system is designed through feedback to support 2D graphing; other aims were to examine the effectiveness of the computer-based graduated prompting assessment system—one type of DA—and to understand students’ learning processes in a computer-aided 2D graphing course. In particular, the major research question was, “How does computer-based graduated prompting assessment influence students’ academic performance in a computer-aided 2D graphing course over time?” Two approaches are suitable for analyzing the growth of individual learning processes: the growth model of hierarchical linear modeling (HLM; Strenio, Weisberg, & Bryk, 1983) and the latent growth model in structural equation modeling (SEM; Meredith & Tisak, 1990). Both approaches appear to offer similar advantages, although SEM is generally considered to be more flexible and is widely used. However, HLM is widely regarded as more suitable for cross-level data (Hox & Stoel, 2005). Thus, this study drew from the TML perspective to design the graduated prompting assessment in an effective TML environment and used the growth model of HLM to explore the longitudinal effect of computer-based graduated prompting assessment.
