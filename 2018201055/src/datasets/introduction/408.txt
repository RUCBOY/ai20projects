Salient object detection focuses on localizing and segmenting the most distinctive object(s) in a visual scene. It mimics the human visual attention mechanism to efficiently allocate visual processing resources on informative visual elements. Thus,SOD can be used as a pre-processing technique and supply informative cues for many other computer vision tasks, such as object detection [1],video object segmentation [2], semantic segmentation [3], [4], image editing [5] and intelligent vision surveillance in smart city application[6].
MostSOD models [7], [8], [9], [10], [11], [12], [13] typically detect salient objects from RGB images. In a pioneer work of [14], Ouerhani and Hugli showed that depth could also supply useful cues and largely boost the performance for saliency detection. This is also intuitive since human beings live in a real 3D environment and depth largely impacts our perception of visual scenes. Many subsequent saliency models, e.g., those in [15], [16], [17], [18], have started to leverage RGB-D images for saliency detection. Recently, Convolutional Neural Networks (CNNs) have widely been seen in the computer vision community andhave also shown excellent performance on various computer vision tasks. Hence, many works have also introducedtwo-stream CNNs for RGB-DSOD to exploit their powerful feature learning capability.
Some deep models [21], [22] appliedthe two-stream Fully Convolutional Network (FCN) [19] architecture to feedforward each input RGB-D image pair intotwo CNN streams and directly obtained the saliency mapby fusing their final feature maps, as shown in Fig. 1(a). FCN processes the input image pair in a bottom-up manner, progressively extracting low-level features in shallow layers and high-level features in deep layers. Although it is simple and straightforward, the single path of the bottom-up information flow heavily limits the model performance since usually the final feature map of a CNN is very coarse, thus the obtained saliency map lacks object details.Download : Download high-res image (166KB)Download : Download full-size imageFig. 1. Comparison of different network architectures. (a)Two-stream FCN [19]. (b)Two-stream UNet [20]. (c) Our proposed network. We cascade both top-down and bottom-up feature aggregation for deep RGB-DSOD to further leverage improved low-level features for promoting high-level features. We also propose to holistically aggregate features across all levels to learn plentiful multi-level feature interactions.Early aggregation paths are also presented to aggregate and propagate cross-modal encoder features.
Considering the multi-level feature maps spontaneously obtained by each CNN, most of other works [23], [24], [25], [26], [27] have adopted thetwo-stream UNet [20] architecture to aggregate multi-level features for RGB-DSOD. As shown in Fig. 1(b),the two-stream UNet first usestwo encoder networks to extract multi-level image features in a bottom-up manner. Then, there areone or two decoder networks to successively aggregate high-level features with low-level ones in a top-down processingand simultaneously fuse cross-modal features. In each decoder module, the features of its symmetric encoder module at the same level are reused through a skip connection and fused with previous decoder features. As such, discriminative semantic information in deep layers can be effectively integrated with local structures in shallow layers through the top-down propagation, thus enabling both accurate object localization and precise shape and boundary segmentation.
However, UNet carries out top-down feature aggregation only once. Only high-level information can be aggregated with low-level features to improve their representation ability in the decoder, while the high-levelfeatures themselves cannot be improved. To solve this problem, in this paper, we propose to add an additional bottom-up aggregation path, in which the improved low-level features from the top-down path are propagated again to high-level layers, as shown in Fig. 1(c). As we cascade both bottom-up and top-down feature aggregation, the features across all levels can be gradually improved.
Another problem is thatabove networks only gradually aggregate features at every two adjacent levels. Although this feature aggregation scheme avoids large scale changes and is widely used in previous works, we argue that it limits direct feature interactions among multi-level features. To alleviate this issue, we further propose holistic aggregation paths to holistically aggregate multi-level features after the bottom-up and top-down processing. Thus, the network can learn abundant cross-level feature fusion mechanism forSOD by considering them all at the same time.
Considering the two-stream architecture, the authors of existing works usually simply adopt two-stream encoders independently and only conduct feature aggregation in the decoding phase [21], [27], [28]. Or they fuse cross-modal encoder features to reuse them in decoders [29], [30], [31], without improving other encoder features. This is because they use pretrained CNN models as encoders and they are required to preserve their network structures and pretrained parameters. In this paper, we aggregate and propagate cross-modal features at the early stage, i.e., in the encoding phase. We adopt a residual-learning based aggregation scheme to aggregate cross-modal encoder features and propagate them back to the original encoder paths, hence enhancing the feature capability from the very beginning.
Furthermore, previous work usually aggregate features by directly concatenating [23], [24], [25] or adding [32] them together. However, not all aggregated features are helpful for the finalSOD task. We propose to generate gated attention for all of the involved features to modulate the aggregation flow at every node. To reduce the amount of the required gated attention weights and the computation and memory costs, we propose to factorize the gate matrix into the multiplication of channel-wise and spatial gates with multiple factors. This proposed multi-factored gated attention mechanism learns different gates in different factors and thus can ensemble multiple attention models to make a better decision.
At last, we summarize the main contributions of this work as follows.
•We propose a novel feature aggregation architecture for RGB-DSOD. We cascade both bottom-up and top-down feature aggregation paths and also introduce holistic aggregation paths, whichpromote both low-level and high-level features and boost multi-level feature interactions.An early aggregation scheme is also presented to enhance the two-stream encoders.•We propose a novel factorized gated attention model for modulating the feature aggregation actions. We factorize the gated attention weight matrix of each feature map as the multiplication of two multi-factored channel-wise and spatial gate matrices. As such, both computational costs and model effectiveness are improved.•We conduct experiments oneight widely used RGB-DSOD benchmark datasets. Experimental results demonstrate that all of the proposed model components can gradually improvethe model performance. Consequently, our final model outperforms other state-of-the-art methods.
In the subsequent sections, in Section 2 we first discuss our model with related work. Then, we present our model in Section 3 and report the experimental results in Section 4. Finally, in Section 5 we draw our conclusion.
