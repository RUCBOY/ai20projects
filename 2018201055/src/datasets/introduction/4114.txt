Assessments of many psychological characteristics can be achieved by analyzing the conversational interactions between people as they experience events in the world. These conversation-based assessments may be used at different grain sizes for different purposes. For example, researchers have assessed knowledge, strategies, and skills in human tutoring (Cade et al., 2008, Chi et al., 2001, Graesser et al., 1995), collaborative learning (Dillenbourg and Traum, 2006, Rosé et al., 2008, Slavin, 2017), and collaborative problem solving (Care et al., 2016, Foltz and Martin, 2008, Griffin et al., 2015, Hesse et al., 2015, Rosen and Foltz, 2014).
These conversations among humans run the risk of diverging in too many directions and not covering enough relevant situations to achieve an adequate assessment of psychological characteristics. For example, students in tutoring sessions and study groups are prone to engage in small talk, gossip and other off topic conversations. These activities do not uncover what they learn about the subject matter. Collaborative problem solving teams run the risk of “group think” (Janis, 1982) where high conformity and agreeableness prevents the group from achieving better solutions than would have otherwise evolved from conflicts, multiple perspectives, and subsequent resolutions. Naturalistic dialogues and group interactions have high ecological validity, but a low likelihood of achieving the necessary states for reliable and valid assessments of many psychological characteristics.
Computer agents provide conversation-based assessment in a more controlled manner that covers relevant situations to achieve an adequate assessment of psychological characteristics.
Conversational agents are computer-generated entities that interact with one or more humans in conversations. The conversational agents interact with humans through chat, talking heads, or embodied animated avatars in virtual worlds. The agents can perform actions, interact with multimedia, and hold conversations with humans and other agents in natural language. An agent in a group conversation can express disagreements and thereby disrupt conformity to assess how the various members in the group resolve conflicts. A human can interact with two or more conversational agents, as pursued in the 2015 Programme for International Student Assessment (PISA) for Collaborative Problem Solving (Graesser et al., 2017, OECD, 2013) and in prototype assessments of scientific inquiry, mathematics, English language learning, and collaborative problem solving at Educational Testing Service (Liu et al., 2015, Zapata-Rivera et al., 2015).
It is important to clarify what is meant by assessment in this article. Stealth assessment tracks students’ psychological attributes at varying grain sizes without the student even being aware they are being assessed, as in the case of games (Shute & Ventura, 2013). Stealth assessment is not used in high stakes assessments for ethical reasons, but is used in educational and entertainment systems that dynamically adjust to the individual’s psychological profile. For example, games become more challenging to the extent that the person playing the game has better performance. Formative assessment occurs at varying grain sizes as feedback to instructors (and sometimes students) so they can adaptively change the pedagogical approach in light of the feedback on the students’ psychological profiles. Summative assessment measures students on what they have achieved or on their stable traits and aptitudes. Summative assessments are high stakes when there are practical consequences of the scores, such as admission to a school, being hired on a job, or allocation of resources in a school district.
The meaning of assessment in the present context includes the stealth, formative, or summative assessments that are part of intelligent tutoring systems with conversational agents, as opposed to high stakes assessments. However, the approaches to conversation-based assessment in intelligent tutoring systems have had an impact on the design of high stakes assessments with agents, as in the case of PISA 2015 and the recent assessments developed by ETS. We refer to these high stakes assessments with agents when relevant.
Some conversational agents are scripted and stage their conversational moves in a rigid manner that does not depend on the previous conversation. Although scripted, one can still collect meaningful assessments of the human by observing how the human responds to the scripted situation. An assessment would have a sequence of scripted conversational episodes, with an assessment of the human at the end of each episode. In contrast, intelligent conversational agents adaptively respond to a person’s actions, verbal contributions, and even their emotions, based on the history of the prior conversation. Most of the systems we have developed are hybrids between scripted and intelligent interactions. Whether the agents are scripted or intelligent, the data are logged throughout the interactions in order to assess the individual’s mastery of subject matters, skills, and proficiencies on psychological characteristics.
This article has two objectives. The first objective is to describe some learning and assessment environments with conversational agents that have different designs. These designs are representative of the different types of social interactions that occur among people in learning, domestic, and work environments, such as tutoring, small group conversations among peers, collaborative problem solving, and collaborative work. There is only one computer agent during dialogues, so the human needs to participate continuously in the exchange. There are two agents in trialogues (Graesser, Li, & Forsyth, 2014) so there are additional social affordances for assessment of humans. For example, the computer can track how the human responds to two agents who stage a conflict or argument with different sides of an issue. A student can learn by observing the social interaction between two agents; the agents turn to the student and ask a simple question to assess the student’s understanding of the conversation between the agents. There are larger groups with different combinations of agents and humans (Liu et al., 2015, Morgan et al., 2013), but it is beyond the scope of this article to describe these efforts.
The second objective of this article is to clarify how assessment is conducted in these dialogues and trialogues with computer agents. There are dozens, hundreds, and sometimes even thousands of observations per hour in these conversational assessments so the volume of data is rich. The diversity of human responses is also rich because the computer environments can track many forms of input data: (a) traditional data (clicks, multiple choice, response times), (b) automated analysis of natural language and conversation patterns, and (c) sensing data from facial expressions, body posture, gesture, speech, and other communication channels (D’Mello & Graesser, 2012). The automated systems in “b” attempt to understand the student’s natural language during the conversational interaction. This is possible because of advances in computational linguistics (Jurafsky and Martin, 2008, McCarthy, 2012) and statistical representations of world knowledge and discourse meaning (Foltz et al., 1998, Landauer et al., 2007). However, it is not necessary to require natural language understanding in these agent-based systems. The human can select a verbal response or action from a menu of alternatives at each turn in the conversation when the human is expected to respond. This multiple choice approach to handling chat-based assessment has been implemented in PISA 2015 collaborative problem solving (Graesser et al., 2017, OECD, 2013).
