1.1. Problem statementThe use of UAVs (Unmanned Aerial Vehicles) is growing significantly for a wide range of purposes and missions (Pajares, 2015). Once the mission ends, the UAV must land onto a safe place, such as a secure platform. The autonomous navigation is based on GPS, allowing the UAV to find the platform location. However, when GPS data are not available, the final phase of landing can be achieved using a machine vision system that recognizes a patented geometric figure (Cruz, Sánchez, & Pajares, 2012). Fig. 2. shows this figure in place on the landing platform. Additionally, the platform could be used as reference for stabilization and control (Lungu, 2012, Lungu and Lungu, 2013) for safety considerations during landing.The geometric pattern used for this purpose is unique and could not occur naturally. The figure is made up of a collection of geometric shapes combined in such a way as to try to ensure that if a part is blinded, the expert system can still work effectively, and the UAV landed. Based on these assumptions, the problem is then to identify the constituent geometric shapes on the platform through the images captured with the onboard vision system. This uses a technique based on structural geometric relations between these shapes which are mapped as a degree of confidence or probability according to the number of relations correctly identified. For our evaluation and testing we use a quadrotor md-400, Fig. 1, along with two different Samsung Galaxy mobile devices that capture and process the images.Download : Download high-res image (49KB)Download : Download full-size imageFig. 1. Real UAVs flying during the testing process.
1.2. Summary of available methodsSeveral strategies have been proposed that combine computer vision with geometric shapes for autonomous flight:
(1)Guili, Yong, Shengyu, Yuehua, and Yupeng (2009): a T-shaped figure was proposed to determine the angle that provides the relative orientation of the figure and the UAV. They used infrared radiation to achieve a high temperature contrast between the figure used to identify the landing place and the environment. This method uses the actual shape of the target on the ground and the start of the disappearance of the line, generating an error that is smallest when the UAV is near the runway. Compliance with the basic requirements of autonomous landing of UAV is achieved. Computer vision techniques employed are pattern recognition using invariant moments related, segmentation and extraction of edges. Although this technique uses infrared radiation instead of a conventional visible light photographic picture, the simplicity of the figure pattern may cause difficulties in outdoor environments. These can be easily confused with natural objects because they do not consider design elements such as texture and color.(2)Lange, Sünderhauf, and Protzel (2008): a figure was designed that consists of several concentric white rings with specific diameters on a black background to enable identification and differentiation of each ring. The difference between outer and inner ring size ratios increases moving away from the centre of the figure. Hence, the visible part of the platform is identifiable even when not all the rings are within the field of view – which can occur when the air vehicle is at a low altitude. The relative height is determined by processing the camera image. This method assumes that the UAV is always parallel to the ground, ignoring the angles of inclination / orientation from the figure. However, this can be a significant limitation of this method, especially if used for landing UAVs that cannot fly vertically, and rather at an angle of inclination to the horizontal. Determining the orientation and these angles is often very important for most vehicles landing in outdoor environments where the platform is not horizontal, such as on a boat.(3)Saripalli, Montgomery, and Sukhatme (2002): like both the preceding techniques, this method is based on the use of a platform that also has a geometric figure silk-printed on its surface. It uses a drawing shape of a white “H”, typical of heliports. The position of the centre-of-gravity of the image is extracted from the figure captured by the camera in a two-dimensional Cartesian plane. The image also allows determination of the angle of orientation of the figure with respect to the UAV. To extract this information from the image, the following computer vision techniques are applied: thresholding, filtering, segmentation and labelling of related components. However, the symmetry and morphological simplicity of the figure results in limitations. If part of it is blind – which frequently occurs in outdoor environments, where you cannot control the brightness and other lighting parameters - it may be impossible to identify the figure or determine the orientation angle. Therefore, if the system cannot access the part of the half of the figure containing the differentiating features relative to the other half of the figure, it becomes impossible to obtain the orientation of an H-shaped figure at an angle of 0–360°. Outdoor environments frequently require the use of more complex figures with subfigures so that recognition is still possible even if a portion is blind.(4)Sharp, Shakernia, and Sastry (2001): this method is based on the use of a figure that is built from six white squares, five having the same size. These squares are included in a larger black square which, in turn, is included in another white square. This figure is acquired from the UAV using a built-in digital camera, to then be processed using the following computer vision-based techniques, including: the thresholding, segmentation, connected components labeling and detection of points of interest (corners). It introduces a design and implementation of a real-time vision system at 30 Hz for a rotor-craft UAV which estimates its pose and speed relative to a known landing target. It applies both linear- and nonlinear optimization algorithms to perform the pose estimation. Although the figure is more complex than those described previously, the use of a simple square may cause those parts of the figure to be confused by other items that may occur in an external environment, such as typical straw cubes cut by a mower. For this reason, it is more convenient to use geometrical shapes that are more difficult to replicate in outdoor environments, such as ellipses or circles.(5)In addition to the methods described above, there are other techniques where an artificial geometric figure is not needed to carry out the approximation process. For example, Cesetti, Frontoni, Mancini, Zingaretti, and Longhi (2010) developed a technique which tries to find natural markings on the outdoor scene by using algorithms based on an analysis of optical flow, from which the image is divided into smaller frames. Finally, a technique known as SIFT (Scale invariant Feature Transform) is applied. Once marks have been identified, the UAV is guided by these to a safe landing.
1.3. Motivational research of the proposed strategyAll the methods, above, apply image thresholding, segmentation and labeling. The main contribution of this work is to exploit the performance of these proven techniques, however with a novel approach that increases efficiency and reliability. This allows the identification of the figure with its use of non-repetitive shapes (circles and ellipses strategically located), allowing the application of a reasoning process, which is translated by expert systems. Our proposed features, from which the reasoning process is derived, are based on:
(a)Using the physical platform (paper) as an extra region, that includes all others.(b)Use of metrical and topological descriptors (Euler number) as prior filtering.(c)Recognition degree of confidence function based on Comparative Partial Analysis (CPA).(d)Use of combined geometric descriptors (area, eccentricity and Euclidean distance) as a unique value.(e)Use of several metric thresholds based on ratios between subfigures.(f)A complex figure comprising different geometrical subfigures in different sizes.(g)Support for different perspectives and distances.By using these new features, the proposed expert system can overcome some issues existing in other proposed methods: the complex morphology of the proposed figure can be easily recognized in an outdoor environment, the inclination/orientation can be determined, and it still works when part of the figure is blind due to the reflection of sun or brightness.
