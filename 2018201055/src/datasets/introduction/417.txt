With the marvelous achievements of deep learning (DL) in computer vision (CV), super-resolution (SR) task attracts lots of attention for its crucial role as the basis of other high-level CV tasks, such as semantic segmentation [1] and image recognition [2]. Basically speaking, deep-learning super-resolution (DL-SR) algorithms, like [3], [4], [5], [6], [7], strive for simulating the map between low-resolution (LR) and its high-resolution (HR) counterpart through a complex nonlinear mapping network. In other words, the trained model approximates the inverse map of down-scaled operation used to obtain LR images from their HR fathers. This raises a troublesome issue: The success of this SR system highly hinges on the quality of LR images. If there are some spots/stains involving in LR inputs, the SR model will treat them as inherent elements of inputs, and the corresponding SR outputs will deservedly enlarge these undesirable details. We learn the issue from the application of SR models on cloth painting. The artifacts of pattern accompanied by C-JPG enlarging are more obvious on cloth than paper. This phenomenon raises the barrier between the ideal SR model and practical use.
Most SR models are trained on the generated LR-HR dataset, like DIV2K [8]. Different from the ideal experimental setting, real-world images, e.g., pictures on the Internet, are usually compressed to reduce their sizes. However, compared with the lossless LR inputs, the quality of compressed JPG(C-JPG) images drop greatly, and further operations yield more unpleasant artifacts. For example, the presence of obvious partition lines coming from C-JPG vastly deteriorates the overall visual feeling. How to alleviate the deterioration makes the SR operation on C-JPG images to be a huge challenge. To address this issue, in this paper, we propose a specialized SR model: RGSR, which generate relatively satisfying high-resolution images from the low-quality inputs (C-JPG images).
Indeed, there are many SR pipelines designed for the real-world degradation SR tasks, like [9], [10], [11], [12], [13], [14], [15], [16]. Some models regard the noise as a kernel estimation problem, solved by removing addictive Gaussian noises, such as [10], [12]. However, the underlying realistic image distributions are usually inconsistent with the hypothetical Gaussian distribution, especially for the C-JPG issue in this paper which decreases information from the original image without adding specific noises. Some models learn the corresponding maps by extracting useful representations from irrelevant LR-HR images, like the unsupervised learning strategy [13], the ensemble learning method [17]. Referring to the image compression artifact reduction, which is defined as part of image denoising, many techniques have been proposed, such as DnCNN [18], RDN [6], and RNAN[19]. These methods focus on how to recover details from the artifacts without concerning the practical application, like SR issue.
As a basic sense, training a DL network requires tremendous data. For the SR model, a large number of image pairs: LR images and their HR counterparts (served as the supervised information) are required for the network to learn the representation. In general, most LR images are produced through performing traditional interpolation methods (mostly Bicubic) on their HR fathers. As a result, the SR training process recovers this down-scaled mapping in a reverse manner. The relationship between the LR-HR pair with a fixed down-scaled kernel has been successfully learned by various SR models, such as SRGAN [20], EDSR [4], and RDN [6]. However, the repair mechanism of the C-JPG images includes more than SR generating process. When previewing the full-size image on the Internet, other than the down-scaled mapping, a number of additional unpleasant details are displayed, especially in the edges of objects. These compressed artifacts make former SR methods fail to generate applicable images. As shown in Fig. 1, the first four SR generations are trained on the LR-HR pairs related to the traditional Bicubic interpolation. Although the RCAN has been proved to be outstanding SR algorithms on a normal dataset, the results of C-JPG inputs still manifest our viewpoint that SR models trained with ideal LR-HR inputs will lead to poor SR performance. To be specified, the DPSR [10] specially designed a principled formulation and framework to handle LR images with arbitrary blur kernels. It generates unpleasant details in SR image. In detail, the damaged grids are apparently enlarged by the approaches designed for traditional non-JPG datasets. More specialized analysis can be found in [21].Download : Download high-res image (317KB)Download : Download full-size imageFig. 1. The comparing of SR generations coming from four methods: bicubic, RCAN, RCAN with Matlab pre-denosied input, and our model RGSR. The obvious different details are marked in red rectangles to indicate the contrast of four approaches.
A specially designed DL model - RGSR is proposed to address this drawback of the C-JPG SR task in this paper. The contributions of this paper can be summarized in the following three aspects. First, we deliberately introduce compressed JPG format LR images to construct a more complicated dataset with three types of training inputs: C-JPG LR, LR, and HR images. Second, the whole training process of RGSR includes two separate functional components: R(recovering stage) and S(super-resolution stage), i.e., the missing detail recuperative part (JPG recovering stage) and SR map learning part (SR generation stage). In order to remove the artifacts accompanied with C-JPG, such as ring and checkerboard, the first half sub-model R is trained with C-JPG LR images as its inputs, and leveraging the corresponding LR ones serve as its supervised information. Accordingly, its output named LR(C-JPG) removes the unpleasant noise and is greatly free of the partition lines phenomenon. Inherited these improved LR images, the latter sub-model S continues to learn the map between LR(C-JPG) and HR images. Therefore, an SR generation pipeline between C-JPG and HR images is achieved through the joint integration of these two sub-models. Finally, because it has been repeatedly proved that multi-scale architecture can leverage complementary details in the image to contribute to better SR generations, a cycle loss across scales is plugged in the second stage. Experimental results demonstrate its effectiveness.
In short, the contributions of this paper can be summarized into three aspects:
•We firstly propose a specialized SR issue to utilize widespread image format, i.e., to generate satisfying and practical SR images from lossy JPG inputs, which bridges the main gap between the practical SR applications and the existing SR models.•To address the proposed issue, we provide a two-step SR model named RGSR which involves two functional sub-models: the recovering part and the SR generating part. In detail, the JPG recovering stage firstly produces restored intermediates from C-JPG inputs, and the SR generation stage leverages the information of intermediates and HR images for the SR outputs. The experimental results demonstrate our approach can successfully solve the proposed task.•To further improve the performance, we introduce a novel integrated loss function: two weighted L1 losses combining with a specific cycle-loss across multi-scale feature maps. We confirm the advantages of this loss function in our experiments.
