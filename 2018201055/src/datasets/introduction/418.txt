The k-core decomposition and algorithms for finding densest subgraphs have proved to be a valuable tool in graph mining and data analysis, with applications encompassing sociology, bioinformatics as well as graph visualization.
Definition 1.1 Coreness Value [30]The coreness value of a node v in a (weighted) graph G is defined as the largest number k such that v belongs to a subgraph of G with minimum (weighted) degree equal to k. We denote the coreness value of v by c(v).
The goal of k-core decomposition is to compute the coreness value of every node in a given graph. Intuitively, nodes belonging to well-connected communities tend to have high coreness values. Besides, several definitions of density have been proposed in the literature. In our work, we focus on the average degree density which is defined as the ratio between the number of edges and the number of nodes in a graph [9]. One of the appealing properties of such a definition is that a densest subgraph (in terms of average degree density) can be computed in polynomial time. Such an optimization problem is often referred to as the densest subset problem. Recently, the diminishingly-dense decomposition has been introduced and studied [12], [23], [31], which elegantly merges the concepts of density and k-core decomposition. Such a decomposition assigns to each node a real number, which we refer to as maximal density value. We also study the min–max edge orientation problem [32] which turns out to be related to the previous problems. The goal is to assign an orientation to every edge such that the maximum weighted in-degree is minimized.
In our work, we develop distributed algorithms for approximating coreness values and local density values, as well as to find an approximate solution for the min–max edge orientation problem. Moreover, we study a weaker version of the densest subset problem.
We envision the following applications for our work. Our distributed algorithms can be executed by agents in a social network or a P2P network, for example, so as to collect relevant statistics of the agents with respect to the underlying graph. Users in a social network with large coreness value are known to have “good spreading” properties in epidemiological studies [24]. Therefore, the coreness value (or an approximation of it) can be leveraged to maximize the spreading of a diffusion protocol. Communities in a social network consist of set of users sharing similar interests, such as hiking, traveling or photography. The density of a given subgraph can be used to measure how likely the corresponding users belong to a same community [34]. Our work allows to approximate such a metric in a distributed fashion. Our distributed algorithms can also be used in distributed graph processing systems [27] to process very large graphs not fitting into the main memory of one single machine.
We are given an undirected edge-weighted graph G=(V,E,w). We consider the classical Local model, in which every node can directly communicate only with its neighbors in synchronous rounds. Moreover, we assume each node knows (an upper bound on) the number n=|V| of nodes. The hop-diameter D (or diameter) of a graph G is at most ℓ if every pair of nodes in G can be connected with a path consisting of at most ℓ edges. We use the convention that the approximation ratio γ is at least 1.1  There is often a tradeoff between the number of rounds and the approximation guarantees of a distributed algorithm. Fig. 1.1 shows that approximating the coreness values or the min–max edge orientation problem within a factor strictly less than 2 requires Ω(D) communication rounds. Similarly, for a node to be aware of whether it is included in an approximate densest subgraph, Ω(D) communication rounds are required. This follows from the fact that such a node has to verify whether a subgraph with higher density (possibly many hops away) is included in the graph or not. Hence, it is natural to investigate the following question: Can we devise distributed approximation algorithms for the aforementioned problems, while requiring a number of communication rounds independent of the diameter?
Although some of the problems discussed above have been studied in a distributed environment, there is no work focusing on breaking the diameter barrier, to the best of our knowledge. All our algorithms require a number of communication rounds logarithmic in n, while we provide tight lower bounds expressing the tradeoff between communication rounds and approximation ratio.
Download : Download high-res image (141KB)Download : Download full-size imageFig. 1.1. Example graphs showing that the we cannot beat 2-approximation for coreness values and min–max edge orientation problem unless the number of rounds is at least Ω(n). All graphs have unit edge weights, and the nodes are labeled with their coreness values. The coreness of v is 2 in (a), but is 1 in (b) and (c). The arrows in (b) and (c) indicate an optimal orientation, where the maximum in-degree is 1; any other orientation of edges incident on v will result in a maximum in-degree of at least 2. It takes Ω(n) rounds for node v to distinguish between the different graphs.
1.1. Our results and contributionCoreness values. Just like almost every work on these related problems [5], [7], [9], [13], [14], [16], [21], [28], [33], we consider an elimination procedure that repeatedly “peels off” nodes with small (weighted) degrees. In particular, we follow the interpretation by Montresor et al. [28]. Specifically, given a threshold value b, in each round, nodes with degree less than b in the remaining graph are removed. Using a compact representation, we can imagine that the elimination procedure for all possible thresholds is run in parallel, where after each iteration, each node v just remembers the largest threshold bv (which we call the surviving number), for which it still survives.It is known that after each iteration, the surviving number of each node v is at least its coreness c(v); moreover, after n rounds, the surviving number will reach the coreness value.2  However, to the best of our knowledge, so far there is no approximation analysis for the process in terms of the number of iterations.Densest subset. It is interesting that a variant of the elimination process was considered by Bahmani et al. [5] to give a 2(1+ϵ)-approximation for the densest subset streaming model. In each iteration or pass, the threshold is chosen to be 2(1+ϵ) times the density of the current subset of surviving nodes. Then, the process terminates in O(log1+ϵn) iterations, and the subgraph from one of the iterations gives a 2(1+ϵ)-densest subset. This inspires us that density can provide the right tool to design and analyze distributed approximation algorithms for coreness values. However, an immediate issue is that for every node to know the (approximate) density of the current subgraph, we already need Ω(D) rounds.Local notion of density. We observe that it is not necessary to use the global density of the (sub)graph, because in some sense, coreness value measures the local density of a node. Recently, Tatti and Gionis [31] considered a so-called locally-dense graph decomposition, which has been further studied by Danisch et al. [12], who defined a quantity known as maximal density for each node. This decomposition has actually been considered in passing by Khuller and Saha [23] in the context of finding densest subsets with large sizes. Intuitively, the decomposition works by repeatedly peeling off maximal densest subsets as follows. Given a weighted graph G, the maximal densest subset B forms the first layer, which induces a subgraph with density ρG(B)≔w(E(B))|B| (here w(E(B)) denotes the sum of weight of edges connecting nodes in B); every node u∈B has maximal density equal to ρG(B), even though no special importance is given to this value in [23]. Next, remove the nodes in B to form a quotient graph G′, where an edge between u∈B and v∈B¯ becomes a self-loop at v in G′. Then, the procedure is recursively applied to G′ until all nodes are removed. Equipped with this notion of maximal density, we can adapt previous analysis to achieve the following result.Theorem 1.2 Gracefully Degrading Approximation Ratio for Coreness ValuesAfter running the compact elimination procedure in the Local model for T rounds, the surviving number at each node gives a 2n1T-approximation to its coreness value (and maximal density).In particular, if every node knows (an upper bound on) the number of nodes n and would like to achieve 2(1+ϵ)-approximation, then T=⌈log1+ϵn⌉ rounds are sufficient.Matching lower bound. For γ≥2, by considering a γ-ary tree, we show in Section 3 that achieving γ-approximation in computing coreness values or maximal densities requires Ω(lognlogγ) rounds.Min–max edge orientation problem. The centralized version of the problem was proposed by Venkateswaran [32] and has applications in telecommunication network design; it is known that the special case of unit edge weights can be solved in polynomial time. The connection of the problem with densest subsets has been explored in subsequent works [3], [4].To the best of our knowledge, the only distributed algorithm for this problem with round complexity independent of the diameter is for unweighted graphs. Specifically, Barenboim and Elkin [6] actually studied a stronger problem, where the goal is to partition the edges of a graph into a minimum number of forests. Instead of density ρ(S)=w(E(S))|S|, a similar notion of arboricity arb(S)=w(E(S))|S|−1 is considered. In hindsight, it is not surprising that they also used a variant of the distributed elimination procedure to approximate the forest-decomposition problem in the Local model. Indeed, they showed that if the maximum arboricity is known by every node, then O(1ϵlogn) rounds are sufficient to achieve (2+ϵ)-approximation. As remarked above, if every node needs to know the (approximate) maximum arboricity, then Ω(D) rounds are required. A careful study of their algorithm reveals that the first phase [6, Algorithm 3] serves a similar purpose as computing the surviving numbers as in our Theorem 1.2, after which they run the second phase as if the maximum arboricity is known. This degrades the quality of the solution, and only 2(2+ϵ)-approximation is achieved.Primal–dual approach. By observing that the LP relaxation of the min–max edge orientation problem is the dual of the densest subset LP (see Section 2), we have the intuition that a procedure for approximating the maximal densities should also give information about the dual problem, without using a second phase. Indeed, we augment the distributed elimination procedure by maintaining an auxiliary subset Nv for every node v (which represents its in-neighbors) to give the same approximation ratio for the edge orientation problem. In addition, a very careful invariant analysis in Lemma 3.11 is performed to make sure that every edge is taken care of by at least one of its end-points.Theorem 1.3 Gracefully Degrading Approximation Ratio for Min–Max Edge Orientation ProblemAfter running the augmented elimination procedure (Algorithm 2) in the Local model for T rounds, the auxiliary subsets {Nv:v∈V} gives a 2n1T-approximation to the min–max edge orientation problem.In particular, if every node knows (an upper bound on) n and would like to achieve 2(1+ϵ)-approximation, then T=⌈log1+ϵn⌉ rounds are sufficient.Densest subset problem. As argued above, for every node to be aware of whether it should be included in an approximate densest subset, it takes Ω(D) rounds. Indeed, Sarma et al. [29] gave a distributed algorithm that gives 2(1+ϵ)-approximation with O(Dlog1+ϵn) rounds.We consider a weaker version of the problem (in Definition 4.1). Instead of just producing one subset, the distributed algorithm will return a collection {Si:i∈I} of disjoint subsets such that for each i∈I, each node will be aware of which subset (if any) it belongs to; moreover, there exists some i∈I such that Si is an approximate densest subset. Using the procedure in Theorem 1.2 as a subroutine, we have the following.Theorem 1.4 Distributed (Weak) Densest Subset ProblemFor any ϵ>0 and n, there exists a distributed algorithm that gives a 2(1+ϵ)-approximation to the (weak) densest subset problem in Definition 4.1 on any graph with n nodes using O(log1+ϵn) rounds.
1.2. Related workIn addition to the most relevant works that have already been compared with our work, we also describe other related works.Coreness values. After Seidman [30] first proposed k-core decomposition, Batagelj and Zaversnik [7] presented a (centralized) O(m) algorithm to compute a k-core decomposition. This notion has been extended to weighted graphs [10], [15] and directed graphs [14]. The distributed setting has been studied by Montresor et al. [28], and was further extended to dynamic graphs by Aridhi et al. [2]. The distributed algorithms have been adapted to (centralized) I/O efficient algorithms [10], [33] that were proposed to handle large graphs that cannot fit into memory.Min–max edge orientation problem. Since Venkateswaran [32] introduced the problem, (centralized) polynomial-time algorithms are known to give optimal solutions for unweighted graphs  [4], [25], [32]. However, a series of works [3], [4] showed that the weighted version is NP-hard even when all edge weights belong to the set {1,k}, where k is any fixed integer greater than 1; on the other hand, for integer edge weights, (2−1k)-approximation can be achieved, where k is the maximum weight. Gillet and Hanusse [16] considered the more general asynchronous distributed model with faults. However, their algorithm has round complexity depending on the graph diameter, and achieves 2(2+ϵ)-approximation.The problem can be also be seen as a special case of a load-balancing task, where each node is a machine and each edge is a job to be assigned to one of its incident machines. From this perspective, minimizing the maximum in-degree is equivalent to minimizing the makespan. Czygrinow et al. [11] considered minimizing a slightly different objective that is the sum of the squares of the loads of the machines. In contrast, they gave a distributed 2-approximation algorithm that runs in O(Δ5) rounds, where Δ is the maximum degree.The Min–Max Edge Orientation Problem shares some similarities with the vertex cover with hard capacities problem [18].Densest subsets. The densest subset problem [17] has been extensively studied and extended to directed graphs [22]. In the centralized setting, it can be solved in polynomial time by an algorithm based on maximum flow [17], linear programming [9] or a recent approach based on convex optimization [12]. Charikar also proposed in [9] a simple greedy approach based on k-core decomposition that produces a 2-approximation.As mentioned above, even though Khuller and Saha [23] have implicitly considered locally-dense graph decompositions, this notion has not been fully studied until recently by Tatti and Gionis [31] and Danisch et al. [12]. One of its surprising applications is its usage in the computation of the (non-linear) Laplacian operator of a hypergraph [8].There are also interesting connections between load balancing and the densest subset problem [1], [19], [20].
