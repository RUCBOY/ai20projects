Computer simulation models are well-established tools within epidemiology and related disciplines. They have proven useful, powerful, and accessible for evaluating questions about the spread of infectious disease within and between many populations and over physical and social spaces (see, for example, Ferguson et al., 2005, Lofgren et al., 2014, Longini et al., 2005, Mahmoud et al., 2006, Yang et al., 2011). Computer simulation models are now employed by a wider range of researchers than ever before, likely due to changes in computing power, availability of software, and accessibility of platforms. While the increased use of models has made positive contributions to an ever-widening group of fields, cross-disciplinary communication about mechanics of modeling can be difficult and may lead to obstacles at any step of the modeling process.
This study begun after the authors noted that many disease modeling papers are unclear in reporting a central aspect of model outcomes: whether an epidemic has or has not happened. Very few modeling papers explicitly address the specific definitions and/or case thresholds used to characterize a simulation run as an epidemic within the model environment. Communication about models is important if replication is to be achieved and if policymakers are to use information from models in order to build effective public policy. As the creation and use of agent-based models proliferates, a discussion about the need for standardized methodology in model creation and reporting has followed. Some have proposed standards for describing model structure, such as the ODD protocol (Grimm et al., 2006, Grimm et al., 2010). However, these protocols do not address disease models specifically, but are directed towards agent-based models in general.
We focus here on how decisions made during the development and analysis of agent-based computer simulations of infectious disease transmission can influence the conclusions drawn from these models. Specifically, we center on how the criterion used to define whether a disease outbreak should be considered an epidemic affects inferences derived from the analysis of simulation outcomes. Because of the stochastic nature of agent-based simulations, most analyses of such models start by averaging the results from large number of runs of the simulation. However, even in models for highly infectious diseases, which usually infect large numbers of agents, occasionally the infection may result in only a small number of cases. If small outbreaks are relatively common (but still not the norm), including them in analyses to identify general epidemic patterns may skew the analyses. Yet, there are few guidelines to use in determining whether a small outbreak should be identified as an epidemic run and therefore included in the calculation of averages across runs or whether it should be omitted from the calculations.
In order to systematically explore the impact of variable criteria in assigning epidemic status to a simulation run, we use different epidemic definitions in analyses of results from simulations of an agent-based model for the spread of communicable diseases. We specifically examine the impact of variation in the criterion used to define when an epidemic occurs on the interpretation of outcomes such as epidemic size, timing, and severity. For example, if 1% of the model population is required to become infected in order to include a run in an analysis, how does that compare with the results from a similar analysis in which a 5% threshold is used? How do these kinds of decisions impact the way in which public health efforts might be designed or implemented?
