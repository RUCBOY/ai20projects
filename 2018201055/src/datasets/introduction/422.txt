Deep learning has achieved great success in many fields, including computer vision [1], [2], natural language processing [3], [4], [5], reinforcement learning [6] and multilabel learning [7]. It is also flexible enough to be combined with basic machine learning methods, e.g. sparse matrix factorization [8], to analyze large-scale data. The success of deep learning depends on the strong fitting ability of neural networks. However, plain neural networks may lead to overfitting. Some works are raised for the regularization of neural networks, such as L1/L2 regularization and dropout [1], [9]. From the Bayesian perspective, L1/L2 regularization introduces the prior of model weights; dropout techniques approximate the posterior of weights through a mixed Gaussian with small variance and the mean of one of the Gaussians fixed at zero [10], [11], [12], [13]. In the form of the Bayesian Occam’s razor [14], Bayesian neural networks (BNNs) restrict the model complexity and thus regularize neural networks. Also, for various models, they perform the comparison and calibration spontaneously, in order to perform learning robust to overfitting. Furthermore, Bayesian approaches provide uncertainty estimation for optimization and out-of-data examples by introducing model uncertainty [15], [16], [17]. This information helps to tackle many problems in AI safety [18]. With model uncertainty, applications that require security, such as self-driving and medical AI, can propagate their uncertainty up the decision-making pipeline [12]. This invaluable uncertainty information is often lost in deterministic deep learning models.
Approximate inference is to find the probabilistic distribution of weights to explain data in BNNs [19]. Markov chain Monte-Carlo (MCMC, [20], [21]) methods can be applied in approximate inference. Chandra and Kapoor [22] introduced MCMC in transfer learning using BNNs. Generally, MCMC methods are time-inefficient. Chandra et al. [23] proposed Langevin-gradient parallel tempering to apply MCMC in settings with larger datasets and network architectures. Gu et al. [24] employed appropriate loss functions to improve the performance of MCMC. One of another commonly used approximation techniques is variational inference (VI, [25]), which is a classic technique for approximate inference. Dropout variational inference, which regards dropout regularization as Bayesian approximate inference, can be used to obtain a practical inference technique [13]. Particle-based VI [26], [27], [28] provided greater non-parametric flexibility than classical VI, and were also more particle-efficient than MCMCs. Francisco and Michalis [29] developed a method that combines VI with MCMC, leveraging the advantages of both inference techniques. VI is a kind of strong inference technique, however, it is restricted in some cases. For example, dropout VI may underestimate the model uncertainty [30]. Expectation propagation (EP, [31]) is considered to be able to characterize uncertainty more accurately than VI. In fact, VI and EP can be unified with alpha-divergence. Hernández-Lobato et al. [32] raised an analyzable black box alpha-divergence objective. Li and Gal [30] combined alpha-divergence minimization with dropout inference and achieved better performance than both dropout [13] and VI [25], [15]. In the above methods, the variational posterior distributions are set as exponential family distributions (such as Gaussian or Bernoulli). Louizos and Welling [33] improved upon classical mean field for BNNs with normalizing flows approximation. Normalizing flows are more flexible than Gaussian and dropout variational distribution. However, they also bring unacceptable large computational complexity in huge neural architectures. In this paper, we aim at finding a compromise solution. Thus, we extend the posterior approximation to mixed density distributions. Except altering the variational distribution for posterior approximation, the choice of the prior distribution is another factor that influences the performance of variational Bayes techniques. In this regard, Wu et al. [34] introduced a hierarchical prior to strengthen the robustness of BNNs.
Generally, the objective of posterior inference is analytically intractable. VI optimizes the Monte Carlo approximation of its objective, called Black Box VI [25], [35], [36]. However, Monte Carlo approximation has to suffer the large variance during training [11], [37], [38]. The reparameterization trick [11] is thus introduced to reduce the variance. On the other hand, EP updates the approximation distribution by moment matching. Sun and He [39] generalized EP with mixtures of exponential family distributions and took Monte Carlo approximation. In Sun’s work, control variables was used for variance reduction but it could not be easily applied in complex models such as neural networks.
In our view, a practical approximation for inference in Bayesian neural networks should be able to scale well to large data and complex models with as few computational consume as possible, and a superior variational posterior should be efficiently computed as well as strong in fitting any distribution. Normalizing flows [40], [33] meet the second demand but need large computation cost. It is necessary to control the computation complexity with the increasing size of neural networks. Therefore, we use the mixed exponential family distributions as the variational posterior instead. A mixed exponential family distribution is theoretically able to approximate any distribution according to [41]. It can also fit a multimodel posterior distribution, which is often closer to the true posterior. Mixed variational posterior distributions have advantages as above. However, the reparameterization trick cannot be directly applied to them because of the difficulty of reparameterizing the discrete distribution over mixture weights. The Gumbel trick [42] is hence introduced to get an efficient reparameterization of mixed density distributions. In addition, we analyze the model uncertainty from both theoretical and empirical perspective. We find that our method can estimate the uncertainty more realistically.
The core of this paper could be summarized as:
•We develop α-divergence minimization with mixed variational posterior for flexible posterior approximation and higher computational efficiency. In our approach, stochastic gradient descent is used to find the local minimum of the α-divergence objective. We also give the theoretical and empirical analysis on the comparison of the models’ predictive entropy between the inference techniques that respectively adopt mixed variational posterior and Gaussian variational posterior. The proposed method keeps confidence in the prediction of in-distribution examples and gives more realistic uncertainty estimation.•We evaluate mixed α-divergence minimization on BNN models with various architecture, and get improvement in regression, classification, uncertainty estimation and adversarial performance, compared to some related state-of-the-art techniques.
