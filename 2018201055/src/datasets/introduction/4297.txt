In the agricultural industry, plant diseases are the major cause of economic losses worldwide . Plants display a range of symptoms from their early stage of attack to the final stage of damage, which can be monitored by utilizing efficient machine vision technology in surveillance systems. The conventionally built surveillance systems would normally require several image samples to be acquired, and then analyzed offline for the extraction of the infected regions. This analysis is further followed by manual pesticide application. The whole procedure becomes tedious if the fields span over several acres – demands large human resource and still remains a time-taking process [1].
An autonomous system, such as a surveillance drone or an unmanned rover, having real-time image acquisition and feature extraction capability, will not only be able to sweep the entire area and capture several samples, but will be able to determine the type of the infection. Subsequently, the system shall be able to determine the appropriate pesticide with minimal human intervention. In this quest , a necessary milestone will be to develop a fast image processing algorithm with an equally fast underlying hardware. Several image processing algorithms have been proposed that exploit parallelism to achieve higher performance. Parallelism, however, is only as good as the number of computing resources available on the hardware the algorithm is running on. The modern trend in digital design called system-on-chip (SoC) designs allows the designer to incorporate several computing resources on a single chip . These computing resources may include processing elements (PE), intellectual property (IP) blocks, digital signal processing (DSP) cores, and to name a few. An efficient image processing algorithm would divide an entire image into several blocks, and then let the central processing unit (master) of the SoC distribute a block to each of the DSP cores (slaves) available, thereby allowing all the blocks to be processed simultaneously . The distribution of blocks to the cores, however, is once again limited by the intercommunication infrastructure. Since the last decade it has been established that networks-on-chip (NoC) is the only viable communication architecture for SoCs [2], which unlike the shared bus allows several message transfers in parallel.
To this end, we have devised an algorithm that transforms an image into three colorspaces, each of which may be processed at the same time. Naturally, this algorithm requires three processing cores on the SoC, and a suitable NoC architecture. In this paper we present details of our proposed algorithm, and the NoC. Considering the stringent power budget of the modern embedded systems, we have adopted an asynchronous implementation of the NoC (further abbreviated as ANoC), thereby relieving the system from the issues of global clocking and synchronization [3].
The rest of the paper is organized as follows: Section 2 reviews basics of NoC, and few of the existing parallel image processing architectures. The proposed algorithm is presented in Section 3. Descriptions of the ANoC architecture and system design are detailed in Section 4. Section 5 presents simulation results of the NoC router and the algorithm, before we conclude the paper in Section 6.
