Widely accepted as a system model for providing service, cloud computing has gradually obtained the popularity among the platforms that manage the operation of data center. In nature, cloud computing indeed changes the routine of using and scaling the physical infrastructure. Instead of separately utilizing different combinations of servers, storage disks and network facilities for each client, it would be more convenient and robust to provide a transparent access to the computing resources via the Internet connection. This can be seen as an effort to unify the capacity of multiple computing nodes to achieve higher level of service composition. In the perspectives of cloud service provider, cloud computing makes it possible to reduce the management cost and the energy consumption which consequently save the budget.
Theoretically, cloud computing mostly relies on the virtualization technology. First, the users interact with the system by choosing the package of service based on their requirement and budget. Depending on the submission of users, the cloud orchestrator allocates the requested resources as virtual machines (VMs). These VMs are usually hosted on the same physical server or cluster according to the objectives of service provider. The procedure of translating from the resource demand to the VM configuration is conducted transparently without the awareness of the user. In fact, the resource provisioning is done elastically, which is the main reason that makes the cloud computing flexible enough to engage in the large scale system. However, in order to do the tasks efficiently, the challenge of balancing between the system performance and the power consumption has been emerged as a crucial issue.
In order to reduce the power consumption, it is worth to list out the source of energy burning as well as the methodology to obtain the energy savings. Clearly, most of the computing facilities use the energy to maintain their working status. Therefore, the waste of power can be originated from the inefficient utilization of provisioned facilities. The common approach to achieve the energy reduction is to dynamically scale down the size of running clusters. With the help of virtualization, the target can be done by applying the VM migration. It means that the VMs can be stacked into a minimum number of physical machines (PMs). After that, the decision of turning on/off the running PMs can help to satisfy the requirement of maintaining the performance as well as reducing the used power.
Although the idea to compact the size of cloud clusters is quite interesting, the problem of latency and inaccuracy in measuring and monitoring the resource utilization might affect the precision of making the optimization. This problem might lead to the inappropriate decisions in migrating and stacking the VMs. Consequently, the effectiveness of the energy savings method might be degraded drastically. To overcome this issue, we would like to propose an approach based on the predictive optimization technique. In our approach, the Gaussian process regression (GPR) is applied to provide the predictive monitoring information instead of the aforementioned obsolete data. Theoretically, GPR can be considered as one of the most effective regression techniques in terms of accuracy, flexibility and robustness. By using GPR in processing the monitoring data, the awareness of futuristic trends on the system utilization can be obtained. Subsequently, this benefit helps the convex optimization to produce more adaptive and precise energy savings scheme for the cloud orchestrator. To summarize, in this research, we couple the prediction technique and the convex optimization to solve two questions. The first one is how to effectively reduce the power consumption in cloud computing based on early predictive system statistics. Subsequently, the remaining question to answer is whether it is possible to find the boundary solution that balances the energy savings and the quality of services.
In particular, our contributions focus on two main points as follows: 
•We apply our prediction technique  [7] to provide the predictive statistics that enhance the usefulness of monitoring data. Note that the useful monitoring data is defined to support the system making early appropriate reactions just in time by providing the futuristic analysis. In our approach, this special kind of data is effectively used to consolidate the virtual machines through the optimization procedure.•We design an energy efficiency model using convex optimization to optimally create the migrating instructions for the orchestrator. By consolidating the VMs via the migration mechanism, the orchestrator can reduce the power consumption as well as improve the cluster utilization by turning-off the idle physical machines, but still keep an acceptable performance for the currently running tasks.
 It is worth noting that the meaning of acceptable performance mainly involves two conditions. The first condition is to maintain the quality of services which is specified in the service level agreement (SLA) document. In case the first condition is violated, the second condition is to minimize the catastrophic effects on the system performance as well as balance the penalty cost with regard to the power savings in the optimization module. When these conditions are still firmly hold, the system performance are kept in an acceptable level. The mechanism of how to preserve these conditions can be found in the following sections.
The remainder of the paper is organized as follows. In Section  2, we introduce some related works in the area of energy efficiency. Section  3 presents an overview of our proposed architecture. Next, Section  4 illustrates our analysis and proposal to enhance the nature of the monitoring data by using GPR technique. Section  5 includes the optimization steps to minimize the size of running facilities with regard to the predictive analysis provided by GPR. Section  6 evaluates the effectiveness of the proposed approach. Finally, Section  7 gives the conclusion of paper and outlines our future work.
