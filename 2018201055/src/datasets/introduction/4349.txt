Big Data has been drawing increasing attention from numerous research communities, which has led to the development and advancement in its theoretical foundations and applications to address the challenges raised by this field. Loosely speaking, Big Data is characterised by the 4 V's, namely volume, velocity, variety and veracity [1], and different approaches might address some of these aspects. In recent times, the analysis of unstructured data from textual sources has played a strategic role in many activities influencing our daily life. Such data are often characterised by a certain degree of uncertainty, as well as inaccuracies, which raise numerous challenges for the accurate extraction of new knowledge [15]. Furthermore, the ability to identify useful connections between concepts, insights and trends from such analysis (in order to automatically build knowledge for supporting decision making processes) is at the heart of cutting-edge research in several research fields with a multitude of applications in many disciplines [1].
The extraction, classification and aggregation of probabilistic information is crucial in modelling complex systems, and the interconnections between the relevant concepts and associated variables underpin the general properties of such systems [4]. In particular, their characteristics are shaped by statistical properties linked to the graph-theoretic features of the associated semantic networks. These can be modelled in terms of nodes, corresponding to specific words or concepts, together with their mutual connections, representing the semantic associations between them. Interestingly, many of such networks exhibit a small-world structure characterised by the combination of highly clustered neighbourhoods, a sparse connectivity and a short average path length [5], as well as scale-free organisation [6]. This is characterised by a node degree distribution following a power law structure. Any knowledge process modelled by such networks reflects the semantic network growth dynamics. Each new node added to the semantic network immediately inherits some of the connections characterising the pre-existing nodes (identified as its neighbourhood).
Furthermore, highly connected nodes are more likely to be associated with more significant knowledge [5]. The structural principles characterising scale-free networks potentially have very important implications in understanding the development of new knowledge. In fact, this facilitates the abstract understanding of how semantic organisations can evolve and grow, based on basic statistical criteria. This enables knowledge construction in the form of probabilistic relationships between concepts [29].
Bayesian networks (BNs) [33], [36] are graphical structures with emphasis on cause and effect modelling in many knowledge-related domains [2], [3]. Their main characteristic is the ability of capturing the probabilistic relationship between variables, as well as their historical information. In particular, they facilitate the creation of systems by modelling knowledge in a way that is easily comprehensible by humans [19], [35], [34]. More formally, BNs are directed acyclic graphs where their nodes represent Bayesian random variables. In other words, they are associated with observable quantities, unknown parameters, hypotheses, etc. Nodes that are conditionally dependent are joined by an edge, and each node is associated with a probability function whose input is a set of values from its parent nodes (i.e. the nodes connected to it). The output is the probability of the variable represented by the node.
BNs have proved to be very successful when a scenario consisting of pre-acknowledge information coupled with uncertain or partially known data, is considered [36]. The extraction of BNs from text is typically a complex task due to the intrinsic ambiguity of natural language [26]. In fact, BNs are defined by strict topological and probabilistic rules, which are difficult to fully automatise. Issues such as low recall and precision, as well as contradictory information, must be dealt with by any BN extraction tool. Therefore, they tend to rely on a substantial level of human supervision and interaction [23].
In this article, we introduce a systematic method to extract and populate fragments of BNs (and hence structured knowledge) from textual sources, based on grammar and lexical properties, as well as on the topological features of networks subsequently being extracted. The aim is to provide an agile yet accurate method to identify and assess probabilistic relations between concepts, which are subsequently embedded onto suitable BNs. However, this is typically a complex problem especially, when addressing the emergence of large volumes of unstructured data sets, typically referred to as Big Data. These are now considered to be one of the most promising sources for knowledge extraction.
The paper is structured as follows: in Section 2 we describe the main architecture of the proposed system; Sections 3 and 4 discuss the ontology used in this context, and the techniques and algorithms that can be used to extract probabilistic information. Sections 5 and 6 focus on the network topology, probabilistic information extraction, and knowledge discovery. In Section 7 we discuss the implementation and evaluation of our approach. Finally, Section 8 addresses future work and research directions.
