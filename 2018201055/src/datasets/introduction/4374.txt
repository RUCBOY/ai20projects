The scope, scale, and speed of modern computational science are breathtaking [1], [2], [3], [4], [5], [6]. Massive supercomputers are used to carry out computation, and humans use modern visualization tools to interact with the generated virtual models [7], [8]. Computational scientists are continually developing new simulated models, and the size and complexity of these models are increasing dramatically. This is partly due to improvements in hardware; according to Moore’s law where the number of transistors is doubling every 18 months or so [9], [10], [11], [12], and new hardware technologies such as general-purpose graphical processing units (GPGPU) are being adapted for scientific computing [13], [14], [15]. Software is becoming more open source, more modular, and the algorithms are also constantly improving to make software faster. This means that human resources can, and often are, the limiting factor in computational science. This is because computational scientists themselves are still critical for extracting knowledge from the generated data.
The interaction of computers with their human creators is fascinating, and this is especially true in computational science. The implied promise of computational science is that we can collectively compute our way to an understanding of the natural world, while riding on the coat tails of Moore’s law, and of course (we hope) that this process will be accelerated by our own stroke of genius along the way. A major challenge in computational science is to try and construct algorithms to be “black-box”. This means that we can apply a prescribed algorithm to new problems in the future. The second great challenge comes from data science, where the central tenet is that given enough data we can extract knowledge from models in an automated fashion. These two grand challenges remain unsolved, and at least for the time being, humans are very much still in the process of scientific discovery.
Humans require visualization tools [7], [8], [16], [17]. The ability to visualize a complex structure intuitively is critical because there is a very well known strong relationship between molecular structure and function, for example human degenerative diseases are from the misfolded structures of proteins [18] and a chiral drug has its efficacy due to spatial arrangements of atoms around its stereogenic centers [19]. It is remains quite difficult to understand a 3D structure on a 2D screen, especially for large bio-macromolecules, and therefore visualization tools are constantly being improved. 3D visualization is becoming more widely adopted in chemistry research and chemical education. The application of anaglyph 3D in protein structure visualization was reported for biochemistry education [20], and the FirstGlance [21] and proteopedia [22] projects are also made available for chemical education. Alternate ways of visualization include iView3D which uses videos to offer a convenient way to have an immersive virtual 3D view [23], and the hyperwall technology that can be used to study the electron density distribution of interesting molecules [24]. Molecular Rift is a virtual reality (VR) and augmented virtual (AR) reality tool for visualization of molecular modeling structures especially for drug design [25], [26].
The essential difference between AR and VR is the former allows the observation of the real-world surroundings, while the later does not. Because of this key distinction, augmented reality can uniquely utilize additional technologies (such as haptic devices [27] or 3D printers [28], [29]). Indeed AR is already widely used [30], [31] in health [32], [33], [34], education [35], [36], [37], [38] and infrastructure [39], [40] fields. AR has been applied to present molecular structures [20], [26], [38], [41], [42], visualize molecular properties [43], analyze data from computational chemistry [44], and discover binding pockets in enzymes [25]. So far chemistry based AR applications just utilize the immersive viewing function of AR to visualize molecules, which makes AR like an extension of 2D computer screen in 3D space.
Pokémon GO [45] has demonstrated just how much the public will embrace AR. The user experience could be improved even further: imagine grabbing a monster with your own hands instead of clicking a ball on the phone screen. AR companies like Meta [46] and the DepthSense software development kit (SDK) [47] make it possible to interact and manipulate objects by using intuitive hand gestures. Clearly AR technology has the potential for providing a very intuitive user experience. Current molecule based AR applications were designed to provide an immersive experience, whereby a user can visualize and interact with the entire structure as a single entity. This limitation may be due to AR being computationally demanding and the resolution of the hand gesture recognition and tracking being a limiting factor. Here we take the first step in developing an AR based human-computer interface for interacting (e.g. modifying and/or building) with a molecular system at an atomistic level.
