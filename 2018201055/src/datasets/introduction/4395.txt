Collaborative problem solving (CPS) is a core competency in today's knowledge economy, and plays a central role in theoretical and technological developments in educational research (Burrus, Jackson, Xi, & Steinberg, 2013). The CPS skills are the skills displayed when two or more parties interact with each other to share and negotiate ideas and prior experiences, jointly regulate and coordinate behaviors and learning activities, and apply social strategies to sustain the interpersonal exchanges when solving a shared problem (Liu, Hao, von Davier, Kyllonen, & Zapata-Rivera, 2015).
Evidence gathered from labor-market economics and occupational survey research (Burrus et al., 2013), as well as employment surveys (Casner-Lotto and Benner, 2006, NACE, 2014), suggest the growing importance of problem solving, social, and communication skills in the labor market. For example, predictive validity and intervention studies show a positive correlation between social skills and success in school and beyond (Lindqvist & Vestman, 2011).
However, the current methodology used to assess the learning benefits of CPS relies on ratings of individuals (self-ratings or ratings for team members' CPS skills), or situational judgment tests, or questionnaires designed for individuals, and on the team's performance. These approaches can provide useful information, but they do not consider the actual process of collaboration. What counts as evidence of learning does not correspond to current best practices for teaching collaboration and what students are ultimately expected to do with their knowledge. Therefore, current individual assessment practices do not measure students appropriately for future career needs and lifelong learning (von Davier & Halpin, 2013). The Assessment and Teaching of 21st Century Skills framework (ATC21S; Griffin, Care, & McGaw, 2012) includes collaboration and problem solving as two of the most important skills necessary for a successful career. The Office of Economic Cooperation and Development's (OECD) inclusion of collaborative problem solving in its 2015 PISA survey (OECD, 2013) has been influential in the United States. ETS and the Army Research Institute co-hosted a working meeting on Innovative Assessments of Collaboration in November 2014, which leads to several publications focused on the assessment of the CPS skills (von Davier, 2017a, von Davier, 2017b, von Davier et al., 2017). While there is a general agreement that collaborative problem solving is an important skill, there is less agreement on how to build an assessment to measure it, especially at scale and as a standardized test.
Predominantly, the existing studies on assessing collaboration or collaborative problem solving are designed from the perspective of revealing important aspects of CPS, which are often based on small samples of participants (Cohen et al., 1999, DeChurch and Mesmer-Magnus, 2010, O'Neil, 2014, Woolley et al., 2010). In many of these studies the data used were collected from small groups of participants based on convenience, and no standardized assessments (in which assessment items, scoring procedures, and interpretations were consistent across test forms) were used. The convenience sampling and the non-standardized instruments in these studies prompt questions about possible bias and the replicability of the findings. ETS has been exploring CPS assessment since 2013, and has focused on developing a large-scale standardized assessment of collaborative problem solving from the very beginning. These considerations necessitated that the assessment design strike a balance between psychometrics expectations and operational feasibility (Hao, Liu, von Davier, & Kyllonen, 2017). Based on these factors, we developed an assessment prototype, the ETS Collaborative Science Assessment Prototype (ECSAP). Throughout the development of ECSAP, one of the most important findings was the realization that developing a serious assessment of collaboration requires an interdisciplinary effort coordinated via a comprehensive research agenda. A consensus on the necessity this interdisciplinary research agenda is a precondition for developing any large-scale, standardized assessment of collaboration.
The research agenda we propose is comprised of 1) construct definition and refinement, 2) assessment design, 3) data management, 4) computational psychometric modeling (which includes artificial intelligence (AI)-based scoring and facilitation), and 5) well-designed validity studies. These five strands are shown in Fig. 1. We believe these five strands and their specific applications to collaborative assessments are indispensable for developing a serious assessment of collaboration. The instantiation of this interdisciplinary research program is not a research framework for measuring collaboration skills, but five sets of different research and development agendas, which, like puzzle pieces, fit together to form collaborative assessments. When taken at a glance, these research disciplines seem to be like those that are necessary for many types of assessments. However, there is a depth and novelty associated with assessing CPS skills in a virtual environment that require new perspectives and designs in each of these areas. Our interdisciplinary research agenda took shape gradually as we developed the ECSAP (Liu et al., 2015, Hao et al., 2015). The ECSAP includes a set of measurement instruments that assess test takers' general knowledge of science, personality, scientific inquiry skills, collaborative problem-solving skills, and the interactions among these constructs, as it is described later. The goal of this assessment prototype was to explore the feasibility of a large-scale, standardized assessment of CPS skills in the science domain.Download : Download high-res image (338KB)Download : Download full-size imageFig. 1. Interdisciplinary research strands to support the development of collaborative assessment.
The paper is organized as follows. First, we present the interdisciplinary research agenda needed to develop a collaborative assessment. We discuss the research strands, focusing on construct identification, assessment design, data management, computational psychometrics, and validity. Then, we introduce the ECSAP and show how these interdisciplinary research strands are implemented. Finally, we conclude with a discussion about the limitations of the ECSAP and future work.
