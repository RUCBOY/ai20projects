Building descriptive models of deductive reasoning has been a major topic of investigation in Cognitive Science, including the construction of natural deduction rules to manipulate propositions in working memory (Rips, 1983). Other theoretical approaches of deduction advocate mental models that propose people reason by manipulating tokens (Johnson-Laird, 2012). A goal for all descriptive models of reasoning is to account for errors. For instance, participants in a study described by Rips (1983) had to decide which propositional arguments were valid. Acceptance of validity ranged from 17% to 92% across 32 valid arguments.
Reasoning is also a major topic in the Information Sciences, including the construction of formal ontologies that use logic-based programming languages to draw deductive conclusions (Pease, 2011). Perhaps the major cause of the lack of integration of work on deductive reasoning in the Cognitive and the Information Sciences is that Cognitive Science is primarily interested in descriptive models of how people reason whereas the Information Sciences are primarily interested in prescriptive (normative) models to enable machine reasoning.
Formal ontologies help people by providing both an accurate knowledge base and deductive rules to derive conclusions. Knowledge should be based on the latest discoveries in science (Smith & Ceusters, 2010) and deductions based on first- or higher order logics that derive valid inferences (Pease, 2011). When these objectives are achieved, the potential is enormous for supporting unambiguous and machine-readable documentation, consistency verification, data classification, querying, and further ontology development (Hoehndorf, Dumontier, & Gkoutos, 2012).
Although formal ontologies are better in deductive reasoning and people are better in possessing an extensive knowledge base, both ontologies and people face the same challenges when reasoning from an inadequate knowledge base. Knowledge in these situations does not entail ‘truth’ but requires search for accuracy. Our objective in this article is therefore to explore, at Marr’s (1982) computational level of analysis, the difficulties created for computers and people when reasoning from imperfect knowledge. The computational level “provides an understanding of how a mechanism functions in broader environments that determines the computations it needs to perform (and may fail to perform)” (Bechtel & Shagir, 2015, p. 31). Marr was concerned with why a function needs to be computed, which requires examining the tasks that need to be performed in the environment.
A primary role of the computational level is to constrain functions that must be computed at the algorithmic and representational level (Cooper & Peebles, 2015). This role enables the computational level to serve as an abstract theory that deliberately avoids lower-level commitments. Cooper and Peebles (2015) proposed that, in addition to Bayesian approaches, a variety of other approaches including formal logic can serve as a foundation for formulating problems at the computational level. Others have shown how logical theories can constrain hypothesis about processing all the way down to the neuroscience level (Baggio, van Lambalgen, & Hagoort, 2015).
Our objective is to analyze the challenges for both people and machines when reasoning from imperfect knowledge. Section 2 describes three major tools in the Information Sciences – SUMO, WordNet, and FrameNet – that can support the construction of computational-level analyses of reasoning. Section 3 summarizes 7 types of imperfect knowledge to illustrate the problems created when reasoning from ambiguous, conditional, contradictory, fragmented, inert, misclassified, and uncertain knowledge. Sections 5 Contradictory knowledge, 6 Misclassified knowledge, 7 Uncertain knowledge elaborate on 4 of these types (ambiguous, contradictory, misclassified, uncertain) that are particularly important for constructing ontologies. Section 8 discusses using ontologies in cognitive science as practical tools and as idealized cognitive architectures. The final section contains concluding remarks.
