The percentage of the elderly increases every year in the world [1] and developed countries are going to suffer from so-called aging society; it is reported that the population of the over-sixty will be one third of the total population in 2050 and this is recognized as one of the serious social issues. Assistive technologies are expected to support the elderly in various application scenarios. One possible technological application is a robot which takes care of people in care houses. Human pose recognition is one of the necessary functions of such robots, which contributes to an accurate care and diagnosis or anomaly detection.
Many human pose estimation methods have been proposed. Felzenszwalb et al. [2] dealt with an image-based human pose estimation using a pictorial structure representation [3], in which a whole body is represented as a collection of parts with their deformable geometrical relationships. Many improvements to this approach have then been proposed. To achieve a better performance, Ramanan et al. [4] improved the accuracy of part detection and Ferrari et al. [5] limited the search area using GrabCut [6].
As low-cost depth sensors like RGB-D cameras are developed, Shotton et al. [7] developed a method of estimating human poses in a depth image. The method first assigns body part labels to each pixel by using a simple depth difference between two points as a feature, and adopting a random forest classifier. It then estimates the pose of every part based on the assigned labels. Foreground/background separation is easily handled by using depth data. These previous works basically deal with pose estimation in ordinary poses.
In actual applications, unusual poses, such as lying and crouching, must also be considered. Ardiyanto et al. [8] applied a human pose estimation to a fallen person monitoring and rescue scenario. Their system continuously tracks the skeleton of a person using an environmental RGB-D camera and can therefore recognize the pose even after falling; such environmental cameras need to be installed in advance. Suppose a situation that a mobile service robot patrols a residence or a nursing home to see if any emergency situation occurs. Without environmental cameras, the robot has to recognize the human state including his/her pose only using on-board sensors. Therefore a pose estimation method for such applications must be able to estimate unusual poses. This is still a challenging problem which has not been fully solved by existing approaches. Wang et al. [9] improved the method by Felzenszwalb et al. [2] in human region detection to cope with lying person pose estimation using a color image. Although the method shows a good performance, it might be weak in the situation where foreground/background separation is difficult due to, for example, a bad illumination condition and where more complex poses with self-occlusions occur.
Convolutional neural networks (CNNs) [10] have recently been very successful in various recognition tasks including human pose estimation. Pose estimation methods using CNNs are divided into two types. One is to directly estimate hunan joint positions. Toshev et al. [11] take this approach and use FLIC dataset [12] which provides human color images with joint positions. The other is to estimate the pose by classifying each pixels into body parts, as in the case of Shotton et al. [7]. Oliveira et al. [13] take this approach and train a fully convolutional network (FCN) [14] using the PASCAL Parts dataset [15] which provides human color images with body part labels. Although these works exhibit good performances, they rely on color images and may be sensitive to changes illumination, clothing, and skin color. They could also face a privacy issue.
Use of depth images is a promising alternative to solve these problems. However, this leads another big problem, that is, to construct a large dataset of annotated depth images. Nishi and Miura [16] generated a set of depth images with head position annotation for several lying poses from omnidirectional viewpoints using a large rotation table and an RGB-D camera. This approach can be applicable only to a small-sized dataset generation. We can use annotation tools like LabelMe [17], [18] for color images, but a similar approach is difficult to apply to depth images. Skeleton tracking techniques [19], [20] could be a possible way but these are applicable only to normal poses but not to unusual poses under consideration.
Since the annotating real depth images is difficult, we adopt computer modeling and computer graphics techniques for generating annotated depth images [7]. The issues are then how to construct human models with various body shapes and how to make the models take various poses. Manually producing such variations is extremely hard when constructing a large-scale dataset. Therefore we propose a novel approach that combines a flexible, parameterized body model, a motion capture system, and computer graphics tools in order to generate a large number of body part-annotated depth images efficiently. We evaluate the constructed dataset by conducting body part labeling experiments using an FCN for synthetic and real depth images.
The rest of the paper is organized as follows. Section 2 describes the detailed procedure of dataset generation. Section 3 explains the FCN that we used for evaluation. Section 4 describes experimental results to show the effectiveness of the dataset. Section 5 concludes the paper and discusses future work.
