In recent years, sparse representation of signals have become an important tool in computer vision. In many applications in computer vision, such as image denoising, image super-resolution and object recognition, sparse representations have produced remarkable performance [1], [2], [3]. It has also been verified that sparse representation or sparse coding can achieve good outcomes in many image classification tasks [4], [5], [6]. The reason of the success of sparse coding is that a signal Y can be well represented by a linear combination of a sparse vector x and a given dictionary D, namely, if x and D can be properly found, then Y can be well approximated as: Y ≈ Dx.
There are two methods to obtain a dictionary for sparse representation: using an existing dictionary and dictionary learning. Using an existing dictionary means to choose a pre-computed basis such as wavelet basis and curvelet basis. However, in different computer vision tasks, one often needs to learn a dictionary from given sample images, then better image representation can be expected from such a task-specific dictionary [7].
Many algorithms have been proposed to tackle the problem of dictionary learning, the method of optimal directions (MOD) [8] and the KSVD algorithm [9] are two of the most well-known methods. The dictionaries learned by MOD and KSVD are linear representations of the data. However, in many computer vision applications, one has to face non-linear distributions of the data, using a linear dictionary learning model often leads to poor performance. Therefore several non-linear dictionary learning methods have been proposed. Among them, a recently proposed method kernel KSVD (KKSVD)[10] has shown its ability to obtain better image description than the linear models. The kernel KSVD includes two steps: sparse coding and dictionary update. In sparse coding stage, the kernel orthogonal matching pursuit (KOMP) is used for seeking the sparse codes. Once the sparse codes are obtained, the kernerlized KSVD is then used in the second stage for dictionary update. It is demonstrated that the kernel KSVD can provide better image classification performance than the traditional linear dictionary learning models.
Although the kernel KSVD can outperform its linear counterparts by introducing the non-linear learning procedure, the learned sparse vector and the dictionary yet comprise both additive and subtractive interactions. From the perspective of biological modeling, the existence of both the additive and subtractive elements in the sparse representations of signals is contrary to the non-negativity of neural firing rates [11], [12]. Moreover, the negative and positive elements in the representations may induce the ‘cancel each other out’ phenomenon, which is contrary to the intuitive notion of combining non-negative representations [13]. Therefore, many researchers have claimed to use non-negative sparse representations in vision-related applications [14], [15]. The non-negative sparse representations are based on the constraints that the input data Y, the dictionary D, and the sparse vector x are all non-negative.
The non-negative sparse representation has been successfully applied in many computer vision applications, such as face recognition [14], [16], motion extraction [16], [17], image classification and retrieval [18], [19]. Nevertheless, these non-negative sparse representations are all based on linear learning models, therefore their ability to capture the non-linear distributions of data is limited.
Motivated by this drawback of the existing non-negative sparse representation models, in this paper, we propose a non-linear and non-negative sparse model: non-negative kernel KSVD (NNK-KSVD), which integrates the distinctive features of the non-linear models and the non-negative models. In NNK-KSVD, the non-negative constraints are embedded into the kernel KSVD for sparse coding and dictionary learning. With the non-negative constraints, the new update rules for sparse vector searching and dictionary learning of kernel KSVD are introduced. The proposed NNK-KSVD sparse model was tested on several benchmark image datasets for the tasks of classification and retrieval, state-of-the-art results were obtained.
Note that this paper is an extension work of our previous conference paper [20]. Compare to [20], more details of the proposed model were introduced in this paper, and the proposed model was evaluated on more image datasets to verify the effectiveness. Especially, in this paper the proposed model was employed for the tasks of image retrieval, competitive results were obtained as well.
The rest of this paper is organized as follows. In Section 2, some related work on non-negative sparse coding and kernel sparse coding is briefly reviewed. The proposed NNK-KSVD sparse model is introduced in Section 3. The experiments and the results are given in Section 4. Finally, we draw the conclusions in Section 5.
