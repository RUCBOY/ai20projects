Chemoinformatics aims to use computer science, mathematics, and information science to predict and analyze molecular properties. One of the major principles in this research field is the similarity principle, which states that two structurally similar molecules should have similar activities and properties. The structure of a molecule can be encoded by a labeled graph G=(V,E,μ,π), where the unlabeled graph (V, E) encodes the structure of the molecule, while μ maps each vertex to an atom’s label and π maps each edge to a type of bond between two atoms (single, double, triple, or aromatic).
Graph comparison is an important problem in many application areas such as bioinformatics, chemoinformatics, engineering, business, sociology, and telecommunications. For example, in finance data analysis, graphs are used to model dynamic variations in the stock price [16]. To analyze biological data, graphs have been utilized to model chemical structures [26], protein sequences [32], protein structures [14], and gene-regulation networks [15].
Graph-classification techniques can be applied to chemical compound structure graphs. These techniques facilitate the prediction of the properties of chemical compounds. In graph classification, each graph is associated with a target value, and the goal is to find a function that sufficiently maps graphs to their target values. Graph-classification algorithms are classified into three groups [3], [21].
The quantitative structure activity relationship (QSAR) field represents the first group of graph-classification techniques. The main aim of QSAR models is to find the correlation between molecule descriptors and molecule properties [7]. Molecular descriptors may be computed using physical properties, biological activities, or structural information [4]. Any statistical machine-learning algorithm that is associated with vectors of these molecular descriptors can be used to predict molecular properties. Such a scheme provides a large set of tools that are available within the statistical machine-learning framework. An artificial neural network (ANN) is one of the machine-learning approaches that are widely used in many QSAR models [27].
In the second group, a set of features (paths, cycles, trees, and subgraphs) is explicitly extracted from a graph. Once the set of features is determined, a graph is described by a feature vector. The graphs feature vectors can be used with any data-mining method that works in n-dimensional Euclidean space to classify the graph. In chemoinformatics, explicit features for graphs are denoted by structural keys. A structural key is a bit string that denotes the presence of certain patterns of interest, such as paths, cycles, and trees [25].
The third group of graph-classification algorithms is based on kernel functions. A set of features is implicitly collected, and the similarity between graphs is computed via a kernel function through this set of features. Kernel functions are used to avoid explicit computations of coordinates in feature space by computing the product between two points in a Hilbert space. Kernel functions have many applications [1].
Many graph kernel functions have been developed, and some promising application results were reported in [22]. Among these methods, some kernel functions use graph features such as walks [17] and cycles [13], while others use different approaches such as genetic algorithms [2], frequent subgraphs [5], and graph alignment [8]. In [11], a local subgraph is used to encode the stereo-isomerism property of each atom of a molecule. A kernel between bags of such subgraphs provides a similarity measure incorporating stereo-isomerism properties.
Many graph kernel functions face the challenge of being required to choose the most significant features [6], [10]. New algorithms are needed to overcome this challenge by reducing the number of features. The kernel functions presented in [6] compare two graphs according to all subgraphs that are in common between their nodes. These subgraphs are used without reduction, and are extracted from each node and its neighbors. To improve kernel performance, additional types of features need to be added, while at the same time, a reduction method is needed to select the significant features. The treelet kernel function presented in [10] is based on the extraction of treelets from graphs and using them to create feature vectors. A single treelet in this kernel function may include many other treelets. For instance, all treelets with heights equal to one can be extracted from a single treelet. This treelet can be represented by a star whose central node corresponds to the tree root.
In this paper, we present a dynamic algorithm that is based on similarity and distance required to classify chemical compounds. The proposed algorithm extracts paths of stars from structure graphs of given chemical compounds, after which it encodes them. These codes are used to create two relationship matrices between the paths of stars. The relationship matrices consist of common and different subgraphs between the paths of stars. The original paths and sub-paths are used to create feature vectors for each compound. Finally, the kernel functions with a support vector machine (SVM) are applied to the feature vectors to predict the compound activity.
The relationship matrices are used to extract the significant sub-paths from the original paths of stars. The proposed algorithm uses the relationship matrices to extract and select paths without consuming excess time for selection. These matrices solve the feature-selection problem, which represents a challenge to some methods that use treelets like [10]. The proposed algorithm reduces the number of features without consuming time, while simultaneously improving or preserving the prediction accuracy.
The remainder of this paper is organized as follows. In Section 2, we discuss the proposed coding system and a method of extracting feature-relationship matrices. In Section 3, we describe the path of stars algorithm and its steps. In Section 4, we describe the computation of feature vectors between chemical compounds, the kernel function, and the proposed main algorithm. In Section 5, we present our results and performance evaluation. Finally, we present the conclusion in Section 6.
