Rubrics are useful for instruction and evaluation (Andrade, 2005), and research has supported the use of rubrics in teaching and learning (e.g. Osana & Seymour, 2004; Reitmeier, Svendsen, & Vrchota, 2006), evaluating programs (Dunbar, Brooks, & Kubicka-Miller, 2006; Knight, 2006), assessing student work (Campbell, 2005, Reddy and Andrade, 2009), and identifying the effectiveness of courses and areas for improvement in instruction (Dunbar et al., 2006, Reddy and Andrade, 2009, Song, 2006). Researchers have continually supported the use of rubrics, as they promote objectivity, consistency, reliability, and validity in assessment (Boettger, 2010, Crusan, 2015, Crusan, 2010; Dempsey, PytlikZillig, & Bruning, 2009).
Specifically, rubrics have been employed in assessing L2 writers, and often aim to assess various essay genres at the high school and undergraduate level (Crusan, 2010, Knoch, 2009a, Knoch, 2009b, Polio, 1997). In assessing academic writing, existing rubrics are mostly used for large-scale, standardized tests evaluating predetermined topics to determine student needs before enrolling in an academic program (Educational Testing Services, 2005, Knoch, 2009a). However, few studies have investigated academic writing courses for graduate students and their outcomes, and rubrics for such cases are lacking: those that have assessed such courses or interventions tend to employ a range of assessment devices, including error and vocabulary analysis (Boscolo, Arf√© & Quarisa, 2007; Ferris and Roberts, 2001, Storch and Tapper, 2009). Furthermore, there are few studies on assessing popular science writing (Baram-Tsabari & Lewenstein, 2013) and almost no systematic evaluation of learning outcomes in training programs (Baram-Tsabari & Lewenstein, 2016) despite the fact that the number of science communication courses at the university level is rising (COMPASSonline, 2013). This highlights the need to evaluate the pedagogy and programs teaching future scientists good written communication skills.
Despite the aforementioned studies, researchers have noted a lack of research on the development of writing scales (Banerjee, Yan, Chapman, & Elliott, 2015; Knoch, 2009b, Knoch, 2011; Lallmamode, Mat Daud, & Abu Kassim, 2016; Sasaki & Hirose, 1999). This article describes the development of a rubric for rating specific goals of graduate level academic writing in advanced L2 STEM students, including acquisition of a contrasting style, i.e. popular science writing. This quantitative scoring rubric provides for a more standardized evaluation of writing outcomes that can be easily applied to assess the progress and effectiveness of a graduate writing course.
