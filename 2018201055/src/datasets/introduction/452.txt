Clustering is an analytical method used to group data objects according to their similarity without any knowledge of ground truth clusters [1]. The cluster analysis has been used in many different areas [2], [3], [4], [5]. In query optimization [6], clustering is used to identify a query group with a similar Query Execution Plan (QEP) due to the semantic representations of the queries. The mass of data is usually stored in distributed databases [7]. The sequence of queries is issued to distributed databases as the primary interaction unit among a database and its users [8]. The same QEP could be used to execute the queries with a similar structure [9]. There are different clustering methods, including density-based clustering [10], [11], [12], fuzzy clustering [13], hierarchical clustering, partitioning clustering, and model-based clustering.
There are various factors, including the size of data, shapes of clusters, the noise of data, and the number of input parameters affecting the quality of these clustering methods. A famous way for data cluster analysis is the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) [14]. It can find clusters with arbitrary shapes and handle the noise. A static DBSCAN algorithm has been used to cluster static datasets in which all data objects have to be collected before running the algorithm [15]. Furthermore, the static DBSCAN algorithm re-cluster all the data objects for new incoming data. In dynamic environments, all data cannot be collected before performing clustering. Such datasets are collected over large environments and evolve quickly. Therefore, the incremental DBSCAN clustering is preferable to traditional static DBSCAN. The incremental DBSCAN [15] can incrementally create and update the arbitrary shaped clusters in large dynamic datasets. In the algorithm, the performance of clustering is influenced by its two input parameters (Epsilon (Eps) and Minimum points (MinPts)). Nevertheless, it is quite challenging to apply incremental DBSCAN to cluster points because of the complexity of determining its input parameters, mainly for handling a massive volume of data and the inaccurate characterizing of many kinds of data. This is why we should introduce automatic methods to calculate the values of these parameters.
Recently, several studies have combined meta-heuristic optimization algorithms with clustering algorithms to improve the quality of clustering [16], [17], [18], [19], [20], [21], [22], [23], for example, in [20], a hybrid clustering method was presented, which combined Differential Evolution (DE) with DBSCAN to automatically detect the best combinations of Eps and MinPts. In [17], Particle Swarm Optimization (PSO) was applied as a parameter tuning tool for DBSCAN for both supervised and unsupervised learning. However, these single-objective approaches can produce unbalanced results. Although, to the best of our knowledge, there is not any work directed at using multi-objective optimization techniques for density-based cluster parameter optimization. Therefore, this paper has proposed a new hybrid approach, NSGA-II based Density-Based Clustering and Classification (NSGA-II/DBCC), to improve the clustering quality of the incremental DBSCAN algorithm by identifying the ideal parameter configurations via searching for the whole parameter space by NSGA-II. In this paper, four kinds of fitness functions have been designed based on internal and external clustering validation indices to determine the best configuration of parameters for both labeled and unlabeled datasets [17] using NSGA-II/ DBCC. As far as we know, no other authors have used NSGA-II to optimize the DBSCAN parameters using fitness functions introduced in this paper. Moreover, the present article has developed a parallel version of the Non-dominated Sorting Genetic Algorithm II (pNSGA-II) to speed computations of fitness functions. The main contributions of this article are as follows:

•Presenting a novel technique based on the integration of NSGA-II and incremental DBSCAN for the automatic determination of the appropriate number of clusters and the enhancement of the quality of clusters.•Using NSGA-II as a parameter tuning tool for reducing incorrectly-partitioned data points of incremental DBSCAN.•Using multiple internal validation indices for choosing the most appropriate number of clusters in unlabeled datasets.•Using multiple external validation indices for generating an efficient data partitioning in the labeled datasets.•Performing the fitness evaluations of the NSGA-II different individuals in parallel.
The article has been structured as follows: Section two refers to previous works. Section three presents the incremental DBSCAN clustering algorithm. The proposed pNSGA-II/DBCC approach is presented in Section 4. Section 5 proposes various fitness functions for supervised and unsupervised pNSGA-II/DBCC. The experimental results and the conclusion are presented in Sections 6 Experimental setup and results, 7 Conclusion, respectively.
