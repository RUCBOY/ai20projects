Medical images are widely used in clinical diagnosis and treatment of various diseases, e.g., the ultrasound images are used to diagnose breast cancer and abdominal disease. The report writing of medical images requires extensive expertise and it is tedious to provide highly-accurate medical image reports. This paper focuses on ultrasound medical images, which are recognized as a cheaper and faster option than CT, X-rays, and MRI. Conventionally, medical image reports are written to record the findings of each area in the ultrasound image. The important local properties, e.g., boundary conditions and tumor morphologies are shown in Fig. 1.Download : Download high-res image (71KB)Download : Download full-size imageFig. 1. An example of ultrasound breast report. Doctors write medical reports based on unified templates, which means a complete report should contain some important properties (e.g., boundary condition, tumor morphology) that are crucial for diagnostic reports.
Labor cost and report quality are the two fundamental issues motivating us to investigate the automatic medical report generation. First, the average time of writing a single ultrasound image report is 5–10 min by experienced doctors. Second, the report quality often significantly varies because of doctors’ various expertise levels. To generate highly-accurate medical reports automatically, recent researches have proposed machine/deep learning based methods. Zhang et al. [1] used a direct multi-modal mapping from the medical images to diagnostic reports. However, their generated reports are limited to describing five types of cell appearance features. Jing et al. [2] and Yuan et al. [3] adopted a hierarchical LSTM decoder to generate paragraph-level medical image reports. Xue et al. [4] proposed a multi-modal recurrent with visual attention to maintain the coherence among the generated sentences. However, these methods did not take advantage of the nature of medical reports based on template writing. Li et al. [5], [6] proposed the retrieval model based on reinforcement learning and graph neural network for medical report generation which degrade the flexibility of report generation.
To address the above critical issues, we develop a unified framework to automatically generate high-quality text reports for medical images. Image captioning is often adopted in the existing studies for report generation and the main problems can be summarized as follows.
Local property description: The medical image reports depict some important local properties, which cannot be accurately described in existing image captioning models. Li et al. [6], [5] proposed a retrieval-based approach to obtain a sentence from a template database. However, such methods degrade the flexibility of sentence generation. To overcome this issue, we design a multi-label classification network (MLC) to predict these important local properties, use the word embedding of these predicted properties as the semantic features. Besides, we also utilize semantic attention to leverage the extracted semantic features.
Report template availability: The unified medical report templates used in hospitals result in fixed phrases such as irregular morphology. The latter word (e.g., morphology after irregular) completely depends on the language model. However, the traditional captioning models force spatial attention to be active for every generated word. Inspired by Lu et al. [7], we introduce a sentinel gate to decide whether to look at current visual features or to focus on memories stored in the Long-Short Term Memory (LSTM) [8] when generating the next word.
The number of ultrasound images ranges from 1 to 10 for each patient. To simplify the analysis, we select the highest quality images with their corresponding medical reports to build our Breast Cancer Dataset (BCD2018).
In summary, the main contributions of our work are as follows:
•We design a MLC to predict crucial local properties of ultrasound images, and use the word embedding of these predicted properties as the semantic features.•We propose a semantic attention network in the light of the spatial attention mechanism to exploit these semantic features.•We introduce a sentinel gate for controlling the attention on current image and language model.
The remainder of this paper is organized as follows. In Section 2, we discuss the related works close to this paper. Section 3 describes our proposed medical report generation method in detail. Section 4 demonstrates the experimental results and the concluding remarks are provided in Section 5.
