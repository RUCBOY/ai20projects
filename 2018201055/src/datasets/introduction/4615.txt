Nearest neighbors (NN) search has acted as a fundamental role in lots of important applications, such as machine learning, computer vision, natural language processing and so forth for decades [1], [2], [3]; however, recently ever-changing Internet technologies have already pushed forward the big data era to come: high-dimensional, massive, and heterogeneous data throw a huge challenge on NN. Even for the simplest linearly scanning, it would be impractical and unrealistic for real scenarios now. Hashing, as a new approximate nearest neighbors method, embedding data into the binary hamming space which is capable of preserving similarities between objects makes the memory and computing both extremely effective [4], [5]; even ordinary PCs can handle large amounts of data.
Hashing methods can be divided into different classifications according to different views. For example, it can be roughly divided into data-independent methods and data-dependent methods by using the data or not, where LSH [6], KLSH [7] and other LSH-like methods [8] are data-independent and ITQ [9], SpH [10], SSH [11] and MLH [12] are data-dependent ones. From another perspective of using supervised information or not, there could be three kinds: unsupervised [6], [13], supervised [12], [5] and semi-supervised [11], [14], [15] methods. Here, we would like to divide the hashing methods into traditional image retrieval methods and current multi-view cross-modal retrieval methods.
Methods mentioned above all belong to the former kind. And as regard to the latter one, there are many new methods emerging in the recent years. Inter-media hashing (IMH) [16] introduces inter-media consistency and intra-media consistency to discovery a common hamming space, and uses regularized linear model to learn view specific hash functions. However, IMH needs to construct the similarity matrix for all the data points, which will impede the effectiveness for large-scale datasets. Latent semantic sparse hashing (LSSH) [17] utilizes the sparse coding to capture the salient structures of images and matrix factorizations to learn the latent concepts from text to perform cross-modal similarity search. However, this kind of learning paradigm, especially the sparsity, makes the training stage consume too much time. Collective matrix factorization hashing (CMFH) [18] learns unified hash codes by collective matrix factorization with latent semantic match model from different modes of one instance, while it's too strict to constraint different modalities to identical hash codes. Semantic topic multimodal hashing (STMH) [19] models text as multiple semantic topics and image as latent semantic structures and then learns the relationship of text and image into their latent semantic spaces. Though STMH has obtained superior performances to some state-of-the-art baselines, we find the extension of out-of-sample need to be simplified.
Although there are many multimodal hashing methods and they all have achieved promising performance in multimodal applications [16], [17], [18], [19], there still needs to be more explorations on models (linear/nonlinear, matrix factorization/probabilistic graphical modes, deep neural network or not), algorithms (convex/nonconvex, distributed parallel gradient-based algorithms) and theories (robustness, sparsity, diversity or low rank), or even for some new formalizations of multi-modal data. In this work, we make full use of the self-characterized image-sentences pairwise data, and map them diversely into a shared latent semantic space via match learning with label-supervised semantic regularizations which is able to preserve similarities between images and sentences, and then put forward a novel method Diversity Regularized Latent Semantic Match for Hashing (DRLSMH). The core contributions of our work can be listed as below:
•We incorporate linear projection instead of direct matrix factorization with learning to match framework, which would definitely lead to two advantages: on one hand, it makes the model look simple (more like convex), and more importantly it would greatly benefit the hashing for out-of-samples just through basic matrix-vector multiplications; on the other hand, this kind of formalizations help to the later closed-form solutions.•Soft orthogonality is introduced as a novel regularizer for diverse hashing functions, which will provide compact and accurate representations with small fixed number of hash bits. Moreover, closed-form solutions can be easily derived with some relaxations on the regularizations under the iterative framework.•To the best of our knowledge, this is the pioneer exploration to perform learning to hash for cross-modal retrieval tasks on such kind of datasets: pair-wise image-sentences corpus. Extensive experiments on two public datasets highlight the superiority over some of the state-of-the-art methods for image-query-image, image-query-text and text-query-image missions.
The remainder of this paper is organized as follows. In Section 2, we introduce related work about diversity regularizations, learning to match and deep learning for representations. In Section 3, we define our problem and give necessary notations. In Section 4, we propose our method DRLSMH and present an approximate learning process for match learning and then derive the optimization algorithms. We conduct experiments on three kinds of tasks to evaluate the proposed models in Section 5, and finally draw conclusions in Section 6.
