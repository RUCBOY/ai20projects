Over the last decades, the advances in multi-core processor architecture enabled parallel processing that can better utilize the power of modern computers. The need for a better computer performance is also stimulated by the increasing availability of massive geospatial data, such as from laser scanning. However, this requires specific software with the ability to employ parallel computational capabilities (Guan and Wu, 2010).
First studies related to parallelization of Geographic Information System (GIS) operations were done by Healey et al. (1998) and Mineter and Dowers (1999). Several parallelization studies were published in the area of digital terrain modeling and analysis (for example, Huang and Yang, 2011; Huang et al., 2011; Schiele et al., 2012; Xie, 2012) and hydrological modeling (Cui et al., 2005, Sten et al., 2016). Still surprisingly, most of the current GIS software products exploit these advances in a very limited way and nearly all operations are executed by a single process. While most GIS operations are computationally simple and therefore executable quickly even by a single process, some geospatial tasks are more complex and computationally very intensive. For example, spatial interpolation techniques, often used in GIS for digital terrain modeling, usually require complex mathematical operations, and only rarely run in parallel. Most GIS operations are serially designed without any consideration of concurrent execution (Guan and Wu, 2010).
There are also various simulation models implemented in GIS ranging from simple models based on map algebra to fully dynamic simulation models such as, for example, hydrological or traffic models that need thousands of iterations to represent the dynamical behavior of the phenomenon. Moreover, these operations must be often run repeatedly with various input parameters in order to get the most accurate result. Thus, the issue of computation speed is very important for most GIS users. However, despite the growing performance of current computers, the tremendous volume of data make their processing using a standard GIS rather problematic. Obviously, the computationally intensive GIS operations originally run in a sequential mode by a single process need a parallelization modification to fully exploit the power of current multi-core systems.
The computer architecture and multiple processor organization determine various parallel approaches. These depend on the number of processors, access to physical memory and communication (Flynn, 1972). Typically, there are two major types of parallel architectures that use either a distributed memory model or a shared memory model. Distributed memory systems require a communication network to connect the inter-processor memory. In the shared memory model the access to the main memory is via Uniform Memory Access (UMA) or Non-Uniform Memory Access (NUMA). NUMA provides a higher scalability to systems with a higher number of processors (typically more than 8–12), however, it increases the complexity of parallel programming (Stallings, 2010). Recently, high performance computing platforms have increasingly used general purpose computing on graphics processing units (GPGPUs). The graphics processor unit is used to perform computation in applications traditionally handled by the central processing unit. The most common parallel computing platforms based on GPGPU are CUDA and OpenCL (Fang et al., 2011). The ideal GPGPU applications have large datasets, high parallelism exploiting a large number of threads, and minimal dependency between data elements.
There are several commonly used parallel programming approaches depending on the memory model. The distributed memory model uses a message passing system with the Message-Passing Interface (MPI) application programming interface being the most widely used. The shared memory model can be used by various parallel programming tools such as Open Multi-Processing (OpenMP), POSIX Threads, or Cilk. The distributed memory systems have dominated on network-connected computer clusters. Currently, however, most mainstream computers are equipped with multi-core central processing units (CPUs), thus opening the power of parallel processing using a shared memory model to any user with a single computer. In this study, we will explore the implementation of shared memory parallelism for multi-core systems using OpenMP and open-source GRASS GIS.
The OpenMP parallelization tool can be used to make new or modify existing programs to run in parallel simply by adding compiler directives or functions to the original program code. OpenMP (Open Multi-Processing) is an application programming interface (API) that supports shared memory multiprocessing (multithreading) on most common platforms ranging from desktop computers to supercomputers, processor architectures and operating systems (Chapman et al., 2007). It consists of a set of compiler directives, library routines, and environment variables that execute a task in parallel by several threads allocated to different processors (cores). The core elements of OpenMP are the constructs for thread creation, workload distribution (work sharing), data-environment management, thread synchronization, user-level runtime routines and environment variables. In C/C++, OpenMP uses #pragmas.
In geospatial tasks, the concept of parallel computing can be used to shorten computation time via decomposing the geospatial problem into several subtasks that are handled simultaneously by different threads. However, it is quite common that some subtasks depend on completion of some other subtasks. Therefore, different parallelization problems have different implementation schemes for shortening the duration of computation. Parallel algorithms are usually used to partition the temporal/spatial domain into sub-domains. Because almost all natural processes are temporally successive, domain decomposition is mostly carried out spatially (Li et al., 2011).
GRASS is an Open Source GIS with a wide-range functionality and applications (GRASS, 2016, Neteler and Mitasova, 2008, Neteler et al., 2012). It can handle 2D and 3D data in vector or raster format and offers many advanced geospatial modeling algorithms and visualization techniques. GRASS is not a monolithic application, but it rather consists of over 300 modules following the Unix philosophy that each module does a specific task. Therefore, each module is autonomous including a memory management and error handling. The core libraries and most modules are written in POSIX-conforming ANSI C. Some functions are written in the C++ and Python programming languages. Recently, Object Oriented Python Application Programming Interface for GRASS GIS was introduced to expand the capabilities of the software (Zambelli et al., 2013). The software is released under GNU General Public Licence (GPL) (Neteler et al., 2012). A few parallelization studies were done for GRASS GIS. For example, Sorokine (2007) parallelized GRASS GIS visualization using high-resolution tiled displays powered by Linux-based cluster of PCs, and Huang et al. (2011) also used a Linux-based cluster for a parallel inverse distance weighting interpolation algorithm using MPI. In GRASS GIS, the shared-memory parallelization model based on OpenMP has been used in the mathematical (gmath) and partial differential equations (PDE) libraries for matrix and vector calculations and linear equation solvers which are used by some GRASS GIS modules, such as r.gwflow or r.solute.transport (GRASS, 2016). There are still many computationally demanding modules that run using a single process and thus do not exploit the full power of the current multi-core technology. For example, the r.sun solar radiation module was used in several studies with large datasets representing Europe (Šúri et al., 2005) or large regions such as Andalusia (Romero et al., 2008). Pintor et al. (2015) have found the speed of r.sun to be a limiting factor for its application to high-resolution DEMs. A similar situation can be found for other modules, such as r.sim.water for dynamic hydrologic simulations or v.surf.rst for spatial interpolation that also require a lot of time to process large datasets.
The goal of this paper is to present our shared-memory parallelization approach based on OpenMP and applied to three existing and computationally very intensive modules of GRASS GIS with different functionality. These modules perform frequent geospatial operations: spatial interpolation (v.surf.rst), solar radiation modeling (r.sun) and hydrologic simulations (r.sim.water). The parallelized modules will be applied to the test area represented by massive airborne laser scanning data to document the efficiency of the parallel implementation.
