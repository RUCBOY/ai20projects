The threat landscape of computer security is continuously changing and new threats are emerging all the time. As a result, users are likely to be familiar with certain online threats more than others. In order to anticipate how users will respond tofuture challenges, it is therefore increasingly important to understand how risk perceptions are formed (Bonneau et al, 2012, Garg, Camp, 2012, Huang et al, 2010). Various threats exist to user information, including public information sharing on social media, user surveillance, identity theft, phishing, viruses, spyware, trojans, and keyloggers (e.g., Rocha Flores et al., 2014). Examples of a very familiar occurrence are cookies whichfeature on many sites. These are text files that are designed to track user activity (BBC, 2011). Cookies may also be set by the browser or third-parties not associated with the browser (for more details see Opentracker, 2014). Due to press coverage regarding corporate privacy disasters (see Clarke, 2014), many users are exposed to information about these threats. However, some threats may be more recent and less known – which may also affect familiarity and thus potentially the extent to which security measures are taken by individuals. These include sophisticated spear phishing (targeted emails that include personal user details to convince users to provide specific information), keyloggers and rogueware. In addition to more traditional online security threats, a number of additional threats need to be considered. These include threats such as cat-fishing, cyber-bullying, social engineering and virtual stalking.
A number of researchers have studied the role of attitudes toward the Internet, and information hiding versus information sharing (e.g., Acquisti and Grossklags, 2004). Similarly, precautionary user behavior such as use of computer security features also requires a certain awareness and familiarity of the threats a user faces (see Dinev et al, 2009, Kruger et al, 2010). We differentiate awareness from familiarity as being aware of something may not necessarily indicate more than a fleeting degree of knowledge that a threat of a certain kind exists. Awareness alone may also be subject to repeated exposure, and thus subject to habituation which leads to less and less attention given to warning (Brinton Anderson et al., 2016). However, this does not guarantee that the user becomes knowledgeable or familiar with what the threat entails – they only recognize it. For example, individuals may be aware of email as a communication medium but not realize that it operates as a storage medium – and that even deleted emails may still continue to be accessible via their devices or cloud servers (e.g., Clark et al., 2015). So awareness of one function does not imply that the user really understands all functions – or threats. Threat awareness suggests individuals show realization, perception of knowledge of a threat – but this knowledge is not driven by experience and may not be very in depth. Attitudes and behaviors may be shaped by what users think they know, rather than their actual knowledge. As a result, awareness may be a precursor to familiarity. In contrast, familiarity is linked to knowledge in more concrete ways in that knowledge is knowing something through experience or association implying an understanding of a threat.
Unfortunately, many individuals are not cognizant of how much personally relevant information they share online (Kurkovsky and Syta, 2010), in line with a low familiarity with the threats that may arise. For example, threats may be dismissed if they appear to be unlikely to occur (no immediacy), the user discounts the possibility of being affected, or they feel competent and confident to tackle potential risks and handle the consequences themselves. These aspects have certainly been observed in relation to password management (e.g., Tam et al., 2010). Security countermeasures such as security policies, security education and awareness, and computer monitoring have also been proposed to affect perceived certainty and severity of sanctions and subsequent misuse of information systems (D'Arcy et al., 2009). This suggests that attitudes and user awareness of consequences play a significant role in determining how risks are perceived and responded to.
1.1. A theoretical perspective to understanding threat familiarity: connecting the human and technical elementsThe difficulties associated with encouraging awareness to progress to actual knowledge and understanding of threats may be best explained using a framework as an explanatory metaphor. It is here that Actor-network theory (ANT; Latour, 1987) may help explain the reactions to, barriers and challenges that arise when we try to understand the many interrelated variables that determine security-related engagement and behavior (e.g., past experience, affordance of technology, and user attributes). A few comments are warranted to define the meaning and relevance of actor-network theory. First, ANT as proposed by Latour (1999, pg. 20) is a “very crude method to learn from actors without imposing on them on a priori definition of their work-building capacities.” Second, it is important to avoid misunderstandings about the meaning of actors and networks as Latour conceptualizes these as interlinked, rather than opposites (hence the hyphen). The actor-network element of Latour's theory does not refer to a dichotomy that differentiates between agency and structure. While the actor does not represent a reflection of human agency, nor does the network element reflect society as such. Both are continuously transformed and redefined through the interdependent activities (Hassard and Alcadipani, 2010). Latour (1999, pg. 17) clarifies and states that network element captures all “interactions through various kinds of devices, inscriptions, forms and formulae, into a very local, very practical, very tine locus”. Indeed, actors and networks are “two faces” of the same phenomenon (Latour, 1999). In other words, actor-network theory acknowledges and highlights the connections between both macro and micro level influencers of social processes (such as societal norms and culture vs. local and personal norms).We propose that ANT is a useful approach to understand how threat familiarity relates to online behaviors (e.g., those that shape Internet experience and online engagement) and the adoption of security behaviors. First, ANT clearly rejects the separation of the human, non-human, technical elements and the social elements (Hassard and Alcadipani, 2010) that drive user behavior in various domains. When we focus on the user alone (e.g., his or her attitudinal indicators), the technical (e.g., automatic processes rather than those that have to be started by the user) or the social influencers (e.g., social norms norms), we may only explain some of the variance in behavioral patterns; however, the interaction of these variables may be particularly informative. ANT therefore considers a combination of variables, in a similar fashion (but not exactly the same) as (many) other “models”, such as ISO 9241 and the Person-Artifact-Task (PAT) model (see Finneran and Zhang, 2003). Security behavior is essentially the outcome of a combination of all these elements as well. For example, personal characteristics and propensity for risk may shape users' willingness to take risks when online. Technical features may protect a user to different degrees from threats, while social pressures and norms may also influence which activities the user pursues and which precautionary behaviors they adopt.Second, as ANT suggests, entities and understanding emerge and gain meaning as the result of their interaction and relations with each other. Arnaboldi and Spiller (2011, pg. 645) note the following, in reference to Latour (2005) and Law (1992): “The increasing popularity of ANT arises from a pivotal, though controversial, feature: the symmetrical treatment of human and non-human actors, and of social and technical elements.” This might indeed be particularly relevant to cybersecurity behaviors. The creation of threats and the effect of certain cybersecurity threats rely on the interactions of numerous technical and human aspects. For example, in the absence of precautionary tools and the users' unwillingness to engage with threats, negative outcomes due to email harvesting or identity theft are also much more likely. This outcome may not be repeated if the precautionary behavior is prompted or prevention tools are automatically triggered, reducing the reliance on the user. However, such settings also reduce their control over their devices, which is why such mechanisms are not always readily adopted by the user. Familiarity with threats, either by direct exposure or experience, is likely to emerge as the result of an interplay between the users' technical experience (e.g., Internet use), their personal characteristics (such as Internet attitudes), and their behavior to date, especially when this is reinforced by social or technical means (such as the adoption of pre-cautionary behavior, which may be achieved through nudges or social norms).Finally, ANT considers the importance of translation in terms of how various, potentially contradictory interests are captured (Hassard and Alcadipani, 2010, pg. 10). This process further recognizes the role of stakeholders, the need for information sharing and evolution in terms of the roles that actors inherit (see also Arnaboldi and Spiller, 2011). Users are often, by default and unintentionally, designated as recipients of data security training – but not necessarily viewed as active participants. This set-up may ensure that training aims at raising threat awareness, but not necessarily foster actual familiarity with threats by involving users directly.Nevertheless, ANT as an explanatory method to understand cybersecurity is still limited. For example, many will argue that the assumption of symmetry between human and non-technical elements is misplaced – and that in the context of cybersecurity, it may not be feasible to aim for such symmetry due to the challenges associated with keeping up one's knowledge of emerging and existing threats.
1.2. Rationale and research questionsA particularly relevant target group for interventions are university students as many are soon entering the workforce – and with that their lack of knowledge or awareness of online threats may represent an important knowledge gap that needs to be addressed in company inductions and training schemes. Learning what students know about threats is the first step to understand why and when they adopt computer security behaviors. In line with current knowledge and knowledge gaps, the present paper poses three questions.The questions are as follows: how familiar are students with the various online threats and is this similar for UK and US samples (RQ1)? Dinev et al. (2009) noted that awareness of the threats posed by spyware predicted favorable attitudes toward protective information technology, but that this relationship was more pronounced for the US than the South Korean sample in their research. This suggests that familiarity and thus awareness of threats may vary across countries. However, in this study we focus on similar cultures to assess the robustness of findings in the UK and a comparative sample from the USA. We propose that the two samples are unlikely to vary significantly in terms of their familiarity with threats. By extension of these findings, we ask if we can identify groups that are more or less familiar with certain new vs. well-known (established) threats (RQ2). We are particularly interested to learn how familiarity clusters relate to Internet attitudes and computer security (e.g., differences between the two subsamples or group clusters).Third and finally, we consider a mediation hypothesis (see Fig. 1). That is, to what extent is past Internet experience and familiarity with threats overall related to security measures being implemented by individuals (RQ3)? Previous research on risk and technology has found evidence in favor of the “familiarity hypothesis” (Lee, Ho, 2015, Satterfield et al, 2009, Wogalter et al, 1991). Accordingly, the perception that the benefits associated with a particular technology outweigh its risks is positively related to people's extent of familiarity with the technology. This means prior experience, if linked to familiarity, may also have implications for the security measures that are being implemented by individuals – in support of a mediation model.Download : Download high-res image (35KB)Download : Download full-size imageFig. 1. Proposed mediation model.
