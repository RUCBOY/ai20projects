Due to presence of the atmosphere, outdoor images may degrade seriously when captured under severe weather. Haze is one of the major factors to reduce the image quality in outdoor imaging, which can make images suffer from the low contrast and loss of color fidelity, and increases the possibility of algorithm failure in subsequent image processing and computer vision tasks. Therefore, there is a critical need for robust image dehazing in practice.
Early dehazing approaches require additional information rather than the input image alone, such as image depth information [1], 3D geographical models [2], images of the same scene at different polarizations [3], [4], as well as images of different weather conditions [5]. Comparing to the single-image dehazing, these algorithms perform effectively when there exists accurate auxiliary information. In practice, however, it may be very difficult, costly, or even impossible to obtain such ancillary data. As a result, the actual application for multiple-image dehazing is quite limited.
Despite being an ill-posed problem, single-image dehazing has different types of prior approaches. Priori based methods tend to learn the statistical law of haze-free images. Tan et al. [6] maximize the contrast of an input image directly, which often results in halo effect and over enhancement of contrast. Kim et al. [7] maximize image contrast by a cost function contains the contrast term and the information loss term. However, some over enhancement appears in their results. He et al. [8] propose a dark channel prior for haze-free images, and the dehazing effect of this algorithm is impressive. But its performance on the sky region and white objects is unsatisfactory, and the time complexity of soft matting is very high. Zhu et al. [9] propose a simple but powerful color attenuation prior for haze removal, which works well for most images, but the enhancement for heavy haze regions is not sufficient. Li et al. [10] present a simple but effective change of detail prior to remove haze from a single image. But this method is only stable to local image regions containing objects at different depths.
As the best algorithm at that time, many algorithms improve [8] in some particular aspects [11], [12], [13], [16], [17], [18], [19], [20]. Chen et al. [14] divide the image into foreground and background based on fisher's linear discriminant, to process images with a dramatic depth change. Xie et al. [15] use multi-scale retinex to accelerate the acquisition of transmission maps. Huang, S.C. and Chen, B.H. [21], [22], [23], [24], [25] combine improved DCP method [8] with white balance and local contrast enhances into a unified solution, which achieves good results on sandstorm weather. Liyu et al. [26] propose a nighttime dehazing model, with the help of varying atmospheric light map and guided image filter [27], this article produces nice dehazing effect on night haze images. But noise is still amplified in sky areas and over saturation occurs around color light source.
There have been a number of novel methods developed recently. Park et al. [28] introduce a ‘weighted least square’ based edge-preserving filter to refine the transmission map. Ancuti et al. [29] and Wang et al. [30] propose similar methods based on multiscale and multidepth image fusion. This is a relatively new subject in the field of single image dehazing, but the experimental results indicate that the dehazed images are significantly over-saturated. Kratz et al. [31] factorize the image by a canonical expectation maximization algorithm. However, this algorithm sometimes causes excessive color saturation, or even loses image details. Gao et al. [32] estimate the correction factor of negative images to rectify the corresponding haze images. This algorithm yields good results especially for sky areas but the computational complexity is unsatisfactory. Meng et al. [33] propose a dehazing algorithm based on a boundary constraint and contextual regularization, which can generate satisfactory results, especially in the edge regions, but some over enhancement appears in sky and road regions. Li et al. [34] introduce a novel edge-preserving decomposition based method to estimate the transmission map, and weighted guided image filter [35] is adopted to refine this map. The algorithm performs well in most cases, but the haze in heavy regions is not well removed and the color of some results is severely shifted.
The dehazing algorithms based on a learning framework have recently become popular. Tang et al. [36] propose a learning framework for image dehazing. Their results show that the algorithm performs well. However, their approach needs to calculate multiple-scale features for each pixel and customize training data for different dehazing problems. Cai et al. [37] and Ren et al. [38] use the Convolutional Neural Network (CNN) and Multi-Scale CNN, respectively. They have both achieved the highest accuracy on their own test sets, including mostly synthetic indoor images. While testing on real-world outdoor images in our database, the above three kinds of learning-based algorithms performs unsatisfactory in heavy haze regions. Also, their sample collection process is very difficult and lack of theoretical basis.
In summary, current algorithms have three main problems: (1) Because the estimation of the transmission map is not sufficiently accurate, their results suffer from either over-enhancement ([6–8]) or under-enhancement ([9,34,38]). (2) The inhomogeneous atmospheric light is not taken into consideration, which lead to underexpose in shadow regions or color-shift ([34,37]). (3) For learning-based algorithms, samples are not easy to collect, and the computational complexity is difficult to reduce.
To solve these problems, we propose a new dehazing algorithm based on a learning framework. Our algorithm can be divided into two parts: training and dehazing. In the training part, we randomly generate a large number of high-quality image patches with diverse textures and colors, which can significantly improve the accuracy of the regression model with a smaller inter-class variance. Seven quality based haze-relevant features are extracted and analyzed, including various contrast, histogram equalization, color saturation and so on. Regression model is finally learned by support vector regression (SVR). In the process of dehazing, we also propose a novel algorithm to estimate the dynamic atmospheric light map based on the maximum filter and median filter. The input haze image is divided into square blocks, where each patch uses the same feature value. This block-based feature extraction significantly reduces the input dimensions, and the algorithm efficiency. A guided filter [27] is used to optimize the transmission map. The experimental results demonstrate that our method has a lower computational complexity, more satisfying dehazing effect without over/under enhancement in any region. The flow chart of the proposed algorithm is shown in Fig. 1Download : Download high-res image (344KB)Download : Download full-size imageFig. 1. The algorithm flow chart.
The rest of this paper is organized as follows. Our method is introduced in Section 2, including atmospheric light estimation and regression model training. In Section 3, we present the experimental results and use two approaches to demonstrate the performance: objective quality assessments and subjective analysis. Conclusion is finally provided in Section 4.
