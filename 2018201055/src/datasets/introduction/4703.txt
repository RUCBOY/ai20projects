Optical flow estimation has been widely applied to computer vision applications, e.g. segmentation, image deblurring and stabilisation, etc. In many cases, optical flow is often estimated on the videos captured by a shaking camera. Those footages may contain a significant amount of camera blur that bring additional difficulties into the traditional variational optical flow framework. It is because such blur scenes often lead to a fact that a pixel may match multiple pixels between image pair. It further violates the basic assumption – intensity constancy – of the optical flow framework.
In this paper, we investigate the issue of how to precisely estimate optical flow from a blurry video footage. We observe that the blur kernel between neighbouring frames may be near linear, which can be parameterised using linear elements of the camera motion. In this case, the camera trajectory can be informatic to enhance the image deblurring within a variational optical flow framework. Based on this observation, our major contribution in this paper is to utilise an RGB-Motion Imaging System – an RGB sensor combined with a 3D pose&position tracker – in order to propose: (A) an iterative enhancement process for camera shake blur estimation which encompasses the tracked camera motion (Section 3) and a Directional High-pass Filter (4 Blind deconvolution, 7.2 Directional high-pass filtering); (B) a Blur-Robust Optical Flow Energy formulation (Section 6); and (C) a hybrid coarse-to-fine framework (Section 7) for computing optical flow in blur scenes by interleaving an iterative blind deconvolution process and a warping based minimisation scheme. In the evaluation section, we compare our method to three existing state-of-the-art optical flow approaches on our proposed ground truth sequences and also illustrate the practical benefit of our algorithm given realworld cases.
