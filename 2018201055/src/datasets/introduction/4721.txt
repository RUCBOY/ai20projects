Human action recognition is a very fertile research theme due to its strong applicability in several real world domains, such as human-computer interfaces, content-based video indexing, video surveillance, and robotics, among others [1], [2], [3]. The main challenges in traditional action recognition systems are occlusions, shadows and background extraction. Recently, the introduction of RGB-D cameras, like Kinect, lightens these difficulties that reduce the action recognition performance in RGB video [4]. The depth maps are different from the conventional RGB images. Pixels in the depth map record the depth of a scene rather than a measure of the intensity of color. Working in low light levels and being color and texture invariant, the depth cameras offer several advantages over traditional RGB cameras.
In this context, an increasing attention be directed to the task of recognizing human actions using depth sequences [5]. Several hand-designed RGB-D action recognition approaches are proposed in the last few years. These methods can be categorized as: skeleton-based measures [6], [7], [8], [9], [4], [5] and depth-based measures [9], [10], [11], [12], [13], [14]. Hand-designed approaches reported good performance on different action datasets. In recent years, machine learning gains the great success in speech recognition and object recognition. The machine learning approaches [15], [16], [17] are also proved to be efficient in action recognition.
Despite a lot of progresses, human action recognition remains a longstanding challenge in computer vision. There are several limitations. (1) With the existence of cluttered background, camera motion and occlusions, it is difficult to fully capture spatial-temporal structures of actions from video. Admitting that spatio-temporal interest point based methods [18], [19], [20] collect spatial-temporal information of actions, but their performance primarily depends on correctly detecting a large number of interest points. Machine learning methods also collect spatial-temporal information. Nevertheless, the disadvantages are time consumption and parameter tuning. (2) There are much of redundant data in action video. If all data of video are involved, the redundant information will probably reduce the precision of recognition algorithm; if specific parts are involved only, some representative information may be discarded. Therefore, it is necessary to design a method to retain only the information strictly needed for classification.
To address these challenges, a novel action recognition method that combines the coarse DS feature and sparse coding is introduced. Firstly, to accurately capture the spatial-temporal information, coarse DS feature is proposed to collect the gradient and spatial information from the RGB-D video. Secondly, It is superior to remove unreliable parts of feature by leveraging the advantages of sparse representation [21]. Therefore, sparse coding is applied on the coarse DS feature. This optimization procedure can effectively suppress redundant information and highlight discriminative parts. Fig. 1 summarizes the proposed approach.Download : Download high-res image (592KB)Download : Download full-size imageFig. 1. Overview of the approach. The illustrated pipeline is composed of two main stages: (1) Extraction of coarse depth-skeleton feature. (2) Optimization procedure using sparse coding.
Our contributions can be summarized as follows.
(1) We present an algorithm to extract coarse DS feature which deals with dynamics in depth videos.
(2) The optimization procedure, sparse coding, is applied on the coarse DS feature to produce a compact and robust representation of action video.
(3) The proposed method produces the relatively low-dimensional feature set compared to other techniques on the same public datasets.
The rest of the paper is organized as follows: Section 2 describes the related work, Section 3 shows the proposed approach in detail. In Section 4, we analyze experimental results. The conclusion is presented in Section 5.
