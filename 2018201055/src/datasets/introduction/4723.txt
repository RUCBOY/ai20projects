A fundamental problem in computer vision is the detection, description, and matching of feature points [1], which forms the basis of many applications such as image registration, object recognition, image retrieval, 3D reconstruction, and object tracking. The detection of feature points deals with the extraction of corners, junctions, line intersections, blob like structures, etc from images [2]. Whereas the feature point description is the assignment of distinct descriptor vectors to feature points so that feature point correspondences can be established reliably between the images by matching the feature point descriptor vectors [3].
Gray scale and RGB images are extensively used in wide range of computer vision applications [4]. Therefore, existing feature point detector and descriptor algorithms are designed for these image formats. These algorithms aim to extract feature points in such a manner that common types of transformations and deformations (such as rotation, scale, affine, projective, and illumination changes) can be overcome efficiently [5].
Recently, multispectral and multisensor images have received a lot of attention [6], [7]. Such images provide more distinct visual information and higher spectral resolution than typical gray scale and RGB images. Cross spectral stereo matching [8], cross spectral image registration [9], cross spectral face recognition [10], and remote sensing [11] are a few applications, where multisensor and multispectral images are used. Feature points are used in these applications to fuse, register, or match different spectral band images.
The demand for robust feature points to deal with non linear intensity changes between spectral band images, has resulted in numerous studies, where existing feature points are either modified [9], [11], [12] or new feature points are proposed [8]. Despite this, the suitability of feature points is still a problem. Because such feature points are not suitable for each and every application that involves multisensor and multispectral images. A comprehensive comparison of feature points is required. In this regard, this paper presents a comparison to identify robust feature points for multisensor images. Our comparison is different from other studies, which either focus on common types of image transformations and deformations [2], [3], [5], [13] or provide limited experimental results on multisensor images [8], [12], [14].
The rest of this paper is organized as follows: Section 2 gives an overview of classical and state of the art feature points. Section 3 presents evaluation criteria and introduces four different image datasets. Section 4, presents a comparison of feature point detectors and descriptors. Finally, the paper is concluded in Section 5.
