Brain–computer interfaces (BCI) based on electroencephalogram (EEG) have received a huge interest as a direct communication pathway between a human brain and an external device [1], [2], [3]. The non-invasive recording procedure is safe and easy to apply, and it is potentially applicable to almost all people including those seriously amputated and paralyzed patients [4], [5], [6].
Motor imagery (MI) has been widely applied in non-invasive BCI as a communication approach [7]. When human imagines or executes the movement of unilateral limb, the power of mu and beta rhythms will decrease or increase in the sensorimotor area of the contralateral hemisphere and the ipsilateral hemisphere, respectively [8], [9]. The former case is called event-related desynchronization (ERD), and the latter is event-related synchronization (ERS) [10]. The ERD/ERS patterns can be utilized as important features in the discrimination between right hand and left hand movement, or hand and foot movement.
Pattern recognition techniques are used for the classification and the detection of MI. In the conventional classification methods, firstly the hand-designed input features are extracted, and then the machine learning algorithms are used to build a mapping between EEG features and MI [11], [12]. However, the separation of two modules (feature extraction and classification) may result in the information loss during the feature extraction process [13]. Besides, the low signal-noise ratio of EEG signal can affect classification accuracy. Therefore, in some previous studies using conventional methods, the MI classification accuracies were lower than 80% [14], [15].
Convolutional neural networks (CNN) are biologically-inspired variants of multilayer perceptron (MLP) designed to use minimal amounts of preprocessing [16]. They have wide applications in image and video recognition [17], and natural language processing [18]. Based on the receptive field and weight sharing, the complexity of the network structure is reduced, i.e., the number of weights is reduced. Due to directly face to the raw signal, it helps to extract the most discriminant features (high-level features) for classification. Some researchers have used CNN for feature extraction and classification of event-related potential (ERP). Hubert et al. [19] proposed a CNN-based method to detect P300 wave, and the results showed a highest classification accuracy of 95% on a data set of the BCI competition. The previous study indicated that CNN seems to be a good approach for EEG signals classification. However, ERP belongs to evoked potential, while MI belongs to spontaneous EEG, which leads to different performances and modes. For now, few studies focused on the MI classification using CNN.
In this paper, we propose a new method based on the deep convolutional neural network (CNN) to perform feature extraction and classification for MI EEG signal. Firstly, based on the spatio-temporal characteristics of EEG, a 5-layer CNN model is built to classify MI tasks (left hand and right hand movement); then the CNN model is applied in the experimental data set collected from two subjects, and compared with other three conventional classification methods (power + SVM, CSP + SVM and AR + SVM).
The remaining of this paper is organized as follows. The materials and methods are described in Section 2. Then the experimental results and discussion are presented in Section 3. Finally, the conclusion is summarized in Section 4.
