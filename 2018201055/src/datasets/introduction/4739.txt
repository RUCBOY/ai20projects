The widespread adoption of electronic health records (EHRs) in the U.S. and around the globe has led to the rapid growth of large repositories of unstructured, free-text clinical documents [1], resulting in a ‘patient information explosion’ [2]. Fortunately, extracting information locked in these documents can be aided with technologies such as medical information retrieval systems—or ‘Google-like’ search engines—although few advanced search engines have thus far been developed specifically for patient records [3], [4], [5], [6], [7], [8], [9].
Retrieving information from such clinical documents is a difficult task due in part to the fact that clinicians may record the same medical concept in a variety of interchangeable forms (e.g., “Tylenol” vs. “acetaminophen”), in addition to the popular use of acronyms and abbreviations [10], [11]. Further, healthcare professionals often lack proper training and skills to formulate effective (i.e., pertinent and inclusive) search queries [12], [13], [14]. For example, when searching for “breast cancer,” few healthcare professionals would be able to compile a reasonably inclusive list of related search terms such as “breast ca,” “BCA,” “breast tumor,” and “breast carcinoma.” All of these are legitimate variations for describing this concept in patient records.
Computer-based query recommendation, also known as automatic query expansion [15], [16], [17], has proven to be an effective solution to assisting non-expert users in achieving better queries to improve both quality and efficiency of information retrieval tasks. Indeed, query recommendation has been commonly used by general-purpose web search engines to enhance search performance. For example, when a user enters “MI pain,” popular search engines (e.g., Google, Bing) are intelligent enough to expand the acronym “MI” to include terms such as “myocardial infarction,” or “Michigan” depending on the context, to help users retrieve the most desirable web pages. Similarly, the term “pain” could be expanded to a number of other related concepts such as “tenderness” and “discomfort”. In healthcare, research has also shown that query recommendation is effective in enhancing search experience not only for consumers (i.e., patients, families, and the general public) [18], [19], [20], but also for professionals such as clinicians and health science researchers [21], [22], [23]. However, to date, studies conducted in professional settings have mainly focused on information retrieval from biomedical literature databases such as PubMed, rather than patient records.
In 2005, the University of Michigan Health System (UMHS) implemented a homegrown EHR search engine available for authorized users, known as EMERSE (http://project-emerse.org) [5]. With a user base of more than 1600, the system has played an instrumental role in supporting a variety of information retrieval tasks in areas such as clinical care, quality assurance, billing, and clinical and translational research [5], [24]. Through several user behavior studies, we recognized that the utility of the system might have been severely limited due to users’ inability to construct effective search queries [25], [26]. As query recommendation has been shown to be advantageous in other settings, in this study we sought to develop this feature for EMERSE and conduct a user experiment to empirically evaluate its potential benefits in the context of retrieving information from EHRs. The U.S. National Library of Medicine (NLM)’s Computational Thinking program supported this work.
