Wireless sensor networks (WSNs) typically are designed to detect and identify neighboring objects in wild [1], [2], [3], [4] with sound or vibration sensors in the form of single [5] or microarrays [6]. The sound or vibration sensor has many advantages [7], [8], [5], such as low cost, low energy consumption, and relatively low in algorithm complexity. However, they are unsuitable for mixed objects detection because their spatial resolutions are usually too low to distinguish each person in a group of pedestrians. To overcome this shortage, we have employed cameras in our WSNs which has been proved to be effective for dense targets identification [9]. Unfortunately, images captured by WSNs are noisy, such as low in illumination, resolution and photographing angle, which are different from most publicly available datasets. Because the severe limitation in data and resources, despite the rapid development in deep learning [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], WSN-applicable deep-learning-based image classification algorithms evolve slowly. So, cost-effective dataset construction methods are needed urgently to build datasets that corresponding to specific WSN applications. Several random images of the target application (target domain) that was captured during our field experiments have been shown in Fig. 1, where targets like persons and cars are hard to identify.Download : Download high-res image (127KB)Download : Download full-size imageFig. 1. Image samples of mixed objects under different illumination. The first row shows low-lighting grey images.
Because of limited communication bandwidth, WSNs cannot run deep neural networks (DNNs) in a remote cloud (or fog) which is a common strategy for embedded devices [21], [22], [23], [24], [25]. To run DNNs in such devices locally [26], [27], a training strategy is wanted to cut computation costs without decreasing identification accuracy significantly. Fortunately, Han et al. [28], [29] have pointed out that only parts of weight parameters in neural networks are playing essential roles during predictions. Therefore, it is possible to train an efficient DNN for WSNs with fewer parameters if we can fully utilize key weight parameters.
Because fewer parameters mean higher utilization of key parameters and usually lead to less computational costs, we investigated model compression approaches that can be separated into four categories [30]: 1) Parameter Pruning and Sharing [31], 2) Low-Rank Factorization [32], 3) Transferred Convolutional Filters [33], 4) Knowledge Distillation (KD) [34], [35]. The compression rates of first three approaches are limited. Some of them focus on reducing storage requirements that do not help in reducing the number of multiplications. The fourth method can train a network with much less parameters which can be further compressed by other three methods if necessary.
Knowledge Distillation (KD) was first proposed by Bucilu et al. [35], which is able to train fast, compact network to mimic better performing but slow and complex network. Usually, the compact network is trained to mimic the high-level features of the complex network. Because first, high level features are highly abstracted that should not be changed during model compression; otherwise, small differences between the features of the compact network and the complex network can lead to big differences in image classification. Second, high level features of image-classification networks are usually low in dimension; with a low dimensional output, one can build slim and compact networks easily. The model compression rate can be very big since the compact network has different structure from the complex network. For example, FitNets [36] trained a network whose parameter number is one-36th of a complex state-of-the-art network.
Data plays an increasingly important role in neural network training. Sun et al. [37] found that model performance on vision tasks increases logarithmically with training data size. However, building a clean, impartial, diverse dataset is a tremendous challenge. In recent years, studies have been done to apply weakly labeled techniques to construct datasets. Xu et al. [38] referenced weakly labeled technology to create a clean face dataset, which based on the continuity structure of face images of same identity. With the newly constructed face dataset, face recognition accuracy was improved massively. Han et al. [39] proposed a method which based on generative adversarial networks to produce images that are high in quality. The main drawback of traditional methods is that images used to construct the new datasets still require a lot of manpower to label. But in this paper, loosely and weakly labeled images are used to construct new datasets which are downloaded from internet and do not require additional manpower to label.
In this paper, we propose Cost Effective Domain Generalization (CEDG) algorithm that yields low computational complexity deep neural networks with minimum requirements on datasets. The network has parameters less than 164 K for feature extraction and requires about 7 million multiplications per prediction (ResNet-201 requires 41 million.). The trained network has reached 87.20% test accuracy on a common domain (CIFAR-10 [40]), and 87.07% category-level averaged global generalization accuracy on an unseen target domain. The problem is hard because the target domain: 1) is poor in picture quality; 2) has different image categories from the common domain; 3) cannot be used as train set for the limited image samples.
Our main contribution is that we proposed Cost-Effective Domain Generalization (CEDG) method to solve the challenges of images classification in WSNs (e.g. limited data and computation resources). Detailed contributions are as follows.
1)We have concluded an efficient procedure to train a small-scale but deep network. Comparing to ResNet-20, the network is 40% smaller (164 K parameters vs. 273 K), 83% faster (7 M multiplications vs. 41 M) and 142% deeper (46 convolutional layers vs. 19).2)We have developed a labor-saving method to build a specific synthetic domain quickly from loosely and weakly labeled images. By loosely, we mean labels of images are not 100% correct. By weakly, we mean the exact locations of the interested targets in the images are unknown.3)We have specially designed data augmentation methods that can transfer the synthetic domain to the target domain so as the classifier can generalize well on the target domain.
This paper is organized as follows. The theory of CEDG algorithm has been analyzed in Section 2. In Section 3, implementations of CEDG have been presented and the experiment results have been shown in Section 4 followed by the conclusions in Section 5.
