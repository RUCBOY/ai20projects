Computational botany consists of applying innovative computational methods to help progress on an age-old problem, i.e. the identification of the estimated 400,000 species of plants on Earth [1]. This interdisciplinary approach combines botanical data and species concepts with computational solutions for classification of plants or parts thereof and focuses on the design of novel recognition methods. These are modelled using botanical data, but are extendable to other large repositories and application domains. Plant species identification is a subject of great importance in many fields of human endeavour, including such areas as agronomy, conservation, environmental impact, natural product and drug discovery and other applied areas [2], [3].
Advances in science and technology now make it possible for computer vision approaches to assist botanists in plant identification tasks. A number of approaches have been proposed in the literature for automatic analysis of botanical organs, such as leaves and flowers [4], [5], [6]. In botany, leaves are almost always used to supply important diagnostic characters for plant classification and in some groups exclusively so. Since the early days of botanical science, plant identification has been carried out with traditional text-based taxonomic keys that use leaf characters, among others. For this reason, researchers in computer vision have used leaves as a comparative tool to classify plants [7], [8], [9], [10]. Characters such as shape [11], [12], [13], texture [14], [15], [16] and venation [17], [18] are the features most generally used to distinguish the leaves of different species. The history of plant identification methods, however shows that existing plant identification solutions are highly dependent on the ability of experts to encode domain knowledge. For many morphological features pre-defined by botanists, researchers use hand-engineering approaches for their characterization. They look for procedures or algorithms that can get the most out of the data for predictive modeling. Then, based on their performance, they justify the subset of features that are most important to describe leaf data. However, these features are liable to change with different leaf data or feature extraction techniques. This observation therefore raises a few questions: (1) In general, what is the best subset of features to represent leaf samples for species identification? (2) Can we quantify the features needed to represent leaf data? We want to answer these questions in order to solve the ambiguity surrounding the subset of features that best represent leaf data.
In the present study, we propose the use of deep learning (DL) for reverse engineering of leaf features. We first employ one of the DL techniques – Convolutional Neural Networks (CNN) to learn a robust representation for images of leaves. Then, we go deeper into exploring, analyzing, and understanding the most important subset of features through feature visualization techniques. We show that our findings convey an important message about the extent and variety of the features that are particularly useful and important in modeling leaf data.
In this paper, we present several major contributions:

1.We define a way to quantify the features necessary to represent leaf data (Section 4). We first train a CNN based on raw leaf data, then use a Deconvolutional Network (DN) approach to find out how the CNN characterizes the leaf data.2.We experimentally show that shape is not a dominant feature for leaf representation but rather the different orders of venation (Section 4.3).3.We quantify the characteristics of features in each CNN layer and find that the network exhibits layer-by-layer transition from general to specific types of leaf feature. We find that this effect emulates the botanists’ character definitions used for plant species classification (Section 5).4.We show that CNNs trained on whole leaves and leaf patches exhibit different contextual information of leaf features. We categorise them into global features that describe the whole leaf structure and local features that focus on venation (Sections 4.3 and 5).5.We propose new hybrid global-local feature extraction models for leaf data, which integrate information from two CNNs trained using different data formats extracted from the same species (Section 6).6.We demonstrate that our proposed hybrid global-local feature extraction models can further boost the discriminative power of plant classification systems (Section 6.2.1).
Our paper begins with an introduction to deep learning. Next, we proceed to a critical and comprehensive review of existing methods and a description of the context of plant identification - i.e. how species are delimited by botanists using morphology. Then, we introduce the idea of deep learning for automatic processing and classification in order to learn and discover useful features for leaf data. We describe how computational methods can be adapted and learnt using visual attention. The universal occurrence of variability in natural object kinds, including species, will be described, showing first how it can confound the classification task, but also how it can be exploited to provide better solutions by using deep learning.
