With the ever-growing amount of data, knowledge bases (KB) such as Freebase (Bollacker et al., 2008) and WikiData1 become larger and larger. The facts in the real world are often represented as triplets (subject entity, predicate, object entity) in knowledge bases, where the subject entity and the object entity refer to two real-world entities and predicate refers to the relation between subject entity and object entity. Such a large volume of data and complex structures make it extremely hard for users to access the information efficiently. To address this issue, Question Answering over Knowledge Bases (KBQA)  (Bordes, Usunier, Chopra, Weston, Yih, Chang, He, Gao, 2015, Bast, Haussmann, 2015, Shin, Jin, Jung, Lee, 2019, Lukovnikov, Fischer, Lehmann, Auer, 2017, Dai, Li, Xu, 2016, Golub, He, 2016, Hao, Wu, Wen, Cai, 2019) was proposed. KBQA systems aim to automatically translate natural language questions posed by users into structured queries, e.g. SPARQL, and return the entities in KB as the answers which attract massive attention (Lukovnikov, Fischer, Lehmann, Auer, 2017, Mohammed, Shi, Lin, 2018). However, the KBQA problem is far from solved as it involves multiple subtasks such as entity linking (Zhao, Wu, Wang, Li, 2016, Pappu, Blanco, Mehdad, Stent, Thadani, 2017) and predicate detection (Shin, Jin, Jung, Lee, 2019, Yu, Yin, Hasan, dos Santos, Xiang, Zhou, 2017). In this paper, we focus on the simple question answering problem, which consists of the majority of KBQA questions. The simple question can be answered with a single fact (subject, predicate, object) in the knowledge base, which constitutes the majority of questions asked on the web. The task can be formulated as finding the best matches of subject and predicate for the given question. For example, for the question “what is a compatible ingredient with a gluten-free diet?”, the task aims to find the subject-predicate pair (m.034n2g_[Gluten-free Diet], food/dietary_restriction/compatible_ingredients) in KBs. Based on the found pair, final answer (m.057xpf_[Breckland Thyme]) can be easily retrieved in a single fact using SPARQL queries.
There are two mainstream research directions for the KBQA task. One category is multi-staged methods that tend to break down the KBQA task into subtasks (Dai, Li, Xu, 2016, Yin, Yu, Xiang, Zhou, Schütze, 2016, Hao, Liu, He, Liu, Zhao, 2018). For example, in AskHow (Dubey et al., 2016), a natural language question was passed through five modules including Part-of-Speech (POS) tagging, template-fitting, relation extraction, token merging, and entity mapping before translated into SPARQL query. However, such approaches suffer from error and uncertainty propagation problems. To deal with these problems, end-to-end based approaches have been developed, leaving all the decisions to the model itself (Yih, Chang, He, Gao, 2015, Lukovnikov, Fischer, Lehmann, Auer, 2017)
Despite the promising results, current approaches are unable to estimate uncertainties of their predictions, which is crucial for the model’s reliability and interpretability. As shown in Fig. 1, for the question “What is a compatible ingredient with a gluten-free diet?”, the model may be uncertain about two conflicting predicates, incompatible_ingredients and compatible_ingredients and output a wrong answer. Such wrong prediction may be fatal for gluten-sensitive users. More importantly, as black-box models, neural network-based KBQA systems can provide nothing but the answers, which are not interpretable. This uninterpretability makes even high-performance KBQA systems unreliable. Because people cannot judge when the system makes an error while the cause of such error, as illustrated in the example, may be unacceptable. On the other hand, if we could measure how uncertain the model is in its prediction, more reliable decisions could be made with such information. Take Fig. 1 as an example, the model is quite uncertain about the answer Barley, so people could refer to another information source and take the decision. Therefore, instead of solely predicting the answer, it is important to measure the uncertainty in model predictions. Recent developments on Bayesian Neural Network (BNN) (Neal, 2012, Blundell, Cornebise, Kavukcuoglu, Wierstra, 2015, Gal, Ghahramani, 2016) make it feasible to quantify such uncertainties. BNNs estimate distributions over the prediction space by placing distributions over network weights. Therefore, uncertainties of the model predictions could be estimated with predictive distributions by calculating their spread.Download : Download high-res image (271KB)Download : Download full-size imageFig. 1. Example of uncertainties in KBQA model.
Moreover, current end-to-end KBQA methods often rely on semantic matching in the embedding space based on the semantic similarity between a given question and the candidate resources including entities and predicates in KBs and return the nearest neighbors as the correct resources for the given question (Yih, Chang, He, Gao, 2015, Lukovnikov, Fischer, Lehmann, Auer, 2017). In such frameworks, (question-subject) and (question-predicate) are often matched separately, ignoring the interaction between each other. For example, for the question “what is the subject of writing home”, two candidate entities corresponding to Freebase IDs: “m.02hvp4r” and “m.04v0_pk” will be extracted. they have the same entity name “writing homewhich output the same score in the matching procedure of (question-subject). However, they are attached with different predicates book.written.subjectsand book.book edition.binding. These predicates can help to distinguish the entities with the same scores.
In this paper, we propose a novel Bayesian end-to-end KBQA model to estimate two types of uncertainties, model uncertainty and data uncertainty, of the predictions, the former one measures the how well the model fits the data and the latter one measure the inherent noise in the data. The model is proposed to select entity and predicate simultaneously considering the relevance between entities and predicates existed in KBs. In specific, both the entity with its context and the candidate predicates are encoded by a Bayesian BiLSTM. The relevance of the entity and predicate pair is calculated based on their representation similarity. Experimental results show that the proposed model outperforms existing state-of-the-art end-to-end approaches. The effectiveness of the proposed uncertainty measures is further confirmed on the misclassification detection and the cause of error analysis.
The contributions of our work in this paper are listed, more succinctly, as follows:
•From a practical perspective, estimating uncertainties of model prediction is crucial for the QA system, especially in safety-related areas. Traditional KBQA methods ignore the uncertainty existed in data and models which lacks reliability and interpretability. We are interested in exploring a neural network-based model to obtain the answer and its confidence simultaneously. To this end, a novel Bayesian-based KBQA model with uncertainty estimated is proposed. To our best knowledge, we are the first one to incorporate BNN in KBQA. Experimental results on several tasks indicate the efficiency of the proposed uncertainty measures.•Multi-staged approaches for simple question answering often contain several separate components which cause error and uncertainty propagation problem. Thus we develop a novel end-to-end framework to jointly select entity and predicate, considering their interaction existed in KB in one single training procedure. Furthermore, it can be easily retrained or reused for a different domain. Experimental results on SimpleQuestions dataset show that the proposed model achieves comparable performance compared to the existing state-of-the-art approaches.
The practical significance of this work is that the proposed approach estimates the uncertainties of predictive results for the KBQA system, which is crucial for safety-related areas. Moreover, the proposed approach achieves comparable performance compared with some state-of-the-art approaches and can be easily adapted to other domain because of the end-to-end framework. The rest of the paper is organized as follows. Section 2 reviews the related literature on deep learning for KBQA and uncertainties quantification in deep learning. In Section 3, a detailed description of the proposed approach is presented. Section 4 introduces the experiment details. Finally, the paper is concluded in Section 5.
