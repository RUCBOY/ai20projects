Online users must frequently make judgments or decisions based on computer-mediated interaction. It is common for individuals to receive emails with hypertext links or a popup messages from a website, or be asked to confirm or cancel some electronic procedure. Many online users receive phishing emails1 requesting personal or sensitive information, or seeking a response (Wright & Marett, 2010). Phishing emails may also induce actions such as answering inquiries about social, financial, or business relationships, or confirming social media friend requests, resulting in online gender fraud (Brady & George, 2013). Repeatedly, online users must determine whether the source of a message is credible and legitimate (Hilligoss and Rieh, 2008, Liu, 2004, Rieh, 2002) in order to maintain privacy and safety (Lopez and Sebe, 2013, Twyman et al., 2014).
A rise in the threat of deceptive communications has accompanied the increased reliance of individuals and organizations on computer-mediated communication (CMC2) systems. In a New York Times interview, Bruce Schneier, an American cryptographer, states that trust is “the glue that binds our societies” and deceptive communications in the digital age have destroyed this trust (Sengupta, 2012, p.1). Because virtual space lacks traditional face-to-face (FtF) visual cues of deception, it has become easier for online users to misrepresent not only the content of their messages but their identities. As technology changes the way we interact socially, it becomes ever more difficult to discern whether an email from our bank is authentic, and how much we can trust authorities with our online privacy. This threat of deception has been shown to be substantial in various domains and manifests in many ways, such as phishing and “spear phishing” attacks (Wright & Marett, 2010), deception in electronic commerce (Xiao & Benbasat, 2010), deception at workplace (da Cunha, Carugati, & Leclercq-Vandelannoitte , 2015), deception in group support systems (George, Marett, & Giordano , 2008), deception in professional virtual communities (Joinson & Dietz-Uhler, 2002), deceptive opinions in online reviews (Fusilier et al., 2015, Ott et al., 2012), deception in 911 calls (Burns & Moffitt, 2014), deception in social media relationships (Hancock et al., 2007, Hancock et al., 2010, Zhou et al., 2004), deceptive opinions and reviews (Ott et al., 2012, Ott et al., 2013, Ott et al., 2011), deception in story-telling (Rubin, 2010), and fake news (Conroy, Rubin, & Chen 2015). The consequences of successful deception range from harmless inconvenience to significant costs. Such deception can pose a major threat when it drives online transaction fraud (Twyman, Lowry, Burgoon, & Nunamaker, 2014), identity theft, theft of credentials, theft of intellectual property, or threats against national security.
One salient dimension of online deception is users’ misrepresentation of their gender (Ho & Hollister, 2013). One's gender, which has been traditionally considered binary due to distinct biological differences at birth, has a tendency to be socially reconstructed (Bussey & Bandura, 1999). Bussey and Bandura (1999) suggested that gender roles are constantly being reconstructed by a broad network of peers and societal influences. Gender and gender role development are constantly mixed with experience and motivation. People's self-development can redefine their gender identity (e.g., recognition or realization of being gay), which eventually contributes to social change (e.g., legalization of gay marriage). Regardless of these social impacts, users’ online identities are continually being constructed by a number of factors, including their redefined gender roles, their motivations, self-efficacy, social interactions with friends and colleagues, as well as personal desires and goals. The binary view of gender creates fundamental representation problems. Rodino (1997), for instance, observed inconsistencies in online chatters’ language and presentation of their gender, and suggested that gender can be “performed” in an online environment. In other words, gender can be made more real and natural in virtual, imaginative communication. Gender, through linguistics, can be socially “constructed,” and online actors may falsify the representation of gender to increase the probability of gaining trust.
Gender can represent a unique feature of online deception in that it can involve fairly nuanced clues and circumstances that one may not normally consider. In asynchronous online communication, individuals may attempt to misrepresent their gender, and recipients of online messaging may lack the ability to identify the gender of their communicators. Regardless of the reasons people may attempt to deceive others about their gender, empirical results show that 18% of males and 11% of females have lied about their gender (Whitty, 2002, p. 348) at some point when engaging in text-based communication. Gender deception can be highly disturbing to both males and females who have been deceived (Stieger, Eichinger, & Honeder 2009). Previous research has found gender-related influences, in the ways males and females communicate—in both FtF and online communication (Herring, 2000, Herring and Martinson, 2004, Savicki et al., 1999, Whitty, 2002). Yet, little is understood about the role of gender deception in the complexity of computer-mediated deception. As gender misrepresentation or gender deception has become a major contributing factor in identity fraud, our research intends to explore, describe, and explain different cognitive factors that facilitate gender deception in computer-mediated communication. Our overarching research question is thus set as follows: How are the cognitive factors of gender deception modeled in asynchronous online communication?
That said, online users can adapt in ways that extenuate or diminish certain facets of their identities (including their gender) in certain social situations depending on social goals, conversational topics, context, or cultural situations (Herring, 1995, Herring, 2000). In other words, depending on the context and topic, it is possible for males to adjust their communication toward female styles, and females can employ communication style more like male utterances in order to disguise their true gender. This paper outlines our investigation to first review deception in FtF interaction as well as online communication when facilitated by computer-medicated technologies. Twelve research hypotheses—examining motivation and self-efficacy of both message senders and receivers that impact the outcome of deception—are discussed within the framework of gender deception. We then discuss our research design and considerations for an experiment deployed in the form of an online game that mimics online users’ asynchronous interactions. We address data collection and analysis to test our hypotheses. Contribution, limitations, and future research are discussed thereafter to conclude this paper.
