Cloud computing has great impact on Information Technology (IT) solutions for both scientific and business applications [1], [2]. Cloud computing environment has important features that are important for both science and business applications/purposes. Clouds also offer solutions to computationally intensive applications similar to HPC (High Performance Computing) environments such as supercomputing centers  [3]. From the business perspective, clouds offer flexible platforms to both cloud providers and application owners. Cloud computing offers a unique computing ecosystem where providers and application owners can establish elastic relationship driven by application performance requirements (e.g. availability, execution time, monetary budget, etc.) and characteristics (e.g. input data size, number of end-users connecting to that application, output data size, etc.)  [4], [5].
Current computing applications demand research on cloud environments for their efficient use of resources  [6]. Cloud providers are concerned and need to maintain their services in a relatively unreliable environment, while producing profitable revenues. Cloud application owners, on the other hand, want services/resources that meet strict performance requirements. Both require access to a cloud scheduler framework and algorithm that can automatically map applications to cloud resources while ensuring application-level performance and provider-level resource utilization goals  [7], [8].
Due to their data intensive nature, modern scientific applications can benefit if cloud schedulers include data reuse and replication techniques in executing their workflows  [9], [10], [11]. Data reuse avoids file transfers by allocating tasks to same computing units, e.g., Virtual Machines (VMs) in context of cloud computing systems such as Amazon EC2 and Microsoft Azure. For tasks requiring the same set of files, the data replication technique duplicates the files across the VMs hosting those tasks. Both techniques can influence (enhance or degrade) optimization objectives. It is up to the scheduler to decide when to apply one or both of these techniques. The scheduler also needs to decide the number of resources (e.g., VMs) it needs to provision for an application workflow. All aforementioned considerations depend on the following two main factors: the type of application and the monetary cost model of the cloud provider (e.g., Amazon EC2 pricing1).
This article presents a scheme for efficient scheduling of scientific workflows in cloud environments. Main contributions of our scheduling scheme (BaRRS) include: concurrently optimizing two important, yet conflicting, objectives in cloud environments, i.e., execution runtime and monetary cost, (2) exploring the trade-off between the aforementioned two objectives through scheduling sample configurations, and (3) computing the exact number of required resources (VMs). To achieve these objectives, BaRRS combines three scheduling mechanisms to manage a workflow plan according to its task dependencies, file sizes, task execution times, and network bandwidth, as well as the underlying VMs’ characteristics (e.g., Amazon EC2 instances2).
The article is organized as follows: Section  2 discusses the related work; Section  3 presents our system model; Section  4 presents the problem statement; Section  5 details the BaRRS; Section  6 explains experiments. Section  7 discusses the results, followed by Section  8 that concludes this work.
