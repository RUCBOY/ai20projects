In traditional machine learning (ML), the efficiency and accuracy of models rely on computational power and training data of a centralized server. Shortly speaking, in traditional ML, user data is stored on the central server and utilized for training and testing processes in order to develop comprehensive ML models ultimately. Centralized-based ML approaches, in general, are associated with different challenges including computational power and time, and most importantly security and privacy with respect to users’ data that has been neglected for a long time. Federated Learning proposed by [1] has recently emerged as a technological solution to address such issues.
Federated Learning (FL) [2] offers a way to preserve user privacy by decentralizing data from the central server to end-devices and enables AI benefits to domains with sensitive data and heterogeneity. This paradigm came to light mainly for two reasons: (1) The unavailability of sufficient data to reside centrally on the server-side (as opposed to traditional machine learning) due to direct access restrictions on such data; and (2) Data privacy protections using local data from edge devices, i.e., clients, instead of sending sensitive data to the server where network asynchronous communication comes into play. Preserving data privacy provides feasibility to leverage AI benefits enabled through machine learning models efficiently across multiple domains. Additionally, computational power is shared among the interested parties instead of relying on a centralized server by iterative local model training processes on end-devices. With its decentralized data concept, FL is one of the growing fields in the area of ML in recent years, as it comes with security and privacy features promising to abide by emerging user data protection laws [3], [4]. In addition to privacy, FL enables ML benefits to smaller domains where sufficient training data is not available to build a standalone ML model.
As phrased by authors in [1] “FL brings the code to the data, instead of the data to the code and addresses the fundamental problems of privacy, ownership, and locality of data”. Even before we can fully appreciate the fact that in FL, data stays intact on the users’ device and the traditional upload of data over the network can be gracefully skipped, we are sharing the model parameters and global ML model with each and every client, which opens numerous ways to exploit vulnerabilities in the FL environment. As FL is in the initial steps of studies, many researchers in different communities are eagerly working to improve the existing frameworks and ensure privacy and security of user data within FL.
Each time a new technology is introduced and a new ecosystem is created, a range of technical ripple effects typically come into fruition over time. In a less positive way and as good as the FL sounds, the introduction of FL has arguably required more profound research into its confirmation, particularly with respect to security and privacy aspects. Therefore, we can question what type of security and privacy issues are we facing now and can we imagine occurring in the future as a consequence of the adoption of this technology? This paper aims to provide the answer to these types of questions and shed light on possible unwanted future security and privacy states that we should be mindful of and prepare for.
Privacy-preserving promises of FL attracts different domains that may contain sensitive data. To an extent, FL does solve privacy concerns of sensitive data in ML environments however at the same time model parameter sharing and an increased number of training iterations and communications exposes the federated environment to a new set of risks and opens new avenues for hacking [5] as well as curious attackers to trace vulnerabilities to manipulate ML model output or get access to sensitive user data. To ensure that we out-turn the benefits of FL over risks and utilize the features of FL properly, we have an immediate need to be on top of this area of research to investigate all possible security and privacy attacks on FL. Without precise information and clear vision, FL may be pushed back without giving a fair chance to explore and leverage its benefits.
As seen in recent publications, the majority of work proposed in the FL space aims to apply this new framework in some shape and form to different domains. Our work touches on the issues within FL and could be used as a reference to promote future cybersecurity-related research advancing the acceptance of this framework. To this end, we address the research objectives by identifying and evaluating open security & privacy threats as well as mitigation strategies of FL by answering several specific research questions.
1.1. ContributionsWhile research already exists on this topic, sufficient progress has not been made concerning understanding FL for its security and privacy risks. This work hopes to contribute a comprehensive overview of FL security in terms of a formal definition, achievements, and challenges, which makes it stand out in comparison to previous works. In doing so, the work can contribute an overall blueprint for data scientists and cybersecurity research on designing FL-based solutions for alleviating future challenges. The outline of the contributions of this paper relative to the recent literature in the field can be summarized as follows:•Providing a classification and overview of the approaches and techniques in the realization of FL.•Identifying and examining security vulnerabilities and threats in FL environments both FL-specific and general ML-based attacks related to FL.•Identifying and evaluating privacy threats, their mitigation techniques, and the trade-off cost associated with privacy-preserving techniques in the FL environments.•Providing insights into existing defense mechanisms and future directions to enhance the security and privacy of the FL implementation.
1.2. Paper organizationThe rest of this paper is structured as follows. Section 2 gives background information about FL and its underlying working process. Section 3 classifies approaches and techniques related to the FL. Section 4 provides the research questions on the security of FL and presents the research results. Similarly, Section 5 gives the research questions on the privacy of FL and presents the research results. Section 6 gives the related work. Section 7 summarizes the future directions for security and privacy in the FL domain. Finally, Section 8 gives the concluding remarks.
