Place perception is one of the essential issues in the artificial intelligence field, which is mainly applied to image retrieval and understanding, or autonomous robot and drone. In the last few years, the related researches [1], [2], [3] mainly focused on the concept of scene recognition or place classification using approaches from the perspective of image recognition and understanding. However, most of these methods have some common drawbacks: (1) they address the place recognition as a simple image recognition problem without considering particular characteristics of place perception, (2) these works usually ignore the high-level semantic information of objects and humans in a place image, which caused an inadequate feature representation for place perception.
There are two fundamental differences between place perception and scene recognition or place classification. First of all, the concept of the place refers to a space area in which people engage in specific activities, and this space area is abstracted in people’s mind according to certain clues and can be represented by symbol labels [1]. Whereas for the concept of the scene, in some research on high-level scene perception [4], it is typically defined (often implicitly) as a semantically coherent view of a real-world environment comprising background elements and multiple foreground objects arranged in a spatially specific manner. In comparison, the conceptual scope of the scene is broader than the place. From a conceptual point of view, some places (e.g. the indoor place like a bathroom, the outdoor place like a garden or the public place like a cafeteria) can be regarded as scenes. However, not all scene (such as village, house, and river) can be classified into places. This difference is mainly because a place should be closely related to demands and actions or states of humans, but a scene is just an aggregation of some objective entities without specific functions. In another viewpoint, exploiting object entities as a clue to recognize the category of a place implicitly considers the concept of the place, that is, a place area should contain specific objects with human-related functionality, which can be regarded as prior knowledge. Several related works [5], [6], [7], [8], [9] studied from the aspect of the category distribution of objects contained in a place image. However, merely considering the object category ignores much valuable information, especially in a complicated place containing many different types of objects. For example, “a man lies in bed and works on a laptop” can roughly infer that this place might be a bedroom rather than an office, or “a stainless steel sink” might appear in the kitchen rather than in the bathroom. More broadly, the relationship between people and objects, states or actions of humans as well as the object attributes play essential roles in the prediction of the place category. However, these clues are kinds of high-level semantic information and hard to be formulated in an explicit form so that they cause difficulties for place perception.
The second difference is between the process of perception and recognition. We argue that the procedure of the place perception in the human brain follows typically three steps: (1) try to analyze the visual information and detect the critical objects in an input image, (2) use abstract symbols to describe the seen objects and organize symbols into semantic knowledge, (3) try to combine this knowledge to infer the possible place and generate some ideas. Thus, perception is not only to identify the category of a place but also to fully understand the containing information, e.g. symbol attribute, spatial attribute, and semantic attribute. More specifically, the perception process can also answer some semantic questions such as what kind of objects are present, what is happening in this place, or even what are the critical elements to the inference of the place category. These are fundamental requirements for service robots and human-computer interaction applications. However, current work merely addressed the label attribute problem of place perception without considering more semantic information required in the understanding process. Therefore, most methods regard it as a pattern recognition problem and use the classification model to solve it according to the type of information source and its features.
Considering those above two primary differences between place perception and scene classification, we intuitively believe that natural language information might become a valid clue for modeling feature representation in place perception. As a kind of symbolic representation form, natural language information is more abstract and suitable for human understanding, which can also cover more representative visual clues using non-redundant contents. Hence, linguistic information can adequately express the attributes, states, and relationships of objects in a place image. Additionally, although natural language can represent high-level semantic information, it also makes the information more ambiguous. Therefore, place perception can not solely rely on natural language and still needs visual information to assist in the understanding process.
The proposed method intends to mimic the human way of place perception by employing the technology natural language generation for obtaining more abundant and complementary semantic cues, which is to boost the perception performance of the current method. The semantic cue has been widely considered in the recent place recognition technology. For example, Cheng et al. [8] proposed a feature representation method from the perspective of object detection, called semantic descriptor with objectness (SDO), to get the distribution of shallow semantic descriptions between object and scene. Furthermore, Lopez-Cifuentes et al. [10] obtained the scene semantic representation by leveraging on semantic segmentation and then combined them with image features through a multi-modal CNN attention module. To eliminate the similarity among different scene categories, related studies change the core idea from discriminating single image information to fusing the semantic information of objects. However, these similar methods still rely on simple semantic elements and do not adequately consider the semantic attributes of objects. Therefore, to the best of our knowledge, this is the first work that using the image caption technology to convert the visual modality into its relevant linguistic modality and combines both cues for place perception.
The contribution of our work is fourfold:
(1)We propose a multi-task deep neural network to realize the indoor place understanding and recognition together, which imitates and learns the process of place perception in a human-style.(2)From the perspective of multi-modal information transformation and complementation, we propose an image captioning model to automatically generate natural language descriptions from place images, which is an additional information source to assist the decision-making in place recognition.(3)We propose a multi-modal feature extraction and fusion architecture based on a mixed-CNN-LSTM network that gathers both visual and linguistic features corresponding to instance-level and concept-level information, respectively.(4)We validate the effectiveness of the proposed strategy of using natural language descriptions to place perception through experiments on public image datasets, including Visual Genome, SUN397, MIT-67, and Places2.
This paper is organized as follows: Section 2 provides an overview of related work in indoor place perception, with a focus on place perception and image caption based on deep learning methods. In Section 3, we elaborate on the proposed approach to place perception. Section 4 describes the implementation details of our algorithm and reports the experimental results. Finally, we conclude our work in Section 5.
