Being the second deadly cancer after lung cancer, breast cancer remains the main cause of death among women aged between 20–59 years [1]. According to the American Cancer Society, there will be approximately 268,600 new cases of invasive breast cancer and around 41,760 people will die from breast cancer in 2019 [2]. However, it has been shown that detecting and diagnosing breast cancer in its primary stages can increase the survival rate up to 80% [3]. Typically, early breast cancer screening usually starts with clinical analysis using common modalities such as mammography, ultrasound or magnetic resonance imaging. Patients with high likelihood of breast malignancies will then undergo a needle tissue biopsy. Pathologists take Hematoxylin and Eosin (H&E) stained tissue samples from suspected breast areas and analyze them under a microscope for establishing a deﬁnitive diagnosis. The visual analysis in diagnostic pathology is a tiresome, error-prone, and subjective task, which makes the wrong decisions inevitable.
To relieve the workload on pathologists and improve the diagnosis efﬁciency, there has been a huge interest over the last few years on automating this process through adopting computer-aided diagnosis (CAD) systems. In traditional machine learning methods oriented CAD, speciﬁc classiﬁers are trained using a set of handcrafted features derived from histopathological images in order to predict the ﬁnal output labels [[4], [5], [6], [7], [8], [9]]. However, due to the complexity (extensive prior-domain knowledge required) and computational burden associated with extracting meaningful handcrafted features, the classiﬁcation results reported from these studies were unsatisfactory and quite far from the need. The recent advances in machine learning and image processing have culminated in the emergence of deep learning concept [10], which has recently sparked an enormous attention and interest in research community. Deep learning, especially with Convolutional Neural Networks (CNNs), can automatically learn the intrinsic features from raw data images instead of adjusting them manually. CNNs-based CAD have recently shown a groundbreaking performance in the ﬁeld of biomedical image analysis. Training a CNN from scratch, however, can also be challenging, time-consuming and requires a lot of experience and patience [11]. In addition, CNNs are data-hungry networks which means that they require a very large annotated dataset to train efﬁciently, which is often elusive in most medical domains including diagnostic pathology.
In view of the foregoing, this paper proposes a new transfer learning-based approach to automatically classify breast cancer from histopathological images, including both MD and MI binary and eight-class classifications. The MD task mimics the real-life practice of pathologists, where each histopathological slide is carefully analyzed, starting from a lower magnification level to a higher one, until a perfect image insight is obtained. In this case, our proposed model is trained and tested out using a specific set of images, all having the same magnification level. However, in the MI task, a set with different magnification level images is employed to train and test the proposed model. In order to capture the intrinsic features from histopathological slides and mitigate the burden of training CNN from scratch, a well-known pre-trained variant of deep residual networks [12] on ImageNet images [13], ResNet-18, is applied to our problem. By considering ResNet-18 as an ensemble of residual blocks and with aim to transfer the gained knowledge from the source task (ImageNet) to our target task (Histopathology images), we present a block-wise ﬁne-tuning strategy by making the last two residual blocks more task-speciﬁc through resuming backpropagation on them and we freeze the remaining initial blocks in the deep network model. The adaptability of the proposed approach is further strengthened by using global contrast normalization (GCN) based on the target’s data values and three-fold data augmentation on train data. On the one side, GCN is used to reduce the negative impact of contrast variations among images during training. On the other side, three-fold data augmentation is applied to each training image to synthetically increase the available data which inherently helps to reduce over-fitting and improve the model generalization ability. We use the Breast Cancer Histopathological Image Classiﬁcation (BreaKHis) dataset [4] to evaluate our approach and we perform both MD and MI tasks binary and eight-class classiﬁcations, respectively. The main contributions of this paper are summarized as follows:
•A new automated approach based on deep learning is proposed for the automatic classification of breast cancer from histopathological images, which can handle both MD and MI binary and eight-class classifications. To the best of our knowledge, the proposed approach is the ﬁrst one to tackle all these tasks in one research work based on a one single model and the ﬁrst one to address the MI eight-class classiﬁcation. Overall, the obtained results outperform recent state-of-the-art methods by a fair margin.•A transfer learning method based on block-wise ﬁne-tuning strategy is introduced to learn the best intrinsic features of histopathological images. Since ImageNet images are very different from histopathology images, we propose to fine-tune the last two residual blocks of the pre-trained ResNet-18 model to make them more task-specific while freezing the rest of the initial residual blocks. The adaptability of the proposed approach is further strengthened by using GCN from the target’s data values and three-fold data augmentation.
The rest of this paper is organized as follows. Section 2 reviews the related works. In Section 3, our proposed methodology is presented in detail. In Section 4, the obtained experimental results are presented and discussed. Section 5 concludes this study and draws some future directions and perspectives.
