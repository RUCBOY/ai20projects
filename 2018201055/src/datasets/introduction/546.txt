As an intractable intra-class variation for image classification, partial occlusion is ubiquitous in real-world images. Many research attempts have been made to address this problem. Some researchers explore the information of the occluded object, the occludee, to design occlusion-robust representation of the images [1], [2], [3], [4]; while others focus on the intervening object, the occluder, to pursue an accurate model of the occluders so as to alleviate the influence of the occlusion [5], [6], [7], [8], [9], [10], [11]. Unfortunately, for classical approaches without employing the deep networks, promising results were only achieved in specific applications, such as face recognition on small datasets under constrained environments like indoor and front-view [7], [11], [12], [13].
Although recent deep convolutional neural networks (CNNs) have achieved significant success in image and object classification [14], [15], [16], [17], [18], [19], the long-standing problem of partial occlusion remains a big challenge for the CNNs. As a data-driven technique, the CNN-based classification usually requires massive labeled training data to model the diversity and alleviate overfitting in network training. To train an occlusion-robust representation for the occluded images, i. e., to handle the occlusion from the occludee side, the training dataset has to be enlarged multiple times to cover the variations caused by the occlusion. The collection and annotation of real data are, however, time-consuming and cost-expensive, especially for real occluded images.
In most practical applications, the training dataset usually contains much fewer occluded images (images are corrupted by the occluders) than clean images (images are not corrupted by the occluders), and sometimes, the available occluded images are irrelevant to the task-specific image classes. In this paper, the occluders are referred to the image patches or objects that are irrelevant to the task, since handling the images with the objects occluded by the task-specific objects is usually regarded as a research topic of multi-label classification. We consider the classification of generic occluded images under this application scenario with a further assumption that a small set of clean and occluded image pairs that are associated with the occluders (or similar occluders) in the occluded test images is available. The images in the small set can either be included in or come from outside the original training set. Each of the clean and occluded image pairs is composed of a clean image and an occluded image, where the difference between the occluded image and the clean image is just the occluder.1 This assumption can be easily satisfied in practice since only a small set is required.
Due to the limited number of the available occluded images, dealing with the occlusion from the occludee side in the above-mentioned application scenario is difficult. On the contrary, modeling an occluder usually requires much less training samples than modeling the variations of the occludees that are caused by the occluder. Therefore, for the above-mentioned application scenario, we present a novel deep feature vector (DFV) augmentation approach in this paper to handle the occlusion in the deep feature space from the occluder side.
The DFV extracted by the CNNs is usually a holistic representation of the image, where the occlusion-related and the occlusion-unrelated elements are indistinguishable. However, we observe that the difference vector (DV) between the DFVs of the occluded image and its original clean image is highly related to the occlusion. Based on this observation and the following analysis, we propose to augment the DFVs in the fine-tuning stage with pseudo-DFVs that are generated by randomly adding the DVs extracted from a small set of clean and occluded image pairs.
Suppose we have a training set containing numerous clean images and a few occluded images. A CNN well-trained on this training set performs a nonlinear mapping from the image space X to the deep feature space Ω,f:X↦Ω. The CNN maps the clean images and the occluded images of the ith image class to the deep feature subspaces: Ωci and Ωoi, respectively. An ideal decision boundary to identify the images of the ith image class should coincide with the boundary of the subspace Ωi=Ωci∪Ωoi, as illustrated in the left diagram of Fig. 1. The classifier, however, can only learn the boundary of Ω^i=Ωci∪Ω^oi from the training set2, where Ω^oi denotes the linear span of the DFVs of the occluded training images of the ith image class. Apparently, Ω^oi is much smaller than Ωoi since only a small subset of the occluded images is employed to train the networks. As a result, the classification accuracy for the occluded images is very poor.Download : Download high-res image (241KB)Download : Download full-size imageFig. 1. Illustration of the DFV augmentation concept. In the left diagram, without fine-tuning, the pseudo-DFVs can extend the classification boundary of the ith image class from the boundary of Ω^i to that of Ω˜i. In the right diagram, by fine-tuning the CNN with the augmented DFVs, the area of Ωoi outside Ω˜i (corresponding to false negative samples) and the area of Ω˜oi outside Ωoi (corresponding to false positive samples) decrease. For simplicity, the shape variations of the subspaces are not shown.
In our preliminary experiments (see Section 3.1 for details), we observed that the intra-pattern DVs associated with the similar occlusion patterns are close to each other on a low-dimensional manifold in the deep feature space. Here, the occlusion pattern is defined as the occlusions with the same texture, shape, size, and location on the image. This observation inspires us to generate a large set of pseudo-DFVs by randomly adding the DVs that are extracted from a small set of clean and occluded image pairs to the DFVs of the clean images. The generated pseudo-DFVs have a high probability of falling into the subspace Ωoi due to the closeness of the intra-pattern DVs to each other. The linear span of the pseudo-DFVs Ω˜oi usually covers more space of Ωoi than does Ω^oi, as illustrated in the left diagram of Fig. 1.
By augmenting the DFVs with the pseudo-DFVs in the training phase, the learned decision boundary of the classifier, in theory, will be aligned with the boundary of Ω˜i=Ωci∪Ω^oi∪Ω˜oi. If the back-propagation to the CNN is taken into account, the network parameters will be updated to represent the images in more compact subspaces, as illustrated in the right diagram of Fig. 1, such that the classification accuracy for occluded images can be improved further.
The proposed approach is characterized by the following features.
1.It is an end-to-end learning technique and can be directly applied to any pervasive CNNs without the need to modify the inference network structure.2.It requires only a small set of clean and occluded image pairs and thus is suited for practical applications.3.It is applicable to the classification for generic occluded images with the occluders of arbitrary shapes and textures.4.The model fine-tuned with the proposed approach does not require occlusion detection in inference and thus is universal for the classification of both the occluded images and the clean images.5.It is validated on a large-scale general-purpose dataset with a large number of occluders.
The rest of this paper is organized as follows. In Section 2, some related works are briefly reviewed. Section 3 elaborates on the main observation on the relationship between the DVs and then presents the proposed deep feature augmentation approach. Section 4 presents the experimental results on both small- and large-scale datasets. Finally, the paper is concluded in Section 5. The generated dataset and source code of the developed model will be available online.
