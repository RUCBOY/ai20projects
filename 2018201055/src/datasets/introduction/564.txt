Depression ranks the fourth among these most serious mental health issues by 2020 [1]. In general cases, it not only has mild harm to individual life, but also has a certain influence for family and society. In some worst cases, it may lead to suicide. Therefore, it is urgent to find an efficient solution to diagnose and treat the clinical depression.
In recent years, many methods from various perspectives to assist psychologists or clinicians to diagnose and treat the clinical depression have been developed, mainly from affective computing, computer vision and machine learning communities and so on. To predict the severity of depression based on audiovisual cues, traditional approaches commonly consist of three successive procedures: 1) feature extraction, 2) feature aggregation, and 3) regression (or classification). Feature extraction plays a significant role for depression recognition in videos. Mining a discriminative feature descriptor is crucial and meaningful for depression recognition and estimation. From the perspective of feature extraction, the technologies can be roughly divided into hand-crafted features, and deep-learned features.
Hand-crafted features utilize domain knowledge to design features that are closely related to the symptoms of depression [2], [3]. Though hand-crafted feature representations have been considered to obtain superior performance for assessing the severity of depression, there exist the following issues reported by researchers. Firstly, exploiting hand-crafted features is time-consuming as they need task-specific knowledge. Local Binary Patterns from three orthogonal planes (LBP-TOP) [4] is typically and computationally heavy. Secondly, hand-crafted features are criticized as lacking significant information closely related to depression patterns [5].
Recently deep-learned features using convolutional neural networks (CNN) has been widely used for deep feature representation and has performed well in depression recognition and analysis [6]. DepressNet [6] is a novel framework, to learn a depression representation with explanation. A selected CNN model (e.g., AlexNet [7], GoogleNet [8], VGG-Net [9], etc.) is pre-trained on the large-scale facial image dataset [10], followed by fine-tuning on the AVEC2013 [11] and AVEC2014 [12] datasets. The performance surpasses most of the video-based depression recognition methods. In [13], a combination of Recurrent Neural Network (RNN) [14] and 3D convolutional neural network (C3D) [15] is used to learn sequential representation of the spatio-temporal features at two different scales from the face regions. Comprehensive experiments on the two depression databases (i.e., AVEC2013 and AVEC2014) demonstrate that the C3D method is promising. In [6], [13], the authors adopt the pre-trained deep model to fine-tune on the two depression databases for depression estimation. And the scheme cannot be considered an end-to-end method for depression recognition.
In general, depression recognition is a regression or classification issue from the perspective of machine learning. AVEC2013 and AVEC2014 aim at predicting the depression scores, the Beck Depression Inventory-II (BDI-II [16], Table 1) recorded video of a subject. It is suggested that most non-verbal behaviours in human interaction are around the facial region [17]. For visual-based depression estimation, salient region of the face can be used to predict the severity of depression, in particular the patch of eye region is crucial, as suggested in [6].Table 1. BDI-II Score Ranges and Depression Severity.BDI-II Score RangesDepression SeverityNone or minimal0 – 13Mild14 – 19Moderate20 – 28Severe29 – 63
In this paper, the focus is on exploring the technologies based on the facial appearance for depression recognition. To overcome the aforementioned problems, we propose a novel framework, termed Deep Local–Global Attention Convolutional Neural Network (DLGA-CNN), for depression recognition and analysis using facial images/videos. More specifically, as shown in Fig. 1, the DLGA-CNN consists of three components: 1) deep-learned feature extraction module Depressed-CNN, 2) Local–Global-Attention-based Convolutional Neural Network (LGA-CNN), and 3) Weighted Spatial Pyramid Pooling (WSPP) module. The Depressed-CNN module extracts feature map representation from the entire image which can help to learn deep characteristic patterns of depression. The LGA-CNN represents the global and local attentive features of the feature map. Global features aim to describe the ensemble of special patterns of depression while local features concentrate upon capturing specific patterns on patch regions, which can mine discriminative characteristic on salient patches of the feature maps. The WSPP module will build a high level feature representation via transforming the multi-scale information from the local–global feature maps. A novel end-to-end depression scales prediction framework is proposed by closely integrating these three components. Mining both local and global characteristic information of depression is vital for a better depression recognition performance.Download : Download high-res image (210KB)Download : Download full-size imageFig. 1. The pipeline of the proposed architecture for the diagnosis of depression.
The key contributions of the present paper can be summarized as follows:
1.We propose an end-to-end framework DLGA-CNN that effectively captures the facial dynamics as a non-verbal measure for estimating the severity of depression scale.2.To encode the robust feature representations, a deep-learned convolutional feature extraction network named Depressed-CNN is designed. Valuable and discriminative features helpful for depression analysis are retained with the Depressed-CNN.3.A CNN with self-attention network, termed LGA-CNN, efficiently describes the discriminative patterns from the faces. By adopting the attention mechanism, LGA-CNN can automatically retain the valuable characteristic and filter the redundant information of the face.4.Extensive experiments on the two databases (i.e., AVEC2013 and AVEC2014) have been conducted to compare with other visual-based depression recognition methods. The results demonstrated the effectiveness of the proposed method.
The rest of the present paper is organized as follows. Section 2 briefly discusses previous work on visual-based depression analysis and recognition. Section 3 details the proposed methods. Section 4 introduces the databases adopted and the experimental results. Conclusions and future works are discussed in Section 5.
