Relief, as an intermediate form between 2D drawing and 3D sculpture, exploits properties of human visual perception to maintain perceptually salient 3D effect using only a thin volumetric space. The design of bas-reliefs has fascinated humankind for thousands of years and it is extensively used on decorations, medals, frescos, pottery and other artworks. However, traditional bas-relief modeling is a time consuming task and relies on professional skills.
How to use computer aided technology to quickly generate bas-reliefs with fine details is a very significant topic. Recently, automatic or semi-automatic digital bas-relief generation has been a subject of interest in computer graphics ([1]). Some of the proposed methods are designed for modeling generic types of bas-reliefs ([2], [3], [4], [5], [6], [7], [8], [9]). Other methods are designed specifically for modeling a certain type of bas-reliefs, for example, portrait bas-relief generation from a 3D object or a 2D image ([10], [11], [12]). Although compressed to a limited height interval, the relief models have rich geometric details. Fortunately, the modern digital fabrication technologies make it possible to easily manufacture these relief shapes with fine geometric details. The digital reliefs generated by these methods can be fed to computer controlled milling machines and 3D printing devices for manufacturing in practice ([13], [14]).
The input form of the relief generation can be roughly classified into three categories, including 3D objects, 2D images and sketch curves. The majority of the previous methods focus on constructing bas-relief from a 3D scene ([1]). To preserve the faithful fine details of 3D objects, most methods depend on the solving of at least one large linear system. The inverse problem of interpreting and reconstructing 3D scenes from the bas-relief depictions is also useful for relief designing ([15]). Modeling relief from 2D image is a more challenging task, because the important shading cues which reflect the structures of 3D shape are ambiguous in a 2D image. however, given an image of a certain type of object, such as a face picture, from which constructing a bas-relief is much more feasible. With some interactive operations, users can design a reasonable bas-relief in a few dozen minutes ([10], [11], [12]). In addition, constructing bas-reliefs from sketch curves is also an interesting and promising direction. Xu et al. propose a bas-relief designing method with isogeometric analysis ([16]). Their method allows the users to input the boundary sketch of a planar domain and the feature constraints of bas-relief surface, then the bas-relief is constructed automatically. Building rich details is one of the future work for this category of methods.
The automatic generation of bas-reliefs from 3D input scenes has been developed in the past decades. These methods take a 3D scene as the input, and generate a relief by compressing the depth of the scene onto a background. Generally, a bas-relief is represented as a height field which has a single height z for each (x,y) position. Consequently, the key ingredient of converting from 3D scenes to bas-reliefs consists of compressing the height field sampled from the input 3D scenes. One of fundamental problems in bas-relief modeling is to remove or squash the discontinuity height gaps. These height gaps are caused by the discontinuities between occluded parts or between objects and background. An illustrative figure is shown in Fig. 1. The red line segments (see Fig. 1(c)) indicate height gaps which are invisible from an orthogonal view. Due to the limited height range of the bas-relief, the gaps should be removed in the resulting bas-relief (see Fig. 1(d)) to preserve as much detail as possible. Most of previous methods focus on designing direct or intermediate non-linear height compression functions to remove the height gaps. However, these methods are computationally intensive, or in relatively low quality, or rely on important parameters. For example, the state-of-the-art methods always suffer from high computational complexity, especially for height fields with a high resolution, which reduces the modeling efficiency.
Download : Download high-res image (88KB)Download : Download full-size imageFig. 1. An illustration of height gaps: (a) input scene; (b) height field sampled from (a); (c) height gaps (red line segments indicate gaps); and (d) the resulting height field with gaps removed and details preserved. While looking down from top, we just catch three patches of these spheres. These red line segments are invisible from an orthogonal view. To preserve the important details within a limited height of resulting bas-relief, height gaps need to be detected and removed. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)
1.1. Motivation of our workIn general, designing a bas-relief from a 3D scene is an interactive task. Given a 3D scene, users interactively select an appropriate view, tune one or more parameter values by trial if necessary, and wait for the feedback of the algorithm. If the result is not satisfactory, the designer adjusts the view and repeats the loop steps above. Therefore, in the pipeline of designing bas-relief from 3D scenes, finding an aesthetically pleasing view of the resulting relief is an important step. Automatically calculating an optimal viewpoint may not be feasible, because everyone has a certain aesthetic preference. In addition, one cannot evaluate the visual effect of a bas-relief until it is built. However, most traditional bas-relief modeling pipelines cannot produce high quality reliefs efficiently. If a set of high-quality reliefs from a great many viewpoints can be generated quickly, designers can then make their own choices instantly according to the visual effects of the resulting reliefs. Therefore, a fast method of generating a batch of high-quality reliefs is required.In practice, large reliefs with fine details are commonly found in architecture and industrial designs. These reliefs are manufactured by computer controlled milling machines or 3D printer. A high resolution is always required to exhibit fine details on the resulting relief. For large resolution height fields, the computational efficiency in the design circle above mentioned will be more severe. Thus, a fast method of generating large high-quality reliefs is quite required.Some previous normal-based and mesh-base methods can produce fine results from 3D scenes composed of 2 manifolds. However, they are inefficient and depend on tuning several important parameters. To facilitate automatic modeling pipeline, this paper aims to propose an efficient solution without requiring parameter tuning to enable high-quality bas-relief design from a 3D scene composed of 2-manifolds or non-manifolds. To this end, we design and train a deep convolutional network to construct bas-reliefs from height fields of given 3D scenes efficiently. Specifically, our method is inspired by deliberating the following aspects:•Domain. To be compatible with 2-manifold meshes and non-manifold meshes, our method takes a height field sampled from a 3D scene as input.•Quality. A fundamental problem of bas-relief modeling is to squash the heights while preserving the fine details and eliminating the unnecessary height gaps. As a non-linear function, a CNN is a natural candidate to solve the fundamental problem. A hierarchical CNN can gather local and global information to remove height discontinuities and to retain fine details and 3D shape simultaneously. Unlike neural networks for general-purpose image processing tasks, we shall equip our network with a specific loss function to maintain rich details for the bas-relief modeling task.•Efficiency. Most previous methods generate the resulting height field by solving at least one sparse linear system, and tens of seconds are taken to compute the bas-relief for an input image with resolution of 1000×1000. Our CNN-based solution is computationally efficient while obtaining high-quality results. It produces a bas-relief within one second via a forward propagation of the network, even if it takes a large image (such as 3000×3000) as input. It is trained to produce a batch of high quality bas-reliefs instantly, thus our method can assist designers to quickly find satisfactory results.Actually, our CNN-based solution takes into account the high quality as well as the efficiency simultaneously. Extensive experiments show that our method achieves better performance and has a better tradeoff between quality and efficiency against state-of-the-art methods.
1.2. ContributionsAlthough the neural network has been used to generate a bas-relief from a frontal face photograph ([17]). Their method is based on the Shape from Shading technique. A neural network is trained to learn the mapping between an image of a 3D face and the corresponding bas-relief which is generated from the same 3D face. Our network is designed and trained to generate bas-relief from 3D scenes composed of all kinds of 3D shapes. To our knowledge, our work is the first to apply CNN for the task of generating bas-relief from a 3D scene. The main contributions of this paper are summarized as follows:•ReliefNet. To the best of our knowledge, this paper is the first to study the modeling of general bas-reliefs from 3D scenes based on an end-to-end trained deep neural networks. Our proposed loss function is very critical for the bas-relief modeling problem. Our network can generate high-quality bas-reliefs without requiring any parameter tuning.•Efficient solution. Once our neural network has been trained, it is very efficient in predicting a batch of bas-reliefs from a 3D scene, even with a given input high resolution model.•Height field dataset. In addition, a bas-relief dataset with diverse types of objects is first constructed to train the neural network for bas-relief modeling. We will publish this dataset for further research on bas-relief generation. The height field in the dataset has a larger bit depth than the RGB color image, which is also potentially beneficial for the research on perception.This paper is organized as follows: Section 2 describes related work and the motivation of our work. Next in Section 3 we introduce the architecture of our ReliefNet and the implementation details. Experimental results and comparisons are shown in Section 4. Finally, we conclude our paper with future work in Section 5.
