Voice Gender Recognition (VGR) is an easy task for humans but a very complex task for machines due to the challenges arising when a voice is recorded such as noises. VGR aims at recognizing the human voice as males or females through recordings. This task is important for some security systems where identifying the gender of the speaker is crucial. Movie analysis is another important application of VGR systems which is used in examining the time when both male and female characters appear on the screen.
The efficiency of a voice gender recognition system is related to the pre-processing techniques and the representation of the audio data. In the literature, there are two main approaches; the first approach is using numeric features and characteristics of the audio data such as mean frequency, mode and standard deviation … etc. [1], [2], [3], the second approach is using spectral features of sound such as MFCCs, Log-Mel features … etc. [4], [5], [6], [7], [8].
Most studies used the first approach and the Gender Recognition by Voice dataset (Gender Dataset) [9] that provides 20 numeric features for each audio file. Ertam et al. [3] scored the best accuracy of 98% taking this approach. They used a relief algorithm as a feature selection method [10] to select the most 10 effective features. After that, they used a double-layer deep Long Short-Term Memory (LSTM) followed by a Dense layer and a Softmax function for classification. Due to the clarity of the Gender Dataset, this model performs well on it but does not generalize well when more challenging environments surround the voice.
Barkana et al. [4] presented a model depending on the pitch-range (PR) feature set for age and gender classification. They used energy and zero-crossing rates as pre-processing steps, to separate conversational speech from silence. They then calculated five different features for that study, namely, MFCCs + energy, relative spectral transform–perceptual linear prediction (RASTA-PLP), fundamental frequency (F0), 3PR and 20PR. For classification, they tried a k-Nearest Neighbors (kNN) and a Support Vector Machine (SVM) classifier. They concluded that MFCC + Energy + 3PR + F0 with SVM scored the best accuracy of 84.7% on the aGender corpus [11].
Ramdinmawii et al. [5] delivered a gender identification system from speech signal using three different features, pitch using autocorrelation, signal energy and MFCC, each with an SVM classifier. They found that MFCC scored the highest accuracy of 69% on the Texas Instruments Massachusetts Institute of Technology (TIMIT) database [12].
Hebbar et al. [7] proposed a model applied to movie audios. It presented an end-to-end gender classification system that consisted of two components: a bidirectional LSTM-based Voice Activity Detection (VAD) and transfer learning from an audio classification model (VGGish). They represented audio data by log-Mel filterbank coefficients features and used three dense layers followed by a Softmax function for classification. Finally, they scored an accuracy of 87%.
Kabil et al. [13] delivered a system by using a Convolution Neural Network (CNN) on raw speech signals followed by a Multi-Layer Perceptron (MLP) and a Softmax function for classification.
Despite the recent advances in the field of Machine Learning and Deep Learning and despite the availability of data, an end-to-end voice gender recognition system that works well under unconstrained environments remains challenging. In this paper, we propose two models to overcome these challenges that arise when the voice gets recorded in uncontrolled acoustic conditions such as background noise, different languages, accents, ages, and emotional states of the speakers. These models are inspired by the Self-Attention mechanism proposed in [14]. The rest of the paper is organized as follows; in the second section, we discuss the proposed models, in the third section, we present experimental results and discuss the advances and limitations of our models, whereas in the last section we give a conclusion.
