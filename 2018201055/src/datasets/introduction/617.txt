Deep convolutional neural networks (CNNs) have become the most influential models of sensory data, such as images, video, and audio [1], [2], [3], [4], [5], [6]. CNNs take advantage of translation variance in perception tasks to use shared weights in different locations of the feature map. For image data, translation invariance exists in both the length and the width directions; therefore, CNNs can share weights in both of these dimensions. In this way, CNNs reduce the number of parameters required in the neural network and improve the generalization performance. However, many other transformation-invariant properties exist among the data features and must be approximated by neural networks. Nevertheless, the practical application of CNN models, which obtain state-of-the-art results, requires enormous amounts of clear data [7], [8], [9], and the datasets must be extended by augmenting them with data [10], [11].
Several studies have attempted to extend other translation-invariant spaces. The most common way is to convert the convolution operation into rotation and reflection [12], [13]. This extension allows the model to adapt to rotation- and reflection-invariant features in the data. Bruna et al. designed a wavelet scattering network that can compute translation-invariant image representation [14]. However, the efficiency of adopting convolution operations in different translation-invariant spaces depends on tasks and prior knowledge. Therefore, we perform convolution in a dimension that is learned by itself. The basic operation of each filter in a convolution layer is the elementwise multiplication of a feature map with the kernel weights, which is given by:(1)y(r0)=∑rn∈Rw(rn)·x(r0+rn),where rn enumerates the spatial locations in R; w denotes the weight of the convolutional kernel; and y and x are the features of two adjacent convolution layers. Since each element of w is a constant, y(r0) is also a constant. If unfixed kernel weights given by w(a,rn) are adopted, a new dimension would be extended. Eq. (1) can thus be written as:(2)y(a,r0)=∑rn∈Rw(a,rn)·x(r0+rn),where a denotes the location in the latent dimension and y(a,r0) depends on the latent variable a. As a result, convolution operations can be employed in this dimension.
If we use learnable parameters to parameterize the function w(a,rn), the latent dimension is obtained during training. In this work, we use piecewise sine curves to define the unfixed kernel weights to make the dynamic kernel (DK) convolution operation both flexible and straightforward, and the unfixed kernel weights w(a,rn) are used as DK weights. In experiments on the Canadian Institute for Advanced Research (CIFAR) [15] and Fashion-Modified National Institute of Standards and Technology (MNIST) [16] datasets, we employ two different DK-CNN structures: one structure extends the dimension in the first layer, and another structure extends the dimension following 3D CNNs and average pooling in the latent dimension. The results show that both structures exhibit better performance than regular CNNs in most cases. In addition, because the degree of weight sharing is increased in the process of obtaining DK weights (see details in the Methods section), the number of parameters in a DK-CNN is not more than that in a regular CNN.
Several previous works have attempted to design a new convolutional network. For example, deep receptive field networks learn the weights of several filter bases [17]. PCANet employs principal component analysis (PCA) to construct a deep learning network [18], [19]. Deep eigenfilters are obtained by eigendecomposition [20]. In this work, we design a new approach to improve CNNs. Our contribution is a learnable latent dimension for convolution operations, and the result is called a DK-CNN. In addition, we describe the initialization of DK-CNNs and perform a complexity analysis. Finally, we perform experiments to verify that DK-CNNs can achieve better performance than regular CNNs.
The remainder of this paper is organized as follows. Section 2 introduces the related background for the proposed model, including the convolution units of CNNs. Section 3 describes the proposed kernel convolution operation. Section 4 details the abovementioned experiments and discusses the experimental results. Finally, Section 5 provides a brief conclusion and directions for future work.
