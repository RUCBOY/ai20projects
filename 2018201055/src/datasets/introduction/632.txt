Increasing enterprise applications and scientific computing tasks are deployed in public cloud systems such as Amazon AWS, Windows Azure, Aliyun and Google Cloud. Cloud service providers allow users to lease a certain amount of cloud resources or virtual machines (VMs) when needed [1] while satisfying specific service level agreements [2], and the users pay the cloud providers on a pay-as-you-go mode. Due to the diversity of types, cost effectiveness and operational reliability of cloud services provisioned by these cloud providers, users are more willing to reserve suitable cloud resources to meet their varied business application demands. However, it is quite difficult for users to accurately reserve how much cloud resources (e.g., CPU cores, Memory size, Disk size and Bandwidth) are needed for their requested workloads (i.e., the task processes that constitute the running applications of users in this paper). Because when the reserved cloud resources exceed the actual ones used, the resources will be wasted or in a state of inefficient utilization. Conversely, if the reserved cloud resources are insufficient, the execution of task workloads will be delayed or suspended. In addition, the workload fluctuation in cloud systems may also result in the over-provisioning or under-provisioning situation of resources [3], [4]. The former situation will bring economic losses due to the higher usage cost of cloud resources (i.e., the more payment for users, and the greater energy waste of cloud data centers for cloud providers), the latter one may delay or even interrupt the execution of user tasks. As the reports show, the hourly mean CPU utilization in Google cloud cluster-usage trace [5] and Aliyun trace [6] is only of 25 to 35%. Therefore, for improving the resource utilization and reducing the usage cost while guaranteeing the cloud service performance desired by users, a timely and efficiently cloud resource prediction method needs to be devised to determine the reasonable resource quantity that should be reserved according to the historical and current resource consumption.
 However, accurately predicting the usage amount of cloud resources for requested workloads is still confronted with the following challenges:Download : Download high-res image (569KB)Download : Download full-size imageFig. 1. The number of relatively-periodic requested workloads and corresponding usage amount of cloud resources.Download : Download high-res image (423KB)Download : Download full-size imageFig. 2. The number of randomly-changing requested workloads and corresponding usage amount of cloud resources.

•Constantly changing data of requested workloads and cloud resource usage. The number of requested workloads varies with time, and some are relatively periodic (e.g., the general user Web applications [7] running in the public cloud system), while others are random (e.g., the randomly-changing workloads from the cluster-usage traces in Google cloud data centers [5]). The usage amount of each type of cloud resources, such as the average usage percentage of CPU, Memory and Disk, and the average number of Bandwidth, fluctuates in a certain degree for the relatively-periodic workloads similar to Fig. 1, or considerably changes for the randomly-changing ones during a day [5], [6] like Fig. 2. These cases reflect that the accurate prediction of the cloud resource usage amount with the continuously changing requested workloads becomes so hard.•Nonlinear relationship between requested workloads and corresponding cloud resource usage. Regardless of whether requested workloads are relatively periodic or randomly changing, due to the nonlinear relationship between requested workloads and corresponding usage amount of cloud resources, it is not easy to establish the mapping relationship between them through employing historical and current data. However, the establishment of this relationship is the key to the cloud resource prediction.•Time-lagging cloud resource prediction. For predicting the cloud resource usage amount, it needs to continually generate request workloads and to survey the changes on the related resource usage in the existing practice. However, during these processes, much time can be taken to wait for multi-round measurement, and the data of the workloads and resource usage cannot be immediately obtained. It is unacceptable for time-sensitive users to reserve the cloud resources with the time-lagging prediction.
In the face of these problems, the existing approaches do not analyze the essential characteristics of workload waveforms to find the intrinsic rules of those workload changes. The data relationship between requested workloads and related cloud resource usage is not also further established. In the aspect of the timely cloud resource prediction, there are no existing methods to carry out the online cloud resource prediction through quickly fetching the real-time cloud resource monitoring data.
Different from the current approaches, we consider the consecutive fluctuation of users’ requested task workloads with the important waveform features, further perform the scalable window waveform sampling on the classified workloads, and finally generate the nonlinear predictable relationship between the requested workloads and their usage amount of cloud resources by training the data model of requested workloads with the corresponding usage amount of cloud resources (called as resource usage labels). Integrating these new solutions can make the fine-grained prediction of cloud resource usage on the basis of continuous changing waveform features of requested workloads, and achieve the online cloud resource prediction with the higher accuracy.
The latest approaches [8], [9], [10] only predict the future trends of users’ workloads or demands in the volatile business requirements for making decisions to adjust the cloud resource allocation instead of establishing the relationship between the business workloads and the cloud resource usage. On the other hand, some prediction methods [3], [11], [12], [13] predict the future cloud workload trends through the historical CPU utilization or usage information used by the different models or algorithms such as the deep learning, time series, swarm and evolution, and ensemble-based regression respectively. However, these methods reversely infer the changes of workloads based on cloud resource usage, without paying attention to the changing characteristics of requested workloads from users’ applications. Unlike the above methods, we should find the intrinsic relevance between constantly changing requested workloads and corresponding cloud resource usage. In the cloud resource allocation based on the workload prediction, some researches [14], [15] propose the skewness-avoidance (balanced) cloud resource allocation in physical machines (PMs) according to the diversified requirement workloads predicted in advance, which relates the different types of cloud resource configurations with the performance of cloud provisioning. However, their work does not also form the relationship between requested workloads and related cloud resource usage.
In the just-in-time prediction, the existing methods via the post-historical data analysis [16], [17], such as generating different users’ workloads and profiling the performance of cloud systems running the applications, do not use a timely manner to predict the cloud resource consumption of users’ applications. When the users’ demand patterns change, new round of profiling jobs must restart. However, users cannot wait for a long time of the profiling process, on the contrary, they expect to know as soon as possible about the cloud resource usage amount for their applications so that the resource reservation can be adjusted quickly to save money.
To address the above challenges, we put forward an online cloud resource prediction model (OCRPM), which encompasses the requested workload trend classification (RWTC), the scalable window waveform sampling (SWWS) on classified workloads, and the optimal error gradient boosting regression (OEGBR) training and prediction. We firstly obtain the data of requested workloads and cloud resource usage (e.g., CPU, Memory, Disk and Bandwidth) through online querying the cloud monitoring trace database from VMs, and further classify the requested workloads into three types of trend waveform patterns (Peak, Steadiness and Trough) in hourly time intervals. Next, with these classified data, a scalable window waveform sampling method is proposed to support the model training on the data of workloads and cloud resource usage. Finally, the OEGBR is designed to train the data model (i.e., establishing the mapping relationship between the requested workloads and corresponding cloud resource usage) and to predict the cloud resource usage amount by the test data. All of the above-mentioned modules and processes are implemented in the cloud service broker layer similar to our previous work [18], [19].
The main contributions of this paper are summarized as follows:

•An OCRPM is proposed to timely and efficiently predict the reasonable resource usage amount that can be reserved in the future according to the historical and current resource consumption.•A way of online querying and sampling cloud trace data from VMs is adopted. To differentiate the waveform features of requested workloads sampled, a measurement called the trend degree (TD) is presented, combining the skewness and kurtosis of requested workloads in a certain time scale. Through using the feature TD, all the requested workloads are classified into three types of waveform trend patterns in hourly time intervals such as Peak, Steadiness and Trough.•A SWWS method on the three types of waveform trend patterns is put forward to extend the suitable workload waveform interval window for supporting the model training with high accuracy on the sampled data of workloads and cloud resource usage, and its sampling algorithm is also designed.•An OEGBR algorithm is devised to train the data model and to predict the reasonable cloud resource usage amount.•Extensive simulation experiments, adopting the datasets of the real-world business applications of an IT company and the opening Google cloud cluster-usage trace, are conducted to evaluate the effectiveness of the proposed method.
The rest of the paper is organized as follows. Section 2 reviews the related work. In Section 3, we demonstrate the overall process of the proposed OCRPM. Section 4 describes the workload trend classification, the SWWS method and its sampling algorithm in detail. In Section 5, we give the OEGBR algorithm on the model training and prediction. Section 6 evaluates the proposed method and algorithms using the different cloud trace data. Finally, we draw the conclusions in Section 7.
