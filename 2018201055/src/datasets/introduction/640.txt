In the last decades, the cyber-security aspects of networked control systems have been emphasized by the research community to provide services with resilience guarantees. In tandem with the growing use of general-purpose networks, malicious entities are paying increasing attention to these sometimes critical networks and are profiting from attacking them. An example of such malicious entities attacks is the Stuxnet incident [1], caused by a malicious computer worm. Other well-known instances are the power system cyber-attacks that occurred in Ukraine [2]. Consequently, the research community has been developing methods to improve the resilience of cyber–physical systems to overcome such abnormal situations. These methods have a central role, because such circumstances may lead the systems to critical stages, which can be irrecoverable or may even, in the worst-case scenario, result in a cyber-war.
Multi-agent systems [3] are a particular case of cyber–physical systems, and they are computerized systems composed of multiple interacting intelligent agents. These systems can solve problems that are hard or impossible for a single agent to resolve. In other words, multi-agent systems may be seen as networks of dynamic agents aiming to achieve a global intent employing local interactions. These systems consist of a research line of paramount importance.
A nuclear problem in multi-agent systems is when all agents in a network seek to agree on a shared value, known as consensus. The problem of consensus has numerous applications, making it a research subject of particular interest. For instance, it emerges in areas like distributed optimization [4], [5]; tasks of motion coordination, e.g. leader following [6]; rendezvous problems [7]; resource allocation in computer networks [8]; and even in computing relative importance of webpages in the PageRank algorithm [9].
A particular type of consensus problem is the average consensus, i.e. designing a linear distributed iterative algorithm that leads agents to compute the arithmetic average of their initial states. This problem has a plethora of applications. It has been studied for both the cases of undirected [6] and directed [10] networks. Further, we may also classify the consensus problems according to the time update domain as discrete-time [11], or as continuous-time [12]. The time-domain can even be hybrid as studied in [13], where resilience consensus is proposed for systems composed of multiple dynamical agents governed by both continuous-time and discrete-time control laws. Further, the network communication between nodes may be synchronous [11], or asynchronous [4], [14] and the communication may occur deterministically [15], or stochastically [16]. Lastly, the communication network can be static [15], or dynamic [11].
The growing use of consensus algorithms praises the need to deal with both faults and attacks. In other words, it is crucial to ensure that consensus methods are resilient to agents that behave abnormally. In [17], a fault-tolerant algorithm to perform approximate Byzantine consensus in asynchronous networks is introduced. The algorithm requires a topological condition to be successfully used, which is less restrictive than the standard requirements. Their work also applies to synchronous networks and networks with delay on the communication paths, and the authors extended the results to systems with a time-varying underlying graph. In [18], the problem of resilient consensus of sampled-data multi-agent networks with double-integrator dynamics is studied. Under the assumption that we know a bound on the number of malicious agents, a resilient consensus method is proposed by making each agent discard a set neighbor values, which are large and small states.
The work in [19] investigates consensus and clustering of expressed and private opinions against Byzantine individuals in directed and time-varying networks. The author outlines a distributed censoring algorithm to rule the opinion dynamics of private and expressed opinions and renders necessary and sufficient conditions for resilient consensus and clustering based on network robustness.
Much work has been devoted in trying to mitigate the effects of possible nodes being attacked. To help better identify the nodes of a network that are easier (with a smaller cost) to attack and for which, when designing a network, one has to pay special attention to, we develop a measure to quantitatively assess how resilient to being attacked a node in a network is. The proposed methodology may be used to prevent attacks and to identify nodes or sets of nodes that may strategically be more protected due to its criticality in a network. Graph resilience has a plethora of application areas, such as consensus methods, power grids, brain connectivity, social networks, geolocation services, digital multimedia content generation and delivery, argument graphs, logistics and supply chain management, computer, and data communication networks, and chemical engineering. The concept of graph resilience quantifies the ability to find alternative, though generally more costly, paths when edges or nodes with their incident edges are deleted from the graph. In this paper, we explore a novel perspective inspired by average consensus. The proposed view translates in a measure of how easy it is to influence the entire network by changing a particular node value.
In [20], a graph measure that the authors called effective graph resistance, derived from the field of electric circuit analysis, was proposed. They define the effective graph resistance as the accumulated effective resistance between all pairs of vertices. The measure the authors proposed only aims to evaluate the resistance of a graph qualitatively. In contrast, we present, in this paper, a measure that can be computed for a node, a set of nodes, and also used to calculate the resistance of the graph. In [21], the authors proposed a new, generic, and scalable graph resilience metric to the edge removal scenario, relying on the weighted sum of the number of paths that cross specific vertices of extensive communication and structural value, is proposed. Also, in [16], an in-depth study of the design and analysis of gossip algorithms for averaging in an arbitrarily connected network of nodes is studied. The authors show that the averaging time needed to reach consensus depends on the second largest eigenvalue of a doubly stochastic matrix, characterizing the averaging algorithm. They discovered that the smaller this eigenvalue is, the faster the averaging algorithm converges.
In [22], the authors apply a machine learning method to evaluate the robustness of multi-agent systems. They use neural networks (NN) consisting of Multilayer Perceptrons (MLPs) to learn the representation of multi-agent networks, and use softmax as the classifiers. Using multi-agent model, in [23], the authors theorize that network metrics such as average path length, clustering coefficient, size of the largest connected component in the network and the maximum distance between nodes in the largest connected component relate to the robustness of supply networks, and statistically test these hypotheses with several examples.
The work of [24] focuses on improving community robustness to attacks and failures. The authors introduce a robustness measure to assess the community similarity between an original network and a broken network. Finally, they propose a multi-agent genetic algorithm to maximize the community robustness on networks.
In this work, we aim to shed light on the problem from a different point-of-view. Instead of viewing from a defense perspective, we look at the issue of attacking the network at the lowest cost. In other words, we evaluate what is the best attacking strategy, in the case of bribing attacks [25], [26], [27], that results in achieving a goal with the lowest cost concerning a given cost function. We seek to find a lower bound on how much cost/energy an attacker has to spend to drive the consensus to the attacker’s desired state, defining a measure to evaluate the bribing resistance of nodes and networks. Our approach contrasts with the usual approaches that intuitively quantify how much a network can continue working when nodes are attacked. We aim to intuitively quantify how easily we can deviate a network from its normal function, by attacking some nodes. Our study is, in a sense, dual to the one in [28], where the authors showed how to compute a threshold for the “maximum impact” of an undetected fault/attack in linear consensus and networked physical systems, by solving a non-convex quadratic problem. Resorting to the framework developed in [28], an attacker can estimate the maximum that it can do, without being detected. With the framework that we develop in this work, an attacker may further determine the minimum cost required to drive the system towards the attacker’s goal. Combining both results, the intrinsic limitations on the attacker capabilities can be derived, which depend on the network topology and on the assumption that the defender can run non-conservative detection methods.
Main contributions.(i) We propose a framework to quantify the resistance to bribery of nodes and sets of nodes in a network via average consensus; (ii) the proposed framework may be used under a concrete setting for average consensus when we know the initial states of each agent, and we know if the dynamic is discrete-time or continuous-time; (iii) if the only available knowledge is the network topology of agents (structure of the network), a general measure of bribing resistance is also proposed; (iv) we used the setup in (iii) to proposed a measure of network bribing resistance.
