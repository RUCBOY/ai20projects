In today’s interconnected digital world, as an ever increasing percent of human activities is performed online, computer security has become a major concern. Disturbances in operation or information leakage can therefore have disastrous consequences to human life. Cyber attacks have been growing in scale, complexity and frequency and have become automated and efficient. They are caused by the exploitation of security vulnerabilities in software or hardware. A vulnerability is a flaw in the design or implementation of a system that can lead to malicious or unintended use. A large number of vulnerabilities, particularly in large-scale closed-source systems, often remain undiscovered and undisclosed for a long time and even when found, are often not remedied. This usually happens due to various reasons, such as lack of the required skills to develop an effective patch, cost or other reasons [1], e.g., system uptime being more important than security, as taking the system down to fix vulnerabilities might incur a significant monetary cost. Furthermore, vulnerabilities can often be combined to form complex attack chains, i.e., each vulnerability increases the attack’s impact on the system. As cyber attackers’ knowledge and tooling become more and more sophisticated and effective, a need for systems that are able to protect themselves against cyber attacks is also becoming imminent.
Manual intervention is often cumbersome, late and inefficient when security threats are encountered, especially in the case of highly complex, automated and sophisticated attacks and systems [2]. A human actor is often slower in terms of response time when facing an attack and prone to external duress in contrast to the system itself. Hence, it is important that the system is able to perform sound and efficient reasoning about its security and take preventative measures at run-time. In that way, the system can itself guarantee the minimum required security level, so that its normal execution will not be disturbed and critical data about its operation or its users will not be leaked or tampered with. We call such systems self-protecting systems, i.e., systems that can protect themselves from attacks and a malicious environment and/or take into account security while performing adaptations in the system.
In general, self-protecting systems are a class of self-adaptive systems that concern themselves with the security aspects of a system, i.e., systems that are able to adapt themselves during run-time in order to cope with frequent changes and uncertainty in their environment or goals and requirements. As any type of computer systems, however, self-adaptive systems are vulnerable to security attacks [3]. In particular, they are susceptible to unique attacks taking advantage of their adapting nature [1]. Firstly, attackers can exploit the operations during the adaptation process to propagate their attacks through paths that would normally not be available in a non-adaptive system. Furthermore, attackers can exploit privileges obtained before an adaptation in order to compromise the current state of the system, e.g., consider a case that an attacker has managed to obtain an administrator password by exploiting a vulnerability in a database manager component. Even though the database manager component might be replaced by a new component that does not expose any vulnerabilities, attackers can still make use of the gained privilege to further compromise the system. For example, by using the gained privileges to login to a part of the system that attackers previously had no access to, which consequently enables them to further exploit the system via an exploit that is only accessible in a previous system state. Therefore, it is required that we consider the security of the system, before, during and after an adaptation.
Furthermore, there is uncertainty involved in designing a self-protecting system, as the factors that affect the security are often domain or implementation specific. For instance, the timeliness of an adaptation in a self-driving car is usually different from a load-balancing server farm. Ideally, a self-protecting system should offer a granular, flexible way to specify what aspects of security are relevant and how important they are in comparison to other non-functional requirements.
Security and vulnerability analysis of self-protecting systems and adaptations have received little attention in the past. Yuan et al. [4] provide an architecture-based approach to self- protecting systems and proposed architectural patterns to protect a system. In an extension of that work, the authors in [5] analyzed adaptations from availability point of view to be able to mitigate DoS attacks. In the network security community, researchers have proposed a few approaches for security analysis of dynamic networks [6], [7], [8], [9]. In [1], we proposed an approach for security risk evaluation of adaptations that employs graphical threat modeling and security metrics to dynamically select secure adaptations according to user preferences. Security metrics provide a measure of how (in)secure a system is by taking measurements of the system’s properties that impact security. However, our previous approach has a few challenges:

•The behavior of the self-adaptive/protecting system is not considered and only the attacker’s behavior is used for security analysis, while the interaction of the attacker with the system behavior is important to suitably analyze a system’s security.•It allows us to check simple properties about the system security, such as “what is the probability of reaching a specific step of the attack?”, or “how many strategies does an attacker have to attack a system?”. However, it does not allow us to reason about more complicated properties, the temporal order and the dependencies of events/attacks and their interactions with the adaptive system components.•In our previous work, the system in a stable state (called a configuration) is separately analyzed and interaction between vulnerabilities over multiple configurations is not precisely analyzed, i.e., the impact of exploited vulnerabilities in the past configurations is not considered in the analysis of later configurations, while an attacker can use the gained privileges in an earlier configuration to obtain new privileges and attack the system, as discussed previously.•The run-time implementation was tied to Rainbow’s adaptation patterns and the self-protection capabilities of the system were limited, as it was not possible to directly forbid an adaptation, rather only penalize its security impact. For instance, we could not guarantee a minimum security level in the system, as one of the candidate adaptations would be selected anyhow, even if they all were detrimental to the system security.
To address the above challenges, we propose a formal approach to design self-protecting systems and perform security analysis in architecture-based self-adaptive systems. We formally specify the adaptation process as well as the attack scenarios. We then formulate security properties in probabilistic temporal logic and employ probabilistic model checking to verify the specified properties. Once properties have been verified, a ranking function is utilized to order the possible adaptations, allowing a system to protect itself by only applying adaptations that meet the minimum required security criteria set by the user. We further describe how to incorporate our approach into any architecture-based self-adaptive system and demonstrate its applicability through incorporating it in Rainbow [10] and applying it on two case studies: a simple document storage system and ZNN, a well known self-adaptive exemplar.
This paper’s contributions are as follows:

•We propose an approach with formal foundations to design self-protecting systems that models the attacker’s behavior as well as the system’s behavior and adaptations. We use probabilistic model checking to verify complex properties about the system’s or the attacker’s behavior.•We designed and implemented the proposed general approach as a security analysis module capable of formal analysis and self-protection at run-time. The design is flexible and can be incorporated into an architecture-based adaptive system with minimal changes to the underlying architecture.•We present a concrete implementation of the proposed general approach and evaluate it using two case studies.
The rest of the paper is structured as follows. Section 2 discusses the required preliminaries and Section 3 introduces a running example. Section 4 provides an overview of our approach and Section 5 describes the formal modeling of the attacker’s and system’s behavior. Section 6 discusses the verification process. Section 7 is devoted to the concrete design and implementation of the approach in Rainbow. We evaluate the approach in Section 8. Section 9 discusses the related work and finally, Section 10 concludes the paper.
