With the recent advancements in computing power along with modern machine learning methods, novel applications are being continuously introduced to assist human in decision making (Webster & Ivanov, 2020). In the current decade, the rise of Artificial Intelligence (AI) has paved the way to change perception in using machine intelligence for the betterment of human life. One of the applications of such technology is automatic traffic sign detection and recognition (Li & Wang, 2018) from the road scenes. Traffic signs are important for driver awareness to ensure safe road communications. Every year thousands of people die and many others get severely injured due to traffic accidents in spite of having well-planned traffic signs installed (Smith, 2016). An AI-based traffic sign detection system can aid the drivers in cases where they might have misread due to fatigue or lack of concentration. Such applications can be used to save human lives from road accident-related casualties with great success (Badue et al., 2020).
Traffic signs are designed in some primary geometric shapes (e.g., circle, triangle, and hexagon) and eye-catching colors (e.g., red, yellow, and blue) so that the signs can be caught easily by human visual systems during traffic maneuver (Hou & Yang, 2020). Image based recognition of traffic signs is a challenging task due to varying deformations and lighting conditions. Traditionally, researchers extract human-defined local features from input images (e.g., LBP, HOG, and SIFT) to represent the shapes of the traffic signs followed by deploying a classifier to predict the class label (Mathias, Timofte, Benenson, & Van Gool, 2013). Very often, feature dimensions become an issue for training classifiers. Moreover, the classification performances based on manually extracted features often are not enough for reliable and practical systems. A practical TSR system should be robust enough to be a replacement or supplement to human visual systems. Speed is also an important factor in realizing industrial application and widespread usability of TSR systems.Download : Download high-res image (250KB)Download : Download full-size imageFig. 1. Proposed CNN architecture for TSR. Convolution layers are represented by light-blue color volumes. Batch norm stands for batch-normalization layer, ReLU stands for rectified linear unit activation layer, yellow volumes represent overlapping max-pooling layers, and Fully connected stands for fully connected hidden layer.
Recently, Convolutional Neural Network (CNN) based solutions have become popular within the computer vision community for its strong capability to learn features automatically using its own built-in mechanism (Marcus, 2018). A CNN combines both feature extraction and classification mechanisms into a single container. CNN has proven its applicability in various fields (e.g., object recognition, speech recognition, and handwritten text recognition) for this characteristic (Pathak, Pandey, & Rautaray, 2018). A CNN architecture arranges several convolutional, subsampling, and activation layers in a sequence for feature extraction and learning together. For the task of TSR, several CNN-based approaches have been proposed. Among them, Cireşan et al., 2012, Jin et al., 2014, Sermanet and LeCun, 2011 and Zeng, Xu, Fang, and Zhao (2015) are notable for achieving high recognition rates on the German Traffic Sign Recognition Benchmark (GTSRB) dataset.
With the recent increase in deep learning based training and graphics processing unit (GPU) accelerated processing, the energy consumption in AI applications have skyrocketed. Very deep and thick networks are often not required for training in case of the majority of the specialized dataset, yet due to lack of availability of need-based customized energy-efficient CNN models, researchers tend to overuse the hardware in general resulting in redundant energy consumption (Strubell, Ganesh, & McCallum, 2019). To be aligned with Sustainable Development Goals (Sachs et al., 2019, Vinuesa et al., 2020) by United Nations and to reduce carbon footprint and global warming in general, we aimed to formulate a novel deep yet thin network specialized in TSR based applications, which is also easily extendable to other similar applications.
Traffic sign images captured from real-life scenarios contain a wide variety of distortions due to different weather conditions, changing light directions, and varying light intensity. Captured images in varying conditions introduce noise, partial or full underexposure, partial or full overexposure, and wide variability in color saturation (due to light intensity) of the traffic signs. Additionally, a wide variety of viewing angles, view distance, and shape/color deformations of the traffic signs make the TSR task challenging for a computer vision system. In traffic sign datasets, we observe that there are no two classes of traffic signs that are differentiable only by the color of signs. Therefore, experimentally it is found that only training on grayscale images can yield a high average recognition rate. However, in difficult cases where images are degraded due to motion blur, distortion, etc. color of the sign sometimes can help CNN in making better predictions. In the proposed DeepThin architecture 1 we addressed the above-mentioned issues moreover reducing complexity and using ensemble for better extract both gray and color information.
We evaluate the performance of our proposed architecture using both grayscale and RGB images. Like any learning algorithm, our proposed architecture contains three modules, namely (i) input processing, (ii) learning, and (iii) prediction. In the input processing module, we analyze the input images in the dataset and determine the input size for the purpose of learning. In the learning module, we use both training images for learning the parameters of the proposed architecture. Finally, during test time, the architecture predicts the class labels for test images. Fig. 1 shows the proposed CNN architecture for TSR.
The major contributions of this paper can be summarized as follows:

1.Traffic signs captured in real-life scenario come in wide variety of sizes. Popular deep and wide CNN architectures (e.g., AlexNet Krizhevsky, Sutskever, & Hinton, 2012, VGGNet Simonyan & Zisserman, 2014, ResNet He, Zhang, Ren, & Sun, 2016, and Inception net Szegedy et al., 2015) are suitable for image recognition of larger images. The proposed CNN architecture is specifically designed for low-resolution images. We introduced a novel architecture that is deep (four layers) but also thin (a small number of feature maps per layer) with only one fully-connected hidden layer with faster training yet achieving higher accuracy. Due to small input images, a small number of feature maps, and increased convolution strides, the proposed framework becomes computationally affordable making it possible to even train without a GPU as shown in Fig. 2.2.Traditionally, max-pooling layers with 2 × 2 disjoint pooling windows following convolutional layers are popular for the purpose of spatially reducing activation volumes and encoding translation and rotation invariance. However, in this work, we instead advocate the use of overlapping max pooling and sparsely used strided convolution for significantly faster training and lower overfitting.3.For ensemble learning, instead of putting together a large number of learners trained on various types of preprocessed datasets, we show that averaging the predictions of a small number of models trained only on color and grayscale training samples is robust enough and faster to execute during test time. This enables the proposed method to be deployed efficiently on a light-weight hardware setup reducing the cost of the applications and also other issues regarding the complexity of hardware integration as shown in Fig. 3.
 Download : Download high-res image (207KB)Download : Download full-size imageFig. 2. Comparison of the state of the art methods in terms of accuracy and FLOPs. Please refer to HLSGD (Jin et al., 2014), Student model (Zhang, Wang, Lu, Wang, & Sangaiah, 2020), MCDNN (Cireşan et al., 2012), CNN ELM (Zeng et al., 2015) Student model (50% pruned) (Zhang et al., 2020) Committee NN (Cireşan, Meier, Masci, & Schmidhuber, 2011) and Student model (70% pruned) (Zhang et al., 2020) for more details of the other methods.Download : Download high-res image (232KB)Download : Download full-size imageFig. 3. Comparison of the state of the art methods in terms of accuracy and parameters. Please refer to HLSGD (Jin et al., 2014), Student model (Zhang et al., 2020), MCDNN (Cireşan et al., 2012), CNN ELM (Zeng et al., 2015) Student model (50% pruned) (Zhang et al., 2020) Committee NN (Cireşan et al., 2011) and Student model (70% pruned) (Zhang et al., 2020) for more details of the other methods.
