Age estimation is an important topic in computer vision with various applications in areas of, for example, human–computer interaction (Han et al. 2013), surveillance and social networking sites. Aging is an irreversible process that causes both appearancial and geometrical variations on human faces (Angulu et al. 2018). Facial aging process can be both affected by personal (e.g., mental/physical states) and situational factors (e.g., living environment).
Age estimation tasks can be classified into two categories: biological and apparent age estimation. Traditional age estimation for still images widely employs biologically inspired features (Kwon and da Vitoria Lobo, 1999, Guo et al., 2009), while estimation using videos often utilizes handcrafted features and temporal dynamics (Dibeklioğlu et al., 2012a, Dibeklioğlu et al., 2015).
In recent years, deep neural network based methods have achieved remarkable performances in multiple face-related tasks. Despite the advancement of deep learning based age estimation, the application of these methods in unconstrained scenarios is still far from ideal. Image variations like extreme occlusion, illumination and blur may negatively influence the performance of these age estimation methods. Moreover, most of the age estimation algorithms focus on still images, and only a limited number of methods are applicable to face videos. One of the main reasons is the lack of large-scale face video datasets with age annotation.
In this paper, we introduce a new video dataset named UvAge, which contains face videos in-the-wild for the purpose of age estimation. This dataset comprises videos of celebrities from the Internet. Information extracted from Wikipedia provides us with the identity, age, gender, and ethnicity labels for each video. Compared with previous single-setting video datasets (e.g., UvA-Nemo dataset from Dibeklioğlu et al. (2012b)), the newly created dataset is a one-of-a-kind dataset containing recordings in-the-wild for a substantial variety of scenarios. In addition to this new dataset, we also propose a new method for age estimation of face videos.
Our method is using a pose invariant representation. To obtain such a representation, a face uv texture representation is computed from the video frames (Feng et al. 2018), which results in a pose invariant texture image containing the estimated frontal view of the face. As head pose changes may cause self-occlusion, the uv map may be negatively affected by missing face parts. To address this problem, we use a Wasserstein GAN based network to complete the missing parts of the uv texture map. Compared to standard inpainting tasks, the occlusion-included missing face regions are highly irregular. Therefore, the GAN based method (AgeGAN) learns to complete missing regions and estimates the age at the same time.
Our contributions are:

•The creation of the UvAge Dataset, the largest video dataset containing face videos in-the-wild with identity, age, gender, ethnicity labels for each video.•A new GAN-based method (AgeGAN) to complete the facial uv texture and to estimate age.•Our proposed method outperforms state-of-the-art age estimation methods on the UvAge dataset
Download : Download high-res image (212KB)Download : Download full-size imageFig. 1. Age distribution of UvAge dataset. The horizontal axis is age. The vertical axis is the number of subjects. Blue bars represent males and red bars represent females. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)
