Protein fold recognition is a critical technology for protein tertiary structure recognition. Folds represent the important features of protein structures, which present the topology of the secondary structures [1]. It is critical to determine the fold for a target protein to reveal its tertiary structure [2]. Classification of protein sequences into known folds is called protein fold recognition, which is a fundamental step in the determination of the protein tertiary structures [2]. Therefore, it is necessary and important to assign protein sequences to known folds by using sequence-based computational predictors.
In this regard, several computational predictors have been proposed to efficiently identify protein folds based only on the protein sequence information, which can be divided into two categories: threading methods (template-based methods) and discriminative methods [3].
Threading methods search the target protein sequence against the template sequences to find the hits according to the alignment scores [4]. Profiles were employed by these methods to improve the performance [5], which can be represented as the Position Specific Scoring Matrices (PSSMs) generated by the PSI-BLAST [6] or the Hidden Markov Models (HMMs) generated by HHblits [7]. For example, Yang et al. [8] proposed the threading method SPARKS-X, which evaluates the alignment scores between the target sequence and the Protein Data Bank (PDB) templates based on the structural information, such as the secondary structure and backbone torsion.
For discriminative methods [9], the target sequence can be predicted as different folds with two phases, including the feature extraction and classification. For the first stage, several features are extracted from the sequences, such as the physicochemical features [10], sequence-order frequency matrix [11], and the autocross-covariance (ACC) based on the PSSMs [12]. For the second stage, Support Vector Machine (SVM) [10], [13], [14], [15], [16], [17], [5], random forest [18], [19], [20], neural network [21], [22], [23], [24], [25], and ensemble classifier methods [3], [26], [27] have been widely used to train the model. For example, Jo et al. [21] constructed the pairwise similarity scores as features and converted the multiclass classification problem into a binary classification problem to predict whether the target sequence and the template sequence are in the same fold or not. Yan et al. [28] proposed a multi-view learning method MV-fold to combine different properties of sequences into common features to improve protein fold recognition performance. Hou et al. [1] proposed a DeepSF predictor that utilizes a deep learning method to classify any proteins into known fold categories to facilitate tertiary structure prediction. Yu et al. [24] proposed a novel deep neural network to enhance the SPE-VLAD layer and WT-loss layer. Yu et al. [25] proposed a HDWE model by combining sparse constraints and an improved RELU operator to address click feature prediction from visual features. Xia et al. [3] proposed an ensemble method TA-fold by combining the SVM and HHblits for protein fold recognition.
The aforementioned methods have contributed to the development of protein fold recognition. Because the fold space becomes more crowded, the candidate sequences selected by the threading methods are not sufficient [29]. Several alignment scores between the target sequence and the corresponding template sequences are not precise. Furthermore, most discriminative methods utilize various features to improve the protein fold recognition performance. However, redundant and irrelevant information exists in the comprehensive features [2].
Multi-view learning models have been successfully applied to protein sequence analysis. For example, the MV-fold predictor for protein fold recognition was constructed based on the multi-view learning models [28]. Song et al. [30] proposed a subspace learning method to learn the reduced dimensional dictionary. Chen et al. [31] proposed a structured sparse subspace clustering method to enforce the coherence and discrimination of affinity. Zheng et al. [32] proposed a low-dimensional sparse subspace learning by using the l2,1-norm constraint to improve the classification performance. Hong et al. [33] proposed a multi-layered deep neural network based on low-rank representation to recovery human pose. Hong et al. [34] proposed a novel face-pose estimation framework M2DL by using the manifold regularized convolutional layers to learn the relationship between outputs of neurons. In this study, we exploit the multi-view learning framework to integrate protein sequence data from various sources to improve predictive performance. Each data source can be considered as a view describing specific characteristics of proteins, such as structural information, function information, and sequence information. Assuming that multiple views of protein sequences are sourced from the same subspace, multi-view learning methods can obtain the latent subspace, which is able to avoid the curse of dimensionality [35]. To increase the performance of the alignment scores based on the threading methods from each view, we employed low-rank modeling [36] to extract the principal features to preserve the intrinsic characteristics.
Low-rank modelling has been widely applied to microarrays [37] and computer vision [38]. Bao et al. proposed inductive robust principal component analysis (IRPCA) [36], which is emerging as a powerful tool for various applications, such as discovering differentially expressed genes [37], [39] and improving residue-residue contact prediction [40]. Robust PCA (RPCA) [41] introduces the nuclear norm to recover the low-rank component, which can recover the low-dimensional space and settle the large corruptions. Liu et al. [42] proposed low-rank representation (LRR) to extract the low-rank component of the original data. MCIF recovers the complementary low-rank transitions from the shared inter-view transitions and individual-view transitions to improve the multi-view clustering performance [43]. MultiVMF proposes a multi-view low-rank factorization method to discover the underlying consistent semantics across different view features [44].
Inspired by the multi-view learning framework [28] and low-rank modeling [36], we proposed a method using the multi-view learning low-rank modeling called MVLR. The proposed methods exploit multiple views from the protein sequences to train the model. For each view, we extract the low-rank principal features to learn a robust representation by using the project learning, and reduce the negative effect of the noise. Then the latent subspace is constructed to represent the common information from different principal components of each view. Finally, an ensemble method called MLDH-Fold is proposed to further improve the predictive performance by combining the MVLR with template-based methods.
The main contributions of this paper can be outlined as follows:
(1)MVLR extracts the robustness component based on the low-rank learning model from each view. The proposed method would be more robust to noise and be more powerful for extracting the feature of each view using the low-rank constraints.(2)MVLR joints the recovering low-rank principal feature and multi-view learning model for protein fold classification. The proposed method constructs the latent information common to the different low-rank principal features views. The latent information used to precisely calculate the similarity between the target and template sequences is used to improve the protein fold recognition performance.(3)We proposed an ensemble method MLDH-Fold by combining the MVLR with the template-based DeepHH method. Prediction results on the two benchmark datasets showed that MVLR and MLDH-Fold outperformed other state-of-the-art methods for protein fold recognition.
