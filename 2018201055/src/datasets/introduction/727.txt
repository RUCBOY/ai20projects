1.1. RBF networks and gradient-based trainingThe radial basis function network (RBFN) was introduced by Broomhead and Lowe in 1988 (Broomhead & Lowe, 1988). It is a simple yet flexible regression model that can be interpreted as a feedforward neural network with a single hidden layer. While it often cannot compete in predictive accuracy against state-of-the-art black box models such as deep neural networks or ensemble methods such as boosting, it is nevertheless a universal approximator (Park & Sandberg, 1991), which means that its predictive accuracy can be improved to match any other predictor by increasing the amount of training data. Especially with large data sets, computational efficiency becomes an essential concern.In this article, we describe a modern gradient-based RBFN implementation based on the same computational machinery that is used in modern deep learning. While gradient-based methods for training RBFN’s have been criticized (Chen, Cowan, & Grant, 1991) because of local optima, tailored training methods have been used in the past with good results (Vakil-Baghmisheh & Pavešić, 2004). We show that suitable optimizers, regularization techniques, and learning rate schedules enable us to train large RBF networks without overfitting and achieve predictive performance on par with gradient-boosted decision trees.Classical algorithms for training RBFN’s usually follow a two-step approach. In the first step, the parameter values describing centroid positions are determined, for instance, by taking a random subset of input data points or applying a suitable clustering algorithm. In the second step, the rest of the model parameters are computed using closed-form analytic expressions (Dash et al., 2016, Orr, 1996, Wu et al., 2012). Another approach for finding RBFN parameters, the Orthogonal Least Squares (OLS) algorithm (Chen et al., 1991), constructs the network sequentially by adding new centroids that maximize the reduced variance of the error vector. Roy et al., 1995, Roy et al., 1997 have proposed a learning theory and associated polynomial-time incremental algorithms for constructing RBF networks.While these methods from late 1990s indeed produce reasonably well-performing RBFN’s, it is clear that the solutions thus found are suboptimal because of the biases introduced by the multi-step algorithms. More recent research (Alexandridis et al., 2016, Lu et al., 2015) has mainly concentrated on developing algorithms that aim to reach good predictive performance while keeping the number of parameters in the network as low as possible (Dash et al., 2016). With our method, it becomes straightforward to train an RBF network with a large number of prototypes.
1.2. Gradient-based pruning and interpretabilityThe parameters of an RBFN have easy-to-understand interpretations. For a network with tens of centroids, this makes the RBFN as a whole quite interpretable; however, a network with hundreds or thousands of centroids is in practice no more interpretable than any large machine learning model. Therefore, we also propose a gradient-based RBFN pruning method that produces a smaller RBFN that globally approximates the larger one. Our approach simultaneously optimizes all parameters of the smaller RBFN and, crucially, minimizes the expected discrepancy over the input data distribution, not the input data points themselves. Hence a pruned RBF network thus obtained is optimized for an objective function that maintains an explicit connection to the larger RBF network and is therefore different from what one would use for directly training a small RBFN of the same size.Interpretability is a great asset especially in those machine learning applications where the learned patterns in the input data can give new valuable insight into the mechanisms underlying the correlations between input and output. Data sets where such patterns, sometimes too nuanced for human intuition to discover, can be revealed by interpretable machine learning models are encountered e.g. in natural sciences.We emphasize that our motivation for pruning is to achieve interpretability, not to minimize the number of centroids used for making predictions. Indeed, we will demonstrate with a materials physics data set that one can train RBF networks with thousands of centroids without overfitting, so there is no inherent need to use pruning as a form of regularization—and that these large networks can be made interpretable with our proposed pruning method. This approach is also fundamentally different from simply training a small RBF network: limiting the number of centroids for the sake of interpretability would compromise predictive accuracy, and in general the pruned networks we obtain are different from those one would get by directly training networks of the same size because the objective functions are different.Somewhat similar ideas on the input data distribution and our pruning criterion’s functional form appear in the growing-and-pruning (GAP) algorithm (Huang et al., 2004, Huang et al., 2005) for constructing RBF networks. However, GAP is designed for constructing RBFN’s in sequential access cases and does not consider pruning as a separate task. Also related are two existing RBFN algorithms that incorporate pruning by initially assigning each training data point its own centroid: The early two-stage algorithm by Musavi, Ahmed, Chan, Faris, and Hummels (1992) prunes the initial network by combining similar centroids using an unsupervised clustering approach, then keeps the centroid locations fixed for the rest of the training process; as discussed above, this is unlikely to converge to an optimal solution. The more sophisticated algorithm of Leonardis and Bischof (1998) alternates between gradient-based optimization steps (performed on the full data set) and centroid removal steps based on the Minimum Description Length (MDL) principle; unfortunately their approach does not seem to scale well to large data sets because of the need to repeatedly solve a combinatorial optimization problem with a search space exponential in the number of centroids.
1.3. Application in materials physicsWe apply RBFN’s to a materials physics data set that describes a subset of parameters for a kinetic Monte Carlo (KMC) model for surface diffusion in copper (Kimari et al., 2020a, Kimari et al., 2020b). In the KMC model, diffusion is interpreted as a series of atomic migration events that have rates Γ defined by their energy barriers Em: (1)Γ∝exp−EmkBTwhere kB is the Boltzmann constant and T is temperature. The barriers in turn are defined by the configuration of atoms around the migrating atom. There are methods for computing the barriers that correspond to different local atomic environments of the event, but problems arise from the vast number of the environments. Computing the barriers accurately is computationally expensive, so either the accuracy or the number of different barriers has to be compromised for parametrizing the KMC model. Machine learning offers a way to interpolate and extrapolate barrier values based on the incomplete data set of calculated barriers.The input data assumes a perfect crystalline structure, where variation only occurs in the occupation of fixed lattice sites—either an atom sits at the site indexed i, or not. Hence, the input data can be losslessly converted to a binary sequence of occupation numbers at lattice positions. The local atomic environment that is assumed to affect the migration energy barrier is extended up to the second nearest neighbors of the migrating atom. In the face-centered cubic copper lattice, this comprises 26 lattice positions.From Machine Learning perspective, we observe a regression or function reconstruction problem, where the input features are 26-dimensional binary vectors and the response variable is a real-valued energy barrier in eV. The data set does not span the entire 26-dimensional input space, that in principle has 226≈67
  million possible values; even setting aside to computational cost of calculating such an immense amount of migration energy barriers, there are other challenges related to finding all of these barriers in crystalline surface systems (Baibuz et al., 2018). In any case, it is necessary to interpolate or otherwise estimate the barriers for the missing input values, and machine learning is a promising approach to accomplish this. Were there a need to introduce another element into the parameterization in addition to Cu, the input space would suddenly grow to have 326 possible values; likewise, expanding the local atomic environment to include third nearest neighbors would grow the dimensionality itself from 26 to 58. For input spaces like this, the only option is to use a method that is capable of generalizing from a small subset of all possible inputs.The large RBFN’s trained to the migration barrier data are then pruned, and the input-associated weights are revealed to contain patterns that correspond to physically meaningful three-dimensional symmetries, even though the networks only ever saw the “flat” binary representations of the atomic environments.
1.4. Structure of this articleThe rest of this article is structured as follows: In Section 2, we describe our gradient-based approach for training and pruning RBF networks. In Section 3, we report experimental results both on toy data and on a materials physics data set. Finally, we summarize our results and discuss future directions in Section 4.
