Deep learning has aided significant progress in solving various computer vision tasks such as object classification [1], [2] and object detection [3], [4]. The solution of more semantic tasks such as visual question answering [5], [6] and image captioning [7], [8] has also seen progress lately. A challenging problem that extends these is that of maintaining a dialog with a user [9], [10] In this case, a system is required to maintain context concerning the history of the conversation while answering a question and this is be more challenging. A specific task in the visual context is that of the ‘Visual Dialog’ task [10]. The aim here is that given an image, we need to train an agent to maintain a dialog. The motivation for this emerges from an interest in developing associative technologies for visually impaired persons or chat-bot based dialog agents. Several methods have been proposed for solving the task, such as using various discriminative and generative encoder-decoder frameworks that aim to solve the task of generating dialog  [9], [10]. In this paper we aim to extend the previous approaches by formulating a probabilistic approach towards solving this task. This approach is illustrated in Fig. 1. Through our approach we can obtain a principled model that we can train end-to-end while being able to have uncertainty estimates and the ability to evaluate and explain the model. Such an ability to explain the model is crucial, especially, when we consider that the method could be used by visually impaired people. At any point in the method, the model can be probed to ensure that it is certain about the answers that it generates and more importantly any failure of the method can be addressed by explaining the precise reason for failure as shown in 2. However, as the task is challenging it is important to have an insight into obtaining estimates regarding the uncertainty of the model. This would aid in knowing when the method is confident about its prediction. In this paper, we consider the task of understanding the uncertainty while solving the ‘Visual Dialog’ task, as shown in 2. This proposed method addresses the limitations of the previous approaches as the previous approaches do not have the ability to obtain uncertainty estimates or obtain diverse conversations.Download : Download high-res image (478KB)Download : Download full-size imageFig. 1. Proposed Probabilistic Diversity and Uncertainty Network (PDUN) consists of three parts, viz. a) Probabilistic Representation Module encodes image feature with a question and history feature in an attentive manner. b) Diversity module captures the diversity, and diverse answer is generated using Variational Auto-Encoder. c) Uncertainty module predicts uncertainty of the network.Download : Download high-res image (673KB)Download : Download full-size imageFig. 2. Results were showing the certainty of the correct class increases from baseline [9] to our proposed uncertainty model (PDUN). In this figure, we show the top 2 class confidence score of the question, ”Is this a park?”. In the baseline model focus on woman, guitar and chair and predicts ”NO,” which is confused with the correct prediction of the answer, whether it is a park or not. PDUN model minimizes the uncertainty and predicts the correct answer ”Yes” with a high confidence score.
Our method consists of the following parts:
•Probabilistic Representation Module: Through this module, we obtain probabilistic representations for image, question, and history of the conversation using Bayesian CNN and Bayesian RNN modules.•Diverse Latent Answer Generation Module: In this module, we use a variational autoencoder based latent representation that allows us to obtain latent representations from which we can sample answers.•Uncertainty Representation Module: In this module, we propose a Reverse Uncertainty based Attention Map (RUAM) method by using Bayesian deep learning methods that allows us to minimize data uncertainty and model uncertainty.
To provide an overview of the technical contributions we make, the main idea is to consider incorporating a Gaussian prior for generating samples of answers. We minimize the KL divergence between the prior and the posterior distribution. The other contribution is to explicitly incorporate a loss to ensure that the correlation between different samples is minimal. We further use these losses along with a loss to minimize the uncertainty. A similar loss has been considered in another context by Patro et al. [11]. In this work we are interested in a principled framework for minimizing uncertainty by sampling and generating diverse answers. Moreover, its use has not been considered for the problem of visual dialog. We evaluate each of the contributions in our work. The technical details mentioned here are discussed further in detail in the following sections.
Deep models are usually not interpretable. They are more like black-box models. Due to the lack of transparency, it is difficult to trust the model. We propose a probabilistic method to estimate the uncertainty for the problem of maintaining a dialog with respect to an image, termed the ‘Visual dialog’ task. In this model, we use gradient certainty based attention model that also improves confidence in the prediction. Using this probabilistic model we do have an improvement in the state of the art results. Moreover, we gain in terms of interpretability by having uncertainty estimates and are also obtain diverse predictions. We have evaluated our method based on the standard matrices as mentioned the visual dialog dataset paper [10]. We observe that, we obtain an improvement in terms of @R10 score around 10% from the baseline ‘Late Fusion’ [10] model & 3.5% from the State of the art (NMN  [12]) method. We also obtain an improvement in terms of NDGC score 9% from base model & 0.5% from State of the art (SOTA) model and in term of MRR, 7% from the base model & 1% from SOTA (NMN  [12]) model using our proposed method.
To summarize, the main contributions of this paper are as follows :
1.We provide a module to obtain a probabilistic representation for image, question and conversation history that are obtained as input.2.The probabilistic representations are used to generate diverse latent representations for candidate answers3.We propose a method for obtaining reverse uncertainty based on attention maps (RUAM). These allow us to select an appropriate answer that minimizes uncertainty.4.We provide extensive analysis and comparison of our framework with previous methods and evaluate the various ablations of the method. Our proposed framework improves recall@10 score by 3.5%, mean reciprocal rank (MRR) by 1% and NDGC score by  1%. Moreover, we also provide estimation & visualization of the uncertainty of the output.
1.1. Problem statement: Visual dialog taskThe visual dialog task requires an agent to be able to respond to a conversation in the context of a visual input in terms of an image. The idea can be thought of as a visually impaired user having a conversation with an AI agent. The concept of visual dialog task has been posed in two different variants. In the first variant, during training, we train a single agent, that is provided a history of previous rounds of conversation (9 rounds) consisting of question and answers. In the end, the agent is asked a question and has to answer it as a classification task. This consists of training a single bot with an image, a conversation history and a query as input and the task is to classify the output answer as shown in Fig. 3. The test setting is similar. In the second variant, there is a question generating bot ‘Q-bot’ and an answering bot ‘A-bot’ both of which are trained. There is a reinforcement learning game between Q-bot and A-bot where they play various rounds of question and answer. At the end, the Q-bot has to guess the image that the A-bot is referring to from a set of images. We have considered the uncertainty estimates for both these models as shown in Fig. 2.Download : Download high-res image (402KB)Download : Download full-size imageFig. 3. This figure explains the Visual Dialog Task. Left side of the figure explains about, given image I, Dialog History, H and the follow-up question Q, the model needs to predict a set of candidate answers A. The right side of the figure provides visualisation of the task.Visual dialog task is introduced by [10]. The visual dialog task is defined as, given image I, a caption C, a dialog history till t−1rounds, H={C,(q1,a1),….(qt−1,at−1)}and the following question qt at round t. The objective of the visual dialog agent is to predict a natural language answer to the question qt as shown in Fig. 3. The visual dialog problem can be solved into two possible ways; one is by using a generative model and the other by using a discriminative model. In a generative model, given the embeddings of image, history, and question(qt), a generative model is trained to maximize the likelihood function to predict ground truth answer sequence. The discriminative model receives embedding of an image, history, and question(qt) along with 100 candidate answers At={at1,…at100}and effectively learns to rank the list of candidate answers.One aspect of previous approaches tends to be a lack of diverse generations of answers; for instance, the tendency to correlate the animal ‘zebra’ with black and white stripes. In contrast, during conversations, a conversation is interesting if an unexpected or novel observation is raised. In our method, we hope to produce such insights. To do that we need an ability to characterize the space of all possible answers. We do that by using a Gaussian prior for the generation of answers. This allows us to generate samples of plausible answers. We then further use a diversity loss that would penalize correlations between the multiple samples. The final task then lies to choose an appropriate retort or response. To do so, we rely on minimizing uncertainty while generating the answer. We now consider the proposed approach in detail in method section.
