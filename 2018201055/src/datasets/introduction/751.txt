Semantic segmentation is a fundamental technique in the field of computer vision [3], [7]. Its goal is to assign a label to each pixel in the image. The result of it can provide a comprehensive description of the surrounding scenes, including object categories, locations and shapes [[9], [40]]. It is of broad interest for many applications, such as autonomous vehicles, robotics, and human-machine interaction [6], [10].
A challenge that exists in the task of semantic segmentation is how to tackle objects at varying scales [1], [2]. Currently, there are several predominant methods that are proved to be effective for dealing with this problem [[16], [17]]. One classical way is to rescale input images into multiple scales and put these rescaled versions into the convolutional neural networks. Through fusion of the intermediate feature maps or final score maps, features of all the versions can complement each other and thus form feature maps with more comprehensive semantic information. Though this kind of method indeed gets the performance of the networks enhanced, such improvement is achieved at the cost of dramatically lowering the efficiency of the whole system [[18], [33]]. First, the input image needs to be resampled multiple times before being imported into the networks. Second, each resampled image needs to go through the whole network once. During this process, the responses of each intermediate layer are repeatedly computed. Such inefficiency is not desirable in practical scenes, especially those requiring real-time predictions. Therefore, how to fuse the multi-scale features at the same time of not bringing about too much computation cost becomes a topic in the research of semantic segmentation [[35], [38]].
To remedy this situation, a method based on Fully Convolutional Networks (FCN) [8] is developed, in which there are usually several skip connections between different intermediate layers of the backbone classification network. As feature maps of different intermediate layers own various semantic levels and receptive fields, the fused feature maps through the skip connections simultaneously contain contextual information collected in different scopes which can match the requirements of comprehensively describing objects with different sizes. The effect of this amounts to the method mentioned above in which the responses of the same layer are repeatedly computed when different resampled images are input.
Another line of methods aims at improving the efficiency of segmentation networks via utilizing the ASPP module. Inspired by the idea of the spatial pyramid pooling, Chen et al. [11] designed the ASPP module to more efficiently tackle this challenge. This module is composed of four parallel atrous convolution layers with different dilated rates. Features maps of each atrous convolution layer encode semantic information abstracted from different receptive fields, and all these feature maps are merged to form a final comprehensive representation of the semantic information of the whole image. The four parallel atrous convolution layers in ASPP can achieve the effect which is equivalent to probing the input image with multiple filters that own different receptive fields. With the ASPP module, the resampling process of classical methods can be avoided, and the efficiency of the whole system can be significantly improved.
Though ASPP can raise the system efficiency, it still causes another two problems at the same time when applied to practical scenes. As mentioned above, the receptive fields of the four parallel atrous convolution layers are complementary to each other, which can guarantee that the information distributing in different scopes can be sampled. With the information from different scopes, the segmentation network can have the ability to tackle objects with sizes varying in a particular range. However, such a distribution of sampling ranges cannot ensure that the information (e.g., global features and context priors), which is exploited as the key clues to predict the label of target objects, can be contained in the sampling ranges. This is caused by two reasons. One is that the diversity of the sizes of the objects in practical scenes is much larger than that of the sampling ranges of ASPP. This means that only objects with the same sizes as those of kernels of ASPP can be sampled while information of other objects cannot be collected. The other is that distribution of objects in the image is arbitrary. Some objects are so far from the scopes covered by the convolution kernels of ASPP that the features they contain cannot be sampled. In a word, such limited variety of sampling ranges of ASPP cannot sufficiently collect information distributed in various ranges in the image.
Additionally, to avoid bringing too much extra computational load, all the points inside of the convolution kernels except for the nine effective sampling points are filled with zeroes. This measure would lead to that as the convolution kernel samples the information surrounding a particular pixel, local delicate features that correspond to the positions with zeroes in the convolution kernels cannot be collected, which may end up with the situation that these delicate features are disregarded in the final result.
To overcome the above drawbacks of ASPP, a new Cascaded Hierarchical Atrous Spatial Pyramid Pooling (CHASPP) module is proposed. Compared with the structure of the single level of the atrous convolutions in ASPP, a hierarchical structure consisting of several levels of atrous convolution layers is adopted. This structure can densify the sampling distribution and sufficiently capture important local features. Apart from this, the stacked hierarchical structures can further enlarge the diversity of the sampling ranges and expand the scopes which our module can cover.
The contributions of our paper can be summarized as follows:
1) A new hierarchical structure consisting of multiple levels of atrous convolution layers is proposed. This structure can remedy the problem of the degenerated representation of local detail features caused by the hollow kernels of ASPP via increasing the sampling density.
2) A novel Cascaded Hierarchical Atrous Spatial Pyramid Pooling (CHASPP) network which contains cascaded hierarchical structures is proposed. Through such a stacked module, the variety of receptive fields can be significantly enlarged compared with ASPP, which can guarantee that global features and contextual information are extensively collected to make a more reasonable and accurate prediction.
3) Experimental conducted on PASCAL VOC 2012 [10] and Cityscape datasets convincingly demonstrate the performance of our network in preserving local detail features and collecting global contextual information distributing in various areas of images.
