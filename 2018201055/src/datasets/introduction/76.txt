Weakly supervised learning (WSL) refers to methods that use only incomplete annotations to train predictive models. Over the last few years, WSL of convolutional neural networks (CNNs) has emerged as a new practical learning framework for various computer vision applications; for example, multi-label image recognition [1], [2], image segmentation [3], object localization [4], [5], and object detection [6], [7]. The performance of fully supervised learning in these applications currently exceeds that of WSL; however, annotation in fully supervised learning [41], [42] is labor-intensive and time-consuming. This fact motivates us to explore methods for weakly supervised computer vision applications.
Although a large number of weakly supervised models have shown promising results, most treat the labels in the image independently. They fail to capture the necessary semantic relations between labels. Whether in the real world or in an image, the co-occurrence of different objects is statistically significant [8], [9]. Consequently, we hypothesize that the semantic label co-occurrence in the input image can provide valuable evidence for image classification and pointwise localization.
Graph convolutional networks (GCNs) [10], [11] have been demonstrated to be useful models for capturing semantic relations between labels in an image. An advantage of GCNs over other methods is the ability to learn the global correlations between labels, which must be acquired from knowledge beyond a single image.
In this paper, we propose a new WSL framework for recognizing and localizing objects in an image. Inspired by ML-GCN [11], we introduce the graph convolutional network to model the label dependencies. Since we combine WSL with GCN, we call the resulting model a WSL-GCN. Weakly supervised learning is effective in preserving the local features of the image. Compared to ML-GCN [11], our model can further capture the relations between semantic labels and local image regions, which can benefit both classification and localization.
In Fig. 1, we present a graphic overview of the differences in network architecture between our WSL-GCN and ML-GCN. The image features in the WSL-GCN pass through the global max pooling process and are then used in the next operation with the label embedding. Through the global max pooling process, the three-dimensional feature tensor is transformed into a two-dimensional matrix by dropping the spatial dimension. Thus, the GCN in the WSL-GCN can effectively capture the correlations between object labels; however, the model ignores the location information of the image features. Contrary to this work, our model first calculates the image features and label embedding directly. In this way, both location information and label co-occurrence are preserved in the feature maps. Our model then uses top-k-max pooling to implement multiple-instance learning, which enables the selection of relevant regions from the image-level label. Thus, the selected region features, together with the label embedding, support the final classification. All components (the feature extraction part, the GCN-based part, and the multiple-instance learning part) of our model are trained together in an end-to-end manner.Download : Download high-res image (468KB)Download : Download full-size imageFig. 1. Differences in network architecture between ML-GCN and our WSL-GCN. In our model, the GCN is designed before pooling, supporting label dependencies to participate in the conversion of features at all locations of the image. This is impossible for ML-GCN because global max pooling has lost location information.
Experiments on the PASCAL VOC 2007, PASCAL VOC 2012, Microsoft COCO, and NUS-WIDE datasets show that our approach outperforms existing state-of-the-art methods for both multi-label image recognition and weakly supervised point-wise localization. Moreover, qualitative results and visualization show that the label embedding learned by our model provides an exact co-occurrence dependence of objects.
The main contributions of this paper are summarized as follows:
1.We propose a new deep-learning framework, WSL-GCN, which can leverage object label interdependence for WSL. The framework first tries to combine the benefits of weakly supervised convolutional architectures and GCNs for learning class-specific representations for the image. Then it uses the image-level label for label embedding fine-tuning and for recognition model learning. We empirically demonstrate that this parallel end-to-end training is feasible.2.We extend the GCN proposed in ML-GCN [11] by a novel initialization method of label embeddings for interrelationships learning, resulting in higher classification and localization performance and reduced over-fitting3.We present a detailed experimental evaluation using four challenging datasets. Our proposed method achieves superior performance over previous approaches, which highlights the importance of training deep CNN models from weak annotations and label dependencies.
The rest of the paper is organized as follows: Section 2 introduces related works. Section 3 presents the WSL-GCN framework and explains the design of each step in detail. Section 4 introduces the process of training and inference. Section 5 and 6 present the experimental result, and Section 7 concludes the paper.
