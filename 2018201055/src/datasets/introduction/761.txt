Neural network compression and acceleration are main research directions to facilitate deep learning into practical application. The performance of evolving deep learning methods surpasses humans on more and more specific tasks, such as image segmentation, tracking, machine translation, etc. Intelligent compositions are widely used in media systems. In [1] and [2] we can find an analysis of recent trends in Machine Learning (ML) approaches for various aspects or applications. On the other hand, current needs of data processing are high demanding therefore even for modern architectures methods which will simplify the data and processing are much expected. In [3] was proposed to use spectral matrix decomposition for motion artifacts detection. Graph embeddings were used to reduce dimensionality of the data, what gave very good results in face and handwriting recognition as presented in [4]. Other approach is feature fusion, as discussed in [5] this idea can boost metric learning models. While in Visual Question Answering (VQA) very often are used words representations [6] and reduction procedures for tensor feature space processing [7]. However in VQA most advances are based on neural networks processing. As the most popular classical neural networks implement recognition processes, Convolutional Neural Networks (CNN) have established visual perception model of the human eye, and Long Short Term Memory (LSTM) neural networks were developed to simulate associative memory functions of the human brain. However, convolution and fully connected layers as basic elements of the above neural networks, which have the number of parameters prohibitive when consider them into real time application. When complex applications orientate on mobile device, to take both CNN and LSTM as collaborative model, it is necessary to compress each of them to have real time system for various application scenarios. As the mostly nearly complete Artificial Intelligence, Visual Question Answering takes CNN and LSTM to extract different features, in which CNN is required to process image features with significant spatial characteristics, while LSTM is used to process text with temporal characteristics. The output of the VQA is formed as a fusion of both results by adequate neural networks. Such multi-tasking and multi-modal systems need more models, so the storage and computing requirements become significant. Therefore, the collaborative compression of multiple models in VQA system is the key link between multi-modal input and multitasking system. Many prior works were devoted to compression and acceleration of typical elements on simple tasks and achieved super performance on toy dataset or validate datasets. Our motivation is to seek an effective compression and acceleration solution which work well on complex system and keep the best performance, furthermore, propose a paradigm which can be used in mostly typical neural networks.
