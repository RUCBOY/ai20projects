Recently, dialogue systems have attracted increasing attention in both academia and industry because of their potential applications and commercial values. Sequence-to-sequence (Seq2Seq) models form the cornerstone of popular dialogue generation models (Serban, Sordoni, Bengio, Courville, Pineau, 2016, Sordoni, Galley, Auli, Brockett, Ji, Mitchell, Nie, Gao, Dolan, 2015, Shang, Lu, Li, 2015). However, neural dialogue systems based on Seq2Seq models tend to repeatedly generate universal and boring responses like “I don’t know.”, “Thank you.”. Although widely applied, conventional Maximum Likelihood Estimation (MLE) training could cause the low-diversity problem above (Li et al., 2016b). Since high-frequency words make up a big proportion of the training set, MLE encourages the model to excessively generate high-frequency words.
Moreover, when training a Seq2Seq model traditionally, we iteratively maximize the log predictive likelihood of each true token in the target sequence, given the previously decoded tokens. Therefore, the model can only see the previous information during learning, unable to grasp the holistic information of the target sequence when decoding tokens. This also leads to the loss of a complete semantic relationship between target sequences and source sequences.
As discussed, we argue that the current learning strategy heavily limits the Seq2Seq models to generate highly diverse responses, and the holistic semantic information of the target response, as well as the global semantic relationship between responses and dialog histories, are missing during the generation process. Most previous solutions simply rely on external information or post-processing models to mask the deficiencies of the Seq2Seq model, while the problem of the Seq2Seq model itself has not been addressed. Therefore, in this paper, we hope to fully exploit the learning potential of the Seq2Seq models without any external information to improve diversity while better to constrain the semantic relevance of generated responses simultaneously. We propose a Holistic Semantic Constraint Joint Network (HSCJN) for model training to predict the subsequent word set in each target utterance for direct supervision in decoding, which directly introduces more linguistic information from target utterances to increase diversity. More specifically, during the training stage, we require each hidden state in the decoder to predict the words in the target utterance which remain ungenerated, and the initial state of the decoder is required to predict all the words in the target utterance. Since the HSCJN enables the decoder network to see all words in the target utterance at every time step, our model also more likely captures direct semantic information such as keywords in target utterances to enhance relevance.
In this way, the relationship of representation spaces between source sequences and target sequences, and the transition between different decoder states could be better constrained. In addition, we consider that the entropy of the output distribution is low if the model is over-confident about high-frequency words. Penalizing the low entropy output distribution can help regularize the model, optimize the predicted output distribution and alleviate the over-estimation of high-frequency words. Therefore, we devise a maximum entropy-based regularizer. Our learning framework can be used as a general joint training method with Seq2Seq models and requires no additional data or annotation. In general, our contributions are summarized as follows:
•We devise a joint training network to introduce future information during the decoding stage in the open-domain dialogue generation task, which can be applied to any Seq2Seq neural model. Our network introduces more linguistic information from target utterances to increase diversity, and likely captures key semantic information such as keywords in target utterances to enhance relevance in a direct manner.•We regularize the model by penalizing low entropy output distribution at each time step in the decoder to alleviate the over-estimation of high-frequency words, which also enables the loss function to consider every word in the vocabulary to improve diversity.•The experimental results on multi-turn dialogue datasets show the effectiveness of our method in terms of both diversity and relevance of generated responses.
