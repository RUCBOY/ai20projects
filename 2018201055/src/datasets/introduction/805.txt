The human visual attention system intends to extract the most informative objects and regions in a scene, and then combines this local information to efficiently understand the whole scene. This kind of visual attention mechanism has prompted many researchers to stimulate this ability in computer vision tasks [61], [6]. Salient object detection (SOD) aims at finding the most attractive object(s) in a scene in order to simulate the functionality of the biological visual attention system [5]. In the past decade, remarkable success of deep convolutional neural networks (CNN) has been achieved in a large number of computer vision tasks. Due to their powerful generalization capability, deep CNN models have been developed and applied not only on image-level classification tasks [70], [36] but also pixel-level classification tasks[58], [110].
Concretely, fully convolutional network (FCN)-based encoder-decoder models have dramatically improved performance on pixel-wise image-to-image learning tasks, including semantic segmentation [58], [110], [12], edge detection [93], SOD [51], [82], [84], [108], and crowd counting [109], [49]. In essence, the trend of mainstream SOD methods developed in recent years indicates that most of them work under the encoder-decoder framework. Some researchers have developed structures based on encoder-decoder model for SOD task and achieved state-of-the-art performance [51], [82], [84]. Specifically, CNN-based encoder-decoder models play an important role in continuously updating the SOD performance on benchmark datasets [5]. Techniques, including multi-scale or multi-level structures [24], attention layers [51], etc., are also developed and introduced into SOD models.
However, an important issue is whether a generic routine exists to augment performance by determining which components are key factors under the encoder-decoder framework. To the best of our knowledge, an empirical study does not yet exist that thoroughly evaluates the performance of this kind of generic framework on SOD task. In this work, we focus on investigating the profound influence of the CNN-based encoder-decoder model on SOD, and providing an empirical study on the performance by applying encoder-decoder models to SOD task. Moreover, we also provide a literature review in terms of key components of the encoder-decoder framework on a broad range of pixel-level classification or regression tasks. According to our experimental results, baseline models and its variants composed of an encoder with ResNet [22], and decoders with pyramid parsing module (PPM) [110], atrous spatial pyramid pooling module (ASPP) [11], and feature pyramid network (FPN) [46], have been found. The new baseline models outperform state-of-the-art deep SOD models. To further understand these results, we performed a thoroughly ablation study on each key module and techniques, under the encoder-decoder framework.
The main idea of this paper lies in broadening the research exploration of SOD by introducing modules and techniques in other similar pixel-level dense prediction tasks of computer vision, such as semantic segmentation [11] and edge detection [93]. In particular, CNN-based encoder-decoder models have been widely used in semantic segmentation. In essence, the trend of mainstream SOD methods developed in recent years indicates that most of them work under the encoder-decoder framework. Some researchers have developed structures based on an encoder-decoder model for SOD task and achieved state-of-the-art performance [51], [82], [84]. However, no article has fully performed cross-domain module validation. Therefore, our paper aims at quantifying the model effectiveness by introducing key techniques into an encoder-decoder model and explore the possibility and potential network structures and learning strategies in developing a baseline SOD model, as well as provides some insights for researchers in SOD.
In this work, the reviewed papers largely cover topics including SOD, semantic segmentation, and the encoder-decoder model and its key techniques and sub-modules. We also noticed that several survey papers [5], [83] exist that review the literature with respect to SOD methods. Specifically, according to the literature review [5], [83] on CNN-based SOD models proposed in recent years, CNN-based encoder-decoder models play an important role in continuously updating the SOD performance on benchmark datasets. Other techniques, including multi-scale or multi-level structures [24], attention structures [51], etc., are also developed and introduced into SOD models. It can be observed that most of the techniques in SOD are inspired or derived from deep CNN-based encoder-decoder models for other similar tasks. Different to the above survey papers, in this work, we focus on solving SOD by leveraging deep CNN-based encoder-decoder models, and present a thoroughly empirical study on baseline encoder-decoder models and comparison of state-of-the-art deep CNN models for SOD on seven image-based benchmark datasets. In addition, the discovered new baseline models were further evaluated on three video-based SOD datasets in comparison to 18 state-of-the-art methods. Instead of limiting our survey to SOD methods, a broader view is presented from the perspective of fundamental architectures of key modules and techniques in CNN-based encoder-decoder models for pixel-level dense prediction tasks.
The remainder of this paper is organized as follows. In Section 2, we reviewed a large body of SOD models proposed in the deep learning era. It becomes a trend to construct CNN-based encoder-decoder models in SOD task for higher performance. The rationale behind techniques in each part of a component is highlighted, including backbone network with powerful generalization capacity, header structures for rich feature mining, attention structure for feature recalibration, multi-scale and multi-level feature integration structure for recovering the details of a salient object segmentation mask. Therefore, Section 3 further outlines the techniques in CNN-based encoder-decoder models for image-to-image learning task which is tightly coupled in similar tasks. Details of empirical study and experimental results on validating the efficacy of each key module are given in Section 4. Finally, in Section 5, we conclude the paper with directions for future work.
