Human pose estimation is an active visual research topic with decades of history. It refers to recognizing and locating the keypoints (e.g., ankles, knees) of each person in an image. The classical methods to solve the problem rely on handcrafted features mainly adopt tree-structured [22] or graphic model [3] technology. With the rapid development of deep learning, the prediction accuracy of pose estimation has been dramatically improved. Nevertheless, current pose estimation approaches are unfriendly to resource-limited devices like smartphones. In this paper, we are interested in the destination of the low computational-cost network for human pose estimation.
At present, many methods adopt the design of the multi-stage network, which usually constitutes of repeated encoder-decoder architecture. All the stages are supervised simultaneously to facilitate a coarse-to-fine, end-to-end training. This kind of network has sufficient scale information but also suffers from high computational cost. On the other hand, the single-stage architecture refers to the network with a backbone and pose network, which usually uses the standard backbones from the classification task, such as ResNet [8], VGG [18]. Therefore, this kind of network is generally more elegant and has better scalability.
Some studies [23], [16] have shown that multi-scale supervision and coarse-to-fine refinement process of the multi-stage network are helpful for pose estimation. However, these characteristics have limited the design of network architecture to some extent. In particular, multi-scale supervision often requires the output of the intermediate stage to be the same size to fit in the heatmap of ground truth, while the coarse-to-fine refinement requires the network to provide various receptive fields from different stages. To well integrate these characteristics into the single-stage network, we propose a novel architecture, i.e., deep supervision pyramid architecture. As shown in Fig. 1, it generates branches at different parts of the backbone instead of repeated encoder-decoder architecture to produce various receptive fields output. Moreover, we take a deep supervision strategy; in other words, we only use the intermediate output during training. Finally, thanks to weight sharing through the final layer of each branch, we could maintain the multi-scale acquisition capability with only one branch during inference, so the network can still retain the elegant single-stage architecture. Experiments show that the proposed architecture can achieve stable accuracy improvement compared with the similar single-stage network Simplebaseline [24].Download : Download high-res image (169KB)Download : Download full-size imageFig. 1. Illustration of the proposed DSPNet, which is a multi-branch architecture with deep supervision. During the training, the weights of the final layer were shared so that the information of different scales could pass through the same feature space to improve the networkâ€™s perception of multi-scale information. When the training is completed, we take the final branch as the prediction branch to retain the simple architecture.
In addition, since the high spatial resolution is required for pose estimation, bilinear interpolation or transposed convolution is usually appended after the backbone network to recover the spatial resolution of deep features. Transposed convolution is better at decoding than bilinear interpolation, but the computational burden of transposed convolution makes it not directly applicable to the design of lightweight networks. Therefore, we design a lightweight up-sampling unit (LUSU), which can avoid expensive computation costs while retaining high estimation accuracy. Firstly, we apply the depthwise separable strategy to transposed convolution for low computational overhead. Secondly, to keep the accuracy unaffected, we introduce channel-wise and spatial attention blocks to make the up-sampling unit pay more attention to effective information at the channel and spatial level. In particular, the spatial attention block is a simplified version of non-local attention from the Sagan [27] called a lightweight self-attention block.
In summary, this paper has two main contributions. At first, we design a lightweight up-sampling unit that integrate separable transposed convolution, channel-wise attention, and lightweight self-attention. It can achieve desirable results while reducing the parameters of transposed convolution. Secondly, we design a deep supervision pyramid (DSP) architecture, which skillfully introduces the idea of multi-scale supervision and coarse-to-fine refinement into the single-stage network. As a result, it achieves steady improvement over the original SimpleBaseline without any compromise to inference speed.
To verify the effectiveness of the proposed method in the balance of computational load and prediction performance, we carried out experimental comparisons with state-of-the-art approaches on two common benchmark datasets, i.e., MPII Human Pose dataset [1] and MS COCO dataset [14]. Experiments have shown that we have a low computational load while keeping comparable accuracy.
