Clustering, which divides a set of unlabeled data into different groups by collecting similar samples together, is one of the most fundamental statistic learning methods. In the past decades, clustering methods have been successfully applied into several areas, such as image retrieval [1], [2], [3], [4], [5], [6], [7], [8], bioinformatics [9], [10], [11], and text analysis [12], [13], [14], [15], etc. In those areas, data points are often formatted as matrix in which the columns represent features and the rows represent samples, or vice versa. Therefore, each sample can be seen as an input data characterized by a vector in the feature space, while each feature can be regarded as a vector spanned in the sample space. In clustering problem, most of traditional methods are designed for one-side clustering, i.e. only perform the clustering algorithm in the feature space or in the sample space solely.
However, in some types of data, such as the document-by-word matrix data in document analysis and the gene expression data in gene analysis, there is a dual relationship between the features and samples, i.e., the feature clustering result and the sample clustering result are dependent on each other [13], [16], [17], [18]. For example, in the document-by-word data, it is reasonable to assume that the documents are clustered according to their relations to the word clusters, and the word clusters are also calculated by the connections to the document clusters. For those types of data, one-side clustering methods ignore the duality between the samples and features. To take advantage of the dual relationship, co-clustering (also referred as biclustering) methods are proposed. Due to the usage of the duality between samples and features, co-clustering mechanisms achieve better clustering performance and make the clustering results more interpretable than the one-side clustering methods.
In the past decades, many co-clustering methods have been proposed to characterize the relations between samples and features. Among these methods, the bipartite spectral graph partition (BSGP) approach and its variants are the most well-known ones [13], [16], [19], [20], [21]. They can not only be used for the co-clustering task but also for the fast spectral clustering tasks [22], [23]. BSGP depicts the relations between samples and features as a bipartite graph, and translates the co-clustering task as bipartite graph partition. As shown in Fig. 1(a), the nodes in the upside row represent samples, and the nodes in bottom row represent the features. The weights of edges between two parts of notes represent the affinities between samples and features. By partitioning the constructed bipartite graph, features and samples can be clustered simultaneously. Generally, the objective of the BSGP is formulated as minimizing normalized cuts (Ncuts) which is a widely used optimization model for graph partition.Download : Download high-res image (229KB)Download : Download full-size imageFig. 1. Illustration of partition of the bipartite graph. (a) The bipartite graph constructed by the data matrix X; (b) The illustration of data matrix X after permutation of rows and columns according to the co-clustering results.
However, traditional solutions for finding the minimal Ncuts need to use the singular value decomposition (SVD). The computational complexity of the SVD is about O(n2m) [24], where m and n are the numbers of samples and features, respectively. Thus, when the volume of the data collection is big or the feature dimension is high, the procedure of SVD makes BSGP computationally prohibitive. It has severely limited the application range of BSGP in real world applications. In addition, BSGP relaxes the origin discrete minimal-Ncuts problem to a continuous one, and then uses the k-means algorithm to output discrete clustering result. In such discrete-continuous-discrete transformation procedure, the obtained optimization problem is much deviate from the original problem of BSGP, and the performance of BSGP would be damaged. Although the BSGP suffers those shortcomings, to our best knowledge, there are few works to cope with these problems to improve the algorithm of the BSGP.
Essentially, BSGP is a special spectral clustering algorithm on the bipartite graph model. Dhillon et al. [25] demonstrates that, when the adjacency matrix is non-negative definite, the spectral clustering algorithm is equivalent to the weighted kernel k-means (WKKM) which is solved by an iterative solution. Compared with the spectral clustering algorithm, the running time of WKKM is faster in the case that the similarity matrix is big and sparse. Therefore, the iterative solution of WKKM can be seen as a fast implementation of spectral clustering. Although the algorithm of WKKM is efficient, it can not be applied to the bipartite graph partition because the adjacency matrix of bipartite graph is not non-negative definite. However, the relationship between models of spectral clustering and WKKM inspires us to propose a fast implementation for BSGP, i.e., using the iterative procedure to replace the implementation of SVD.
In this paper, we propose a novel co-clustering method named weighted bilateral k-means algorithm (WBKM) to solve the minimal-Ncuts problem in bipartite graph. Compared with BSGP, the proposed method achieves much faster running speed and more promising result. Like weighted kernel k-means being the iterative solution of spectral clustering, the WBKM can be seen as the iterative solution of BSGP. Since the bipartite graph partition is also used to perform the fast one-side spectral clustering, we also apply the WBKM to improve the performance of fast spectral clustering. Lastly, we evaluate the proposed method on different types of datasets.
The work in this paper significantly extends [26]. Specially, compared with the conference version [26], the extensions in this paper are summarized as follows:
•The model named bilateral k-means (BKM) proposed in [26], is a special case of the WBKM proposed in this paper, with the assumption that the weight of each sample is set as 1.•The meaning of the relaxation strategy used in the deduction from BSGP to WBKM is more clear than that presented in [26]. We can claim that the WBKM is the iterative method for solving the minimal-Ncuts problem of bipartite graph.•The application range of WBKM is broader than that of BKM. Since the proposed WBKM can be used in any tasks involving in the minimal-Ncuts problem of bipartite graph, we not only employ the WBKM to undertake co-clustering tasks, but also apply it to perform the fast spectral clustering which is based on the bipartite graph partition.
Notations. Throughout this paper, the boldface uppercase letters represent matrices and boldface lowercase letters represent vectors.
Given a data matrix X∈Rd×n, in which (i, j)-element is denoted as xij, the ith row is denoted as xi., and the jth column is denoted as x.j. Therefore, X can be written in two types, i.e., X=[x.1,…,x.n] or X=[x1.T,…,xd.T]T. Other matrices appearing in this paper also have two types of writing form like this.
The columns {x.i}i=1n represent samples and the rows {xi.}i=1d represent features. In this paper, we assume that the feature clusters and sample clusters have the same number, i.e, c. The feature clusters are denoted as {Ωl}l=1c and sample clusters are denoted as {Θl}l=1c.
Two partition matrices P ∈ {0, 1}d × c and Q ∈ {0, 1}n × c are utilized to represent clustering results of features and samples, respectively. If the ith feature xi. belongs to cluster Ωj, pij=1, and if the ith sample x.i belongs to cluster Θj, qij=1. In P or Q, each row, i.e., pi.(1 ≤ i ≤ d) or qi.(1 ≤ i ≤ n) has one and only one element equal to 1 which indicates the cluster membership of the ith feature or the ith sample, and the rest elements are 0. Therefore, we call such type of matrices as indicator matrices, and denote the set of them as Φ, thus P ∈ Φd × c and Q ∈ Φn × c.
