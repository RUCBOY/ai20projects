In many fields, an instance will be described with various modalities. For example, the fingerprint, face and iris are usually used for a person identification; LBP and SIFT are applied to measure an image. These types of data are generally named multi-view, multi-modal or multi-source data [1]. Its corresponding multi-view learning [2], [3], [4] which regards multiple views as the inputs has shown that exploiting multi-view data contributes to the performance improvement in contrast to the traditional approaches [5], [6], [7], [8], [9]. Being similar to many works, we concentrate to propose a novel multi-view method for classification [10], [11], [12].
A main focus for methods of multi-view learning is to extract the correlation of multiple inputs, which is ignored by the single-view based strategies. Combining different views to be a single one is a straightforward strategy. Then some traditional classifiers, such as KNN and SVM, can be utilized to classify it. Although this method is simple to be implemented, the relationship in distinctive views is unconsidered, and it may be easy to encounter the phenomenon of overfitting under the case with large feature-dimensionality but small training-number. Thus, in multi-view learning, a general assumption is that multiple observations can be projected to a common subspace or are the projections from the shared or similar variables by using view-specific transformation or projection functions. A classic approach is called Canonical Component Analysis (CCA) [13] which transforms a pair of inputs onto a shared subspace, through which their correlation enjoys the maximization.
Although many algorithms have been studied for multi-view learning, most of them estimate the transformation functions linearly, which cannot fully and powerfully model the distribution of the real-world data. To tackle this problem, [14] and [15] etc. introduced the deep network [16], [17], [18], [19], [20], [21] to get the better data modeling. However, they are limited to the requirement of a large number of training samples, which may be not available in some applications. In other words, when training number is relatively small, [14] and [15] would encounter the over-fitting, meeting the performance degradation. Different from these existing works which estimate the parametric or deterministic projections, GPLVM [22], [23], [24], [25] as a non-parametric strategy is quite suitable for the set with a few of training samples and has achieved a satisfactory performance in many applications, e.g., dimensionality reduction [26], classification [27] and cross-modal retrieval [28], etc. GPLVM based multi-view learning approaches aim to estimate a common manifold subspace, in which the fused latent variable is computed and it follows the assumption that this variable can generate multiple observed inputs by meeting the Gaussian Process prior. Despite that GPLVM based methods are superior to other existing multi-view learning methods, they still encounter a key problem: how to get the fused variable if a testing instance is input. GPLVM only takes the assumption from the latent variable to multiple views into account, being intractable to compute the transformation from the given data to the latent variable in the testing phase. A straightforward technique is to jointly input the training and testing samples into GPLVM based methods and learn the latent variables in an unsupervised way. However, this technique would cost a lot of time and is unable to utilize the supervised knowledge which is valuable for classification. No matter that Lawrence et al. [29] proposed a back constraint regularization to tackle the aforementioned problem, only a matrix is computed to simply transform the observed input to the subspace, like the study in [30], being remarkably different from the Gaussian Process structure. Fortunately, Li et al. [31], [32], [33] proposed an auto-encoder GPLVM structure which takes a GP based back constraint into account. Thanks to this structure, the latent variable corresponding to a testing instance can be simply attained. However, this approach only exploits the specific kernel function for each view, failing to reveal the shared correlation in the back projection. In these multiple observations, generally, the distance between each pair of points is relatively similar in each view. Thus, the view-specific kernels is not enough for fully utilizing this kind of information. Also, in [31], [32] and [33], Laplacian and SVM priors are respectively embedded into the model to achieve the discriminative task. However, this strategy would also introduce additional parameters that should be hand-tuned.
In this paper, a novel multi-view learning method under the GPLVM structure is proposed to simply but effectively get a testing instance associated latent variable. Being similar to [31], except for learning transformations from the subspace to the observed spaces, another transformation with the Gaussian Process prior is also taken into account, being capable of mapping multiple observations to the shared variable. However, differently, for this additional transformation, in particular, a view-specific kernel function is used to construct its associated covariance matrix and in order to reveal the relationship among various views, another kernel function with the shared parameter is estimated. We then get the covariance matrix of the distribution of the latent variable under the multiple observations by combining the view-shared and view-specific matrices together. Furthermore, in order to achieve the classification task, the supervised prior should be proposed to measure the latent variables belonging to different classes. Here, being similar to [34], we also assume that the shared variable can also generate the observed labels. Compared with some discriminative regularization such as LDA and Laplacian [30], [31], [32], this supervised strategy avoids introducing a human being tuned trade-off parameter. Since the transformations from and to the latent variable are asymmetric, we name our proposed method as Asymmetric Gaussian Process Multi-view Learning (AGPMvL). The pipeline of the presented approach is depicted in Fig. 1, in which the left part denotes the transformations from multiple views to the shared variable, and the right part denotes the transformations from the shared variable to observed views as well as the label. In detail, as we can see, an asymmetric gaussian process latent variable model is presented for multi-view learning. Despite the transformation from the shared variable to various views, we also jointly consider the transformation from the multi-view inputs to the shared variable, which encourages us to attain the shared variable simply if a testing instance is given. In this transformation, specifically, the view-specific and view-shared kernels are jointly utilized to establish the covariance matrix, fully exploiting the correlation across different views.
The organization of this paper is shown as follows. The related works about multi-view learning and GPLVM methods are briefly described in Section 2. Our proposed method AGPMvL as well as its optimization and inference are analyzed in Section 3, followed by the experimental analysis in Section 4. This paper is finally concluded in Section 5.Download : Download high-res image (381KB)Download : Download full-size imageFig. 1. The framework of the proposed method. Here a same object is represented with the image and text. In the left part, a projection with the Gaussian Process prior is learned to map the multiple views to a shared and latent variable. Note that different views in this part enjoy the view-specific and view-shared parameters. In the right part, another types of transformations are learned to transform the shared variable to each view and the projections also enjoy the Gaussian Process prior. To further exploit the supervised information in the training phase, the ground-truth label is introduced which is generated from the latent variable through a Gaussian Process mapping function.
