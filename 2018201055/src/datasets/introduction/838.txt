Several mechanisms are involved when humans interact with their environment, each making use of information from different sensing modalities, such as visual cues and proprioception(Scheidt et al., 2005). These sensory modalities serve the brain's monitoring system, which instructs, plans, and executes interactions (Ozkan and Pezzetta, 2018). Importantly, this monitoring is constant to ensure one's perceptions of their surroundings are continually updated (Singh et al., 2018) to match reality (Padrao et al., 2016, 2015). Should a change occur ‘mid-strategy,’ i.e., during the process of planning and executing an interaction, the result is a mismatch response known as cognitive conflict (Fan et al., 2003). The human brain makes predictions about the outcome of an interaction, continuously comparing perceived information to that prediction, and when the prediction fails to hold, conflict occurs.
Cognitive conflict was first discussed in an article by Donchin and Coles (1988) and republished in Donchin and Coles (2010). While there was no specific mention of event-related potential (ERP) related to an error, the work of Donchin and colleagues described P300 amplitude modulations due to changes in the environment. Later, Coull and Nobre (1998) showed that cognitive conflict causes one to redirect attention and reconfigure their initial plan, causing higher cognitive resources than non-conflict. In subsequent years, a first systematic experimental task was devised for cognitive conflict, known as the bimanual choice reaction task, which revealed that cognitive conflict causes a sequence of two types of ERP. First, the erroneous response causes an error-related negativity (ERN or Ne), which is a negative ERP typically peaking at around 50–150 ms (Falkenstein et al., 1991; Gehring et al., 1993). This is followed by error-related positivity (Pe) after the erroneous response begins, which typically peaks at around 200–400 ms. Since this discovery, several experimental scenarios have been developed to test and demonstrate ERN and Pe. These scenarios include tasks like the Eriksen flanker task (Eriksen and Eriksen, 1974; Kopp et al., 1996), the oddball task (Halgren et al., 1998; Squires et al., 1975), and the Stroop task (Stroop, 1935; West and Alain, 1999). Some other variants of ERN include feedback-related negativity (FRN) (Holroyd and Coles, 2002), and observational error, due to a person observing another person making an error (van Schie et al., 2004).
However, most of the experiments, protocols, and findings described above only pertain to passive one-dimensional (1D) or two-dimensional (2D) stimuli and cannot necessarily be generalized to a three-dimensional (3D) world. A realistic 3D input, for example, grasping a bottle on a table in front of you, adds significant complexity to an interaction task given the computations need to move one's body parts through space.
At the same time, realistic 3D interactions provide a window of opportunity to understand better the brain's monitoring function and how it conducts complex monitoring of the real world (Jungnickel and Gramann, 2016). One of the most basic 3D interactions is an object selection task (Argelaguet and Andujar, 2013). To grasp an object in the 3D world using the hand, the user is required to perform a set of complex movements that involve positioning their palm and fingers over the object. Our previous work with a 3D object selection task demonstrated that changing the selection radius of a virtual cube (leading to premature feedback of touching the object) could lead to a mismatch between the visual and the proprioceptive feedback, invoking cognitive conflict (Gehrke et al., 2019; Singh et al., 2020, 2018). We found the conflict reflected a form of prediction error negativity (PEN) that seems to belong to the same class of ERP as the ERN and FRN found in the studies mentioned above. Additionally, the results indicated that sensory integration plays an essential role in monitoring and producing ongoing actions, particularly for 3D object selection. Our findings also suggest that visual feedback dominated proprioceptive feedback in participants who completed the task in a short amount of time. We thus concluded that proprioceptive feedback is more important for slower movements. However, limitations in the experimental protocol did not allow us to analyze hand movement velocity and its role in integrating visual and proprioceptive information.
To overcome the limitations of our previous studies and to further investigate the role of movement velocity on the electrocortical responses to cognitive conflict, we designed an experimental protocol that manipulated hand movement velocity. Our intuition was that the velocity at which a hand moves does impact cognitive conflict processing in 3D object selection tasks. To test this hypothesis, we devised a task to measure hand movement velocity in tandem with brain electrical responses to cognitive conflict using two different sizes of the cube to invoke two kinds of hand movement velocity profiles. By manipulating the hand movement velocity, we manipulated the hand and arm movement of participants in different experimental conditions leading to differences in proprioceptive feedback. The concurrent processing of proprioceptive feedback and its comparison with the predicted feedback when an action is executed, is one major sensory source for controlling the accuracy of the movement itself (Desmurget and Grafton, 2000). Deviations of the proprioceptive feedback from the predicted movement feedback should thus contribute to error detection and the associated brain dynamic markers like the PEN.
