The use of photo-identification (PID) in animal research is well established and has been demonstrated to provide valuable information on individual animal movements, growth rates, and species population status (Riley et al., 2010). This is because natural markings and color patterns may both be stable over several life history stages (Carpentier et al., 2016; Van Horn et al., 2014), and unique to individual animals within a population (Gardiner et al., 2014; Vaissi et al., 2018), unlike physical tags or marks placed on individual animals by researchers. As a result, various PID techniques have been used to re-identify and track individual animals over time, including manual visual comparisons of photographs, and the use of a number of computer-assisted PID programs and processes. Several studies have used one or more of these techniques in work with terrestrial species, such as reptiles (Gardiner et al., 2014; Knox et al., 2013; Sacchi et al., 2010; Sreekar et al., 2013), felids (McClintock et al., 2013), ursids (Anderson et al., 2010; Anderson et al., 2007), African equids (Rubenstein et al., 2018), and rhinocerids (Jewell et al., 2001), as well as dozens of marine species, such as whale sharks (Graham and Roberts, 2007; Holmberg et al., 2008; Holmberg et al., 2009; Riley et al., 2010), sharks (Towner et al., 2013), whales (Blackmer et al., 2000; Frasier et al., 2009), seals (Karlsson et al., 2005), seadragons (Martin-Smith, 2011), lionfish (Chaves et al., 2016), and several marine invertebrates (Gallardo-Escarate et al., 2007; Gosselin et al., 2007; Raj, 1998).
PID in sea turtle research is relatively new and has only recently been reported as a useful tool for the identification and conservation of sea turtle species. Possibly the first use of PID in sea turtle research was reported in 1996 by McDonald and Dutton (1996) on matching unique pineal spots on the heads of leatherback turtles (Dermochelys coriacia). In 1998, Richardson et al. (2000) reported manually matching videos of green turtles (Chelonia mydas) in Hawaii with a small number (n = 93) of facial scale photographs. Recently, several sea turtle studies have also used manual visual matching of photographs to understand nesting female remigration patterns (Chew et al., 2015; Valdés et al., 2014), examine population sex ratios (Su et al., 2015) and long-term differences in intersexual survival rates (Schofield et al., 2020), investigate hatchling scale pattern stability over time (Carpentier et al., 2016; Chew et al., 2015), identify individual turtles in their foraging grounds over time (Dunbar et al., 2014; Lloyd et al., 2012; Schofield et al., 2008; Su et al., 2015), and estimate flipper tag loss (Reisser et al., 2008). However, for PID investigations using manual methods, both the time and financial commitment to retrieve, assess, and determine positive matches through manual visual comparisons becomes prohibitive as the number of photographs in a database increases (Dunbar et al., 2014; Jean et al., 2010). Recent advances in computer algorithms have facilitated partial automation of PID in sea turtle research, allowing for ease in identification of individual sea turtles over time within a single study area (Carter et al., 2014; Chassagneux et al., 2013; Dunbar and Ito, 2015; Dunbar et al., 2014; Jean et al., 2010), identification of dead turtles (Long, 2016), and the identification of scale-less leatherback turtles during nesting (McDonald and Dutton, 1996; Pauwels et al., 2008).
There are, however, consistent drawbacks in the use of computer-assisted PID across animal studies. Several authors have suggested that automated matching can be hindered by the use of low-quality photographs in the computer database. For example, in her study of cheetahs over a 25-year period, Kelly (2001) found that up to 33% of matches were unreported, and also discovered matching accuracy decreased when poor quality images were used. Long (2016) found that while using the NaturePatternMatch (NPM) pattern recognition software (Stoddard et al., 2014), poor-quality underwater photos of sea turtles often resulted in no matches. Therefore, these results necessitated that new photos be manually compared with all other photos to determine if the animals had a match in the database. Likewise, Carter et al. (2014) and Calmanovici et al. (2018) suggested that using images with excessive blur, lighting changes, angle differences, and low visibility can hinder the association of images within computer PID software. Another drawback of several computerized PID programs is the requirement to utilize photographs taken from consistent angles and distances relative to the subject. For example, Chaves et al. (2016) reported that only photos of lionfish (Pterois volitans) taken consistently at right angles to the flank of the animals were used for identification with I3S Pattern PID software (Den Hartog and Reijns, 2014), and that matching accuracy could be affected by photo angle variations. Similarly, Calmanovici et al. (2018) found that photos taken of turtles underwater at different angles, distances, and in different light conditions reduced the accuracy of matches using I3S Pattern. Likewise, Long and Azmi (2017) were able to more successfully identify individual turtles through NPM if photos were taken at horizontal and vertical angles <45° from where face scales were visible. In a more recent study, Steinmetz et al. (2018) also found photographs taken at high vertical or horizontal angles usually resulted in poorer potential matches among photographs of nesting hawksbill (Eretmochelys imbricata) turtles on Mahé Island in the Seychelles. The difficulty of consistently photographing marine animals with little variation from a perpendicular angle is increased due to highly variable marine conditions at both temporal and spatial scales during diving or snorkeling.
As an additional challenge, Carter et al. (2014) described adequate software and computing power as potential limitations because of the need to analyze many thousands of photograph pixels, especially if assessing color patterns is important in providing matches. The fact that many computer-assisted PID programs require laborious preprocessing manipulations of each photograph before new photographs can be queried or matched against the photo database (Calmanovici et al., 2018; Carter et al., 2014; Chaves et al., 2016; Dunbar et al., 2014; Jean et al., 2010; Pauwels et al., 2008) means that both manual input time and expense to identify individuals increase correspondingly with increased photo entry requirements.
If PID software is to be both effective at matching individual animals, and useful for general utility by both trained scientists and community scientists, it would be best to effectively reduce or eliminate the factors that are consistently reported as drawbacks in PID studies. Reducing or eliminating these drawbacks may help decrease manipulation time and requirements for extensive user training, as well as increase tolerance to low quality data that includes varied viewpoints and photographic conditions, ultimately improving PID software for analyzing low-quality photos from a variety of angles and lighting regimes. These features are especially important if animals are to be photographed within a marine environment in which it may be nearly impossible to repeatedly photograph the animal in similar light conditions and from the same angle.
The purpose of this study was to evaluate the accuracy of the computerized PID program, HotSpotter (HS) (Crall et al., 2013) that requires almost no photographic manipulations (Dunbar et al., 2017). HS works by localizing and matching Scale-Invariant Feature Transform (SIFT) (Lowe, 2004) keypoints using the Local Naïve Bayes Nearest Neighbor (McCann and Lowe, 2012) search algorithm. We aimed to determine if turtles within an open population of juvenile hawksbills in a marine protected area could consistently be identified over a period of years from photographs taken with different photographic devices, and in variable in-, and out-of-water conditions, including lighting, angle, and annual differences.
