Advanced cancer is typically manifested by the disordered growth of malignant tumours. There are several types of cancer, among which breast, colorectal and lymphomas three of the most common ones, and have resulted in higher mortality rates (Noone et al., 2018).
Breast cancer is a disease that initially begins with a tumour in the breast area but can later spread to other organs. Colorectal cancer consists of the growth of malignant polyps in the colon or rectum area. Lymphomas are a type of cancer that affects cells of the immunological system, wherein the most common occurrence is the non-Hodgkin lymphoma (NHL). NHLs are divided into categories, each one requiring specific treatments. According to the National Cancer Institute, the combined amount of new cases expected for these three types of cancer in 2020 is approximately 500,000 only in the United States (Howlader et al., 2017). The early diagnosis of these types of cancer is essential to provide adequate treatment and prevent death. Therefore, the histopathological analysis is inevitable for detecting the disease (Jothi & Rajam, 2017).
Histopathology, which consists of the analysis of histological tissues and the study of how diseases affect the cells, is often performed during or after a tumour removal surgery. The tumour characteristics may determine the following treatment decisions. Usually, a pathologist performs this analysis by observing histology slides through a digital microscope (Bentaieb & Hamarneh, 2018). However, this task is prone to errors as the evaluation is often subjective and dependent on the pathologist’s experience, which may lead to misdiagnosis (Mueller et al., 2016).
To provide support to pathologists, several computer vision techniques have been applied to images obtained from histology slides. These techniques consist of performing a series of evaluations on the input images and then provide a classification based on predefined classes, such as benign or malignant. This is a complex procedure, often referred as computer-aided diagnosis (CAD), which can be split into several stages, from image acquisition, going through pre-processing, segmentation, feature extraction, feature selection and classification (Jothi & Rajam, 2017). Therefore, a CAD system is an important tool that provides a second view to the pathologist, increasing the diagnosis accuracy and reducing the amount of time and physicians required to label large amounts of medical exams (Huang et al., 2018). In this paper, we focus on the feature extraction and classification stages of a CAD system for histological image analysis.
Different techniques can be applied to extract handcrafted features from these images. Among the most recently researched techniques, we can cite local binary pattern (LBP), grey level co-occurrence matrix (GLCM), speeded up robust features (SURF) or fractal geometry, which were applied for kidney tissue analysis (Simon et al., 2018), breast cancer classification (Yu et al., 2019), colon cell nuclei detection (Amalina et al., 2019) and lymphoma classification (Ribeiro et al., 2018), respectively. However, the main research focus for this area in recent years has been the application of deep learning approaches, more specifically, the use of CNNs.
The CNN models have shown to be efficient for the classification of objects, mainly in multiclass problems (Jiang and Su, 2018, Juefei-Xu et al., 2017), face recognition (Song et al., 2020) and satellite images (Akshay et al., 2020). However, these relevant results are not as often in the context of histological images (Araújo et al., 2017, Cireşan et al., 2013, Wang et al., 2014). One of the reasons is that CNNs require large sets for training, given that a major part of the public histological datasets available contains a limited number of samples (Bošnački et al., 2019, Yamashita et al., 2018). To handle this situation, more data is generated for training by applying rotation, mirroring or region cutting on the images. Nonetheless, this data augmentation raises, even more, the high computational cost of a CNN (Liu et al., 2019).
One of the possible solutions to reduce processing time consists in simplifying the network architecture by reducing the number of layers. However, the removal of deeper layers may hinder the image analysis from a global perspective (Araújo et al., 2017), which may compromise the network performance. Some alternative approaches, like hybrid networks, have been explored. These approaches associate non-deep learning techniques such as Gabor filters or LBP operators with the convolution operations of a CNN, which allows replacing some of the network’s layers (Jiang and Su, 2018, Juefei-Xu et al., 2017). Other approaches aim to achieve a lower processing time by reducing the images’ dimensionality. In Kausar et al. (2019), the authors applied Haar-wavelet decomposition on breast histology images and used the decomposed images as input to a CNN.
Recent researches have shown that a fusion of handcrafted features with deep learning models can enhance common approaches (Nanni et al., 2017). The application of fractal features, which have provided relevant results in different contexts of histological image classification such as breast tumours (Roberto et al., 2019), colorectal tumours (Ribeiro et al., 2019) and NHLs (Roberto et al., 2017), could also be associated to hybrid CNNs. In Xu et al. (2017), CNNs were applied to extract values from an invariant fractal dimension filter for detecting object curves in greyscale images. The authors in Mohammed et al. (2018) applied multifractal analysis to quantify and detect breast cancer, classifying the generated feature vectors using deep learning. However, an approach similar to the proposed by Kausar et al. (2019), wherein the CNN receives as input secondary images generated by a specific technique, has not yet been experimented in the fractal geometry context. Moreover, methods that directly associate fractal geometry with CNNs through an ensemble for the classification of histological images were not found in the literature.
In this paper, we propose a novel approach, which we name as Fractal Neural Network (FNN), to classify histological images through the association of fractal geometry and CNNs. In our proposal, fractal features are extracted from the histology images and then rearranged to generate an artificial RGB feature image. Both this artificial image and the correspondent original image are given as input to a CNN ensemble, wherein a classification based on the sum rule outputs the class prediction. This new method provides the following contributions to the literature:

1.Double-CNN classification ensemble wherein an image generated from handcrafted fractal features and the respective regular image are given as input to a CNN;2.An adaptive method that is able to classify different sets of histological images, including datasets with imbalanced classes, few samples and varying image dimensions;3.The combination of different fractal measures to provide a set of features capable of describing the image’s properties;4.A deep learning model that requires a small number of training epochs, even when classifying new types of histology images.
In the second section of this paper, we provide a technical background on the use of fractal geometry for feature extraction from colour images. The proposed methodology is presented in Section 3, and in Section 4, the results obtained by applying the method on the tested datasets are presented and discussed. Finally, we conclude the paper in Section 5, with an overview of the obtained results and suggestions for future researches.
